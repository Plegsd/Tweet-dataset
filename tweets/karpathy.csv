id,created_at,text
1259705301046972400,Mon May 11 04:42:02 +0000 2020,RT @dilipkay: Reference PyTorch code released by @YonglongT for our paper on Supervised Contrastive Learning (https://t.co/HwIU5JRdUZ)! Fin‚Ä¶
1258950217333764000,Sat May 09 02:41:36 +0000 2020,HN discussion on frameworks vs libraries https://t.co/kIgrZzwibD I've been trying to formulate in my mind the geome‚Ä¶ https://t.co/2Ji11nXQBP
1258833070276264000,Fri May 08 18:56:06 +0000 2020,looks great! üëè https://t.co/kjnzPGka6u
1257757537639653400,Tue May 05 19:42:19 +0000 2020,@j_brorsson no, the details matter in these papers - this one is offline processing of input video, slow, and finet‚Ä¶ https://t.co/EbkYjsH9Z9
1256827661394952200,Sun May 03 06:07:19 +0000 2020,"Real-time temporal and spatial video analysis of table tennis" https://t.co/vJiVmR6brC so the future includes this‚Ä¶ https://t.co/29Mis7j5BG
1256700922144583700,Sat May 02 21:43:42 +0000 2020,"My First Year as a Freelance AI Engineer" https://t.co/uU2MeLVskC fun read
1256363312524095500,Fri May 01 23:22:10 +0000 2020,RT @UnitreeRobotics: Quadruped robot A1 is running with you to the future. üòÉ Maximum outdoor running speedÔºö3.3m/s(11.88km/h). Maximum torqu‚Ä¶
1253813599773982700,Fri Apr 24 22:30:31 +0000 2020,RT @thirdrowtesla: Starting today Teslas in the US can automatically stop for traffic lights and stop signs.üö¶üõë  Just say where you want to‚Ä¶
1253525245731827700,Fri Apr 24 03:24:42 +0000 2020,I can only afford to half pay attention to the party going on over at the NLP camp, but I recently tried to piggyba‚Ä¶ https://t.co/d8LioQl0wF
1253524533106991000,Fri Apr 24 03:21:52 +0000 2020,"The Future of Natural Language Processing" https://t.co/PKl4cSSlZ8 from @huggingface, well done quick summary of r‚Ä¶ https://t.co/w8jbAe5tbE
1253461015984889900,Thu Apr 23 23:09:29 +0000 2020,Happy Earth Day! üåèüåçüåé (with an off by 1 error :p) https://t.co/o8TBwwd1Cr
1252096039672115200,Mon Apr 20 04:45:33 +0000 2020,RT @cyrildiagne: Just pushed the code of a chrome extension that turns every Instagram posts into 3d images using #3DPhotoInpainting. No GP‚Ä¶
1251596226979442700,Sat Apr 18 19:39:28 +0000 2020,micrograd https://t.co/ulT1YkQCsY is now on PyPI with pip install micrograd. The full (scalar-valued) autograd engi‚Ä¶ https://t.co/r6XLib9nyT
1250229648128004000,Wed Apr 15 01:09:10 +0000 2020,@biochemistries I restarted it. Basically the server, with the current code and how it's structured, throws a coin‚Ä¶ https://t.co/PCuOmxGkaE
1250229240437457000,Wed Apr 15 01:07:33 +0000 2020,@evgeniyzhe :D nice!
1250130857425133600,Tue Apr 14 18:36:37 +0000 2020,@biochemistries @quantixed @JACoates91 ü§¶‚Äç‚ôÇÔ∏èfixed
1250130618513363000,Tue Apr 14 18:35:40 +0000 2020,@lavishsaluja back up, sorry! will try to stabilize it going forward when i get a chance later this night.
1250130446643417000,Tue Apr 14 18:34:59 +0000 2020,@SingingData it's back, sorry. i have to set up a monitoring process for it
1249876052047884300,Tue Apr 14 01:44:07 +0000 2020,@tim_zaman my lucky rng seed! ;)
1249759048238379000,Mon Apr 13 17:59:11 +0000 2020,@dennybritz @mlpowered @ArtirKel I wrote "Yes you should understand backprop" on this topic https://t.co/laCKNvva0W‚Ä¶ https://t.co/FuXvI0iCaV
1249750451903287300,Mon Apr 13 17:25:01 +0000 2020,@hardmaru Haha yes, this is pytorch-like recurrentjs. I went through stages of enlightenment similar to the industr‚Ä¶ https://t.co/6HYV1kYaoI
1249747233597042700,Mon Apr 13 17:12:14 +0000 2020,@ArtirKel @dennybritz I've interviewed enough people by now to guarantee that it is not.
1249564562854051800,Mon Apr 13 05:06:22 +0000 2020,@anidhlfc (and even better it's in Python, for that extra molasses factor)
1249561661855297500,Mon Apr 13 04:54:50 +0000 2020,@anidhlfc Oh it's the slowest autograd engine imaginable, just like that puppy. In fact, I don't even know how to m‚Ä¶ https://t.co/3qADQxHofp
1249559365532582000,Mon Apr 13 04:45:43 +0000 2020,(so the graph is built only on individual scalars and only +,*,max(0,-) ops, and e.g. decomposes a neuron into all‚Ä¶ https://t.co/skH7p2zAas
1249557623231279000,Mon Apr 13 04:38:47 +0000 2020,Might as well make it an actual repo because it's not exactly done and may want to grow it over time just a bit   https://t.co/ulT1YkQCsY
1249551992315195400,Mon Apr 13 04:16:25 +0000 2020,ok I'm pretty sure I wrote the tiniest autograd engine with a neural net library on top of it, weighing about ~50 L‚Ä¶ https://t.co/1zsbu9hDR0
1248406091890692000,Fri Apr 10 00:23:01 +0000 2020,@m_ashcroft I'm proud to have picked the bin with least votes :)
1247992176073511000,Wed Apr 08 20:58:16 +0000 2020,Rebelling against the "correct" game theory strategy, when you cut one slice of the pizza bigger and let the other‚Ä¶ https://t.co/Osmm6xeORM
1247222505124679700,Mon Apr 06 17:59:52 +0000 2020,RT @Tesla: Engineering update on the Tesla ventilator
1246867953905053700,Sun Apr 05 18:31:00 +0000 2020,@nufuau Unfortunately Khan Academy is quite bad. My fastest progress came from 1) working through Molecular Biology‚Ä¶ https://t.co/n8Ielq7FK7
1246505280348684300,Sat Apr 04 18:29:52 +0000 2020,@ben_eater I love these videos a lot ‚ù§Ô∏è. Instead of going up from breadboards I'd rather see the other way deeper d‚Ä¶ https://t.co/Cg8z4rqCuP
1246314332306067500,Sat Apr 04 05:51:06 +0000 2020,My earlier https://t.co/U88bTCuxRy now pulls tweets chattering about every COVID-19 paper and shows them inline. Be‚Ä¶ https://t.co/69lYf2EmR6
1246186895760998400,Fri Apr 03 21:24:43 +0000 2020,@mrkspflr @IsomatheBenni @flcnhvy I started with Pascal :) This was around 1998 so I was ~12. I probably wouldn't r‚Ä¶ https://t.co/1fXzNnHqUH
1246178106123022300,Fri Apr 03 20:49:48 +0000 2020,@IsomatheBenni @flcnhvy ConvNetJS is an old project just for fun and representative of nothing. All of deep learnin‚Ä¶ https://t.co/xG6pKU3iJR
1244484801773498400,Mon Mar 30 04:41:12 +0000 2020,@philmohun Agree! Not exactly a fork, but I was able to copy paste out and re-assemble a lot of snippets from its g‚Ä¶ https://t.co/SXsoVu6nyw
1244483664018174000,Mon Mar 30 04:36:41 +0000 2020,@etzioni Great to see so much data out in the open in common schema! So much work is possible going beyond a search‚Ä¶ https://t.co/wwVIG9RFgN
1244465441528938500,Mon Mar 30 03:24:16 +0000 2020,I hacked together https://t.co/U88bTCuxRy today. It pulls all (884) COVID-19 papers from bioRxiv / medRxiv (‚Ä¶ https://t.co/lMxBT790MY
1243598646089863200,Fri Mar 27 17:59:56 +0000 2020,@ErikBjare @ActivityWatchIt This looks cool! Can you clarify if all data stays fully on local machine? This was the‚Ä¶ https://t.co/42skpeOBdb
1243236062358573000,Thu Mar 26 17:59:10 +0000 2020,@jcjohnss @CorentinJemine @oliviawiles1 https://t.co/BMwE7FbfjA
1243234905494114300,Thu Mar 26 17:54:34 +0000 2020,RT @PyTorch: PyTorch supports 8-bit model quantization using the familiar eager mode Python API to support efficient deployment on servers‚Ä¶
1243077338000220200,Thu Mar 26 07:28:27 +0000 2020,"We implement our renderer using a sequence of custom CUDA kernels ... takes 36ms for the forward pass and 5ms for‚Ä¶ https://t.co/d7L63ML7Kx
1242695409132351500,Wed Mar 25 06:10:48 +0000 2020,Egg + physics -&gt; chicken https://t.co/sLRZEz1ye6 incredible video
1241790351339409400,Sun Mar 22 18:14:25 +0000 2020,@hardmaru Related to this I'm curious about potential benefits of discrete representations in the net to robustness‚Ä¶ https://t.co/Q5cITn1krg
1241787713893871600,Sun Mar 22 18:03:56 +0000 2020,Neuroevolution of Self-Interpretable Agents https://t.co/IYtVK9LffC creative work from @hardmaru et al. Love the co‚Ä¶ https://t.co/SzJwoKeJxz
1241772759417385000,Sun Mar 22 17:04:31 +0000 2020,@KaweesiRobert8 come on Robert, this is sentence 2 of the abstract.
1241771945688879000,Sun Mar 22 17:01:17 +0000 2020,I was reading Cryo-EM structure of the 2019-nCoV spike paper https://t.co/3VAu4tSQPo, which led me to supplemental‚Ä¶ https://t.co/9WA5LfGh5l
1241042395304611800,Fri Mar 20 16:42:19 +0000 2020,NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis https://t.co/d3c882xViW impressive! https://t.co/jXjAEaSNzO
1240151230133014500,Wed Mar 18 05:41:08 +0000 2020,I, Pencil. ‚ÄúAs I sat contemplating the miraculous make-up of an ordinary lead pencil, the thought flashed in mind:‚Ä¶ https://t.co/QPTYrx7Jaf
1240133586889650200,Wed Mar 18 04:31:02 +0000 2020,RT @CUPAcademic: We are making higher education textbooks in HTML format free to access online during the coronavirus outbreak. Over 700 te‚Ä¶
1240059761741172700,Tue Mar 17 23:37:41 +0000 2020,A Conference Call in Real Life https://t.co/mNrBOODcEn :D so accurate! Including (surprisingly) the comments for extra suggested additions
1239349505394241500,Mon Mar 16 00:35:22 +0000 2020,That's a lot of linksüß™ https://t.co/SXu7XnoLJm https://t.co/Sfyz2nhUAt
1239336130899665000,Sun Mar 15 23:42:14 +0000 2020,Bill Gates' 2015 TED talk "The next outbreak? We‚Äôre not ready" feels prescient https://t.co/QGc3eOFx4k ; a good "ca‚Ä¶ https://t.co/gU19JmrYSC
1238874456128282600,Sat Mar 14 17:07:42 +0000 2020,ü§¶‚Äç‚ôÇÔ∏è https://t.co/dBkKDpsSA9
1237580860003479600,Wed Mar 11 03:27:24 +0000 2020,RT @ak92501: StyleGAN2 Distillation for Feed-forward Image Manipulation pdf: https://t.co/1Ah4u3PPeu abs: https://t.co/ZFR5hYH2Ts github: h‚Ä¶
1236739485192163300,Sun Mar 08 19:44:05 +0000 2020,(Twitter doesn't allow a poll and an image in one tweet, so here is the poll as a reply)
1236739138587508700,Sun Mar 08 19:42:42 +0000 2020,@russelljkaplan Agree, turns out Twitter doesn't allow a poll with an image in one tweet.
1236738926691270700,Sun Mar 08 19:41:52 +0000 2020,@ampanmdagaba It turns our that Twitter doesn't allow polls with images. They are both treated as an "attachment" a‚Ä¶ https://t.co/YNoiZEK2bw
1236737502200791000,Sun Mar 08 19:36:12 +0000 2020,Which style of drawing residual networks is semantically superior? 1: residual connection on the side of the layer‚Ä¶ https://t.co/RyiqH7iEWd
1236700658197123000,Sun Mar 08 17:09:48 +0000 2020,@pragmaticml @iandanforth That was me I think :)
1234697749515268000,Tue Mar 03 04:30:57 +0000 2020,A critique of pure learning and what ANNs can learn from animal brains https://t.co/pfH1xLIkZE "a large component o‚Ä¶ https://t.co/Er2U6TJ3P8
1234682603573137400,Tue Mar 03 03:30:46 +0000 2020,This course is quite good: Virology Lectures Spring 2020 https://t.co/ifiFgMDxHQ https://t.co/YyQf25MQ82
1233932700009955300,Sun Mar 01 01:50:55 +0000 2020,‚ÄúThe Analytical Engine weaves algebraical patterns just as the Jacquard loom weaves flowers and leaves.‚Äù A beautifu‚Ä¶ https://t.co/BmnPrPBNja
1233867946700591000,Sat Feb 29 21:33:37 +0000 2020,@TeslaMilton Same here it‚Äôs so strangely endearing!  :)
1233827441186988000,Sat Feb 29 18:52:40 +0000 2020,Rewatched Avatar last night for the 4th time. In many ways it‚Äôs a bit basic but I love that movie so much and it makes me so angry.
1233822063862808600,Sat Feb 29 18:31:17 +0000 2020,RT @jeremyphoward: We've made a draft of our deep learning book available as @ProjectJupyter notebooks.  Important: This is for personal us‚Ä¶
1233104299766345700,Thu Feb 27 18:59:09 +0000 2020,Can optimizing (imitation) likelihood by backprop converge on intelligence given infinity data? Is the answer stron‚Ä¶ https://t.co/H0VQRDxDe6
1231735715974697000,Mon Feb 24 00:20:53 +0000 2020,Maillardet's "The Draughtsman-Writer", an awesome Automaton from ~1800 https://t.co/pSBNrNaUbw programmed by etchin‚Ä¶ https://t.co/PIdR2xUP0Y
1231720028162019300,Sun Feb 23 23:18:33 +0000 2020,@realAkhmed More like AI identifies molecules that are likely to be E.coli growth-inhibiting based on similarities‚Ä¶ https://t.co/MtcQu6Hez8
1231707127300812800,Sun Feb 23 22:27:17 +0000 2020,New antibiotic ("halicin") discovered by training a neural net f: [molecule -&gt; P(growth inhibition of E. coli)], th‚Ä¶ https://t.co/epCPWzlUaz
1231447539863322600,Sun Feb 23 05:15:47 +0000 2020,Stumbled by great lecture series on MIT's Nuclear Engineering and Ionizing Radiation (üëåinstructor)‚Ä¶ https://t.co/Q5DcujGOiv
1231385879467290600,Sun Feb 23 01:10:46 +0000 2020,@gambsgambs @Cathx9 obvious difference being that one can be used in practice to give real results while the other cannot.
1231378194948706300,Sun Feb 23 00:40:14 +0000 2020,This is a troll, but I think it would be funny. https://t.co/JfS2w5tudu
1231276886866575400,Sat Feb 22 17:57:40 +0000 2020,I'm unnerved by common claims of "with our super duper library X, doing Y is just 5 lines of code: ...". Ok you hid‚Ä¶ https://t.co/FTaCQzEZ93
1230973030785962000,Fri Feb 21 21:50:15 +0000 2020,RT @TaylorLorenz: Tired: Fully electric 0 emission cars Wired: https://t.co/Y7OdpkYrIY
1228117295970439200,Fri Feb 14 00:42:35 +0000 2020,RT @YSongStanford: Excited to share our paper on accelerating feedforward computations in ML ‚Äî such as evaluating a DenseNet or sampling fr‚Ä¶
1227672616036491300,Wed Feb 12 19:15:35 +0000 2020,@iandanforth @jeffclune feels like it would be up @hardmaru 's alley ;)
1227460419230539800,Wed Feb 12 05:12:23 +0000 2020,Fun related meta project idea: use this style of CA not to grow an arbitrary visual pattern but grow a neural net (‚Ä¶ https://t.co/Ml92oQ4q2n
1227429295309475800,Wed Feb 12 03:08:43 +0000 2020,RT @distillpub: Growing Neural Cellular Automata -- A new Distill article by @zzznah, @RandazzoEttore, @eyvindn and @drmichaellevin https:/‚Ä¶
1225978526601363500,Sat Feb 08 03:03:52 +0000 2020,@gdudg Way too smart! Turns out üòÇ
1225977885049012200,Sat Feb 08 03:01:20 +0000 2020,I‚Äôm sure my email and unsalted password hash for the account won‚Äôt be part of this breach. Or that my email hasn‚Äôt‚Ä¶ https://t.co/Wx5cwGv3nw
1225977212903444500,Sat Feb 08 02:58:39 +0000 2020,My smart coffee mug warmer‚Äôs companion app demanded I make an account, and now wants to send me push notifications‚Ä¶ https://t.co/cn0r49sseH
1224453222535876600,Mon Feb 03 22:02:52 +0000 2020,RT @elonmusk: üî•üî•üî•
1224408275627602000,Mon Feb 03 19:04:15 +0000 2020,@RalevVladimir The raw image data is much higher resolution than this mp4. But on top of that the neural net can in‚Ä¶ https://t.co/a7K9XKjgiF
1224406763161542700,Mon Feb 03 18:58:15 +0000 2020,@teslafantweets This has been the most interesting infra to design. It's all about catching the neural net in its u‚Ä¶ https://t.co/cjHGcObTnX
1224400424712556500,Mon Feb 03 18:33:04 +0000 2020,Help revolutionize the world with full self-driving by joining us at Tesla Autopilot: https://t.co/ekekjKDOZF It is‚Ä¶ https://t.co/5AOwL4RDjc
1224087716008059000,Sun Feb 02 21:50:28 +0000 2020,RT @elonmusk: Tesla will hold a super fun AI party/hackathon at my house with the Tesla AI/autopilot team in about four weeks. Invitations‚Ä¶
1222630655516762000,Wed Jan 29 21:20:38 +0000 2020,Big congrats on the launch @CovariantAI ! üéâ It's awesome to see more examples of cutting edge deep learning lifted‚Ä¶ https://t.co/Ktju8Ws0eI
1218984753392570400,Sun Jan 19 19:53:07 +0000 2020,@KravaPlava Gah, sorry about that. I finally introduced https support for it yesterday but then didn't properly set‚Ä¶ https://t.co/04fwCUIJXG
1218599782974779400,Sat Jan 18 18:23:23 +0000 2020,Open Syllabus Project https://t.co/3Qmm9Tbp9D Open Syllabus is a non-profit organization that maps the curriculum o‚Ä¶ https://t.co/ZFEiJH6ftX
1217511704864510000,Wed Jan 15 18:19:45 +0000 2020,@selfprime :(
1217376450736615400,Wed Jan 15 09:22:18 +0000 2020,Why the Future of Farming is in Cities - The Big Money in Vertical Farming https://t.co/o5tI3f9lmw
1215455601796366300,Fri Jan 10 02:09:32 +0000 2020,Stumbled by a thread on Reddit: "Is it theoretically possible to do object recognition with classification algorith‚Ä¶ https://t.co/gXwYMQv4zV
1214063945327100000,Mon Jan 06 05:59:35 +0000 2020,RT @TTEchironex: A very important read. It's long, but I'd HIGHLY suggest reading every word. Twice. https://t.co/QrLLolCcOP
1213981359275835400,Mon Jan 06 00:31:25 +0000 2020,@gdb @nickwalton00 also related &amp; not to be missed: Reddit's r/AIDungeon https://t.co/PpcHYEQ8X3
1213980509128122400,Mon Jan 06 00:28:02 +0000 2020,RT @gdb: I agree with this article that AI Dungeon 2 (the GPT-2 powered text-based game of infinite possibilities) is "one of the coolest v‚Ä¶
1213545710383030300,Sat Jan 04 19:40:18 +0000 2020,[Papers with Code] Image Classification on ImageNet https://t.co/jnuVsuZWzw https://t.co/SBsPmkrsVL
1213363969190068200,Sat Jan 04 07:38:08 +0000 2020,Incredible video series (and YouTube channel), thank you for the pointer! https://t.co/a5IUZLMVFw
1213347809962803200,Sat Jan 04 06:33:55 +0000 2020,Metabolic Engineering and Synthetic Biology of Yeast - Jens Nielsenü§Øhttps://t.co/cQ1txSPGNT (the whole channel is q‚Ä¶ https://t.co/uYNDq4O9EN
1212782900866764800,Thu Jan 02 17:09:10 +0000 2020,Fun! Exceed my expectations in result quality. https://t.co/dBfw1OG3m9 https://t.co/mp2hH62Pu9
1212573947583066000,Thu Jan 02 03:18:52 +0000 2020,@perlover_here Haha, I have a rather vague bullet point for a single global digital currency but yeah I did not see‚Ä¶ https://t.co/dfVS9Ha93i
1212444808259616800,Wed Jan 01 18:45:43 +0000 2020,@Turcikx Quite a few as it turns out, I hand wrote them down meticulously in cursive Slovakian on a page dated 7.10‚Ä¶ https://t.co/MJYf6pg3y9
1212287432722272300,Wed Jan 01 08:20:21 +0000 2020,I made some bets in 2001 on what 2020 (a crazy future at the time, two whole decades away) would be like. And now i‚Ä¶ https://t.co/cowaIJs4LX
1210857892309434400,Sat Dec 28 09:39:52 +0000 2019,Still slowly making my way through this year's NeurIPS talks. Esp like to stumble by good talks from slightly diffe‚Ä¶ https://t.co/KArgtWLduF
1206067778572214300,Sun Dec 15 04:25:40 +0000 2019,Biology is able to pass a lot information from one individual to another as lots of animals are born ‚Äúready to go‚Äù‚Ä¶ https://t.co/DY5Fy9q8ng
1206064174129930200,Sun Dec 15 04:11:21 +0000 2019,A 4 year old child actually has a few hundred million years of experience, not 4. Their rapid learning/generalizati‚Ä¶ https://t.co/pKJDj7anjH
1205955966006710300,Sat Dec 14 21:01:22 +0000 2019,@bradsferguson Labeling is a job for highly trained professionals, not volunteers. (I'm very protective of my datasets.)
1205950241750573000,Sat Dec 14 20:38:37 +0000 2019,@bradsferguson it is a common mistake to underestimate and trivialize data labeling.
1205584067447709700,Fri Dec 13 20:23:35 +0000 2019,@MatthewRideout @rhensing On weekdays. For trucks only. Unless full moon. If P=NP.
1205559794263871500,Fri Dec 13 18:47:07 +0000 2019,@rhensing I've seen much worse :)
1205547468127125500,Fri Dec 13 17:58:09 +0000 2019,RT @OpenAI: We're releasing "Dota 2 with Large Scale Deep Reinforcement Learning", a scientific paper analyzing our findings from our 3-yea‚Ä¶
1204944485404143600,Thu Dec 12 02:02:06 +0000 2019,@vadimkantorov fixed with commit earlier today, ty for tip!
1204192394142310400,Tue Dec 10 00:13:34 +0000 2019,@joespeez &gt;&gt;&gt; loss.backward() üìé"""Hey there! It looks like you're accumulating gradients. 99% of the time this mean‚Ä¶ https://t.co/olg5iP8MBb
1204180413666578400,Mon Dec 09 23:25:57 +0000 2019,@ericjang11 @gpapamak hey Eric, yep seeing your nf-jax is what finally made me pop the item off my todo list. I don‚Ä¶ https://t.co/7SaDoVwOwY
1204147816173424600,Mon Dec 09 21:16:26 +0000 2019,RT @DavidDuvenaud: Classifiers are secretly energy-based models!  Every softmax giving p(c|x) has an unused degree of freedom, which we use‚Ä¶
1204119210990788600,Mon Dec 09 19:22:46 +0000 2019,This week's excitement and adventure in Machine Learning: #NeurIPS2019! üéâ Talks &amp; slides are live and being posted‚Ä¶ https://t.co/F9dV2hyEij
1204102782728302600,Mon Dec 09 18:17:29 +0000 2019,I implemented some normalizing flows yesterday (NICE, RealNVP, MAF, IAF), tried to make core of it somewhat clean i‚Ä¶ https://t.co/3oGXxkcHJK
1203818489875558400,Sun Dec 08 23:27:48 +0000 2019,@FlyingOctopus0 I know! It just makes it worse. I even wrote a whole blog post pointing this out again. It's a "mem‚Ä¶ https://t.co/Rs3vmH5zpI
1203802860825108500,Sun Dec 08 22:25:42 +0000 2019,~2 hours debugging an issue I thought was due to something I misunderstood in the deep mathematics involved but I j‚Ä¶ https://t.co/TNE8BAmO3z
1203104717099786200,Sat Dec 07 00:11:31 +0000 2019,This is very well done and readable, thank you so much for putting it together! (was starting to be hard to keep tr‚Ä¶ https://t.co/W1YOOYg1cB
1203082779447062500,Fri Dec 06 22:44:21 +0000 2019,Nice. Over last ~3 weeks I accumulated some BATs from ads/tips, and, in turn, in a few days ~$5 of it is automatica‚Ä¶ https://t.co/D1FdAqgJ3d
1203051730776158200,Fri Dec 06 20:40:58 +0000 2019,RT @ari_seff: Normalizing Flows let you build up complex, yet still easy to work with probability distributions. Want to learn more? Check‚Ä¶
1203050662830821400,Fri Dec 06 20:36:44 +0000 2019,RT @Yubico: Interested in protecting your accounts with a security key but not sure where to start?  @Stammy has you covered in his latest‚Ä¶
1202672396710248400,Thu Dec 05 19:33:38 +0000 2019,RT @OpenAI: A surprising deep learning mystery:  Contrary to conventional wisdom, performance of unregularized CNNs, ResNets, and transform‚Ä¶
1202640108400205800,Thu Dec 05 17:25:20 +0000 2019,@Chakri30024542 thank you for reporting, for some reason mongo just goes down sometimes and i have to restart it. n‚Ä¶ https://t.co/F1epCN8Ptf
1197599584651841500,Thu Nov 21 19:36:05 +0000 2019,RT @valvesoftware: We're thrilled to announce Half-Life: Alyx, a new full-length entry in the Half-Life series, built by Valve for VR.  Ret‚Ä¶
1197369564322885600,Thu Nov 21 04:22:04 +0000 2019,The intensity of joy can only be matched if Valve announces Half Life 3. I want to believe.
1197369089867432000,Thu Nov 21 04:20:11 +0000 2019,Age of Empires IV first gameplay footage and a few details released a few days ago!! https://t.co/rAAVQl1dZa a lot‚Ä¶ https://t.co/vyzRm2Xmks
1197257408122216400,Wed Nov 20 20:56:24 +0000 2019,Nice slides and pointers! Sim is not real, but a "widened enough" sim (using enough augmentation) contains real as‚Ä¶ https://t.co/7fimFwv1wj
1197238003673862100,Wed Nov 20 19:39:18 +0000 2019,@DuckDuckGo Thanks! Not so much questions as suggestions. I would pursue and pay close attention to BERT variants‚Ä¶ https://t.co/Apo7iKp6rN
1196886789408952300,Tue Nov 19 20:23:42 +0000 2019,@maxpumperla @brave @DuckDuckGo Now that I pay more attention to it it was interesting to learn that a large fracti‚Ä¶ https://t.co/NPPL833hss
1196885541096022000,Tue Nov 19 20:18:44 +0000 2019,@aliyousuuf I don't want to bypass NYT paywall; Their articles offer value to me and I want to support them. For no‚Ä¶ https://t.co/8R3bX1RpJa
1196556673491460000,Mon Nov 18 22:31:56 +0000 2019,@BraveSampson @willfrancis @brave @DuckDuckGo Haha, didn't realize that. I feel some strange need for reciprocity a‚Ä¶ https://t.co/Y7o2S1eAtc
1196555017538302000,Mon Nov 18 22:25:21 +0000 2019,@BraveSampson @willfrancis @brave @DuckDuckGo üéâ!! :D Great, eager to pass it on! I've worked hard to click all the‚Ä¶ https://t.co/ZkfrtbHq6l
1196538467850674200,Mon Nov 18 21:19:36 +0000 2019,@BraveSampson @willfrancis @brave @DuckDuckGo Great! Yes, the convenience made it very easy to use Chrome thus far,‚Ä¶ https://t.co/Fq4DGRIXG4
1196529053924122600,Mon Nov 18 20:42:11 +0000 2019,@willfrancis @brave @DuckDuckGo Yes, for me: - Brave's sync is still feature incomplete (only bookmarks) and bit bu‚Ä¶ https://t.co/PyTqNSzS2N
1196527517525409800,Mon Nov 18 20:36:05 +0000 2019,@HarriKoponen @brave @DuckDuckGo @Signal Yes, unmentioned but I do use @signalapp. I also switched to @AppleCard be‚Ä¶ https://t.co/nRV9YuXDFL
1196524791433330700,Mon Nov 18 20:25:15 +0000 2019,I'm experimenting with @brave browser, @DuckDuckGo as default search engine, and VPN in an attempt to improve my in‚Ä¶ https://t.co/s9o8Ld0wam
1196508900809273300,Mon Nov 18 19:22:06 +0000 2019,RT @dsmilkov: Amazing work by my colleagues and external collaborators! BodyPix 2.0 with multi-person segmentation and increased accuracy!‚Ä¶
1196491370921201700,Mon Nov 18 18:12:27 +0000 2019,Neat! :) I expect a lot more can be done in this space. Why would you browse the web in an "unassisted legacy mode"‚Ä¶ https://t.co/wPARf7N29c
1196490782863024000,Mon Nov 18 18:10:07 +0000 2019,@Karolis_Ram Yep! The Audiobook is an excellent format in this case - Dan has a very intense and engaging delivery :)
1196296024555262000,Mon Nov 18 05:16:13 +0000 2019,@KerenGu too many things ;( https://t.co/RBYSXo3adx
1196237668633329700,Mon Nov 18 01:24:19 +0000 2019,@Davidromogr Sadly there aren't too many. I'm not a huge fan of much recent non-fiction in the space. For fiction a‚Ä¶ https://t.co/WO6Xajj4jJ
1196217514688041000,Mon Nov 18 00:04:14 +0000 2019,Quite enjoying Dan Carlin's new book "The End Is Always Near: Apocalyptic Moments, from the Bronze Age Collapse to‚Ä¶ https://t.co/UKs06lhker
1195790661594710000,Sat Nov 16 19:48:05 +0000 2019,@mgdurand Yep! :) Would be about a 20min jog
1195789993706311700,Sat Nov 16 19:45:25 +0000 2019,So your body explodes ~3 dynamite sticks to get you through your night, but uses doughnuts and equivalents instead of nitroglycerin.
1195787955505442800,Sat Nov 16 19:37:19 +0000 2019,A typical doughnut üç© of ~220kcal (using the standard Atwater estimate for metabolizable energy) appears to be ~1MJ,‚Ä¶ https://t.co/1MbxFCeibC
1194698539302973400,Wed Nov 13 19:28:22 +0000 2019,RT @animesh_garg: Scaling crowdsourcing robotics with Human Reasoning &amp; Dexterity for Large-Scale Dataset Creation Blog: https://t.co/154TH‚Ä¶
1193771034962325500,Mon Nov 11 06:02:48 +0000 2019,@lilianweng good list! very hard to be exhaustive for such a big area but  e.g. i'm also a big fan of geometric sel‚Ä¶ https://t.co/HULgKgGDG0
1193700794597462000,Mon Nov 11 01:23:41 +0000 2019,üíªüß†+üåçüå≥ recent reads: Green AI vs Red AI https://t.co/KP5H03UM9s and "Tackling Climate Change with Machine Learning"‚Ä¶ https://t.co/1da5b8DgbO
1193641036255334400,Sun Nov 10 21:26:14 +0000 2019,Nice work &amp; repo on knowledge distillation https://t.co/tJ3ycra8fR dark knowledge remains one of few amusingly brai‚Ä¶ https://t.co/8q8NhWlfAR
1193213590364254200,Sat Nov 09 17:07:43 +0000 2019,Ok someone must find a way to use this in some Reinforcement Learning slides https://t.co/w25T5kOdrG üòÇ
1192256199682490400,Thu Nov 07 01:43:23 +0000 2019,@CorentinJemine whoa
1192214472527466500,Wed Nov 06 22:57:35 +0000 2019,`numpy.split(ary, indices_or_sections, axis=0)` vs. `torch.split(tensor, split_size_or_sections, dim=0)`; indices o‚Ä¶ https://t.co/i0tZElGQos
1192188196328599600,Wed Nov 06 21:13:10 +0000 2019,@shoniko model compression quantization distillation something something
1192170601059741700,Wed Nov 06 20:03:15 +0000 2019,@AndrewM_Webb Hahah, I think I have thrown GPT-2 into an out of distribution region on that one, which I'll take as a compliment.
1192169928079503400,Wed Nov 06 20:00:34 +0000 2019,Chrome extension request: Highlighting a paragraph of text reports the GPT-2 log prob of that text. Maybe it's not‚Ä¶ https://t.co/6HVAmdSKmO
1192168096829558800,Wed Nov 06 19:53:18 +0000 2019,That something sounds/reads like it was generated by GPT-2 is an interesting new kind of an insult.
1189759071668203500,Thu Oct 31 04:20:41 +0000 2019,RT @paulg: The web is 25 years old, and signing up for and paying for things is still broken. Why do you have to create an account and make‚Ä¶
1189004363349364700,Tue Oct 29 02:21:45 +0000 2019,RT @jcjohnss: This week we open-sourced pycls, a flexible research framework for image classification with @pytorch encapsulating current b‚Ä¶
1185603859915296800,Sat Oct 19 17:09:22 +0000 2019,RT @facebookai: We're developing alternative ways to train our AI systems so that we can do more with less labeled training data overall. L‚Ä¶
1184299617740972000,Wed Oct 16 02:46:46 +0000 2019,@fchollet @DavidSHolz okay but what is the % chance that pasta fixed that? :D
1184299172456829000,Wed Oct 16 02:45:00 +0000 2019,@DavidSHolz it's a fun point! i was surprised a long while ago (can't find the link anymore) by a derivation that c‚Ä¶ https://t.co/ROD6gC8jTd
1184298052984553500,Wed Oct 16 02:40:33 +0000 2019,Fun python gotcha: hash() returns different results for the same inputs with each new interpreter session, can lead‚Ä¶ https://t.co/77q5QVwEzf
1184237365285404700,Tue Oct 15 22:39:24 +0000 2019,@nbonneel Eg people think bananas / honey crisp apples can't be bad for you because they come from nature. Which is‚Ä¶ https://t.co/h4VsfSHJcY
1184197268083110000,Tue Oct 15 20:00:04 +0000 2019,I'm quite sympathetic to the paleo argument and why I've tended to low/slow carb diets recently. White carbs/soda/c‚Ä¶ https://t.co/lzL56Pr7OM
1182692386020851700,Fri Oct 11 16:20:12 +0000 2019,Some highlights from PyTorch DevCon: PyTorch 1.3 üéâ https://t.co/ZEeGgT1sUQ named tensors, type promotion, quantizat‚Ä¶ https://t.co/uGBxDfpQuJ
1182548596245196800,Fri Oct 11 06:48:50 +0000 2019,RT @cHHillee: Finally managed to release this data!  Some highlights: From CVPR 2018-2019, PyTorch has grown from 82 -&gt; 280 papers, while T‚Ä¶
1180978631054508000,Sun Oct 06 22:50:21 +0000 2019,I clicked to read an article. Web 2019 https://t.co/ZdSzKwFfyG
1178820734212141000,Mon Sep 30 23:55:39 +0000 2019,RT @cleantechnica: Tesla Smart Summon Tests Show Oodles Of Laughter (10¬†Videos) https://t.co/DqlnkMaDUz https://t.co/yHpsF2TKnh
1177680931122892800,Fri Sep 27 20:26:28 +0000 2019,RT @elonmusk: Summon is improving rapidly  https://t.co/khgXDRnD2Z
1176665396394356700,Wed Sep 25 01:11:06 +0000 2019,RT @MIT_CSAIL: Ready for the Olympics, via @BostonDynamics. https://t.co/71TAR89VXp https://t.co/6QmIod4z1T
1175167039503130600,Fri Sep 20 21:57:10 +0000 2019,RT @mlpowered: One of the biggest tool gaps in ML right now is tin building utilities to more easily inspect and understand data.  I gave a‚Ä¶
1175166430695678000,Fri Sep 20 21:54:45 +0000 2019,@mlpowered I love this slide a lot. üëè https://t.co/I6BNttFR8O
1175165953794965500,Fri Sep 20 21:52:51 +0000 2019,@strangecosmos Haha yes, because I just made it up. It's the subtle art of composing batches of data during trainin‚Ä¶ https://t.co/hkNytFdMVO
1175139297281708000,Fri Sep 20 20:06:56 +0000 2019,@21st_title There's no paper. That's exactly the problem.
1175138633113694200,Fri Sep 20 20:04:17 +0000 2019,(likely an artifact of most of academia focused on finding models conditioned on standard datasets)
1175138379198914600,Fri Sep 20 20:03:17 +0000 2019,We see more significant improvements from training data distribution search (data splits + oversampling factor rati‚Ä¶ https://t.co/N23x824CUF
1174049741249757200,Tue Sep 17 19:57:25 +0000 2019,RT @OpenAI: We've observed AIs discovering complex tool use while competing in a simple game of hide-and-seek. They develop a series of six‚Ä¶
1173844140741644300,Tue Sep 17 06:20:26 +0000 2019,@wenbinf I don't think I will pitch in too much when it comes to the arxiv-sanity ::cough:: "tech stack" ::cough::‚Ä¶ https://t.co/iuYvt1awYR
1173842533375283200,Tue Sep 17 06:14:03 +0000 2019,The boring technology behind Listen Notes by @wenbinf https://t.co/1xe7KG9nlU &amp; the HN discussion‚Ä¶ https://t.co/Np52vGtOrN
1173088095463510000,Sun Sep 15 04:16:11 +0000 2019,RT @ben_eater: New video! I'm starting a series on the 6502: The classic microprocessor that started the personal computer revolution. Part‚Ä¶
1173077130848157700,Sun Sep 15 03:32:37 +0000 2019,ü§¶‚Äç‚ôÇÔ∏è https://t.co/Sr0QCZZWuU
1170548875683254300,Sun Sep 08 04:06:14 +0000 2019,"Why did we wait so long for the bicycle?" https://t.co/eZpNEvRrxw (on top of this article also an excellent site more broadly)
1170089504004198400,Fri Sep 06 21:40:51 +0000 2019,RT @pfau: Thrilled to be able to share what I've been working on for the last year - solving the fundamental equations of quantum mechanics‚Ä¶
1168974577508257800,Tue Sep 03 19:50:32 +0000 2019,@Snarik Nick Lane is really good, loved his latest too
1168794298315206700,Tue Sep 03 07:54:10 +0000 2019,Wow, this YouTuber needs his own Netflix TV show. üëè "Fire Ants vs. Simulated River Jungle", and more generally the‚Ä¶ https://t.co/GpAIaQLk8v
1168759114849079300,Tue Sep 03 05:34:22 +0000 2019,@TheGabeLyfe Blizzard didn't mention this but The Zerg and Protoss in Starcraft also breath oxygen and breath out carbon dioxide.
1168747285603160000,Tue Sep 03 04:47:21 +0000 2019,Why O2 Is Required by Complex Life on Habitable Planets and the Concept of Planetary ‚ÄúOxygenation Time‚Äù‚Ä¶ https://t.co/zMeXuxez7P
1168255902350135300,Sun Sep 01 20:14:46 +0000 2019,@ebenbayer @Tesla üôå haha, just stumbled by your podcast with John, loved it a lot, and then found this in your stream :)
1167995441327136800,Sun Sep 01 02:59:48 +0000 2019,"Modern microprocessor built from complementary carbon nanotube transistors" https://t.co/9SAHAzlIc0 RV16X-NANO, fa‚Ä¶ https://t.co/dAjhxTirUC
1167502577900015600,Fri Aug 30 18:21:20 +0000 2019,@Berci Currently using AutoSleep + AppleWatch combo. Oura looks nice for some future.
1167351173109567500,Fri Aug 30 08:19:42 +0000 2019,@tim_zaman üòÇ Hahah! This sounds great but UVBs are just barely non-ionizing radiation, maybe I'd rather pop some pills or eat more salmon :D
1167348352498843600,Fri Aug 30 08:08:30 +0000 2019,@vedrankaracic yep, still 16:8 IF and low carb (or slow carb if any). At the very least knowing what I know now I t‚Ä¶ https://t.co/bsnAcozGv9
1167339816398123000,Fri Aug 30 07:34:35 +0000 2019,@typesfaster I know, I know, ty :). I just thought it was hilarious because it plays into a narrative
1167338225553166300,Fri Aug 30 07:28:15 +0000 2019,(I should clarify this was a random check-in just for curiosity ü§ì. I also regularly measure glucose/BHB, DEXAs, sle‚Ä¶ https://t.co/CQ0agDn53w
1167335740402851800,Fri Aug 30 07:18:23 +0000 2019,@madmaxbr5 now now, let's not get too crazy
1167289579742744600,Fri Aug 30 04:14:57 +0000 2019,A thorough blood test just to ‚Äúdiscover‚Äù that I‚Äôm fine except my cortisol is too high and my Vitamin D too low. Not‚Ä¶ https://t.co/s6Zr0cvgyQ
1164982796546261000,Fri Aug 23 19:28:37 +0000 2019,Recent developments on this topic are highly concerning and depressing. If you zoom out to decades our planet looks‚Ä¶ https://t.co/LojBSJ3nK4
1164982796546261000,Fri Aug 23 19:28:37 +0000 2019,Recent developments on this topic are highly concerning and depressing. If you zoom out to decades our planet looks‚Ä¶ https://t.co/LojBSJ3nK4
1164312999667986400,Wed Aug 21 23:07:05 +0000 2019,Also interesting from Hot Chips: Gaudi from Habana: https://t.co/YGYncwxnbc white paper: https://t.co/8cgHxk3dtp an‚Ä¶ https://t.co/lb9hYbcstM
1163885862184087600,Tue Aug 20 18:49:48 +0000 2019,Human cortex is ~120,000mm^2 running at 20W. Maybe growing cortex tissue and coercing it for compute is a good pathü§î:)
1163885460134879200,Tue Aug 20 18:48:12 +0000 2019,Wafer-scale deep learning, Cerebras presentation at Hot Chips 31 https://t.co/4DHjXtLnBJ &amp; https://t.co/9DQpaQTQoA‚Ä¶ https://t.co/myTISgAIaA
1163713702836625400,Tue Aug 20 07:25:42 +0000 2019,&gt;&gt;&gt; print(4 // 0.4) üßê
1161734608624312300,Wed Aug 14 20:21:29 +0000 2019,@Kaelberviridae üò¨ sorry to hear that! the technology is absolutely there to do this much faster today but potential‚Ä¶ https://t.co/DVdH4mRYw8
1161525595429376000,Wed Aug 14 06:30:56 +0000 2019,@a_nemecek not obvious because it's thought that LUCA (of this fame https://t.co/wozAI8bRTk), which already used DN‚Ä¶ https://t.co/8dZGIc3cQI
1161522644723929000,Wed Aug 14 06:19:13 +0000 2019,@a_nemecek mostly out of interest but deep learning is mentioned in the lecture because in this case it helps them‚Ä¶ https://t.co/KLMtzXTLT2
1161518941698699300,Wed Aug 14 06:04:30 +0000 2019,Cryogenic electron microscopy (cryo-EM) intro lecture https://t.co/tcGH7mjrnj &amp; more detailed class‚Ä¶ https://t.co/8xdsIkpudP
1161381237790875600,Tue Aug 13 20:57:19 +0000 2019,RT @ctnzr: Here‚Äôs how we trained an 8.3B parameter GPT-2. We alternate row- and column- partitioning in the Transformer in order to remove‚Ä¶
1160632901244899300,Sun Aug 11 19:23:41 +0000 2019,Paying with an Apple Watch sparks joy ‚ö°Ô∏è
1160006331765416000,Sat Aug 10 01:53:56 +0000 2019,RT @jcjohnss: I'm super excited about the new LVIS dataset from my colleagues @facebookai -- I hope it will do for low-shot recognition wha‚Ä¶
1159699558172991500,Fri Aug 09 05:34:55 +0000 2019,@arram Exactly, you‚Äôll go the extra mile knowing others may scrutinize it. Part of the reason I enjoyed blogs early‚Ä¶ https://t.co/as2a9Kuclr
1159664453069049900,Fri Aug 09 03:15:25 +0000 2019,@arram I'd try resolving to writing something (anything) every day on some pet project, pushing it to Github, tryin‚Ä¶ https://t.co/RvDPD4n5P4
1159542229301489700,Thu Aug 08 19:09:45 +0000 2019,Climate Change Threatens the World‚Äôs Food Supply, United Nations Warns - The New York Times https://t.co/LVdvab4YNb
1158897024994988000,Wed Aug 07 00:25:56 +0000 2019,@ESYudkowsky @karmacondon The ground truth is "", don't bother responding at all. Also, ~2.3sec* :)
1158587642251841500,Tue Aug 06 03:56:34 +0000 2019,Incredible lecture, thank you for the link! https://t.co/b27kr2arFQ
1158433755591135200,Mon Aug 05 17:45:04 +0000 2019,Listening to the neural network gradient norms during training https://t.co/45EH7MoM6P cool approach, would be inte‚Ä¶ https://t.co/oL2r8RO9AD
1158225988943089700,Mon Aug 05 03:59:29 +0000 2019,Biotech is so much more powerful than our Normaltech. Imagine if we could tap its full potential; maybe your car co‚Ä¶ https://t.co/XB3Gl0bG5S
1155618700445175800,Sun Jul 28 23:19:03 +0000 2019,‚ÄúBase Metabolic Rate calculator wants to use your location. Allow?‚Äù Fascinating
1155550478786130000,Sun Jul 28 18:47:57 +0000 2019,Amazon Protections Slashed and Forests Fall https://t.co/6cgcZ58FHy
1154926045373452300,Sat Jul 27 01:26:41 +0000 2019,@David_Delchev haha yes I'm told carnivore is the latest best ever fad diet, it's great :) I'll stick with Keto+IF‚Ä¶ https://t.co/jEtB0zuzOJ
1153544868947361800,Tue Jul 23 05:58:23 +0000 2019,RT @geoffreyhinton: This is a much better version of capsules. https://t.co/h9GDx5HsrS
1153048772349313000,Sun Jul 21 21:07:04 +0000 2019,@ChrKroer Relative to sugar water, chips and Twix? Quite likely.
1153026049338294300,Sun Jul 21 19:36:47 +0000 2019,@sunilmallya me too, I ate a slightly more regular apple somewhere in 90s in a random place in Europe and it was sm‚Ä¶ https://t.co/B1SlY8nWXg
1153023718886531000,Sun Jul 21 19:27:31 +0000 2019,Few examples of fruits and vegetables before they were domesticated ~10K years ago https://t.co/BvheKOcfuL (for the‚Ä¶ https://t.co/0aZ9aX7vMx
1152732451673759700,Sun Jul 21 00:10:07 +0000 2019,@pfau @LittleBimble @michael_nielsen Ty for pointer! I also like to refer to DL as "fill in the blanks programming"‚Ä¶ https://t.co/Kive1gWUgQ
1152726425289445400,Sat Jul 20 23:46:11 +0000 2019,@InnovateWithAI Only the first few chapters, the rest will take a while :) But found the brown fat mention in Freeman‚Äôs bio.
1152703003469574100,Sat Jul 20 22:13:06 +0000 2019,@mjd1735 Lol as in ‚Äúvery‚Äù
1152701561212031000,Sat Jul 20 22:07:23 +0000 2019,(The ‚Äúcorrect‚Äù area of research to watch closely is stupid large self-supervised learning or anything that finetune‚Ä¶ https://t.co/BE4tE4MMMm
1152698651774337000,Sat Jul 20 21:55:49 +0000 2019,@coffeenmusic Yes apparently that works, eg if you sleep in cold temperatures as well
1152695673403265000,Sat Jul 20 21:43:59 +0000 2019,A bit late to the party here, but "State of AI Report 2019" is a nice overall ambitious attempt at summarizing AI‚Ä¶ https://t.co/mc0u4zN5HJ
1152689227663941600,Sat Jul 20 21:18:22 +0000 2019,Interesting: "brown fat" is adipose tissue peppered with mitochondria that perform cellular respiration as normal e‚Ä¶ https://t.co/FZt7RqEbaw
1152668494162300900,Sat Jul 20 19:55:59 +0000 2019,@mtyka Haha yes and the anxiety of not replying goes up and peaks at about 1 week and then also goes down.
1152606522150543400,Sat Jul 20 15:49:43 +0000 2019,@pfau @LittleBimble @michael_nielsen I don‚Äôt really care for the specifics of the optimizer and think a good chunk‚Ä¶ https://t.co/8BBrEF4Y33
1152321826174861300,Fri Jul 19 20:58:27 +0000 2019,@michael_nielsen We're moving up the stack a bit; Instead of writing explicit fully defined program we write a roug‚Ä¶ https://t.co/y9YPoAsWRI
1152320624158601200,Fri Jul 19 20:53:40 +0000 2019,My anxiety as a function of number of unread emails in my inbox grows and peaks at about 50, but then somehow ramps‚Ä¶ https://t.co/590QaFNMDh
1151887984691576800,Thu Jul 18 16:14:31 +0000 2019,Autocompletion with deep learning https://t.co/WenacHVj7z very cool! I tried related ideas a long while ago in days‚Ä¶ https://t.co/6M92KCnIcy
1148323751928324100,Mon Jul 08 20:11:31 +0000 2019,Large Scale Adversarial Representation Learning https://t.co/1ZffPc749V un/self-supervised learning is a highly fer‚Ä¶ https://t.co/X0y4IqjWXl
1147957720881848300,Sun Jul 07 19:57:03 +0000 2019,@shaden_smith üòÇ a previous life so far away that I'm uncertain it happened
1147943983781302300,Sun Jul 07 19:02:28 +0000 2019,@shaden_smith :) thank you for your support! I don't actually have a link, but I found this in the source code, whi‚Ä¶ https://t.co/grd3DyAKOw
1146859728980496400,Thu Jul 04 19:14:01 +0000 2019,List of unsolved problems in physics https://t.co/WNYIEFLRGP
1144141988276473900,Thu Jun 27 07:14:41 +0000 2019,@MIT_CSAIL The work of identifying a desirable Turing Machine, obviously.
1143992186461016000,Wed Jun 26 21:19:26 +0000 2019,@gras_johan I find the 16/8 fast (12-8pm) to be very simple, elegant, and easy to stick to. This window also makes‚Ä¶ https://t.co/FAmv6pKiLE
1143991473970397200,Wed Jun 26 21:16:36 +0000 2019,@jasoncbenn yep! I have very little trouble with hunger on my 16/8 schedule, especially now that I've stuck with it‚Ä¶ https://t.co/S0VLg1ubEk
1143978392242384900,Wed Jun 26 20:24:37 +0000 2019,@brunoeducsant I'm still early into it but my weight and body fat % are on clear downward trend with healthy deriva‚Ä¶ https://t.co/Rq9WXpHWCR
1143976039443394600,Wed Jun 26 20:15:16 +0000 2019,@lentilcurry I saw the app but I've been trying to keep it KISS principle so far. I just eat in 12-8 every day so there's not much to track.
1143973147605004300,Wed Jun 26 20:03:47 +0000 2019,Keto+IF: so hot right now :) I've been trying it for ~1mo (I do 16/8 from 12-8pm) and so far enjoying it quite a bit.
1143391487964721200,Tue Jun 25 05:32:28 +0000 2019,@SpaceX üéâ‚ù§Ô∏è
1143244596090036200,Mon Jun 24 19:48:46 +0000 2019,Deep Set Prediction Networks https://t.co/c63TOjvGEd interesting; we now have a lot of effective encoders for objec‚Ä¶ https://t.co/3nbJWj5Hg6
1142870404316323800,Sun Jun 23 19:01:52 +0000 2019,RT @ylecun: resnext101_32x8d_wsl: the ConvNet pre-trained on Instagram hashtags and fine-tuned on ImageNet, yielding a record-breaking 85.4‚Ä¶
1141951052737998800,Fri Jun 21 06:08:42 +0000 2019,@michael_nielsen @emmalsalinas Wow
1141950996123271200,Fri Jun 21 06:08:28 +0000 2019,RT @michael_nielsen: @emmalsalinas Skydancing is becoming really amazing: https://t.co/shIn9H5z05
1141946814582497300,Fri Jun 21 05:51:51 +0000 2019,@wittyperceptron Haha, you‚Äôre right, it all kind of blended :)
1141868903745765400,Fri Jun 21 00:42:16 +0000 2019,An interesting trend from this year's CVPR are the numerous new papers on self-supervised learning. Andrew Zisserma‚Ä¶ https://t.co/Xia0PUkqra
1139768169441067000,Sat Jun 15 05:34:42 +0000 2019,RT @shancarter: A new way of looking inside vision neural networks, activation atlases: https://t.co/XDesfSx4LO https://t.co/ucQhaBHhpg
1139763235077288000,Sat Jun 15 05:15:05 +0000 2019,@slashML @MattDeitke @MattDeitke awesome!! :)
1139697492277125100,Sat Jun 15 00:53:51 +0000 2019,Boston Dynamics: New Robots Now Fight Back https://t.co/jt5bXIqR8j :O :D
1139571630122782700,Fri Jun 14 16:33:43 +0000 2019,RT @allen_ai: Our @SemanticScholar team just released Semantic Sanity! Semantic Sanity is your personalized research feed, based on @karpat‚Ä¶
1138859244206215200,Wed Jun 12 17:22:57 +0000 2019,@MagnusHyttsten I spent quite a bit of time on it but ended up regretting it afterwards. Should have done it in 3D :(
1138701177476960300,Wed Jun 12 06:54:51 +0000 2019,@petewarden hahaha! the number of times I felt the need to point out during a talk that this isn't me being lazy, t‚Ä¶ https://t.co/VF9BL6oLZC
1138699798217781200,Wed Jun 12 06:49:22 +0000 2019,This diagram, which I hastily sketched out in Google slides one day a few years ago at 3am, has become the most pop‚Ä¶ https://t.co/tMIk0JcwvF
1138674750350217200,Wed Jun 12 05:09:50 +0000 2019,@jondoda Indeed. And the thought has crossed my mind, because tonight the situation may be dire. A number of people‚Ä¶ https://t.co/Az8NAtVgsn
1138670990341300200,Wed Jun 12 04:54:54 +0000 2019,Overheard a proposed workaround from a similarly struggling customer upon discovering the absence of inventory: "We‚Ä¶ https://t.co/AahOQUezBi
1138652785220522000,Wed Jun 12 03:42:33 +0000 2019,The temperatures climbed to ~100F+ for the first time this year but ACs / fans are sold out in multiple stores. In‚Ä¶ https://t.co/wY9MdoMpPx
1134904532826173400,Sat Jun 01 19:28:20 +0000 2019,Speech2Face: Learning the Face Behind a Voice https://t.co/9enUz600fK With increasingly large/effective library of‚Ä¶ https://t.co/1pArav9E71
1134898895736066000,Sat Jun 01 19:05:56 +0000 2019,@danielgross ugh, not aGAN ü§¶‚Äç‚ôÇÔ∏èüòÇ
1134894565964492800,Sat Jun 01 18:48:44 +0000 2019,git clone tree_of_life; git checkout -b syn61; sed -i 's/TAG/TAA/g' ecoli/MDS42/dna.txt #(...okay not exactly but c‚Ä¶ https://t.co/uvocOBru6q
1134889095585386500,Sat Jun 01 18:27:00 +0000 2019,Total synthesis of E. coli genome https://t.co/W6NuyO8xhX  (&amp; paper https://t.co/Fs3KwmMC2T) incredible; Synonymous‚Ä¶ https://t.co/o9VXwYMnxJ
1134241354567934000,Thu May 30 23:33:06 +0000 2019,Pete did you retweet my retweet of your tweet? üòÇ
1134231565205004300,Thu May 30 22:54:12 +0000 2019,ConvNets on microcontrollers (e.g. Arduino Uno). In ranges of ~1cm^2 chips, ~$1 costs, running at ~1mW, and 4 MOPs/‚Ä¶ https://t.co/IpPJWzLYhj
1134158587427557400,Thu May 30 18:04:13 +0000 2019,RT @iamtrask: After a year of work, I'm *very* excited to share a #beginner level @Udacity course on  - Differential #Privacy - Federated L‚Ä¶
1133931772855537700,Thu May 30 03:02:56 +0000 2019,"Multi-Sample Dropout for Accelerated Training and Better Generalization" https://t.co/5KfvugwXR1 fun idea: when us‚Ä¶ https://t.co/jUlnnDQegm
1133848597617766400,Wed May 29 21:32:26 +0000 2019,@quocleix Neat, would be interesting to see the comparison of compound scaling to the naive approaches of scaling r‚Ä¶ https://t.co/WV90c7E4Ck
1133840969059655700,Wed May 29 21:02:07 +0000 2019,RT @quocleix: EfficientNets: a family of more efficient &amp; accurate image classification models. Found by architecture search and scaled up‚Ä¶
1133612094308343800,Wed May 29 05:52:39 +0000 2019,@elonisourhero @zachary1978 I think this is correct. We‚Äôll go through a phase where the motion is helpful but in th‚Ä¶ https://t.co/Tot4Tnb4G9
1133609735318429700,Wed May 29 05:43:17 +0000 2019,@ot_y Actually it will instantiate a full VR environment where you can relive the memory like in Harry Potter Pensi‚Ä¶ https://t.co/Hds8CMp5RU
1133605485477634000,Wed May 29 05:26:23 +0000 2019,Protip: move your phone in a wide circle while capturing live photos to ‚Äúfuture proof‚Äù them, so that the motion par‚Ä¶ https://t.co/FzDRPwo92e
1133239785764610000,Tue May 28 05:13:14 +0000 2019,RT @Erdayastronaut: Want to know how @SpaceX's Raptor engine works? Confused about what the full flow staged combustion cycle is? Why are t‚Ä¶
1132845901465022500,Mon May 27 03:08:04 +0000 2019,@Surviving_Mars super excited about Green Planet! Will it be released on the Mac app store soon by any chance?
1132171497798156300,Sat May 25 06:28:14 +0000 2019,Jonathan Blow - Preventing the Collapse of Civilization https://t.co/NnvPOP3MJW interesting talk, a bear case for m‚Ä¶ https://t.co/4MtgbYpHZX
1132103771314479100,Sat May 25 01:59:07 +0000 2019,RT @DavidBeniaguev: A story of a Cortical Neuron as a Deep Artificial Neural Net:  1) Neurons in the brain are bombarded with massive synap‚Ä¶
1129816553623412700,Sat May 18 18:30:32 +0000 2019,@uPeterKris it's the best platform we have for molecular software engineering
1129816150320148500,Sat May 18 18:28:55 +0000 2019,RT @PyTorch: A walkthrough of the PyTorch Internals by core developer @ezyang . It's a great resource if you want to contribute to PyTorch.‚Ä¶
1129808369907163100,Sat May 18 17:58:00 +0000 2019,RT @strubell: Are you interested in deep learning for NLP but also concerned about the CO2 footprint of training? You should be! Excited to‚Ä¶
1127988660412928000,Mon May 13 17:27:08 +0000 2019,'We Don't Know a Planet Like This': CO2 Levels Hit 415 PPM for 1st Time in 3 Million+ Yrs - "How is this not breaki‚Ä¶ https://t.co/0bshLVHF1a
1127796346847543300,Mon May 13 04:42:57 +0000 2019,@kkulk1 Ew
1127794789355622400,Mon May 13 04:36:45 +0000 2019,@kkulk1 Haha you‚Äôre absolutely right :D, maybe calculus + linear algebra at least. Also technically missing some on‚Ä¶ https://t.co/BJ7jSNASHP
1127792584380706800,Mon May 13 04:28:00 +0000 2019,The two tech stacks ‚ù§Ô∏è https://t.co/eDJx6N6iDJ
1127767078952267800,Mon May 13 02:46:39 +0000 2019,@chivingtoninc @ben_eater Yes and I liked it a lot. Though it somehow doesn‚Äôt mention MOSFETs at all, and uses a bi‚Ä¶ https://t.co/zvMzUbtU2E
1127754813314195500,Mon May 13 01:57:54 +0000 2019,@shmick thank you! Somehow I've mostly seen them going between $1-2 a piece, and only sold in smallish packs. But I‚Ä¶ https://t.co/9xCG9eIIuj
1127749820813234200,Mon May 13 01:38:04 +0000 2019,An SR latch from while ago that I tried to use for a 555 timer to get clock signal for an all-breadboard transistor‚Ä¶ https://t.co/F1wYwnQmHa
1126579087105904600,Thu May 09 20:05:59 +0000 2019,@Thom_Wolf :( lololol https://t.co/J13QlPXn69
1126532002910429200,Thu May 09 16:58:54 +0000 2019,@adnothing @ToyotaResearch @vitorguizilini @sudeeppillai haha! I only think people shouldn't try to "be a hero" too‚Ä¶ https://t.co/w6hLh1YgjB
1126219392155574300,Wed May 08 20:16:41 +0000 2019,RT @AdamDanielKing: Yesterday I launched Talk to Transformer, a site where you can try out @OpenAI's new text-generating language model on‚Ä¶
1125253216013361200,Mon May 06 04:17:27 +0000 2019,Reading through ‚ÄúFuture Crimes‚Äù by Goodman. On the dark side of technology in the connected world. Does a great job‚Ä¶ https://t.co/JdSWRmkmeB
1124547117496672300,Sat May 04 05:31:40 +0000 2019,@spartanhaden I do think its existence and background should become common knowledge. The technology exists to deli‚Ä¶ https://t.co/4DE2vywtaR
1124539994553536500,Sat May 04 05:03:22 +0000 2019,Quite enjoyed ‚ÄúA Crack in Creation‚Äù by Doudna &amp; Sternberg - reads a bit like Watsons‚Äôs The Double Helix combining s‚Ä¶ https://t.co/BL5SrGIOPV
1123262342756614100,Tue Apr 30 16:26:26 +0000 2019,RT @hardmaru: A series of blog posts on applying machine learning to architecture  Experiments: https://t.co/zhmOsAjeaE Background: https:/‚Ä¶
1123047665120362500,Tue Apr 30 02:13:23 +0000 2019,Fun factoid: Cas9 does not hydrolyze ATP. The biophysics its relatively complex function the elude me.
1121449636403638300,Thu Apr 25 16:23:23 +0000 2019,New blog post: "A Recipe for Training Neural Networks" https://t.co/5lBy4J77aS a collection of attempted advice for‚Ä¶ https://t.co/ygzRbbL9Pd
1120760442312245200,Tue Apr 23 18:44:46 +0000 2019,@j_becke oops, just triggered a recomputation, should be updated in ~day. Will re-setup the automatic recompute.
1120509507036229600,Tue Apr 23 02:07:39 +0000 2019,So proud of the Tesla Autopilot team and very excited to see the the veil lifted on some of their work earlier toda‚Ä¶ https://t.co/FgcFLFB0PR
1117130666922000400,Sat Apr 13 18:21:20 +0000 2019,RT @OpenAI: Today's the day!!! Watch OpenAI Five Finals here, starting 11:30a PT: https://t.co/IDxWTCVd7D. This event will be the first tim‚Ä¶
1116414632678182900,Thu Apr 11 18:56:05 +0000 2019,RT @tejasdkulkarni: depth from unconstrained video (unknown camera parameters). the results look really impressive!  https://t.co/g3nzfNo1e‚Ä¶
1115328416079700000,Mon Apr 08 18:59:50 +0000 2019,RT @ReiiYoda: Style transfer without a specific style image. I minimize only the content loss from neural style transfer and directly optim‚Ä¶
1114585336208810000,Sat Apr 06 17:47:06 +0000 2019,RT @DrCamiloOrtiz: Im amazed. My car drove me practically all the way home, with no input from me, changing lanes, merging on and off of 3‚Ä¶
1114022726811836400,Fri Apr 05 04:31:30 +0000 2019,RT @xsteenbrugge: HoloGAN: Unsupervised learning of 3D representations from natural images. Another demonstration that hardcoding prior kno‚Ä¶
1110943338893471700,Wed Mar 27 16:35:06 +0000 2019,Hinton, LeCun, Bengio win the Turing Award https://t.co/4u5lzCs7fD This is so incredible. I'm so lucky to have witn‚Ä¶ https://t.co/cM7LQ23zDQ
1110609786960150500,Tue Mar 26 18:29:42 +0000 2019,RT @elonmusk: That‚Äôs exactly it. You‚Äôre no longer mentally fatigued after a long drive. Makes a major difference to your happiness level co‚Ä¶
1109970502313869300,Mon Mar 25 00:09:24 +0000 2019,@jigarkdoshi that the original mixup seems to work on blended images makes me sad.
1109961535630143500,Sun Mar 24 23:33:46 +0000 2019,Some ways of combining information in two branch of a net A &amp; B: 1) A+B, 2) A*B, 3) concat [A,B], 4) LSTM-style tan‚Ä¶ https://t.co/gO3AxHOQnb
1108222436640616400,Wed Mar 20 04:23:13 +0000 2019,RT @drfeifei: BIG NEWS! @StanfordHAI says ‚Äúhi‚Äù to the world! :) We are launching the biggest effort ever in human-centered #AI research, ed‚Ä¶
1107519927953420300,Mon Mar 18 05:51:42 +0000 2019,"A New Golden Age for Computer Architecture  History, Challenges, and Opportunities" by Patterson at the recent RIS‚Ä¶ https://t.co/zyPkUYZgzV
1107463319626014700,Mon Mar 18 02:06:45 +0000 2019,Starting with Homo Sapiens ~50K years ago approx 108B people have lived, of whom ~7B (6.5%) are alive today.  #funfact
1107421890270781400,Sun Mar 17 23:22:08 +0000 2019,Certainly one of my favorite ever videos https://t.co/6gjMhlwFci
1106749416403165200,Sat Mar 16 02:49:57 +0000 2019,@slaterstich i'm very glad the irony has not been lost on you :D
1106605823000666100,Fri Mar 15 17:19:22 +0000 2019,When a person says that f(x) = f(a) + f‚Äô(a)(x - a) and someone disagrees strongly because of f‚Äô‚Äô(a)(x - a)^2/2
1106589010829336600,Fri Mar 15 16:12:34 +0000 2019,‚ÄúThe Bitter Lesson‚Äù by Sutton, on the longevity of domain knowledge in algorithms. Also apparent if you skim throug‚Ä¶ https://t.co/mGsmausIks
1105942174560981000,Wed Mar 13 21:22:16 +0000 2019,RT @akmtn_twi: The next stage of "Fashion/Human image synthesis" with GANs? Higher-res datasets are needed.  „Éï„Ç°„ÉÉ„Ç∑„Éß„É≥ÁîªÂÉè„ÅÆÁîüÊàê „Éù„Éº„Ç∫Êù°‰ª∂„Çí‰Ωø„Çè„Å™„ÅÑ„Åß„ÄÅ„Éé„Ç§„Ç∫„Åã„ÇâÁîü‚Ä¶
1103527738579738600,Thu Mar 07 05:28:10 +0000 2019,RT @petewarden: Launching @TensorFlow Lite for Microcontrollers! https://t.co/Py8i26dSgQ
1102774025535647700,Tue Mar 05 03:33:10 +0000 2019,MIT Mini Cheetah https://t.co/mur18guRw3 impressive
1102280681361616900,Sun Mar 03 18:52:48 +0000 2019,RT @SpaceX: Dragon is 20 meters from the @space_station https://t.co/kijFqCn8hr
1101750093747695600,Sat Mar 02 07:44:26 +0000 2019,T-00:05:00
1101280952481796100,Fri Mar 01 00:40:14 +0000 2019,RT @Tesla: $35,000 Tesla Model 3 Available Now https://t.co/xZ0J4rbbgM
1100664376464367600,Wed Feb 27 07:50:11 +0000 2019,@TheNerdStation yes, I got a few of those üòÇ, and was totally going to! Not sure that I'm learning the right lesson over here ;)
1100658918324199400,Wed Feb 27 07:28:30 +0000 2019,haha, so I just sat down to submit that PR to numpy to print more human-friendly error messages when you make the v‚Ä¶ https://t.co/Qym6H987AL
1100599801228386300,Wed Feb 27 03:33:35 +0000 2019,Fixup Initialization: Residual Learning Without Normalization https://t.co/hupA0avEfi looks great if it works. Batc‚Ä¶ https://t.co/oSQQndyF7g
1099852226808270800,Mon Feb 25 02:02:59 +0000 2019,RT @soumithchintala: cancel meetings on your calendar until it sparks joy!
1099824173545746400,Mon Feb 25 00:11:31 +0000 2019,(granted the existence of numpy saved the human race a gajillion times that many hours. my tweet was intended to ra‚Ä¶ https://t.co/tR9nkn2N5P
1099822609024221200,Mon Feb 25 00:05:18 +0000 2019,@pfau hahaha yes, I think I did. hey this must happen because of the pigeon hole principle ;)
1099793055853375500,Sun Feb 24 22:07:52 +0000 2019,&gt;&gt;&gt; a = np.zeros(5, 5) &gt;&gt;&gt; TypeError: data type not understood # thanks numpy, that's very helpful. pretty sure if‚Ä¶ https://t.co/ZWiyPqQsJv
1099761220092014600,Sun Feb 24 20:01:22 +0000 2019,@IshmeetSRaina I love how the dialog for that not only obscures part of the webpage but steals focus (in the techni‚Ä¶ https://t.co/DjSBdGiqOU
1099525983193854000,Sun Feb 24 04:26:37 +0000 2019,web browsing in 2019: page takes 5 seconds to load a pound of JavaScript. Video ad loads, autoplays and offsets you‚Ä¶ https://t.co/u4sGQeudVa
1097364729331298300,Mon Feb 18 05:18:34 +0000 2019,@jordannovet Yep! I play a good fraction of management games :)
1097359413554212900,Mon Feb 18 04:57:26 +0000 2019,Randomly stumbled on ‚ÄúSurviving Mars‚Äù (game). It‚Äôs a bit like sim city but on Mars, and pretty fun üëå https://t.co/wSNlsW5zde
1097025436800868400,Sun Feb 17 06:50:20 +0000 2019,Loved seeing Alita - really well done CGI, cool world, great action. For dog lovers. On RT 59% critic rating, but 9‚Ä¶ https://t.co/ZvyXTR5bbh
1096937832487170000,Sun Feb 17 01:02:14 +0000 2019,@then_there_was Oh cool! exactly what I was going for of course
1096931094069358600,Sun Feb 17 00:35:27 +0000 2019,I am painting for the first time since I was ~10 :D. This is ‚Äúthe descent of man‚Äù - time is from left to right:  ro‚Ä¶ https://t.co/I7SeHI0gDQ
1096649767000535000,Sat Feb 16 05:57:33 +0000 2019,@then_there_was A real future language model ++ will learn that about you üòâ
1096647604174172200,Sat Feb 16 05:48:58 +0000 2019,The more of your writing you put online the higher risk you‚Äôre taking on for future language models++ fine tuned on‚Ä¶ https://t.co/6IOei5mRpc
1096525179126112300,Fri Feb 15 21:42:29 +0000 2019,@dennybritz Would love to see the fixed point of that üòÇ
1096172373034754000,Thu Feb 14 22:20:34 +0000 2019,RT @OpenAI: We've trained an unsupervised language model that can generate coherent paragraphs and perform rudimentary reading comprehensio‚Ä¶
1095947479109910500,Thu Feb 14 07:26:55 +0000 2019,üëè to Facebook for releasing this research, data, and code. https://t.co/xewPzNaOzI
1093764139938238500,Fri Feb 08 06:51:06 +0000 2019,was randomly reading through python docs and re-stumbled by the "for ... else" construct https://t.co/ie53Yhb0r8 ew‚Ä¶ https://t.co/cGW1TiW78S
1093306420886265900,Thu Feb 07 00:32:18 +0000 2019,RT @genekogan: imitating videos with BigGAN: first predict Y from the source, then feed it to the generator. input here is the trailer for‚Ä¶
1093306005025243100,Thu Feb 07 00:30:38 +0000 2019,RT @genekogan: The new StyleGAN code is super neat. You can cross-breed latent vectors to get a sort of style transfer effect. https://t.co‚Ä¶
1092158516045832200,Sun Feb 03 20:30:56 +0000 2019,@Heffhop @michael_nielsen @pfau It‚Äôs amusingly common to look down on labeling as something anyone could do on spot‚Ä¶ https://t.co/rqWwMYmNlT
1092136617181990900,Sun Feb 03 19:03:55 +0000 2019,@michael_nielsen @pfau To me that would be at odds with how effortless it is to eg watch cartoons, interpret art, e‚Ä¶ https://t.co/SJHEo6DzSh
1092133633589051400,Sun Feb 03 18:52:03 +0000 2019,@pfau They might, if they are allowed to. The fact that you can do this for me reflects more poorly on ImageNet than ConvNets
1091813185995358200,Sat Feb 02 21:38:43 +0000 2019,"Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet" https://t.co/9Qj8HlwXzf‚Ä¶ https://t.co/Ss03696heu
1090301662797807600,Tue Jan 29 17:32:27 +0000 2019,@Eklavya_FCB Me too
1090197118789120000,Tue Jan 29 10:37:02 +0000 2019,A New Golden Age for Computer Architecture | February 2019 | Communications of the ACM - quite nice summary read on‚Ä¶ https://t.co/zmSH9ue7CG
1089680583494492200,Mon Jan 28 00:24:31 +0000 2019,Forbidden planet üòÇ https://t.co/zBnl4YTTGr
1089270158953082900,Sat Jan 26 21:13:38 +0000 2019,Keynotes from Hot Chips 30 (2018) https://t.co/MyUF3dgbzF
1089013576398921700,Sat Jan 26 04:14:04 +0000 2019,RT @josh_tobin_: 1/ Excited to share something I've been working on for a while now. Troubleshooting Deep Neural Networks: a decision tree‚Ä¶
1088586970731667500,Thu Jan 24 23:58:53 +0000 2019,RT @OriolVinyalsML: Happy that we could share #AlphaStar progress with you all! Good Games @LiquidTLO and @Liquid_MaNa, and @Artosis and @R‚Ä¶
1086683224812642300,Sat Jan 19 17:54:05 +0000 2019,When you order something with avocado but when it arrives it‚Äôs just a small slice on the side
1086403056575512600,Fri Jan 18 23:20:47 +0000 2019,RT @Reza_Zadeh: ANYmal robot abilities: standing up, crawling, running, jumping, recovering from falls, climbing stairs, overcoming/removin‚Ä¶
1086007393224249300,Thu Jan 17 21:08:34 +0000 2019,GANs continue to break my brain https://t.co/FD9yna3ho3
1085965814535082000,Thu Jan 17 18:23:21 +0000 2019,pretty cool! https://t.co/FemwBaN9rW
1084900766245040100,Mon Jan 14 19:51:13 +0000 2019,@patbarry :D great way to put it!
1084641729288884200,Mon Jan 14 02:41:54 +0000 2019,Nature stuff all around us (plants, animals, etc) are best thought of as basically super advanced alien technology.‚Ä¶ https://t.co/tEjXDiYCzz
1084631279381839900,Mon Jan 14 02:00:23 +0000 2019,Synthetic bio overview video: write some logic in Verilog and compile it to E.coli plasmids, using repressors to im‚Ä¶ https://t.co/u3aYfg3MUB
1084511930272833500,Sun Jan 13 18:06:08 +0000 2019,Iguana hatchling vs Snakes https://t.co/xLpVdYqlMb quite possibly the most incredible nature video ever made, by a‚Ä¶ https://t.co/pThzAP4Xeu
1084502595526262800,Sun Jan 13 17:29:02 +0000 2019,@mat_kelcey @hardmaru One of my favorite videos ever! Not at all clear how all of that visual/motor/behavior init is represented or encoded.
1084294386442166300,Sun Jan 13 03:41:41 +0000 2019,RT @mat_kelcey: "tinyML Summit: Advances in ultra-low power Machine Learning technologies and applications"   this looks AWESOME !!  https:‚Ä¶
1084170322134192100,Sat Jan 12 19:28:42 +0000 2019,@AndreTI genome is also not the sole transfer of information, but I am surprised at the apparent encoding efficienc‚Ä¶ https://t.co/kFCDL79Abr
1084164152044572700,Sat Jan 12 19:04:11 +0000 2019,I'm developing a pet peeve around slides showing children learning things "one/few-shot", allegedly super magically‚Ä¶ https://t.co/RtT7wbP7cI
1083233580807970800,Thu Jan 10 05:26:25 +0000 2019,@stranger_quark We have 2 ton objects traveling at 70mph and put meat in the loop.
1083232964299780100,Thu Jan 10 05:23:58 +0000 2019,@stranger_quark I notice this too! The power of always-on sensors and super-human response times. Meat is a low bar.
1083214408732487700,Thu Jan 10 04:10:14 +0000 2019,"Tesla's Navigate on Autopilot Hands-On: Road trip to CES 2019!" https://t.co/ax9x1WCuyv with NoA enabled and a nav‚Ä¶ https://t.co/x0TdhruHaE
1082101265503477800,Mon Jan 07 02:27:00 +0000 2019,Assassin's Creed Odyssey: How Ubisoft Rebuilt Athens https://t.co/gtcVkS6dmn quite remarkable job, makes it very en‚Ä¶ https://t.co/IU4hg46SWo
1082074778259714000,Mon Jan 07 00:41:45 +0000 2019,The raw value of a loss (in a multitask setting) does not reflect how much your model "cares" about that component.‚Ä¶ https://t.co/VeDtihGaDW
1081775327523655700,Sun Jan 06 04:51:51 +0000 2019,"Tensor Considered Harmful" https://t.co/UnsEA1BEm3 actually quite interesting, can strongly relate to many of the traps.
1080700888266637300,Thu Jan 03 05:42:24 +0000 2019,My parents were visiting me once and as I was leaving for work I saw my mom sitting on the couch in the living room‚Ä¶ https://t.co/zocGjsiu7x
1076927879995285500,Sun Dec 23 19:49:49 +0000 2018,Similar to Chemistry making Alchemy rigorous, Divination could be resurrected as a discipline but take on a highly‚Ä¶ https://t.co/ipzcHyuN7u
1076667977645228000,Sun Dec 23 02:37:04 +0000 2018,@mat_kelcey Same here, eventually struggled through it in Audible format. I really liked 5% of it (mostly around wo‚Ä¶ https://t.co/wnMfTwV9qX
1076617775752175600,Sat Dec 22 23:17:34 +0000 2018,To understand X I need to review my Chemistry. *2 hours pass*. To understand this part I need to review my Quantum‚Ä¶ https://t.co/02lFa9rw7n
1076241917426393100,Fri Dec 21 22:24:03 +0000 2018,RT @hardmaru: A GAN trained on accepted @CVPR papers. https://t.co/6S5nIIdcfV
1075253201006280700,Wed Dec 19 04:55:15 +0000 2018,A super boring evening :D https://t.co/5Iqfz5ziI5
1074760156762669000,Mon Dec 17 20:16:04 +0000 2018,@jamesproud Oh I know about this and have turned this on a long time ago. Still seems like an exceedingly dumb default behavior.
1074759657896403000,Mon Dec 17 20:14:05 +0000 2018,Chrome: Cmd+w: closes current tab. Empirical usage: 100 times / day. Cmd+q (1cm to the left): nuke every single one‚Ä¶ https://t.co/5DOByn4jZo
1074152084851777500,Sun Dec 16 03:59:48 +0000 2018,RT @genekogan: this repo lets you implant random things into paintings https://t.co/yT1LX4jYNL https://t.co/VAiVu2Tja7
1074110668226232300,Sun Dec 16 01:15:13 +0000 2018,A typical ~2GHz CPU will clock pulse every 0.5ns. Since the speed of light is ~0.3m/ns, light only traverses ~15cm‚Ä¶ https://t.co/qkkpALvznw
1073404228079542300,Fri Dec 14 02:28:05 +0000 2018,RT @hardmaru: A Style-Based Generator Architecture for Generative Adversarial Networks. @NvidiaAI does it again! https://t.co/W2Av34ta9O ht‚Ä¶
1073403748964196400,Fri Dec 14 02:26:11 +0000 2018,RT @goodfellow_ian: These style-based generator results look great: https://t.co/RL825n0yNP https://t.co/k7UtJMTWhM
1071912588227690500,Sun Dec 09 23:40:50 +0000 2018,Incredible NeurIPS talk from @drmichaellevin on "Bioelectric Computation Outside the Nervous System"‚Ä¶ https://t.co/N9wKIH4X81
1071904986768977900,Sun Dec 09 23:10:38 +0000 2018,@mat_kelcey yep - liked that game quite a bit too! "I'll just sacrifice multiple pawns and then leisurely move my k‚Ä¶ https://t.co/TqozflfNxw
1071897644929183700,Sun Dec 09 22:41:28 +0000 2018,Fun chess analysis videos of the newly released AlphaZero vs. Stockfish 8 games, some of my favorites so far on the‚Ä¶ https://t.co/Ou4veyc41y
1071809794435035100,Sun Dec 09 16:52:22 +0000 2018,#BigGAN breaks my brain. I can't stop watching. music recommended. https://t.co/WHdiDP5B5y
1071808456426848300,Sun Dec 09 16:47:03 +0000 2018,RT @phillip_isola: #BigGAN is so much fun. I stumbled upon a (circular) direction in latent space that makes party parrots, as well as othe‚Ä¶
1071618763798134800,Sun Dec 09 04:13:17 +0000 2018,Good read! Fave quote: ‚Äúsuppose you are playing tennis &amp; hit the ball incorrectly. Which of your 100 trillion synap‚Ä¶ https://t.co/fNITnvOVYe
1071313996999991300,Sat Dec 08 08:02:15 +0000 2018,RT @twiecki: JAX: GPU- and TPU-backed #NumPy with differentiation and JIT compilation. https://t.co/NEvRyXwvem via @fonnesbeck https://t.co‚Ä¶
1070894457510338600,Fri Dec 07 04:15:09 +0000 2018,@chriscanal4 üòÇ
1070091216505585700,Tue Dec 04 23:03:22 +0000 2018,There are appear to be a number of good reasons to eat crickets (preferably ground up), from health/nutrition to ec‚Ä¶ https://t.co/yDh6mt7dVT
1069449187933048800,Mon Dec 03 04:32:10 +0000 2018,So much fun to wave at other Teslas on the road. Find this especially common when the models and the color match :)‚Ä¶ https://t.co/FHBkaokxLH
1067637309829406700,Wed Nov 28 04:32:25 +0000 2018,Ancient Egypt was more ancient to Romans than Romans are to us. #funfactoidoftheday
1067466861724323800,Tue Nov 27 17:15:07 +0000 2018,RT @henddkn: Tataa ! I'm happy to announce the release of #GANpaint today - based on the new #GANdissect method, which helps to identify wh‚Ä¶
1067234091936837600,Tue Nov 27 01:50:10 +0000 2018,RT @PyTorch: Microsoft VSCode integrates deeply with PyTorch out of the box.  As @aerinykim highlights:  1. It shows values inside tensors.‚Ä¶
1067173690662481900,Mon Nov 26 21:50:09 +0000 2018,RT @elonmusk: Join to create exciting new worlds of technology!! If getting things done matters to you, then @SpaceX, @Tesla, @BoringCompan‚Ä¶
1063470115637743600,Fri Nov 16 16:33:28 +0000 2018,RT @cleantechnica: We Are So Screwed: Study Warns Of 5 Degree Celsius Warming By¬†2100 https://t.co/PKJZUjY7wR https://t.co/vUdexOcaDa
1063462231189348400,Fri Nov 16 16:02:08 +0000 2018,RT @michael_nielsen: New essay from @patrickc and myself, arguing that science has suffered from greatly diminishing returns over the past‚Ä¶
1063343573637066800,Fri Nov 16 08:10:38 +0000 2018,last fun thing to think about is that we're doing 1.28M images over 90 epochs with 68K batches, so the entire optim‚Ä¶ https://t.co/ITAGYjY6SE
1063335018997542900,Fri Nov 16 07:36:38 +0000 2018,so... if this rate keeps up then around 2020 we'd be training ImageNet to 75% accuracy in 0.5 seconds :)
1063334554482536400,Fri Nov 16 07:34:48 +0000 2018,Nice comparison table in the paper showing the wall clock time to 75% accuracy, over time. He et al. was CVPR 2016,‚Ä¶ https://t.co/Vx51fSl9es
1063333353909190700,Fri Nov 16 07:30:02 +0000 2018,ResNet-50 on ImageNet now (allegedly) down to 224sec (3.7min) https://t.co/3Z77Edfj0u using 2176 V100s. Increasing‚Ä¶ https://t.co/t7neUpjbRQ
1062047503841775600,Mon Nov 12 18:20:31 +0000 2018,Differentiable Monte Carlo Ray Tracing through Edge Sampling https://t.co/NtVmZUxkz9 "differentiable ray tracer [..‚Ä¶ https://t.co/8U8n8XDjgx
1061020527618273300,Fri Nov 09 22:19:41 +0000 2018,RT @hardmaru: Key Papers in Deep Reinforcement Learning curated by @OpenAI https://t.co/34WUV3DiKN
1059856407887933400,Tue Nov 06 17:13:53 +0000 2018,Could Solar Radiation Pressure Explain 'Oumuamua's Peculiar Acceleration? https://t.co/YSIXZvLIen
1059485741376405500,Mon Nov 05 16:40:59 +0000 2018,RT @patrickc: While there's a lot of discussion about bots on social media these days, I just found out about the real, physical bots that‚Ä¶
1059484735628435500,Mon Nov 05 16:36:59 +0000 2018,Hidden Technical Debt in Machine Learning Systems https://t.co/szYRTtSpDd on some of the new joys and struggles of‚Ä¶ https://t.co/B1RHSsVrwR
1058436440370044900,Fri Nov 02 19:11:26 +0000 2018,RT @MishaAhrens: We made public:  1.5 million neurons, cell-level activity during multiple behaviors 15 TB raw, 56 GB compressed 18 fish wh‚Ä¶
1057707302378123300,Wed Oct 31 18:54:06 +0000 2018,¬Ø\_(„ÉÑ)_/¬Ø I was feeling very casual this morning ü§¶‚Äç‚ôÇÔ∏èü§£ https://t.co/RPN6SozWiD
1056753601840734200,Mon Oct 29 03:44:26 +0000 2018,overtourism https://t.co/fzPBtrZQ7z
1056320696857460700,Sat Oct 27 23:04:14 +0000 2018,Was going to fix the most recent arxiv-sanity issues with a memory-efficient refactor (with 56K papers and 23K user‚Ä¶ https://t.co/egg0AzKdf5
1055930594251595800,Fri Oct 26 21:14:06 +0000 2018,@Even_Oldridge i'm aware there is a problem :( i'll try to find some time this weekend to ssh in and see what's happening. sorry!
1055215128017137700,Wed Oct 24 21:51:06 +0000 2018,RT @fvsmassa: Today we are releasing Mask R-CNN Benchmark: a fast and modular implementation for Faster R-CNN and Mask R-CNN written entire‚Ä¶
1055213898289229800,Wed Oct 24 21:46:12 +0000 2018,RT @PyTorch: MaskRCNN-Benchmark: - A fast, modular reference of {Mask,Faster}RCNN - by @fvsmassa (PyTorch), optimized by Nvidia - reusable‚Ä¶
1055136081551609900,Wed Oct 24 16:36:59 +0000 2018,RT @randal_olson: Private businesses and rising powers are replacing the cold-war duopoly in the #space race. #dataviz  https://t.co/4CVHOh‚Ä¶
1054252581789159400,Mon Oct 22 06:06:17 +0000 2018,Reminiscences of the VLSI Revolution: How a series of failures triggered a paradigm shift in digital design https://t.co/8oB5LNpI9K
1053371823251849200,Fri Oct 19 19:46:28 +0000 2018,@richardgalvez done! ty :)
1053187817440915500,Fri Oct 19 07:35:17 +0000 2018,Insufficiently many people are aware of backscatter. "Towards Battery-Free HD Video Streaming"‚Ä¶ https://t.co/L1EQPWQn4A
1053183192704806900,Fri Oct 19 07:16:54 +0000 2018,Humans have really lucked out with a number of animal species, eg esp horses and dogs come to mind, without which s‚Ä¶ https://t.co/orUDGGpxcR
1052859557444083700,Thu Oct 18 09:50:54 +0000 2018,feels so nice to stay up late into the night coding, reminds me of grad school ‚ù§Ô∏è (except back then it was also oka‚Ä¶ https://t.co/UaEZZi5Rqp
1052246855411626000,Tue Oct 16 17:16:14 +0000 2018,"Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point sup‚Ä¶ https://t.co/EUSrPjaCvr
1052244892091482100,Tue Oct 16 17:08:26 +0000 2018,good post &amp; links! Touches on gradient accumulation, gradient checkpointing (no, not the normal checkpointing), the‚Ä¶ https://t.co/gNSWNRGqGj
1051553258970308600,Sun Oct 14 19:20:08 +0000 2018,@MichaelDevinsky yes except it won't survive 500+ years.
1051547219273207800,Sun Oct 14 18:56:08 +0000 2018,Finished Isaacson's Leonardo da Vinci; Especially intrigued by Leonardo's use of art as a thinking tool for science‚Ä¶ https://t.co/58Nn0FWAQD
1050424673291264000,Thu Oct 11 16:35:32 +0000 2018,RT @petewarden: A Cortex M3 CPU with 1MB Flash and 288KB RAM and wifi for under $1 at retail! https://t.co/lVrXINB5Zs - thanks @aallan for‚Ä¶
1048284180960833500,Fri Oct 05 18:49:59 +0000 2018,RT @ajmooch: GANs learn about eyes very early in training, and immediately begin sticking them everywhere. I'd like to think this one would‚Ä¶
1047507352943878100,Wed Oct 03 15:23:09 +0000 2018,:( https://t.co/LsrZQ91gio
1046490172857045000,Sun Sep 30 20:01:14 +0000 2018,RT @kenshirriff: The Intel 8087 floating point chip contained an unusual high-density ROM. It stored 2 bits per transistor by using four di‚Ä¶
1046169119274364900,Sat Sep 29 22:45:29 +0000 2018,RT @OriolVinyalsML: Best GAN samples ever yet? Very impressive ICLR submission! BigGAN improves Inception Scores by &gt;100.  Paper: https://t‚Ä¶
1045734744414011400,Fri Sep 28 17:59:26 +0000 2018,RT @harvardnlp: First pass at up &lt;-&gt; down keywords. Seems like "meta-learning", "imitation learning", and "architecture" search are up üöÄ. W‚Ä¶
1045120596219052000,Thu Sep 27 01:19:02 +0000 2018,RT @jeremyphoward: Proud to be launching "Introduction to Machine Learning for Coders" today. If you're looking for a modern, code-first, o‚Ä¶
1045120290571747300,Thu Sep 27 01:17:49 +0000 2018,RT @OriolVinyalsML: Interesting papers using https://t.co/3bDrOTlE5b showing the difficulty of StarCraft2 1vs1 for Deep RL (even w/ handcra‚Ä¶
1044497573216567300,Tue Sep 25 08:03:21 +0000 2018,A report on the geopolitics of AI by @timhwang, especially found Part 3 interesting https://t.co/uZGWXe9sGV, and th‚Ä¶ https://t.co/tLl0DTOdXv
1043584473445453800,Sat Sep 22 19:35:01 +0000 2018,Growing as a programmer is to a large extent the accumulation of scars in your mind, which burn with each new line‚Ä¶ https://t.co/bgrydTwr3i
1038476966997852200,Sat Sep 08 17:19:37 +0000 2018,‚ÄúThe state of the art in explanation of a concept‚Äù - a phrase I first heard in a chat with @3blue1brown a while ago‚Ä¶ https://t.co/mAR52SD7LM
1037014294372614100,Tue Sep 04 16:27:29 +0000 2018,2023+: only those with access to powerful AGIs can now register for the NIPS conference.
1037013128330891300,Tue Sep 04 16:22:51 +0000 2018,plan: 2019: be ready &amp; fully caffeinated the millisecond it goes up 2020: write some JS to register me instantly 20‚Ä¶ https://t.co/nI0enZAtWQ
1037011082777251800,Tue Sep 04 16:14:43 +0000 2018,My morning coffee turned out to be the difference between going and not going to NIPS 2018 this year. Apparently so‚Ä¶ https://t.co/Dve89169FZ
1036336247445180400,Sun Sep 02 19:33:10 +0000 2018,Available video speeds on YouTube: 0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 2.0. What monster left out the 1.75x
1036305390672142300,Sun Sep 02 17:30:33 +0000 2018,‚ÄúA Magazine Is an iPad That Does Not Work‚Äù https://t.co/Vlomg0RORo a fave video. As our technosphere becomes more a‚Ä¶ https://t.co/0JncpfhG6z
1035653597462028300,Fri Aug 31 22:20:33 +0000 2018,Full Body Surrogacy for Collaborative Communication https://t.co/a6KaA5Q6gb interesting
1035585148203327500,Fri Aug 31 17:48:34 +0000 2018,RT @PyTorch: We're excited to host the first PyTorch Developer Conference, featuring talks, discussions and posters from the core-devs, aca‚Ä¶
1034829612889460700,Wed Aug 29 15:46:20 +0000 2018,@prajjwal_1 should clarify that PhD for me was not a matter of deep thought and analysis so the quora post suggests‚Ä¶ https://t.co/dWUfxUg6qK
1033826150244483100,Sun Aug 26 21:18:56 +0000 2018,"Hybrid Optical-Electronic Convolutional Neural Networks" https://t.co/k4YVtmSPn1 incredibly interesting work - dev‚Ä¶ https://t.co/d2ntpXYBMQ
1033419924528496600,Sat Aug 25 18:24:44 +0000 2018,@gwern That‚Äôs it!! It‚Äôs one of few short stories with a very good ratio of uniqueness, creativity and apparent ridi‚Ä¶ https://t.co/aR6kvpaSlZ
1033410317756158000,Sat Aug 25 17:46:34 +0000 2018,There was an interestingly prophetic short story that has left a lasting impression on me and now can‚Äôt find. It‚Äôs‚Ä¶ https://t.co/jSrMMrp5eA
1032711121751298000,Thu Aug 23 19:28:12 +0000 2018,RT @jhnhw: First 1e6 integers, represented as binary vectors indicating their prime factors, and laid out using the sparse matrix support i‚Ä¶
1032710679818428400,Thu Aug 23 19:26:27 +0000 2018,RT @ericjang11: Incredible style pose transfer + generative models paper applied to dance videos. This is so cool, my fingers are trembling‚Ä¶
1032709906573406200,Thu Aug 23 19:23:23 +0000 2018,RT @PyTorch: Try out @NvidiaAI 's Vid2Vid project for photorealistic video-to-video translation, synthesizing label maps to realistic video‚Ä¶
1031405488745967600,Mon Aug 20 05:00:05 +0000 2018,Great post exploring the details of one of the first few programs. https://t.co/STaGSbOVn4
1031272045298954200,Sun Aug 19 20:09:50 +0000 2018,@DanBrink91 Yeah, I wanted to impulse buy Stanford‚Äôs undergrad Physics book the other day and it was around $280. Like whoa.
1031269084661338100,Sun Aug 19 19:58:04 +0000 2018,@ChrisTorresLugo Oh wow!!
1031267058271408100,Sun Aug 19 19:50:01 +0000 2018,was trying to compile the list based on courses at schools and which books they use to make this a bit more data dr‚Ä¶ https://t.co/RGlOLogjik
1031266180240093200,Sun Aug 19 19:46:32 +0000 2018,Discovering (paradoxically late in life) that I get more out of textbooks than books and that I don‚Äôt have to stop‚Ä¶ https://t.co/LbDzQ7FcsJ
1027302798331789300,Wed Aug 08 21:17:28 +0000 2018,RT @elonmusk: Tesla deliveries &amp; AP hardware chart by @lexfridman at MIT https://t.co/6vZxKMcec2
1026516318164410400,Mon Aug 06 17:12:16 +0000 2018,@madebyollin sorry, not sure what happened there. I went, did a reboot and all seems well now. This thing is a tick‚Ä¶ https://t.co/pGGr7InJLA
1026312574143361000,Mon Aug 06 03:42:40 +0000 2018,Was quite fun watching the OpenAI Five match earlier today, despite my limited awareness of DOTA macro strategy. Si‚Ä¶ https://t.co/BreBxx7OEI
1026311313222328300,Mon Aug 06 03:37:39 +0000 2018,"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling"‚Ä¶ https://t.co/l9fndYqyIM
1024488234607292400,Wed Aug 01 02:53:23 +0000 2018,@TriTexan haha, yes. https://t.co/EEJmTk6GPj
1024485692687044600,Wed Aug 01 02:43:17 +0000 2018,The latest entry in turning ImageNet into MNIST: 75.8% top-1 test accuracy with ResNet-50 (90 epochs) in 6.6 minute‚Ä¶ https://t.co/5jkPTBy72V
1023304552987091000,Sat Jul 28 20:29:52 +0000 2018,RT @NathanBenaich: #AI newsletter, State of AI 2018 edition, coming out tomorrow. Drop your deets here to get it straight to your üì• https:/‚Ä¶
1021825233093705700,Tue Jul 24 18:31:34 +0000 2018,@YannFletBerliac @seb_ruder @dennybritz @ch402 @michael_nielsen haven't used it yet but was impressed with a demo of https://t.co/oEaDF74jX0
1021138468045406200,Sun Jul 22 21:02:37 +0000 2018,That deeply soul crushing feeling when you're super excited to try out this new thing you just impulse bought only‚Ä¶ https://t.co/h7QqsBxgqP
1020393995636072400,Fri Jul 20 19:44:21 +0000 2018,RT @ericjang11: "There are exactly four normed division algebras: the real numbers (R), complex numbers (C), quaternions (H), and octonions‚Ä¶
1020361806118703100,Fri Jul 20 17:36:26 +0000 2018,RT @patrickc: While @elonmusk is in the headlines for many reasons these days, this particular chart probably doesn‚Äôt get enough attention.‚Ä¶
1018577453399224300,Sun Jul 15 19:26:03 +0000 2018,Fantastic set of videos on building a programmable 8-bit computer from scratch on breadboards using only simple log‚Ä¶ https://t.co/fBNsea0XXy
1018555368991948800,Sun Jul 15 17:58:18 +0000 2018,@SalehCU Precise tweets are less fun :D
1018544870112165900,Sun Jul 15 17:16:35 +0000 2018,It took me a while to really admit to myself that just reading a book is not learning but entertainment.
1017933824146079700,Sat Jul 14 00:48:30 +0000 2018,RT @petewarden: There are some fantastic links on neural network acceleration hardware in this CS217 syllabus: https://t.co/f056QIt2AT - th‚Ä¶
1017092381672271900,Wed Jul 11 17:04:55 +0000 2018,RT @hardmaru: An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution, from UberAI. Adding CPPN-style coordinate‚Ä¶
1016441743883944000,Mon Jul 09 21:59:30 +0000 2018,RT @dpkingma: Check out https://t.co/cBigTutSGn, my work with @prafdhar on improving flow-based generative models with invertible 1x1 convo‚Ä¶
1015782502818934800,Sun Jul 08 02:19:55 +0000 2018,@jigarkdoshi I know, I was making fun of this in my reddit comment here https://t.co/U2chTHd8hH , but I didn't call this one :\ ü§¶‚Äç‚ôÇÔ∏è
1015753605914099700,Sun Jul 08 00:25:06 +0000 2018,RT @alexis_b_cook: The official repository for the Deep Reinforcement Learning Nanodegree program at @udacity is now public!  Check it out‚Ä¶
1015727047753101300,Sat Jul 07 22:39:34 +0000 2018,The quest for optimal normalization in neural nets continues. SwitchNorm: add BatchNorm + InstanceNorm + GroupNorm‚Ä¶ https://t.co/5jcXlbc6wh
1014289445225263100,Tue Jul 03 23:27:02 +0000 2018,RT @goodfellow_ian: This new family of GAN loss functions looks promising! I'm especially excited about Fig 4-6, where we see that the new‚Ä¶
1013843807421399000,Mon Jul 02 17:56:14 +0000 2018,RT @jaschasd: Adversarial Reprogramming of Neural Networks https://t.co/yYrLGNrAJT A new goal for adversarial attacks! Rather than cause a‚Ä¶
1013322763790999600,Sun Jul 01 07:25:48 +0000 2018,6) thinking view() and permute() are the same thing (&amp; incorrectly using view)
1013273597677224000,Sun Jul 01 04:10:26 +0000 2018,RT @ericjang11: New blog post in which I share my thoughts on the ICRA conference &amp; state of robotics research! https://t.co/Qde92HjXF0
1013251163330732000,Sun Jul 01 02:41:17 +0000 2018,@mat_kelcey @kasiahayden yep, happened to me a few times that I turn my data back on and get the same loss :) also‚Ä¶ https://t.co/0cN135oHft
1013248794513702900,Sun Jul 01 02:31:52 +0000 2018,@mat_kelcey @kasiahayden exactly. I like to start with the simplest possible sanity checks - e.g. also training on‚Ä¶ https://t.co/5MmSRA6zPC
1013247593554403300,Sun Jul 01 02:27:06 +0000 2018,@mat_kelcey @kasiahayden it's by far the most "bang for the buck" trick that noone uses that exists.
1013245864570073100,Sun Jul 01 02:20:13 +0000 2018,oh: 5) you didn't use bias=False for your Linear/Conv2d layer when using BatchNorm, or conversely forget to include‚Ä¶ https://t.co/QWFE58QolK
1013244313327681500,Sun Jul 01 02:14:04 +0000 2018,most common neural net mistakes: 1) you didn't try to overfit a single batch first. 2) you forgot to toggle train/e‚Ä¶ https://t.co/3phWC64Amc
1013140353472389100,Sat Jun 30 19:20:58 +0000 2018,Scalable Deep Reinforcement Learning for Robotic Manipulation https://t.co/4exGdTMSLM hand-designed init -&gt; 580k gr‚Ä¶ https://t.co/sPsJQtGEuF
1013133081660698600,Sat Jun 30 18:52:04 +0000 2018,e.g. RL DNN trained on CSGO would likely relatively quickly but somewhat unimpressively become a superhuman aimbot
1013132900303138800,Sat Jun 30 18:51:21 +0000 2018,would be interesting to see a strategy game (e.g. Starcraft/DOTA) match mode with focus on strategy &amp; taking out ag‚Ä¶ https://t.co/i2sctd8P0h
1013100639969144800,Sat Jun 30 16:43:09 +0000 2018,@DavyLandman Ty aware of some existing projects in the space that don‚Äôt go far enough (today), unaware of papers.
1013092027246891000,Sat Jun 30 16:08:56 +0000 2018,Fun project request following up on last tweet: visually render in 3D code bases (git repos) to look like construct‚Ä¶ https://t.co/L7QOPhpBC2
1012892915922698200,Sat Jun 30 02:57:44 +0000 2018,RT @RobJHeaton: I've been working on a system to remember more of what I read. It‚Äôs obviously not the result of years of (or indeed any) sc‚Ä¶
1012758097058660400,Fri Jun 29 18:02:01 +0000 2018,Spent some time at the factory last night. Felt like Alice in Wonderland, except with Wonderland as the home planet‚Ä¶ https://t.co/Y2BSi5cQr2
1011653463866871800,Tue Jun 26 16:52:36 +0000 2018,RT @ajmooch: DARTS: Differentiable Architecture Search by Hanxiao Liu, Karen Simonyan, and Yiming Yang.  They operate on a continuous relax‚Ä¶
1011298711551397900,Mon Jun 25 17:22:56 +0000 2018,RT @OpenAI: Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams (including a semi-pro team) at Dota 2:‚Ä¶
1010987336279064600,Sun Jun 24 20:45:38 +0000 2018,RT @devonzuegel: San Francisco has... üë™ 884k people üöó 497k vehicles üÖøÔ∏è 275k parking spaces  https://t.co/49TKxa6SOy
1010983022953357300,Sun Jun 24 20:28:30 +0000 2018,https://t.co/BkTRjWp0vs
1010978625414357000,Sun Jun 24 20:11:02 +0000 2018,Congratulations Reddit for being one of the most annoying websites begging you to download the app when there is ze‚Ä¶ https://t.co/QmD5S1k02L
1010946886151237600,Sun Jun 24 18:04:54 +0000 2018,RT @janexwang: Dissolving the Fermi paradox. What a way to end a paper - Conclusion: Loneliness and existential ennui. https://t.co/eoLUz1x‚Ä¶
1009903441110429700,Thu Jun 21 20:58:38 +0000 2018,RT @NVIDIAAIDev: Today at #CVPR2018 we introduce @NVIDIA DALI &amp; nvJPEG, new #deeplearning libraries for data augmentation and image decodin‚Ä¶
1009823165348962300,Thu Jun 21 15:39:38 +0000 2018,Was interesting to see this year‚Äôs industry expo and its scale, surrounding the poster session. The first time I vi‚Ä¶ https://t.co/KaLAQMG2IS
1009822791653154800,Thu Jun 21 15:38:09 +0000 2018,Was very fun to bring Tesla to #cvpr2018, in style. With the Model X at our booth I think we accidentally sold a fe‚Ä¶ https://t.co/M0O8wMaVk5
1009474974736764900,Wed Jun 20 16:36:03 +0000 2018,RT @DavidDuvenaud: Neural ODEs: Instead of updating hiddens layers by layer, we specify their derivative wrt depth with a neural network.‚Ä¶
1009195199497568300,Tue Jun 19 22:04:20 +0000 2018,RT @Reza_Zadeh: Best paper award at #CVPR2018 main idea: study twenty five different visual tasks to understand how &amp; when transfer learnin‚Ä¶
1008794116623196200,Mon Jun 18 19:30:34 +0000 2018,RT @pabbeel: Very excited to announce something we‚Äôve been working on for a while now: https://t.co/uQfNtBNki6 3-day bootcamp!  Instructors‚Ä¶
1007335199175086100,Thu Jun 14 18:53:21 +0000 2018,RT @evolvingstuff: More of this kind of thing, please.  A Connectome Based Hexagonal Lattice Convolutional Network Model of the Drosophila‚Ä¶
1006968831363805200,Wed Jun 13 18:37:32 +0000 2018,Through-Wall Human Pose Estimation Using Radio Signals https://t.co/9IXsdpgJnM  "wireless signals in the WiFi frequ‚Ä¶ https://t.co/cNPd0ALC3c
1005974362044764200,Mon Jun 11 00:45:52 +0000 2018,#randomscifisundays Exhalation, from Ted Chiang https://t.co/6gmteQEV9o steampunk spin on heat death of the Universe
1005927969913630700,Sun Jun 10 21:41:31 +0000 2018,Jeff Bezos @ ISDC 2018 https://t.co/FhjwFLj6tt
1001513272024096800,Tue May 29 17:19:05 +0000 2018,@lukasheinrich_ @KyleCranmer @arxiv_org @CERN @JannickePS very cool! hope it wasn't too hard to get working. Feel f‚Ä¶ https://t.co/TUhdqkzzDJ
1001512854443323400,Tue May 29 17:17:26 +0000 2018,RT @lukasheinrich_: We just deployed a high-energy physics version of @karpathy's  @arxiv_org-sanity interface at @CERN on https://t.co/SF1‚Ä¶
1001224500887744500,Mon May 28 22:11:37 +0000 2018,RT @petewarden: Why you need to improve your training data, and how to do it: https://t.co/ArVq78E6vX
1000853961547497500,Sun May 27 21:39:14 +0000 2018,lots of exciting recent work in large-scale distributed training of neural nets: (very) large-batch SGD, KFAC, ES,‚Ä¶ https://t.co/i2qyAc31iM
1000798279213305900,Sun May 27 17:57:58 +0000 2018,@lishali88 I‚Äôve used Software 2.0 to refer to the resulting artifact, the final piece of code, only portion of whic‚Ä¶ https://t.co/hgMGlh72Iv
1000796796988280800,Sun May 27 17:52:04 +0000 2018,@pwang Oooh, nice. üëè:)
1000496548239757300,Sat May 26 21:59:00 +0000 2018,@andrey_kurenkov not a fan because "learning" is too overloaded and brings a lot of baggage, and also ML as a field‚Ä¶ https://t.co/s6GAfBjyhp
1000488820372996100,Sat May 26 21:28:17 +0000 2018,not a huge fan of the term "differentiable programming". The big deal isn't that it's differentiable, it's that the‚Ä¶ https://t.co/rO7mlr1MWa
1000456663344627700,Sat May 26 19:20:30 +0000 2018,@s_m_i Closes at 5pm ;( This is the problem with libraries. Otherwise it looks beautiful!
1000453622293921800,Sat May 26 19:08:25 +0000 2018,@s_m_i I spent a lot of time there! Something just like it but with coffee/food closer, and at the edge of a cliff‚Ä¶ https://t.co/mOpNQ0TtIS
1000452692039254000,Sat May 26 19:04:43 +0000 2018,@michael_nielsen Interesting! An uncharted search space :)
1000451636366475300,Sat May 26 19:00:32 +0000 2018,Searching for a place in some vicinity of Bay Area, pretty, quiet, with WiFi, ability to sit down for few hours and‚Ä¶ https://t.co/OHLu9GDmAI
1000154379545071600,Fri May 25 23:19:20 +0000 2018,RT @OpenAI: Releasing Gym Retro ‚Äî 1000+ games for reinforcement learning research, plus an integrator tool to add your own classic games. h‚Ä¶
998726359357640700,Tue May 22 00:44:54 +0000 2018,RT @hardmaru: Generative Ramen https://t.co/ye76r0v8p1
998328635726557200,Sun May 20 22:24:29 +0000 2018,Good recent episode on Rationally Speaking podcast on one of my favorite subreddits, r/changemyview (‚Ä¶ https://t.co/Y3c1ZWx3t4
997943054869790700,Sat May 19 20:52:19 +0000 2018,@AnneEUrai @neuroecology @neurograce my original post has a bit more info: https://t.co/2SQ8tBWuo0 would be interes‚Ä¶ https://t.co/CVawvZBAhi
997941791046303700,Sat May 19 20:47:18 +0000 2018,RT @neurograce: Ok, it's done: Fifteen questions and answers about the use of convolutional neural networks as a model of the visual system‚Ä¶
997941312610422800,Sat May 19 20:45:24 +0000 2018,@AnneEUrai @neurograce @neuroecology Great question. Original data is from google image search (basically) by googl‚Ä¶ https://t.co/nt8ugBOgIJ
997940827346227200,Sat May 19 20:43:28 +0000 2018,@neuroecology @AnneEUrai @neurograce It is me, because I couldn‚Äôt find anyone else who wanted to train for 3 weeks,‚Ä¶ https://t.co/5wfLN52Il6
997939971410415600,Sat May 19 20:40:04 +0000 2018,@neuroecology @AnneEUrai @neurograce If by one day you mean 3 weeks, and a number of attempts to include other peop‚Ä¶ https://t.co/SBTdPSeIzL
995157228310093800,Sat May 12 04:22:27 +0000 2018,Towards battery-free HD video streaming https://t.co/YP0DO3zuAL "we can harvest sufficient energy to enable battery‚Ä¶ https://t.co/ih9DTpwLvN
994383016221802500,Thu May 10 01:06:00 +0000 2018,RT @elonmusk: Tesla quarterly all-hands video. Love the shot of wild horses &amp; Giga in winter https://t.co/ZGZbpSFhus
994274638258622500,Wed May 09 17:55:21 +0000 2018,RT @Sydonahi: We rely on 15 people to do our science. Without them matplotlib, numpy and pandas would not be maintained. https://t.co/6shDU‚Ä¶
994130628177051600,Wed May 09 08:23:06 +0000 2018,Duplexes talking to duplexes would be an amusing use of existing (human) interfaces but by AIs. Just like autonomou‚Ä¶ https://t.co/12sZjhFWXy
991802480672391200,Wed May 02 22:11:52 +0000 2018,RT @ylecun: We are releasing ELF OpenGo, a go bot that has attained professional level in two weeks of training and has won 15 games agains‚Ä¶
991769625007308800,Wed May 02 20:01:19 +0000 2018,RT @phillip_isola: Nonparametric image synthesis has gone out of fashion but this paper shows that it can still do amazing things when comb‚Ä¶
991768545418604500,Wed May 02 19:57:02 +0000 2018,RT @jeremyphoward: Training Imagenet in 3 hours for $25; and CIFAR10 for $0.26 ¬∑ https://t.co/GEOZuodrZj https://t.co/NkeUAUZ7Lk
991766587551113200,Wed May 02 19:49:15 +0000 2018,Great to see roadmap for production support in PyTorch and, very importantly, on strictly opt-in basis üëç. The featu‚Ä¶ https://t.co/3AKEQ0j3DY
991446428089106400,Tue May 01 22:37:03 +0000 2018,RT @cnancyxu: so @gradientpub launched today üéâ  Weekly publications on cutting-edge topics in #AI by academic and industry researchers. Wou‚Ä¶
989214862721994800,Wed Apr 25 18:49:36 +0000 2018,@gabzolina very nice. what are we looking at exactly?
988909049562284000,Tue Apr 24 22:34:25 +0000 2018,PyTorch 0.4.0 is out! https://t.co/LwDzyfwLQb lots of welcome additions: Variables/Tensor merge, more numpy-likenes‚Ä¶ https://t.co/hTwBbPlBbX
988468452493934600,Mon Apr 23 17:23:38 +0000 2018,RT @nickgrossman: John Oliver on cryptocurrencies: "everything you don't understand about money combined with everything you don't understa‚Ä¶
988131204221190100,Sun Apr 22 19:03:32 +0000 2018,Delighted to stumble by this article bringing more attention to Stanislaw Lem and his work. Very high ratio of inte‚Ä¶ https://t.co/uxxiq85rp8
987433051738202100,Fri Apr 20 20:49:19 +0000 2018,@hmason @randal_olson @Ronald_vanLoon +1 me as well, thank you.
986472582055526400,Wed Apr 18 05:12:45 +0000 2018,@de3ug After 7pm?
986455651613225000,Wed Apr 18 04:05:29 +0000 2018,@sdavidmiller numpy!
986454492534128600,Wed Apr 18 04:00:53 +0000 2018,1 hour and 5 diagrams later I optimized 100 lines of code that ran in 13 seconds to 20 lines of heavily vectorized‚Ä¶ https://t.co/h7EOC0SBsX
985266482555711500,Sat Apr 14 21:20:09 +0000 2018,@mikb0b even then, I'd be inclined to use a compute heater on moral grounds alone. At least it's doing _something_‚Ä¶ https://t.co/X5h9djdSKZ
985057866305257500,Sat Apr 14 07:31:11 +0000 2018,The QC-1 "Crypto heater" doesn't waste entropy, heats your house while mining ETH, pays for itself in ~5 years https://t.co/iTFbCocb5f
983749712762126300,Tue Apr 10 16:53:03 +0000 2018,RT @pabbeel: Existing RL methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips‚Ä¶
983425254725832700,Mon Apr 09 19:23:46 +0000 2018,Another fun entry joins the growing "RL Anonymous" collection, documenting 8 months of trying to get RL to work‚Ä¶ https://t.co/V16qmzr3Dw
982726518131441700,Sat Apr 07 21:07:14 +0000 2018,@shuieryin Try overfitting on a single fixed batch with a very small learning rate. If that doesn‚Äôt work it‚Äôs proba‚Ä¶ https://t.co/zPdpqfQ0eu
980552106187739100,Sun Apr 01 21:06:54 +0000 2018,Got a chance to try out a Bird (https://t.co/MNw4UQKfem) this morning and it is THE BEST. Waiting for someone to ph‚Ä¶ https://t.co/F7fzog9ASq
980243665598611500,Sun Apr 01 00:41:16 +0000 2018,@backus haha, it looks like we had the same fun saturday project
979490650864345100,Thu Mar 29 22:49:03 +0000 2018,RT @minimaxir: My weekend project: automatically block people in images (like in Black Mirror) using a pretrained neural network.  https://‚Ä¶
979424411408150500,Thu Mar 29 18:25:51 +0000 2018,@michael_nielsen @jimmfleming @TheAtlantic 3) paper that is persistent and can simultaneously be edited by multiple‚Ä¶ https://t.co/Rtk9xi2lIx
979424094381752300,Thu Mar 29 18:24:35 +0000 2018,@michael_nielsen @jimmfleming @TheAtlantic a better paper and pen might be 1) paper that supports delete/cut/copy/p‚Ä¶ https://t.co/4aBEvzT511
979399867750539300,Thu Mar 29 16:48:19 +0000 2018,@michael_nielsen @TheAtlantic It's frustrating how thinking feels like exploring a large idea cave serially with a‚Ä¶ https://t.co/a7VR8n30pZ
979395997544558600,Thu Mar 29 16:32:56 +0000 2018,"As We May Think" Vannevar Bush in 1945 trying to predict future https://t.co/JBqyDAPYTo "A memex is a device in wh‚Ä¶ https://t.co/8DejUzVHJv
979173920401014800,Thu Mar 29 01:50:29 +0000 2018,RT @Tesla: Model 3 is Popular Mechanics‚Äô Car of the Year https://t.co/k0a9c4X6Wq
978318163552043000,Mon Mar 26 17:10:01 +0000 2018,Haha, "YOLOv3: An Incremental Improvement" https://t.co/1sl4LHqij4 reads like good stand up comedy
977987742293360600,Sun Mar 25 19:17:02 +0000 2018,@jesseallhands yes, i meant VI - typo
977960230968442900,Sun Mar 25 17:27:43 +0000 2018,@tarinziyaee Oh crap, it‚Äôs 5am already? Let‚Äôs check my calendar for tomorrow
977957214341115900,Sun Mar 25 17:15:44 +0000 2018,Worse, I watched a few YouTube videos on it on my phone (no incognito) and now the YouTube recommendation model mus‚Ä¶ https://t.co/mzuvZt7EuO
977956174971641900,Sun Mar 25 17:11:36 +0000 2018,I‚Äôve resisted Civilization IV: Rise and Fall expansion for almost a month and a half now. This morning after an art‚Ä¶ https://t.co/NApqx0kBBl
977618080275681300,Sat Mar 24 18:48:08 +0000 2018,@randal_olson Empirically looks they way so far for the most challenging problems. Not religiously tied to it otherwise
976191766809333800,Tue Mar 20 20:20:28 +0000 2018,RT @hardmaru: "Simple random search provides a competitive approach to reinforcement learning", by Mania, Guy and @beenwrekt Paper: https:/‚Ä¶
975205338847723500,Sun Mar 18 03:00:45 +0000 2018,"Alexa, turn on the light!". "A few devices share that name, which one do you want?". "Living room". "A few devices‚Ä¶ https://t.co/jC66avIYi5
974704734073274400,Fri Mar 16 17:51:32 +0000 2018,It's very rewarding to watch the early feedback on our latest Autopilot update: https://t.co/6K1ROFrlDK a result of‚Ä¶ https://t.co/vCu8ZHJSAX
974008882015039500,Wed Mar 14 19:46:28 +0000 2018,If you squint a bit academia is a kind of blockchain. Each paper is a transaction, a block is a conference. The rev‚Ä¶ https://t.co/HRAr0O5o8a
973278513947033600,Mon Mar 12 19:24:15 +0000 2018,RT @evolvingstuff: Highly recommend this paper for practitioners of / those with an interest in Evolutionary Computation and Artificial Lif‚Ä¶
972756401511477200,Sun Mar 11 08:49:33 +0000 2018,Idea for a "metalearning-chess" variation: keep the dynamics the same but make the reward function for each game be‚Ä¶ https://t.co/KECxdM9902
972701286746353700,Sun Mar 11 05:10:33 +0000 2018,I often try to remind myself that it‚Äôs only ~6 years ago that I was hacking custom architectures with manually writ‚Ä¶ https://t.co/tIJcMwke2M
972701240017633300,Sun Mar 11 05:10:22 +0000 2018,It is starting to look like deep learning workflows of the future feature autotuned architectures running with auto‚Ä¶ https://t.co/11UphWITVm
972619046234423300,Sat Mar 10 23:43:45 +0000 2018,@sjmielke I know, I know, once you see it, you cannot unsee it :)
972579327568052200,Sat Mar 10 21:05:55 +0000 2018,@iandanforth OneNote might in fact be closest to what I had in mind so far, will do; (cc @Vitaliy)
972560848475467800,Sat Mar 10 19:52:30 +0000 2018,@Simply_Sukumar definitely not. don't think slides with cool transitions. think 100page documents packed with infor‚Ä¶ https://t.co/rlUbYCmkhL
972558363539079200,Sat Mar 10 19:42:37 +0000 2018,I lack a tool to "lay out" image/text information visually. Like a word doc but not just linearly downwards, but al‚Ä¶ https://t.co/zS8gahqhmg
972303025522921500,Sat Mar 10 02:48:00 +0000 2018,@fchollet it's based on arxiv-sanity data, so: cs.[CV|CL|LG|AI|NE]/stat.ML
972299022374289400,Sat Mar 10 02:32:06 +0000 2018,(sorry, percentages in original tweet only refer to the last month. looking at the totals so far it's 5.9% of all p‚Ä¶ https://t.co/2L8P0WRq2K
972296031466537000,Sat Mar 10 02:20:12 +0000 2018,(this is using the same code that I used in generating the original figure in my earlier Medium post‚Ä¶ https://t.co/3phIUL3dg1
972295865187512300,Sat Mar 10 02:19:33 +0000 2018,Unique mentions of deep learning frameworks in arxiv papers (full text) over time, based on 43K ML papers over last‚Ä¶ https://t.co/erNhVgnEgE
971087679579242500,Tue Mar 06 18:18:39 +0000 2018,RT @sedielem: "We conclude that the common association between sequence modeling and recurrent nets should be reconsidered, and convolution‚Ä¶
970793150779342800,Mon Mar 05 22:48:18 +0000 2018,RT @PyTorch: Tensor Comprehensions are now integrated and interoperable with @PyTorch . Read our blog post to get started: https://t.co/CJ0‚Ä¶
970439370447634400,Sun Mar 04 23:22:30 +0000 2018,RT @NathanBenaich: Your guide to AI in Q4 2017, straight from ‚òÉÔ∏è London! Check it out below üëáhttps://t.co/IVp5ALOzCd
970426320306896900,Sun Mar 04 22:30:39 +0000 2018,Google Search trends: Deep Learning vs. Bitcoin. Search traffic is not the best proxy, but I find it interesting th‚Ä¶ https://t.co/VFjNlO3e0F
970015310693609500,Sat Mar 03 19:17:26 +0000 2018,RT @rivatez: this is a much more accurate depiction of silicon valley culture than all this bro stuff  https://t.co/6igGk3zDOU
970014012246118400,Sat Mar 03 19:12:17 +0000 2018,RT @goodfellow_ian: 4 years of GAN progress (source: https://t.co/hlxW3NnTJP ) https://t.co/kmK5zikayV
967853003540594700,Sun Feb 25 20:05:12 +0000 2018,miniaturization, decreasing hardware costs and intelligence at the edge. starts to look a bit like the beginning of‚Ä¶ https://t.co/t4LNBu6Zkf
967816218924085200,Sun Feb 25 17:39:02 +0000 2018,@jigarkdoshi fixed, thanks.
967649535869599700,Sun Feb 25 06:36:42 +0000 2018,"It is believed by many that electricity fulfills more of the necessary conditions of a successful motive power for‚Ä¶ https://t.co/EM218dV2hX
967641232615731200,Sun Feb 25 06:03:42 +0000 2018,this find has made my day: "The Progress of Invention in the Nineteenth Century", written in 1900. https://t.co/xQeasnwY4v
967481495249014800,Sat Feb 24 19:28:58 +0000 2018,My email app icon badge shows that I have 1 unread email but when I open it I can‚Äôt see/find it. Hashtag the struggles of modern age :‚Äô(
966407353053560800,Wed Feb 21 20:20:42 +0000 2018,RT @hardmaru: "Policy gradient is nothing more than random search dressed up in mathematical symbols and lingo." üî•üî•üî• Another excellent arti‚Ä¶
966400357369765900,Wed Feb 21 19:52:54 +0000 2018,@quasimondo @pfau @goodfellow_ian üëè
966139043183341600,Wed Feb 21 02:34:32 +0000 2018,RT @poolio: speech cloning + few shot image generation = unlimited fake video content of anyone doing anything. deepfakes was just the tip‚Ä¶
966135056568746000,Wed Feb 21 02:18:42 +0000 2018,RT @petewarden: Blue Pill: A 75MHz 32-Bit Computer for $2! https://t.co/iQcC6BvtTp
966028634711507000,Tue Feb 20 19:15:49 +0000 2018,RT @ProjectJupyter: üéâ JupyterLab is Ready for Users üéâ  https://t.co/aOCrcuJEtQ
966028634711507000,Tue Feb 20 19:15:49 +0000 2018,RT @ProjectJupyter: üéâ JupyterLab is Ready for Users üéâ  https://t.co/aOCrcuJEtQ
966010281368236000,Tue Feb 20 18:02:53 +0000 2018,also reminds me of SENets. Information mixes too slowly across space in vanilla CNNs. would normally compensate for‚Ä¶ https://t.co/oIu1EyLKGc
966008142940131300,Tue Feb 20 17:54:23 +0000 2018,seeing self-attention (a kind of global "message passing" operation) popping up in a number of places recently, fol‚Ä¶ https://t.co/onmryU85iF
964563974262898700,Fri Feb 16 18:15:46 +0000 2018,SysML (a new systems + machine learning conference) happening today @ Stanford + live stream available https://t.co/4rX7cgW24K
964179615521521700,Thu Feb 15 16:48:28 +0000 2018,RT @soumithchintala: Tensor Comprehensions: einstein-notation like language transpiles to CUDA, and autotuned via evolutionary search to ma‚Ä¶
964179210439819300,Thu Feb 15 16:46:52 +0000 2018,RT @carpedm20: PyTorch implementation of "Efficient Neural Architecture Search via Parameters Sharing" from Google Brain https://t.co/UvGm3‚Ä¶
963850798886039600,Wed Feb 14 19:01:52 +0000 2018,"Deep Reinforcement Learning Doesn't Work Yet" https://t.co/xT7EqvIGy6 great read, hits a lot of points I've also c‚Ä¶ https://t.co/GkPrga3VjP
963665207968100400,Wed Feb 14 06:44:24 +0000 2018,Quite like the pedagogy of this visual, concrete, example-driven, "live demo" approach to a blockchain tutorial https://t.co/qJQtJEP5d7
963482386431225900,Tue Feb 13 18:37:56 +0000 2018,RT @SkydioHQ: This is Skydio R1 Frontier Edition: a self-flying camera that knows what to film and flies itself to get the best shot, letti‚Ä¶
963475318492180500,Tue Feb 13 18:09:51 +0000 2018,neat, ICLR 2018 papers sorted by their score https://t.co/HyM77rm2Ft would be fun to see it sorted by score "entrop‚Ä¶ https://t.co/dMGl9xUCWh
963470974711513100,Tue Feb 13 17:52:35 +0000 2018,New Boston Dynamics video is making rounds https://t.co/2NNd33GD3h looks very cool! Just a bit worried that behind‚Ä¶ https://t.co/fn7rE4Xs2w
961307010246492200,Wed Feb 07 18:33:46 +0000 2018,It looks like if you bombard Earth with photons for a while, it can emit a Roadster. hah
961003510744604700,Tue Feb 06 22:27:46 +0000 2018,There is a Roadster in space. And it has a live feed: https://t.co/3S8AWf9wwj definitely the fastest car :) https://t.co/2XR05bg1ON
961000903833567200,Tue Feb 06 22:17:24 +0000 2018,RT @elonmusk: View from SpaceX Launch Control. Apparently, there is a car in orbit around Earth. https://t.co/QljN2VnL1O
960982793550364700,Tue Feb 06 21:05:26 +0000 2018,RT @SpaceX: Falcon Heavy side cores have landed at SpaceX‚Äôs Landing Zones 1 and 2. https://t.co/oMBqizqnpI
960982775942688800,Tue Feb 06 21:05:22 +0000 2018,RT @SpaceX: Liftoff! https://t.co/2ypESsi1sF
960929107197403100,Tue Feb 06 17:32:07 +0000 2018,RT @OriolVinyalsML: Evolution &gt; RL (for now...) for architecture search. New SOTA on CIFAR10 (2.13% top 1) and ImageNet (3.8% top 5). üî• 450‚Ä¶
960589356376277000,Mon Feb 05 19:02:04 +0000 2018,RT @elonmusk: Falcon Heavy sends a car to Mars https://t.co/Y7uBtU6Mt2
960569652140060700,Mon Feb 05 17:43:46 +0000 2018,@MichaelNied1 @michael_nielsen I randomly noticed it in a bookstore, didn't do much research about it before. It's‚Ä¶ https://t.co/MJyPAF6BXm
960560619249287200,Mon Feb 05 17:07:52 +0000 2018,@elontimes yes, like that, but with more deep learning LSTM something something :)
960560348569878500,Mon Feb 05 17:06:48 +0000 2018,@Eklavya_FCB @michael_nielsen hmm, but I find Anki's very non-flashy, clunky, looks-like-someones-side-project UI kind of endearing :D
960558703588999200,Mon Feb 05 17:00:15 +0000 2018,Makes me want to work on a browser extension where you can highlight some text from an article on the web and the e‚Ä¶ https://t.co/4NceeDGCSG
960558005279375400,Mon Feb 05 16:57:29 +0000 2018,I tried to Ankify some facts yesterday from a book I'm reading (on how humans are destroying nature, it's really qu‚Ä¶ https://t.co/BftwRYsQBS
960556555526524900,Mon Feb 05 16:51:43 +0000 2018,Getting fairly addicted to Anki as a result of this twitter thread from @michael_nielsen &amp; few posts I've encounter‚Ä¶ https://t.co/rEUz1tkARI
960305002664218600,Mon Feb 05 00:12:08 +0000 2018,The Secret Life of Plankton https://t.co/DeKNJpeOgF i still can't quite wrap my head around our laws of physics app‚Ä¶ https://t.co/03JA4jbduW
958810204266684400,Wed Jan 31 21:12:21 +0000 2018,RT @pabbeel: ICLR accepted paper analysis by Arthur Pajot.  Berkeley coming in second after Google, followed by Stanford, CMU, Facebook, Mi‚Ä¶
957371714781917200,Sat Jan 27 21:56:18 +0000 2018,- Sometimes find my phone in morning uncharged. I suspect alerts vibrate the phone to the edge of the charging plat‚Ä¶ https://t.co/YD0Renf5UU
957368412434346000,Sat Jan 27 21:43:11 +0000 2018,@LayOn_OverWhale you had to press the button to wake the phone, and then swipe. now you just swipe. so if you simpl‚Ä¶ https://t.co/wSPQ56fh2g
957360134291832800,Sat Jan 27 21:10:17 +0000 2018,My iPhoneX switch has turned out to be a UX regression: - Face ID doesn't work: when phone is on table next to me.‚Ä¶ https://t.co/2AjMxJvEqc
957044269256122400,Sat Jan 27 00:15:09 +0000 2018,@visarga @PowerDNS_Bert absolutely! gene regulatory networks look very much like neural networks, except implemente‚Ä¶ https://t.co/sTpDrwuC5D
956779545952075800,Fri Jan 26 06:43:14 +0000 2018,@rupspace The code would be readable just fine basically forever. We can fight about this later :)
956778322922369000,Fri Jan 26 06:38:22 +0000 2018,DNA seen through the eyes of a coder https://t.co/mYURxxmXsb I like this a lot.
955894369181081600,Tue Jan 23 20:05:51 +0000 2018,RT @gwern: Best of 2017 links: https://t.co/sGmz6zvigk
954916614608117800,Sun Jan 21 03:20:37 +0000 2018,@Grady_Booch Haha, i'm talking about (convolutional neural network) architectures. As I always do.
954914791264366600,Sun Jan 21 03:13:22 +0000 2018,@filippie509 hahah :D. "We propose a new architecture (see Appendix A). Section 2: Experiments"
954913831532179500,Sun Jan 21 03:09:33 +0000 2018,Instead trying to describe an architecture in a paper with words, tables and diagrams across 2 sections and 4 pages‚Ä¶ https://t.co/vuiRo13yEk
954476136628564000,Fri Jan 19 22:10:18 +0000 2018,RT @PyTorch: We are a year old :) A post looking back at our journey, the lovely community, the engineering and love. https://t.co/a6AfIALI‚Ä¶
954256656807809000,Fri Jan 19 07:38:10 +0000 2018,UC Berkeley EECS Colloquium talk on GraphCore's Colossus IPU https://t.co/6H6alJ3wSM
953041830278410200,Mon Jan 15 23:10:53 +0000 2018,faster-rcnn.pytorch https://t.co/i0ZP0dKryy object detection is deceivingly highly error-prone, tricky, and labor i‚Ä¶ https://t.co/6WsHmWWW9k
952740110558048300,Mon Jan 15 03:11:58 +0000 2018,RT @CadeMetz: How big is the sudden explosion of startups building AI chips? There are 45 of them, and at least five have raised $100 milli‚Ä¶
952254784706248700,Sat Jan 13 19:03:27 +0000 2018,@cipri_tom None ^_^
950617826338881500,Tue Jan 09 06:38:46 +0000 2018,RT @hardmaru: KaTeX is so much better than MathJax https://t.co/4Q4jBnqwl1
950424871036530700,Mon Jan 08 17:52:01 +0000 2018,@EmilWallner when i first read it: cool! now: ugh.
950171329466048500,Mon Jan 08 01:04:32 +0000 2018,A long while ago I came across a great document describing the human brain strictly as a computing device, from a c‚Ä¶ https://t.co/q4WymBwOwW
949809136509702100,Sun Jan 07 01:05:19 +0000 2018,Reading Silicon: How to Reverse Engineer Integrated Circuits https://t.co/HIx2ajUZeQ wow. I felt proud reverse engi‚Ä¶ https://t.co/hvyG0COPyd
949527089744552000,Sat Jan 06 06:24:34 +0000 2018,Curiously, the dynamics of this system are such that when you bombard hot earth stuff with photons for a while, it‚Ä¶ https://t.co/eDX2gIPYAv
949387481379627000,Fri Jan 05 21:09:48 +0000 2018,@tpanum felt a bit too much like a washed-down, slightly more mysterious outtake from Terminator
949386870382780400,Fri Jan 05 21:07:23 +0000 2018,@LayOn_OverWhale I liked that it's one of the more believable and very much on the horizon episodes. You already se‚Ä¶ https://t.co/UcK9xODarW
949377679437922300,Fri Jan 05 20:30:52 +0000 2018,@whiskeyandwry Agree, they are starting to recycle some themes now, not always with a fresh enough perspective.
949377464978915300,Fri Jan 05 20:30:00 +0000 2018,@agbutteriss what _really_ bothered me is that person's memories are obviously not encoded in their entirety in their DNA. It's just dumb.
949376276959084500,Fri Jan 05 20:25:17 +0000 2018,@TJzafar haha barely!
949376168863588400,Fri Jan 05 20:24:51 +0000 2018,Overall a solid season. I like that there seems to be a lot of disagreement over the episode ranking with people i'‚Ä¶ https://t.co/jzmBFldO8h
949375690654171100,Fri Jan 05 20:22:57 +0000 2018,Black Mirror Season 4: 1. "Hang the DJ" - fun twist 2. "USS Callister" - entertaining but unrealistic 3. "Arkangel"‚Ä¶ https://t.co/PhJJLpBHkQ
949196481977729000,Fri Jan 05 08:30:51 +0000 2018,Cool analysis (but overall a bit of a missed opportunity) from RescueTime on productivity trends‚Ä¶ https://t.co/PHQxtFNyMv
949142465805561900,Fri Jan 05 04:56:12 +0000 2018,@RuchiJain_ 5 out of 5 means there are only very few reviews
949123388328493000,Fri Jan 05 03:40:24 +0000 2018,Basically everything is rated in range of 3.5-4.2 out of 5.
948755604755038200,Thu Jan 04 03:18:57 +0000 2018,RT @OriolVinyalsML: "Optimal" running, brought to you by Deep RL. https://t.co/NimTGxSDbu https://t.co/Sln3HO68Ot
948389452916772900,Wed Jan 03 03:04:00 +0000 2018,RT @dennybritz: I wrote up a (not so brief) summary of AI developments that stood out to me in 2017  https://t.co/3oLEOlC1GE
948381506858135600,Wed Jan 03 02:32:25 +0000 2018,RT @LauraDeming: Sorry for the late posting! I made a research primer (https://t.co/WqfzklS65I) - would love any feedback/thoughts/comments.
947631546281836500,Mon Jan 01 00:52:21 +0000 2018,China Shuts Down Its Legal Ivory Trade https://t.co/OMvs9h897U prices of ivory drop 65%. %chance of a good future += 0.0001
944347285105676300,Fri Dec 22 23:21:52 +0000 2017,RT @SpaceX: A Red Car for the Red Planet https://t.co/PakS3rvp5C https://t.co/440bvUHJeO
944346807655579600,Fri Dec 22 23:19:58 +0000 2017,RT @Tim_Dettmers: Deep learning hardware limbo is the battle between @Nvidia vs @AMD vs @IntelNervana for the throne of deep learning hardw‚Ä¶
941761197346455600,Fri Dec 15 20:05:41 +0000 2017,RT @zzznah: My submissions for #nips4creativity are here https://t.co/VSdCJW2lPE https://t.co/KJtnjYViAo
941068821325942800,Wed Dec 13 22:14:25 +0000 2017,@_karfly a great specimen, adding! :)
941059591160217600,Wed Dec 13 21:37:45 +0000 2017,Visual Domain Decathlon - classify 10 datasets at the same time https://t.co/WJ8xGrbxWV a fun setup, brings some pr‚Ä¶ https://t.co/fSNcn93ayu
940496521136545800,Tue Dec 12 08:20:18 +0000 2017,RT @JeffDean: Slides from my talk in yesterday's ML Systems workshop are now up at  https://t.co/cbCLDMqF3T #NIPS2017
940496191728468000,Tue Dec 12 08:19:00 +0000 2017,RT @JeffDean: If you're interested in learning to do machine learning research, you should investigate the Google AI Residency program.  Ap‚Ä¶
940386390751064000,Tue Dec 12 01:02:41 +0000 2017,RT @RichardSocher: https://t.co/ZmHFcIFQxw Interesting visualization of how much Twitter-based influence/mindshare people/organizations hav‚Ä¶
940257777267621900,Mon Dec 11 16:31:37 +0000 2017,RT @chrmanning: Machine Learning just ate Algorithms in one large bite, thx to @tim_kraska, @alexbeutel, @edchi, @JeffDean  &amp; Polyzotis at‚Ä¶
939179243493236700,Fri Dec 08 17:05:55 +0000 2017,RT @fchollet: My book Deep Learning with Python has been officially released yesterday -- it's now shipping. 384 pages of deep learning, wi‚Ä¶
938593138217586700,Thu Dec 07 02:16:57 +0000 2017,RT @haldaume3: .@ylecun replies to Ali Rahimi's "alchemy" and Ali replies to that. v nice!  my opinion is empirical work is great w/o provi‚Ä¶
938530722058399700,Wed Dec 06 22:08:55 +0000 2017,RT @ctnzr: People have been asking for a fast open source CUDA matrix multiplication for ages. My colleagues just released one! In many cas‚Ä¶
938530710440177700,Wed Dec 06 22:08:53 +0000 2017,Block-Sparse GPU Kernels release from OpenAI https://t.co/lzhxRV0Qlj
938529389469298700,Wed Dec 06 22:03:38 +0000 2017,Some strong results reported in Chess from AlphaZero (an AlphaGo generalization) https://t.co/yiQJkRRcuV winning ag‚Ä¶ https://t.co/Qyh1XIrce9
938229734445523000,Wed Dec 06 02:12:54 +0000 2017,RT @PyTorch: New release[v0.3.0]: Performance improvements, new layers, ship models to other frameworks (via ONNX), CUDA9, CuDNNv7, lots of‚Ä¶
938193659161276400,Tue Dec 05 23:49:33 +0000 2017,RT @seb_ruder: New blog post: Optimization for Deep Learning Highlights in 2017 https://t.co/gnc3IueS8r
937863347982164000,Tue Dec 05 01:57:01 +0000 2017,(Thanks to everyone who expressed interest. Tonight's event is being postponed, we'll share more information soon)
937768490668191700,Mon Dec 04 19:40:05 +0000 2017,To friends attending NIPS: we'd like to invite you to our AI fireside chat and party!  Starts at 7pm tonight. If yo‚Ä¶ https://t.co/gpu2Rwmcco
936662960679743500,Fri Dec 01 18:27:06 +0000 2017,(bracing myself for people who really like Photoshop and feel strongly that this is really just a continuation of the smart brush :))
936661664602005500,Fri Dec 01 18:21:57 +0000 2017,@SethHWeidman Nice, but don't think you're seeing the full force and scope of my original post. (Which of course is‚Ä¶ https://t.co/ngVPkJxHz8
936659464295346200,Fri Dec 01 18:13:13 +0000 2017,HoME: a Household Multimodal Environment https://t.co/IdWY3N6xej looks pretty cool! vision, audio, semantics, physi‚Ä¶ https://t.co/GTi0HkZpf7
936658409247477800,Fri Dec 01 18:09:01 +0000 2017,Wow, GANs are on a roll. Quite amazing results from pix2pixHD: https://t.co/sJUNWiWd9i Also the most tangible glimp‚Ä¶ https://t.co/E5BzA41Skd
935942409124421600,Wed Nov 29 18:43:53 +0000 2017,RT @goodfellow_ian: ML researchers, reviewers, and press coverage of ML need to get a lot more serious about statistically robustness of re‚Ä¶
935236980060778500,Mon Nov 27 20:00:46 +0000 2017,RT @OriolVinyalsML: Great stuff from @maxjaderberg et al on hyperparameter search based on evolving populations that actually outperforms r‚Ä¶
934504706386231300,Sat Nov 25 19:30:58 +0000 2017,Can't find a website, but name is Sean Kilcoyne (sean3v@hotmail.com). A lot of beautiful work. (@ Market in SF near ferry building)
934503967685460000,Sat Nov 25 19:28:02 +0000 2017,Randomly picked up this beauty from an artist on a street market. https://t.co/4fKTcIoOgB
933834166021513200,Thu Nov 23 23:06:29 +0000 2017,@Imaculate3 nope, long gone, forever.
933767141312139300,Thu Nov 23 18:40:09 +0000 2017,@_AntreasAntonio \alpha_k ? :) Almost my initials
933763912045965300,Thu Nov 23 18:27:19 +0000 2017,Haha! :) And I thought I'd have to stay in physics if I wanted my own constants. https://t.co/bHG0dbK7oT
933031548982517800,Tue Nov 21 17:57:10 +0000 2017,@thvasilo it's in the plans, for the last year :) I wish I had the time, sorry :(
931391751100575700,Fri Nov 17 05:21:12 +0000 2017,RT @Tesla: https://t.co/0rBaJNQrum https://t.co/pyoDmOj4XC
931391532069879800,Fri Nov 17 05:20:20 +0000 2017,RT @jackclarkSF: Untethered 'Atlas' robot backflip. Pretty incredible stuff from Boston Dynamics.  https://t.co/hJo4pO1RwG https://t.co/Nc8‚Ä¶
930927349255643100,Wed Nov 15 22:35:50 +0000 2017,RT @OpenAI: Are you a programmer who wants to get into deep learning? Apply to our Machine Learning Fellow role: https://t.co/15Oatnkw2t
930353679001034800,Tue Nov 14 08:36:16 +0000 2017,RT @Reza_Zadeh: The New Computing Stack:  - GPUs/TPUs are eating Linear Algebra. - Linear Algebra is eating Deep Learning. - Deep Learning‚Ä¶
930350573731201000,Tue Nov 14 08:23:56 +0000 2017,Very good reading from Rodney Brooks "The seven deadly sins of predicting the future of AI" https://t.co/l8MnwBnQqj
930269464410464300,Tue Nov 14 03:01:38 +0000 2017,RT @soumithchintala: use gradient magnitude as a signal for gradient importance.  Sort your gradients, find a threshold, clip your gradient‚Ä¶
929953576905982000,Mon Nov 13 06:06:25 +0000 2017,RT @hardmaru: Evolution Strategy Variant + OpenAI Gym https://t.co/t2R0QQ5qcH
929953203218550800,Mon Nov 13 06:04:55 +0000 2017,RT @petewarden: Deep Learning is Eating Software - https://t.co/RPS885THdC - a post inspired by chatting with @karpathy about Software 2.0!
929473842749120500,Sat Nov 11 22:20:07 +0000 2017,New blog post: "Software 2.0" https://t.co/psXB9T1anp
929424549115863000,Sat Nov 11 19:04:15 +0000 2017,RT @quasimondo: Facefeedback II https://t.co/XuFlNWGJ7r
929184035309469700,Sat Nov 11 03:08:32 +0000 2017,RT @hnisimasu: Single-molecule movie of DNA search and cleavage by CRISPR-Cas9. https://t.co/3NQxmbvzJF
929183583385747500,Sat Nov 11 03:06:44 +0000 2017,RT @sla: Preferred Networks achieved 74.9% accuracy on ImageNet training in 15min, the world's fastest result using ChainerMN and 1,024 P10‚Ä¶
928929643196854300,Fri Nov 10 10:17:40 +0000 2017,RT @GaborMelis: Give your baselines some love and they might surprise you: https://t.co/Bi0sZCw76r
928502913579696100,Thu Nov 09 06:02:00 +0000 2017,@taehoonleeml looks like @RemiCadene also has a PyTorch implementation here as few hours ago: https://t.co/4fjAMAly7E
928501896813330400,Thu Nov 09 05:57:57 +0000 2017,@taehoonleeml wow, nicely done! (if equivalent.) need to step through :s, really not looking forward to
928453696979009500,Thu Nov 09 02:46:25 +0000 2017,Google released NASNet in TF a ~week ago, which is exciting https://t.co/cwXKDVzriP the code is a bit difficult to‚Ä¶ https://t.co/bqifZILdOU
927981664919208000,Tue Nov 07 19:30:44 +0000 2017,RT @ch402: What do neural nets see? You may be surprised. @zzznah @ludwigschubert &amp; I explore. https://t.co/bLQMQLYz9c https://t.co/9uOL6uF‚Ä¶
926950061241548800,Sat Nov 04 23:11:31 +0000 2017,RT @jeremyphoward: Very handy reference to relative Imagenet performance of many recent architectures https://t.co/05IiapgtiC https://t.co/‚Ä¶
925605588792369200,Wed Nov 01 06:09:03 +0000 2017,TensorFlow Eager https://t.co/lGc6lVjWB8 now more like Chainer, as a response to PyTorch
925196035818889200,Tue Oct 31 03:01:38 +0000 2017,@gwern @hardmaru (e.g. forward a batch through backbone, then pick pairs, make virtual examples batch, evaluate los‚Ä¶ https://t.co/NxzVMw5e3G
925194505543811100,Tue Oct 31 02:55:34 +0000 2017,@gwern @hardmaru also "where (xi,yi) and (xj,yj ) are two feature-target vectors drawn at random from the training‚Ä¶ https://t.co/KGZU6sVCZH
925193141111570400,Tue Oct 31 02:50:08 +0000 2017,@gwern @hardmaru I had the same question. Paper does say "prior knowledge that linear interpolations of feature vec‚Ä¶ https://t.co/7qKvsYCFUg
925192096788529200,Tue Oct 31 02:45:59 +0000 2017,RT @hardmaru: Mixup: Beyond Empirical Risk Minimization. Use random linear interpolation for data &amp; labels to increase robustness of networ‚Ä¶
924865988968857600,Mon Oct 30 05:10:09 +0000 2017,Efficient Processing of Deep Neural Networks: A Tutorial and Survey https://t.co/1YkpCPxOcE good reading.
924709028416053200,Sun Oct 29 18:46:27 +0000 2017,@mrdonut oh yeah :s sorry, i'll try to bring it back. will call them to see what's happening.
924470737334763500,Sun Oct 29 02:59:34 +0000 2017,(the phrase "pretty cool" is specific, and refers to my earlier post on VR problems https://t.co/6NXEJf9Fvj)
924470514160091100,Sun Oct 29 02:58:41 +0000 2017,"Why Snapchat Spectacles failed" https://t.co/jDDpQRE83E I had both Google Glass &amp; Spectacles. They were "pretty cool", like VR, Kinect etc.
924398490192461800,Sat Oct 28 22:12:29 +0000 2017,RT @quasimondo: Looks like nobody reads the README. There is a 1 hour clip of @nvidias's generated faces with just 166 views: https://t.co/‚Ä¶
924362569619456000,Sat Oct 28 19:49:45 +0000 2017,@jacobandreas üî•üî•üî•
924341334055403500,Sat Oct 28 18:25:22 +0000 2017,Article also correct to point out the very small few months (~3) payback costs wrt AWS for these kinds of configs
924340245478256600,Sat Oct 28 18:21:02 +0000 2017,"DeepLearning11: 10x NVIDIA GTX 1080 Ti Single Root Deep Learning Server." That's a lot of firepower for $16K https://t.co/f5v7HdevXJ
924108651119251500,Sat Oct 28 03:00:46 +0000 2017,There are only a few things that compete for top spots on my "what would I do with an exaflop computer". This is now up there.
924107414000898000,Sat Oct 28 02:55:51 +0000 2017,0_o https://t.co/M3yB6rzTiO
924107119585927200,Sat Oct 28 02:54:41 +0000 2017,wow, blown away &amp; hypnotized by results from Progressive Growing of GANs https://t.co/hMpersJEps &amp; code on github: https://t.co/dLTld3Tc6L
923758019757797400,Fri Oct 27 03:47:29 +0000 2017,RT @fhuszar: AlphaGo Zero: the Minimal Policy Improvement principle, connections to vector fields, EP, Contrastive Divergence https://t.co/‚Ä¶
923252189878935600,Wed Oct 25 18:17:29 +0000 2017,@smc90 :) np, like the podcast! one of my favorites
923225824307716100,Wed Oct 25 16:32:43 +0000 2017,Heard my name name dropped on the latest a16z podcast during my morning commute, wrt AI. Unfortunately they think I work at Google ;'(
921915708539256800,Sun Oct 22 01:46:47 +0000 2017,Good &amp; quick to the point reading: "Introduction to High Performance Scientific Computing" [book pdf] https://t.co/QOiEqZmUn7
921257591254032400,Fri Oct 20 06:11:40 +0000 2017,RT @Smerity: A fascinating discussion of Fermi Paradox / Drake Equation parameters that shifted my thinking on the matter üôÇ Link: https://t‚Ä¶
920736843909312500,Wed Oct 18 19:42:24 +0000 2017,My fave part is that the prediction accuracy on professional moves goes up during training, and then eventually goes down a bit. Nice.
920733867681521700,Wed Oct 18 19:30:35 +0000 2017,Should add that it's quite general, but within limits. Not all applications (most) allow a simulator and self-play https://t.co/tI3VkUGYsT
920733502500356100,Wed Oct 18 19:29:08 +0000 2017,AlphaGo Zero https://t.co/ylFOFZl3jf v cool based on skim: no sup pretraining, raw board input, resnet, new training scheme. more magic.
919974751312928800,Mon Oct 16 17:14:07 +0000 2017,RT @NathanBenaich: Welcome to Issue 21 - Part 1 of 2! ü§ì https://t.co/FVuX59UqG8
919779463721656300,Mon Oct 16 04:18:07 +0000 2017,Stanford's EE380 Colloquium on Computer Systems videos https://t.co/A9PLUV7Jzm
919424442442301400,Sun Oct 15 04:47:23 +0000 2017,@LH Sounds legit.
919396251849728000,Sun Oct 15 02:55:22 +0000 2017,The heat expelled from the back of a computer makes me sad.
918578398405914600,Thu Oct 12 20:45:31 +0000 2017,RT @genekogan: it's like a Shepard tone. the center mask appears as if it's cascading outwards, but it's an illusion. it always stays in th‚Ä¶
918511175352008700,Thu Oct 12 16:18:23 +0000 2017,@brandondamos e.g. sometimes the activations have strong columns, or are weirdly sparse or weirdly dense, or some ReLU neurons die, etcetc
918510983902982100,Thu Oct 12 16:17:38 +0000 2017,@brandondamos more generally, curious how one could measure overall "health" of a network. When you look at loss/ac‚Ä¶ https://t.co/jw9J9c3fGc
918299912189513700,Thu Oct 12 02:18:54 +0000 2017,An uncharacteristically good discussion spotted on r/ML https://t.co/kqqErqjMtV TLDR: use trunc float32 ("bfloat16") instead of float16
918162458098810900,Wed Oct 11 17:12:43 +0000 2017,RT @OpenAI: AIs which develop faking, tackling, blocking, kicking through self-play: https://t.co/Ml4AAqFa67
917954439029276700,Wed Oct 11 03:26:07 +0000 2017,RT @pabbeel: Deep RL Bootcamp lecture videos and labs release https://t.co/XNUmQ5SHkx! :)  [Organized by @pabbeel, Peter Chen, Rocky Duan,‚Ä¶
916807828362293200,Sat Oct 07 23:29:54 +0000 2017,@pedrordz wat
916807347703398400,Sat Oct 07 23:27:59 +0000 2017,Every noise at once https://t.co/YnFu2cJeBB lays out all possible music in 2D + spotify samples. very cool.
916206859131879400,Fri Oct 06 07:41:52 +0000 2017,@dauber @3Blue1Brown @lishali88 :) spotted on top of r/MachineLearning
916201024813015000,Fri Oct 06 07:18:41 +0000 2017,I'm apparently quite late to the party, but I discovered a very good/thorough math YouTube channel; 3Blue1Brown: https://t.co/TKIEVx10jf
916027459593691100,Thu Oct 05 19:48:59 +0000 2017,RT @goodfellow_ian: Google Brain Residency has been upgraded to Google AI Residency. Now possible to work with more AI teams at Google. htt‚Ä¶
915663462751076400,Wed Oct 04 19:42:36 +0000 2017,RT @OriolVinyalsML: WaveNet becomes the voice of Google Assistant! 1000x faster &amp; better, brought to you by a neural net : ) https://t.co/6‚Ä¶
915260543824314400,Tue Oct 03 17:01:33 +0000 2017,@KelloggsUS Hi, there are not enough raisins in your Raisin Bran. This is causing me significant distress.
913799302735994900,Fri Sep 29 16:15:05 +0000 2017,RT @OpenAI: Deep linear networks can learn to perform nonlinear computation due to imprecision in floating point arithmetic: https://t.co/T‚Ä¶
913655857115627500,Fri Sep 29 06:45:05 +0000 2017,@jeremyphoward frequent conversation could be a hint of something amiss. I don't see insight from "I used 50 pretra‚Ä¶ https://t.co/boyHLwJfTq
913654199170170900,Fri Sep 29 06:38:30 +0000 2017,RT @SpaceX: Supporting the creation of a permanent, self-sustaining human presence on Mars. https://t.co/kCtBLPbSg8 https://t.co/ra6hKsrOcG
913619934575390700,Fri Sep 29 04:22:21 +0000 2017,Kaggle competitions need some kind of complexity/compute penalty. I imagine I must be at least the millionth person who has said this.
913618235337064400,Fri Sep 29 04:15:36 +0000 2017,My favorite quote is from the winning solution (https://t.co/p6fH7lb3s7)  "9.I tried bayesian inference but I found it was not helpful." LOL
913618108199211000,Fri Sep 29 04:15:05 +0000 2017,Reading through winners of the Amazon Space Kaggle competition https://t.co/ylMZFYr10A the solutions are out of control with ensembles
913611634647621600,Fri Sep 29 03:49:22 +0000 2017,(for a long while I preferred writing backprop manually in raw numpy instead of adopting Theano. irrationally so. good old days.)
913610558166855700,Fri Sep 29 03:45:05 +0000 2017,RIP Theano https://t.co/xPn1umD86b I was never able to pick it up, but it was _the_ thing to use for deep learning for a good while.
911494923135811600,Sat Sep 23 07:38:19 +0000 2017,"Facebook, you needy sonofabitch" https://t.co/Zamv9fhopx hits a nerve. You can measure my click throughs but you can't measure my annoyance
910335579316830200,Wed Sep 20 02:51:29 +0000 2017,When my loss goes down it's not "cool, it's working!", it is "hmm it should be going down faster, something must be wrong". Okay, &lt;/rant&gt;.
910334146748149800,Wed Sep 20 02:45:48 +0000 2017,The "move fast &amp; fix stuff until it compiles then it's probably fine" approach is inadequate when each bug silently subtracts 2% accuracy.
910333448790827000,Wed Sep 20 02:43:02 +0000 2017,To get neural nets to work one must be super-OCD about details. With bugs nets will train (they "want" to work), but work silently worse.
909601650045677600,Mon Sep 18 02:15:07 +0000 2017,@hardmaru should be explicitly pointed that this is for an AlexNet, not ResNet-50 for which they match the time. Bi‚Ä¶ https://t.co/l526KrCjSV
909593391641518100,Mon Sep 18 01:42:18 +0000 2017,RT @hardmaru: ImageNet Training in 24 Minutes. "Our hardware budget is only $1.2M, which is 3.4 times lower than Facebook's $4.1M" https://‚Ä¶
909592435440869400,Mon Sep 18 01:38:30 +0000 2017,spotted on PyTorch Slack :D dynamicgraphs.png https://t.co/Wgi4vL9yEQ
909215510646026200,Sun Sep 17 00:40:44 +0000 2017,@hholst80 "It might not catch an existing bug...". that's a bug.
909149999174344700,Sat Sep 16 20:20:25 +0000 2017,One of more unintuitive Python gotchas is that assert is a statement not a function. Can easily introduce large bugs https://t.co/vAUtLZ2N4L
908868908563652600,Sat Sep 16 01:43:28 +0000 2017,RT @lxbrun: Deep learning hype in one picture (NIPS conference registrations, 2002 through 2017) #nips2017 https://t.co/APOrzY1gpD
907294467723374600,Mon Sep 11 17:27:12 +0000 2017,RT @evolvingstuff: "5-10x faster than cuDNN-optimized LSTM" Training RNNs as Fast as CNNs https://t.co/Cs4WDXgoiW PyTorch source code: http‚Ä¶
906976288824422400,Sun Sep 10 20:22:52 +0000 2017,(I actually use a different 3-letter acronym but I'll try to keep my feed pg13 :))
906975947332632600,Sun Sep 10 20:21:31 +0000 2017,alias wat='python -m pdb -c continue' # you're welcome
906732707329085400,Sun Sep 10 04:14:58 +0000 2017,RT @ylecun: Fast.ai has switched from Keras+TensorFlow to PyTorch for their deep learning course. They tell us why in great... https://t.co‚Ä¶
905858379230281700,Thu Sep 07 18:20:42 +0000 2017,RT @PyTorch: You can now export our models to other frameworks, starting with @caffe2ai and @mscntk. Run them on mobile and production! #re‚Ä¶
905666952584077300,Thu Sep 07 05:40:02 +0000 2017,"The Relationship Between Hurricanes and Climate Change" https://t.co/3xGO3BvWz1 &amp; Global Greenhouse Emissions data https://t.co/cOpJLDcLlt
904820359022559200,Mon Sep 04 21:35:58 +0000 2017,(already linked to this once before) "Risks with Infinite impact": https://t.co/f8DL2Gqr58 [pdf]
904808674845007900,Mon Sep 04 20:49:33 +0000 2017,A ConvNet that is given a label before it did the forward pass cannot do the backward pass.
904807765931024400,Mon Sep 04 20:45:56 +0000 2017,Ideally never absorb information without predicting it first. Then you can update both 1) your knowledge but also 2) your generative model.
904441448128327700,Sun Sep 03 20:30:19 +0000 2017,@usmanghani I found "Professional CUDA C Programming" lying around, read some, coded some, then just kept going. Di‚Ä¶ https://t.co/0xsV5eAy6V
904433891573776400,Sun Sep 03 20:00:17 +0000 2017,I've only picked up GPU/CUDA at random. Actually working through CUDA book from Chapter1 proving to be something I should have done long ago
902972008467595300,Wed Aug 30 19:11:17 +0000 2017,@yashk2810 interns welcome!
902971190368550900,Wed Aug 30 19:08:02 +0000 2017,We're hiring strong ML/CV/Roboticists for the Tesla Autopilot Vision team. We ship autonomy at scale. Join us: vision@tesla.com
901999322597752800,Mon Aug 28 02:46:11 +0000 2017,RT @lishali88: Full house at last talk of #deepRLbootcamp! Thank you @pabbeel, Rocky Duan, Peter Chen, @karpathy and TAs for a great weeken‚Ä¶
901313926574465000,Sat Aug 26 05:22:40 +0000 2017,@kevin_zakka More like no time to shave :p
901308221750521900,Sat Aug 26 05:00:00 +0000 2017,Last minute preparation for the Deep RL Bootcamp :) @pabbeel https://t.co/9gGIu12lvk
900977368805724200,Fri Aug 25 07:05:18 +0000 2017,@necro351 see next tweet
900933445311791100,Fri Aug 25 04:10:46 +0000 2017,If you voted "other" in the previous poll, the other is:
900930713171525600,Fri Aug 25 03:59:55 +0000 2017,@moyix LOL
900929602956140500,Fri Aug 25 03:55:30 +0000 2017,Your editor.
900410327241596900,Wed Aug 23 17:32:05 +0000 2017,@yieldthought oh stop it! :)
900029475080904700,Tue Aug 22 16:18:43 +0000 2017,not for any reason to do with humans. As in, the Universe is worse off without a forest than with a forest in some metric.
900029300270706700,Tue Aug 22 16:18:01 +0000 2017,It seems intuitive that a thriving life ecosystem (e.g. jungle) is valuable &amp; that deforestation is morally wrong. Can't formalize why.
899885064909070300,Tue Aug 22 06:44:53 +0000 2017,Tonight is a good night to read through NVIDIA's V100 GPU architecture white paper https://t.co/ODEy7WuHZs
898766318618333200,Sat Aug 19 04:39:23 +0000 2017,@anmolsj Not that I'm aware of
898761218185285600,Sat Aug 19 04:19:07 +0000 2017,:) would add few categories, esp profiling, size/interpretability of lib code base, distributed training, community/support, ...
898759907091951600,Sat Aug 19 04:13:54 +0000 2017,Pretty good list. Except the article makes it sound like there's a contest. https://t.co/lbQJ7j8dwZ
898601408680808400,Fri Aug 18 17:44:05 +0000 2017,Straight forward progression. We first didn't learn anything. Then just the classifier. Then just the ConvNet params. Now also architecture.
898601035458953200,Fri Aug 18 17:42:36 +0000 2017,RT @hardmaru: Neural Architecture Search discover efficient ConvNets that require much fewer parameters and use less computation. https://t‚Ä¶
897316028320849900,Tue Aug 15 04:36:27 +0000 2017,RT @petewarden: I have a free 60-page O'Reilly ebook out called "Building Mobile Applications with @TensorFlow"! https://t.co/Pc9hMX2F8j
896783291906351100,Sun Aug 13 17:19:32 +0000 2017,Thanks for the link! TIL: "Shepard Tone", the musical illusion that monotonically builds tension https://t.co/FlbFr3T2CZ
896781217781039100,Sun Aug 13 17:11:18 +0000 2017,@prajax_ Wow, this is just about the best thing I've seen this month :D
896780482695712800,Sun Aug 13 17:08:23 +0000 2017,@atroyn haha! I'll try it out today. I'm somewhat scared it will lose its punch if I keep it on repeat too long. Ve‚Ä¶ https://t.co/PXcJB229Rl
896780482695712800,Sun Aug 13 17:08:23 +0000 2017,@atroyn haha! I'll try it out today. I'm somewhat scared it will lose its punch if I keep it on repeat too long. Ve‚Ä¶ https://t.co/PXcJB229Rl
896779062479212500,Sun Aug 13 17:02:44 +0000 2017,Listening to Hans Zimmer (e.g., "no time for caution" from the Interstellar docking scene) makes even the most mundane things feel Epic.
896166726055755800,Sat Aug 12 00:29:32 +0000 2017,Awesome work from @OpenAI: Dota 2 bot, a neural net trained with self-play beats the world's top players at 1v1. Le‚Ä¶ https://t.co/UIyjukuT6Z
896122333563207700,Fri Aug 11 21:33:08 +0000 2017,Neat, the CS231n 2017 lecture videos are now up: https://t.co/pmjPvJSFtq I hear that was a lot of work :) great job @jcjohnss and @syeung10!
896120271756640300,Fri Aug 11 21:24:56 +0000 2017,@geoffreyirving yeeea about that
895347940390191100,Wed Aug 09 18:15:58 +0000 2017,RT @OriolVinyalsML: Launching StarCraft2 Learning Environment (Linux)! A3C baseline on mini &amp; full game + policies trained on 1M replays.ht‚Ä¶
895347870974361600,Wed Aug 09 18:15:41 +0000 2017,RT @AndrewYNg: Big thanks Hinton, Bengio @pabbeel @goodfellow_ian @karpathy @YuanqingLin @rsalakhu in course's Heroes of DL videos! https:/‚Ä¶
895008508902424600,Tue Aug 08 19:47:11 +0000 2017,RT @AndrewYNg: Announcing deeplearning.ai! Deep Learning on Coursera: Master Deep Learning, and build a career in AI! https://t.co/DIDCYAKB‚Ä¶
894250298000121900,Sun Aug 06 17:34:20 +0000 2017,The updated ImageNet training example with support for distributed training is a beauty https://t.co/i39By0OCl3 clean 300 lines
894249705563013100,Sun Aug 06 17:31:58 +0000 2017,PyTorch v0.2 release sooo goood https://t.co/4bLTxuhyXS more numpy-like (broadcasting/indexing), distributed training, also like retain_grad
893576281375219700,Fri Aug 04 20:56:01 +0000 2017,Gradient descent can write code better than you. I'm sorry.
892777603458752500,Wed Aug 02 16:02:22 +0000 2017,RT @SashaVNovikov: 2 megapixel layout -&gt; photo synthesis! https://t.co/lwS5DQNgyW https://t.co/mGxgXFmy02 https://t.co/OahwYOj14t
891858687974809600,Mon Jul 31 03:10:55 +0000 2017,I'm not eligible to renew my driver's license online, or over mail with &lt;60 days left &amp; 1st in person appointment is in 4 months. Thanks DMV
891127073279836200,Sat Jul 29 02:43:45 +0000 2017,RT @NvidiaAI: Get a recap of the top highlights from #CVPR2017 including our V100 giveaway to #AI researchers, demos, and more: https://t.c‚Ä¶
891096428117807100,Sat Jul 29 00:41:58 +0000 2017,Spotted on the internet: "reinforcement learning: the study of teaching computers how to beat Atari". haha
890954550697279500,Fri Jul 28 15:18:12 +0000 2017,@akm Haha good point, we had a temporary regression there
890771181296508900,Fri Jul 28 03:09:34 +0000 2017,Was driving a basic 1800 technology car today, forgot that the cruise control does not automagically slow down with a vehicle ahead. Ughh
889600098316963800,Mon Jul 24 21:36:06 +0000 2017,RT @ChrisChoy208: Went for a ride in #Tesla P100D with SOTA autopilot @ #CVPR2017. 1.1G acceleration was  ludicrous as advertised! Thanks @‚Ä¶
889189802888712200,Sun Jul 23 18:25:44 +0000 2017,RT @ChrisChoy208: NVidia CEO Jensen Huang presented Tesla V100 for the first time @ #CVPR2017 and we got one! https://t.co/NNNsff7VNk
888823577935347700,Sat Jul 22 18:10:29 +0000 2017,RT @hardmaru: Decoding the Enigma with RNNs. They trained a LSTM with 3000 hidden units to decode ciphertext with 96%+ accuracy. https://t.‚Ä¶
888473226333966300,Fri Jul 21 18:58:18 +0000 2017,Flying to #CVPR17 later tonight! ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets ConvNets
887350083322232800,Tue Jul 18 16:35:20 +0000 2017,week late to the party here but experiments on 300M images (300x larger than ImageNet) are awesome  https://t.co/IJvykpoBam 50 K80s 2 months
887176549522325500,Tue Jul 18 05:05:47 +0000 2017,"Most metrics are good until you start optimizing for any of them"
887176097334349800,Tue Jul 18 05:03:59 +0000 2017,Pretty sure Facebook app has a bug that doesn't clear old notifications, but they left it in because engagement is up as I keep rechecking
887157524255735800,Tue Jul 18 03:50:11 +0000 2017,But then, I also did 94% on CIFAR-10 and predicted that we won't be able to go above 90% with CNNs, and we all know what happened there.
887157339622522900,Tue Jul 18 03:49:27 +0000 2017,i.e. for ImageNet, we went from ~3% to 2.25% in last year. Fun to revisit my 2014 post human vs machine https://t.co/2SQ8tBWuo0
887142667582189600,Tue Jul 18 02:51:08 +0000 2017,RT @hardmaru: ImageNet 2017 results are out. Beijing-based momenta.ai team achieved top-5 error of 2.25%, down from ~3% last year. https://‚Ä¶
886223974543138800,Sat Jul 15 14:00:35 +0000 2017,en route to Boston for 1 day @ RSS. 35 min from waking up in SF to gate must be my record.
883745429677944800,Sat Jul 08 17:51:44 +0000 2017,Nice collection of slides &amp; pointers (near the end) on poorly understood / unintuitive properties of Neural Networks https://t.co/Yem9gghBv3
882015290594213900,Mon Jul 03 23:16:46 +0000 2017,RT @jcjohnss: Project reports for #cs231n 2017 are now online! 250+ amazing applications of deep learning:  https://t.co/MM2P8qG6W5
881927122838708200,Mon Jul 03 17:26:26 +0000 2017,@SamuelCox @udacity nice! like.
881720306066272300,Mon Jul 03 03:44:37 +0000 2017,Driving around PA with a Ludicrous mode Model X, testing a new Autopilot build. I see it will take a while before this gets old.
881254213510021100,Sat Jul 01 20:52:32 +0000 2017,@manhuichi oops! I wish I could go to Dublin, sorry about that. All the best with the event!
881002660345794600,Sat Jul 01 04:12:57 +0000 2017,@Caenorst @elonmusk 100?? that still leaves 9.7 hours for leisure and sleep.
880983289820987400,Sat Jul 01 02:55:58 +0000 2017,First week @ Tesla turned into an intense (in a good way!) firehose. I forgot I own a Twitter account.
878291423342207000,Fri Jun 23 16:39:27 +0000 2017,Berkeley AI Research (BAIR) is launching a blog! https://t.co/fcJeIDPZXc 1st post from Jacob Andreas @jacobandreas on Neural Module Networks
877679850982473700,Thu Jun 22 00:09:17 +0000 2017,Measuring the Progress of AI Research https://t.co/QRsQoAz91w looks quite comprehensive!
877350685955694600,Wed Jun 21 02:21:18 +0000 2017,@kentf :) good times.
877330494555177000,Wed Jun 21 01:01:04 +0000 2017,Excited to join Tesla as the Director of AI! https://t.co/5AdhaF40kM
876628148489605100,Mon Jun 19 02:30:12 +0000 2017,"One Model To Learn Them All" another step in Google's attempt to turn all of itself into one big neural network https://t.co/Dt1EAyQdlt
876105053521592300,Sat Jun 17 15:51:36 +0000 2017,@brandondamos Nice! - Cambridge was a great visit when I was around. I met up with @ankurhandos who was postdoc the‚Ä¶ https://t.co/gXDGK08Tl7
875795704844701700,Fri Jun 16 19:22:22 +0000 2017,My regularly scheduled programming has been interrupted by Elon's release of his plan to colonize Mars https://t.co/iHFoTCEbro
875795184948092900,Fri Jun 16 19:20:18 +0000 2017,Reminder: Deep RL Bootcamp application deadline is today. Take the action: https://t.co/N5lZizCXlH observe rewards :)
875240513326137300,Thu Jun 15 06:36:14 +0000 2017,Oh no, Stanford's Thai Cafe closes down  https://t.co/G2te6erbBp this place was revered as THE model of efficiency. Stuff of myths.
875177945760911400,Thu Jun 15 02:27:36 +0000 2017,@Smerity haha yes, not ideal :D e.g. i was going to add @dwf who proposed the idea, but I don't think that's his AS username :) ohwell.
875175819672342500,Thu Jun 15 02:19:10 +0000 2017,@memimo :)
875174612585271300,Thu Jun 15 02:14:22 +0000 2017,e.g. you can click your account (top right) and add me (username "andrej"). I'll approve and then we're best friends forever.
875174358871715800,Thu Jun 15 02:13:21 +0000 2017,so I'm 95% sure I implemented friends feature on arxiv-sanity. Can follow ppl and if accepted see summary of their libs in new "friends" tab
874683151808737300,Tue Jun 13 17:41:28 +0000 2017,(This is a DeepMind/OpenAI collaboration paper). I like it a lot because it is v promising approach for mitigating perverse instantiations.
874682119653515300,Tue Jun 13 17:37:22 +0000 2017,Hand-designed reward functions are the worst. Hence: "Learning from Human Feedback" https://t.co/gUVt074UFn + https://t.co/ksyNkhfshs
874678781201469400,Tue Jun 13 17:24:06 +0000 2017,RT @hardmaru: Attention Is All You Need, from @GoogleBrain. No RNNs, No CNNs, Just Attention. Very fast training; SOTA on WMT'14. https://t‚Ä¶
874396687065784300,Mon Jun 12 22:43:10 +0000 2017,@dwf quite easy to implement too I think. Will look into if I can spare some time in the next few days.
874396139935604700,Mon Jun 12 22:40:59 +0000 2017,@dwf sounds like a good arxiv-sanity feature ;p
874003974247940100,Sun Jun 11 20:42:40 +0000 2017,I know I'm very late to the party, but Stratechery is good reading https://t.co/3pDSKi129f
873251874136178700,Fri Jun 09 18:54:05 +0000 2017,maybe it's all generated by a char-rnn. I suspect we will never know.
873251783631450100,Fri Jun 09 18:53:44 +0000 2017,The "Whoa are you serious" award for an Appendix goes to "Self-Normalizing Neural Networks" https://t.co/YHLDtiKmXv proposes "selu" nonlin
872883711548719100,Thu Jun 08 18:31:08 +0000 2017,well, ~1 week -&gt; ~1 hour is ~200x speedup. So... 1 hour -&gt; 0.3 minutes? Surely that can't be right? :) https://t.co/aGi2U2K31c
872881628787261400,Thu Jun 08 18:22:52 +0000 2017,Remember ~5 years ago when this took ~1-3 weeks, worked much worse, and required writing complex, custom CUDA kernels?
872881195746447400,Thu Jun 08 18:21:09 +0000 2017,Training ImageNet in 1 hour with 256 GPUs, minibatches of 8192. From  Facebook's FAIR: https://t.co/R0BxFOFshe 1 hour... incredible
872340712964149200,Wed Jun 07 06:33:27 +0000 2017,Nice/fun writeup from Ryan Dahl (of node.js fame) on his Google Brain residency https://t.co/Igg9v9mkWN accurate assessments allaround
872172660993646600,Tue Jun 06 19:25:41 +0000 2017,CS231n poster session, today from 12-3pm at Stanford's Bing Convert Hall! Several hundred projects to go through no‚Ä¶ https://t.co/dD6eej3HiK
871865689002225700,Mon Jun 05 23:05:53 +0000 2017,Excited to see Apple's Core ML. ~2 years ago I had to write manual fragment shaders to do CONV (not fun). Today you can compile Keras models
871064787723051000,Sat Jun 03 18:03:23 +0000 2017,@hindupuravinash yeah, trying to fix... thank you!
871064569845760000,Sat Jun 03 18:02:31 +0000 2017,@ZaneSterling thank you, trying to fix... somehow mongo process just decided to shut down.
870835782243582000,Sat Jun 03 02:53:24 +0000 2017,In this particular stretch you have to shift 4 lanes in 15 seconds because the exit is immediate and on other side. Not part of objective :/
870835092523896800,Sat Jun 03 02:50:40 +0000 2017,Google Maps prefers a 14 minute route with 10 turns and a stressful/short highway stretch to a 14.5 minute route where you just go forward.
870711519951986700,Fri Jun 02 18:39:38 +0000 2017,RT @echen: Exploring LSTMs: tutorial + discovery https://t.co/hnwxYfqoWu https://t.co/BweLJBicOj Finally moving my blog into modern times.‚Ä¶
870349536190881800,Thu Jun 01 18:41:14 +0000 2017,RT @pabbeel: (1/2) Want to learn more about Deep RL, theory and practice? Apply by June 16 to join us at https://t.co/Hq2z1vvt28 Aug 26-27.‚Ä¶
870349145172656100,Thu Jun 01 18:39:41 +0000 2017,We are organizing a DeepRL bootcamp, with top notch instructors from Berkeley/DeepMind/OpenAI https://t.co/MtgTw3ac8g apply by June 16
870342070891708400,Thu Jun 01 18:11:34 +0000 2017,@yoavgo everything we've done so far is "narrow" in my definition because we don't have AGI, yet
870019856573145100,Wed May 31 20:51:12 +0000 2017,New post on placing AlphaGo in context of AI research https://t.co/tI3VkUGYsT trying to mix in a pinch of low-level depth to popsci/PR
869993453240832000,Wed May 31 19:06:17 +0000 2017,Mary Meeker‚Äôs 2017 internet trends report is making the rounds https://t.co/JMKDNHn6HP for a good reason - 355 pages of interesting.
869753990828802000,Wed May 31 03:14:45 +0000 2017,Multiple high quality nature videos on the Smithsonian YT channel; e.g. on Cheetah https://t.co/0x3977Aylh &amp; more: https://t.co/WloSr1hEF4
869289384687714300,Mon May 29 20:28:34 +0000 2017,(probably the biggest gotcha that is unique to DL/multi-gpu is to pay attention to the PCIe lanes supported by the CPU/motherboard)
869288186211475500,Mon May 29 20:23:48 +0000 2017,Quite detailed post on setting up a Deep Learning box from scratch https://t.co/a5ZWUIufdp (I can relate to the CPU install problem, hah)
869271699358793700,Mon May 29 19:18:18 +0000 2017,@visarga I capped it if I recall correctly. Really? 300? That's a lot of papers for a library. Are you sure you wan‚Ä¶ https://t.co/OoNBP64cwk
868228331392573400,Fri May 26 22:12:19 +0000 2017,@sleepinyourhat @PyTorch i like lineprofiler
868190765603635200,Fri May 26 19:43:03 +0000 2017,@soumithchintala @sprobertson @debuggermassa yep i was looking at that account this morning, which triggered this tweet :)
868189920967503900,Fri May 26 19:39:42 +0000 2017,RT @sprobertson: @karpathy Talk to your doctor to find out if PyTorch is right for you.
868178954032513000,Fri May 26 18:56:07 +0000 2017,I've been using PyTorch a few months now and I've never felt better. I have more energy. My skin is clearer. My eye sight has improved.
867510175862636500,Wed May 24 22:38:38 +0000 2017,@nntsn You're right, I incorrectly "double counted" their papers. The actual total number is 60 papers, or 6.3% of‚Ä¶ https://t.co/fL507EsSZ8
867458482424893400,Wed May 24 19:13:13 +0000 2017,Ran some quick numbers on ICML accepted papers https://t.co/muBweFvinN Google "wins" ICML, involved in 10% of papers. ~25% are from industry
867107799725088800,Tue May 23 19:59:44 +0000 2017,@samfjacobs @vkhosla that's not something we can do right now. we can set objectives as things that the computer ca‚Ä¶ https://t.co/sW50K3UmUU
867086487237533700,Tue May 23 18:35:02 +0000 2017,@j_jason_bell yes. and we can calculate/show the win margin but not the win probability. it's quite not intuitive t‚Ä¶ https://t.co/qAXVzDEQkJ
867085279126888400,Tue May 23 18:30:14 +0000 2017,also imo an empirical study of this unintuitive consequence of seemingly intuitive objective would make the best kind of AI safety paper.
867081978427826200,Tue May 23 18:17:07 +0000 2017,certainly not intuitive. a fun glimpse into a future of uncertainty about AI. "Is it screwing up, or is it actually on a whole new level?"
867081341334020100,Tue May 23 18:14:36 +0000 2017,@systemresearch agree. i'd want to see that version too, instead.
867077807779717100,Tue May 23 18:00:33 +0000 2017,it prefers to win by 0.5 with 99.9999999% chance instead of 10.0 with 99.99% chance.
867075706827690000,Tue May 23 17:52:12 +0000 2017,"Yes AlphaGo only won by 0.5, but it was not at all a close game. It's an artifact of its training objective." &lt;- me 10 times this morning.
866897849996394500,Tue May 23 06:05:28 +0000 2017,I'm trying to search deep through my Dropbox for my Bitcoin wallet. Pretty sure I mined a few on my laptop back in the old days. Sigh
866762999389802500,Mon May 22 21:09:37 +0000 2017,Instead of tourism across space I'd love to do pretend time tourism. E.g. "travel" to ancient Rome for 2 days, no AD tech allowed, etc.
866749907469705200,Mon May 22 20:17:36 +0000 2017,@NickPinkston @44thfloor @kevin2kelly sounds highly dubious :) I'd argue the opposite, and especially in the case o‚Ä¶ https://t.co/aUV7vWVPSO
866699905645002800,Mon May 22 16:58:54 +0000 2017,@NickPinkston @kevin2kelly agree, it read like a lot of hair-splitting that those concerned are largely indifferent to
866433031841632300,Sun May 21 23:18:26 +0000 2017,The energy expansions of evolution https://t.co/CJTAUoFavI lovely read. geo, sunlight, oxygen, flesh, fire all "unlocked" new organisms.
866367735411859500,Sun May 21 18:58:59 +0000 2017,All I want is the grand theory of personality. Seems like ppl quibble about surface corollarys when the real disagreements are fewer/deeper.
866366787884994600,Sun May 21 18:55:13 +0000 2017,@marshray @BrendanEich hahaha, I like this a lot :D
866359192608661500,Sun May 21 18:25:02 +0000 2017,Fun to try come up with N binary questions that ppl answer with 50% yes, and 0 correlation. Info rich. Bit like Myers Briggs but ++
866000641243586600,Sat May 20 18:40:17 +0000 2017,@KaiLashArul @PyTorch (the word "argmax" was missing from the official docs, search came up with 0 results.)
865997383468933100,Sat May 20 18:27:20 +0000 2017,haha. I like good docs. They are under-appreciated by at least a factor of 1,000. https://t.co/dSRPZ2gUkl
865423367020585000,Fri May 19 04:26:24 +0000 2017,RT @spencerchen: I just laid the audio from the Blade Runner 2049 trailer to the new Google Assistant ad.  I'm scared. Literally no extra e‚Ä¶
865310520068288500,Thu May 18 20:57:59 +0000 2017,ahh, the arxiv dilemma: put up your A- result now or risk getting scooped by someone with a very similar idea but only B- standards.
864737065337999400,Wed May 17 06:59:17 +0000 2017,@AlecRad @goodfellow_ian we apply "directly supervised learning"...
864724993011142700,Wed May 17 06:11:18 +0000 2017,RT @AlecRad: @goodfellow_ian @karpathy The mode of the "distance of my head to a GPU when home" distribution is less than 2 ft. https://t.c‚Ä¶
864700757009813500,Wed May 17 04:35:00 +0000 2017,@goodfellow_ian @AlecRad Alec has his GPU at home plugged into a naked motherboard, casually on the table. That's how he rolls :)
864665267929927700,Wed May 17 02:13:59 +0000 2017,Dinner conversation today: @AlecRad revealing his tips and tricks for distinguishing CNN/RNN/RL training by the sound the GPU makes.
864519817906212900,Tue May 16 16:36:01 +0000 2017,based on One-Shot Imitation Learning https://t.co/r5G90T2iXF. My 1st metalearning epiphany was via Matching Networks https://t.co/c9cxuGicPW
864518383147941900,Tue May 16 16:30:19 +0000 2017,what's cool about this is that the policy is parameterized by a demonstration (instead of trained on it); can acquire new skills rapidly.
864516493689487400,Tue May 16 16:22:48 +0000 2017,At OpenAI we are teaching robots new skills through demonstrations in VR, and it's pretttty cool! Blog+video: https://t.co/gR5wCjB2p8
864268724374609900,Mon May 15 23:58:15 +0000 2017,OpenAI released Roboschool: robot simulation envs integrated with OpenAI Gym, based on Bullet instead of MuJoCo. https://t.co/gJVQNcYAzP
864244796566536200,Mon May 15 22:23:11 +0000 2017,I'm updating my generator 5x as much as my discriminator, and now I feel bad for it because the game is not fair. It's trying its best :(
863585148381478900,Sun May 14 02:41:58 +0000 2017,I found a code base that goes against everything I believe in and stand for as a person. It pains to think that some CPU had to execute that
863533128870109200,Sat May 13 23:15:16 +0000 2017,NYT article on ransomware https://t.co/vca6Osg2Zw and "How to Accidentally Stop a Global Cyber Attacks" https://t.co/0gekfuuGAs amazing
862776877047439400,Thu May 11 21:10:11 +0000 2017,@Smerity yep that was one of my favorite parts. Some fun/good ideas, but mixed in with lots of crackpot/nonsensical‚Ä¶ https://t.co/sIkRj0u9bW
862772778981707800,Thu May 11 20:53:54 +0000 2017,@iandanforth yes but why would anyone want to do that? is the harder piece.
862770876814577700,Thu May 11 20:46:21 +0000 2017,But wait, why would you want to extract what's in paintings? Can't you just look? Yes, but... other steam engines want to ride your horses.
862769864196333600,Thu May 11 20:42:19 +0000 2017,It's like... a steam engine searching large mathematical expressions over a collection of paintings to extract what's in them? I give up
862768754752602100,Thu May 11 20:37:55 +0000 2017,It's fun to think about how you'd explain e.g. training ResNets on ImageNet to someone from 200 years ago. Even cameras didn't exist.
862360625141252100,Wed May 10 17:36:09 +0000 2017,Inside Volta: The World‚Äôs Most Advanced Data Center GPU https://t.co/rc85NcnK6M  from the NVIDIA blog
862336715083489300,Wed May 10 16:01:08 +0000 2017,NVIDIA GTC keynote starting any second!! Live video: https://t.co/4FnRwGq2Y9  TFLOPs TFLOPs TFLOPs TFLOPs TFLOPs üòç‚åõÔ∏èüéâüóùÔ∏èüìà
861991703300915200,Tue May 09 17:10:11 +0000 2017,Noticed ppl can be too "trigger happy" in throwing RNNs everywhere, when finite contexts (e.g. CNNs) work quite well in many situations.
861991299620102100,Tue May 09 17:08:35 +0000 2017,MT with CNNs from FB https://t.co/01Od0QdOU4 CNNs are nice (shorter causal chain, more parallel), should often be tried in place of RNNs.
861897560708980700,Tue May 09 10:56:06 +0000 2017,"As We May Program" https://t.co/T7sd1O9urR fun talk by Peter Norvig. insightful tidbits on challenges of writing modern, complex code.
861597499299045400,Mon May 08 15:03:46 +0000 2017,Was about 2 weeks. I'm supposed to have highly insightful epiphanies to my work now or something, which I am eagerly awaiting.
861597252015366100,Mon May 08 15:02:47 +0000 2017,Back from a small whirlwind eurotrip (toulon, rome, florence, venice, pompeii, kosice, bratislava, vienna, dusseldorf). esp liked pompeii
860231829038805000,Thu May 04 20:37:05 +0000 2017,@brandondamos alex graves has quite a few in his iirc
858269866024988700,Sat Apr 29 10:40:56 +0000 2017,@Mvandepanne Neat! On vacation, will look at when I get back!
856648638893875200,Mon Apr 24 23:18:45 +0000 2017,@AdrianoCarmezim No no! Try "a GAN". Get it? Haha?
856648193983074300,Mon Apr 24 23:16:59 +0000 2017,"If it doesn't work, try a GAN".
855891153954238500,Sat Apr 22 21:08:47 +0000 2017,I only discovered Allbirds üëüa few months ago but they are the best and everyone should have them. https://t.co/pTl25nSjB6
855886175332163600,Sat Apr 22 20:49:00 +0000 2017,Sad to spend my favorite day (Earth day) almost entirely in flight. En route to ICLR. üåµüå≤üå≥üå¥üåøüçÄ‚òòÔ∏èüåπüåªüèîüè°
855474655552864300,Fri Apr 21 17:33:46 +0000 2017,"Frugal science": diagnosing malaria on budget https://t.co/B3JXqSSfnp Great work, great video.
855317270599315500,Fri Apr 21 07:08:22 +0000 2017,And few in ML: The definition of "unsupervised learning". The importance of neuroscience to building AI. The review process. Schmidhuber.
855315918963974100,Fri Apr 21 07:03:00 +0000 2017,Topics that, if brought up, derail any conversation: Simulation hypothesis. Fermi paradox. AGI. Soylent. Universal Basic Income. Trump.
855193406691082200,Thu Apr 20 22:56:11 +0000 2017,RT @waitbutwhy: It's finally here: the full story on Neuralink. I knew the future would be nuts but this is a whole other level. https://t.‚Ä¶
854599106513190900,Wed Apr 19 07:34:39 +0000 2017,@TorkelD @adamjsimmons Sony also has a 24-240mm f3.5-6.3; lower quality? &amp; then also + a 55mm f1.8. Odd that sharpn‚Ä¶ https://t.co/q8aUHNm16S
854578795860197400,Wed Apr 19 06:13:56 +0000 2017,@brianwilt looks great, ty for pointer!
854578671859847200,Wed Apr 19 06:13:27 +0000 2017,@adamjsimmons ty! I find the wide lenses look too much like iPhone shots except bigger. Not a huge fan; mostly ok with 24mm+
854577369918480400,Wed Apr 19 06:08:16 +0000 2017,@ayman yep thank you, i figured it out now - downloaded &amp; installed a pack of Presets. But it could be more front &amp;‚Ä¶ https://t.co/N0s58Q12Rz
854576898726174700,Wed Apr 19 06:06:24 +0000 2017,@dotseba hahahaha :D a fine summary :)
854575116931350500,Wed Apr 19 05:59:19 +0000 2017,(playing with my new shiny Sony a7Sii (fullframe, mirrorless), which I quite like! Struggling with what ~2 lenses to get for travel)
854574551090438100,Wed Apr 19 05:57:04 +0000 2017,what are all these gazillion sliders in Adobe's Lightroom for processing DSLR images? I really just want a few Instagram filters.
853649968178974700,Sun Apr 16 16:43:07 +0000 2017,@pmigdal @jekyllrb @github I didn't turn from it, I just wanted something faster for quick/small posts on a side an‚Ä¶ https://t.co/Ibpj15c6Jr
853453616979390500,Sun Apr 16 03:42:53 +0000 2017,@fferreres yes.
853450914958499800,Sun Apr 16 03:32:09 +0000 2017,@sedielem @EricBattenberg @AlecRad Yeah, heard someone say that when you take it out later in training by "absorbin‚Ä¶ https://t.co/HcDFb2TnrE
853288337456504800,Sat Apr 15 16:46:07 +0000 2017,@sedielem yes, i was trying to reproduce a paper that used N(0,std). As @AlecRad put it, "friends don't let friends use N(0,std) init"
853073541201150000,Sat Apr 15 02:32:36 +0000 2017,@patrickhop oh, yes- no batchnorms involved in this one for various reasons
853054007668990000,Sat Apr 15 01:14:59 +0000 2017,a 20 layer model. weight init N(0,0.02): stuck completely. try weight init N(0, 0.05): optimizes right away. initialization matters a lot :\
852938032499933200,Fri Apr 14 17:34:08 +0000 2017,@gokcen looks great!
852937394483482600,Fri Apr 14 17:31:36 +0000 2017,RT @jackclarkSF: Me: Constantly agonize about AI being portrayed in aggressive and/or violent forms.  Russians: Our robot can dual wield pi‚Ä¶
851905290324684800,Tue Apr 11 21:10:23 +0000 2017,A Computer Scientist‚Äôs View of Life, the Universe and Everything, Schmidhuber 1997 https://t.co/YD2WJxeTxn I'm ok making this my religion :p
851855846891962400,Tue Apr 11 17:53:55 +0000 2017,"The Website Obesity Crisis" https://t.co/B80UsrYY3Q fun talk/article spotted on "Electron is flash for the desktop" https://t.co/7e780OdBX8
851126755507044400,Sun Apr 09 17:36:46 +0000 2017,RT @goodfellow_ian: CycleGAN turning a horse video into a zebra video ( https://t.co/YYCsVt4rIP ) https://t.co/KlZlKG5k6W
850772106870640600,Sat Apr 08 18:07:31 +0000 2017,#funfactsaturdays Humanity collectively experiences the entire age of the Universe every 2 years (as pointed out to me by @catherineols) ha.
850495586805481500,Fri Apr 07 23:48:43 +0000 2017,@SebastienBubeck yeah I thought about that title for a while, then eventually decided that some of it is more broad‚Ä¶ https://t.co/Xbs9x3kSMT
850404038327676900,Fri Apr 07 17:44:57 +0000 2017,New quick blog post: "A Peek at Trends in Machine Learning" https://t.co/TXSzyQG6EZ a few "Google Trends" of ML papers on arxiv
850121294838243300,Thu Apr 06 23:01:25 +0000 2017,r/place was an awesome social experiment. A summary post: https://t.co/Ib4x7AJ6ci (except the reason for no hate symbols was active banning)
850042987484557300,Thu Apr 06 17:50:15 +0000 2017,The TPU is cool, but there is a lot of fine print to "15-30X faster". Noticing confusions around. Some discussion: https://t.co/MUgtW4rvzP
850020863118147600,Thu Apr 06 16:22:21 +0000 2017,If a simple autoregressive model discovers sentiment on text, are similar results on videos "just" a matter of compute and data?
850019812277338100,Thu Apr 06 16:18:10 +0000 2017,New OpenAI post "Unsupervised sentiment neuron" https://t.co/4dRmWxGuwL train a big char-rnn on 82M reviews -&gt; SOTA‚Ä¶ https://t.co/ZpMhAhfs3j
849872587136016400,Thu Apr 06 06:33:09 +0000 2017,@Smerity @dennybritz "SanityGAN"
849718393888424000,Wed Apr 05 20:20:26 +0000 2017,@hardmaru oh no, we'll be out by the end of the year!
849338608297406500,Tue Apr 04 19:11:18 +0000 2017,Came to visit first class of @cs231n at Stanford. 2015: 150 students, 2016: 350, this year: 750.‚Ä¶ https://t.co/StE11V6Vs6
849305680771248100,Tue Apr 04 17:00:28 +0000 2017,RT @distillpub: Why Momentum Really Works -- A new Distill article by @gabeeegoooh https://t.co/47DD7fzFwA https://t.co/5q2iZyFhvR
849135057788850200,Tue Apr 04 05:42:28 +0000 2017,GANs seem to improve on timescales of weeks; getting harder to keep track of. Another impressive paper and I just barely skimmed the other 3
849086036022104000,Tue Apr 04 02:27:40 +0000 2017,@fchollet unless running the optimization again takes 1B years of evolution, in which case inspecting a solution might be a decent shortcut.
849051830260686800,Tue Apr 04 00:11:45 +0000 2017,RT @stanfordnlp: Stanford Lecture Collection‚ÄîNatural Language Processing with Deep Learning‚ÄîManning/Socher https://t.co/yE6ufYHCyw https://‚Ä¶
848968318140665900,Mon Apr 03 18:39:54 +0000 2017,@Shmuma sometimes the arxiv API suspiciously does not return the newest batch of papers for a few extra hours. Sigh.
848432661374787600,Sun Apr 02 07:11:24 +0000 2017,@soswow would be same as is standard for ATARI - e.g. concat last 4 (grayscale) 84x84 frames, feed to a CNN to get actions.
848221074521112600,Sat Apr 01 17:10:38 +0000 2017,RT @OpenAI: We've created the world's first Spam-detecting AI trained entirely in simulation and deployed on a physical robot: https://t.co‚Ä¶
848201083243552800,Sat Apr 01 15:51:11 +0000 2017,@soswow Would be fun to train with self-play!
847923402190987300,Fri Mar 31 21:27:47 +0000 2017,@pterojacktyl hey, thank you for arxiv-sanity support!! üôå
847612015451320300,Fri Mar 31 00:50:27 +0000 2017,RT @SpaceX: Falcon 9 first stage has landed on Of Course I Still Love You ‚Äî world‚Äôs first reflight of an orbital class rocket.
847371306060234800,Thu Mar 30 08:53:57 +0000 2017,I spent 9am to 2am today hunting a single bug, and failed. A great use of 1/365th of one of only several dozen years of my life that remain.
847147501249474600,Wed Mar 29 18:04:38 +0000 2017,RT @jeremystan: #deeplearning with üç™üç´üçïüçñ‚òï (not math) - how @instacart learns to sort shopping lists with #Keras https://t.co/6d3IYOul2i
847131134550917100,Wed Mar 29 16:59:36 +0000 2017,I was coding when Docker popped up an "Update?" dialog. Instead of a newline in my code I accidentally confirmed an Update&amp;Restart. UX fail.
846967875449618400,Wed Mar 29 06:10:52 +0000 2017,@nikoSuenderhauf ty for supporting arxiv-sanity! üôå
846924285935419400,Wed Mar 29 03:17:39 +0000 2017,@kcimc oh you mean at OpenAI? Haha, I'm having a second dinner at a random place in SF, thought that was an odd coincidence or something :)
846923347522863100,Wed Mar 29 03:13:55 +0000 2017,@kcimc potentially creepy! ;) where??
846768501427658800,Tue Mar 28 16:58:37 +0000 2017,And also 52 startups from YC W17 demo day 1 (from ~week ago, I'm slow) https://t.co/7Xng5yVEmv Like Cowlar, Playment, Boxouse
846623928810319900,Tue Mar 28 07:24:08 +0000 2017,51 startups from YC W17 Demo day 2 https://t.co/eRoqrdm8g6 A lot of cool stuff! Like Peer5, Zestful, KidPass, Voodoo, Wright
845371860766277600,Fri Mar 24 20:28:52 +0000 2017,@jackclarkSF @iandanforth of course not. Linters are very annoying
845310477118824400,Fri Mar 24 16:24:57 +0000 2017,New blog post from OpenAI on "Evolution Strategies as a Scalable Alternative to Reinforcement Learning" https://t.co/uLLefJeTH0 w00t!!
845184320708919300,Fri Mar 24 08:03:39 +0000 2017,I already linked to https://t.co/Z5aoTPCGif a few times, if I recall correctly. This is a real problem.
845183673703968800,Fri Mar 24 08:01:05 +0000 2017,I just have to vent about this. Asana (which we use at OpenAI) takes 5.0 seconds to load a todo list. Of 10 strings. Web has gone Backwards.
845032457657200600,Thu Mar 23 22:00:12 +0000 2017,Deep Photo Style Transfer https://t.co/0pYfLkvDlC wow results. PhotoShop of the future will be amazing. https://t.co/tocKvVs0so
844361003483643900,Wed Mar 22 01:32:05 +0000 2017,12 Risks that threaten human civilization https://t.co/qkqTdzVu4Q that's a long/depressing pdf (from Feb 2015, Future of Humanity Institute)
844263993707446300,Tue Mar 21 19:06:36 +0000 2017,RT @MikeTaylor: Every attempt to manage academia makes it¬†worse https://t.co/0ruHAZBG6u https://t.co/gMXuaSt7AQ
844247548655095800,Tue Mar 21 18:01:15 +0000 2017,Mask R-CNN https://t.co/DONA0SZiR9 results look like ground truth. Also CV ppl write signif. more professional looking papers than ML ppl
843930339034595300,Mon Mar 20 21:00:46 +0000 2017,We're expanding our book/textbook library at OpenAI. Curious to hear recommendations on any "THE book" on any AI/CS/bio/etc - related topics
843887305731395600,Mon Mar 20 18:09:47 +0000 2017,Excited to join the steering committee of Distill https://t.co/OgnakIpMQF 1) exposition is main focus, 2) articles use modern web technology
843577964046372900,Sun Mar 19 21:40:34 +0000 2017,@kyield no - i mean unfair to AI researchers who are trying to build similar systems :)
843576819550892000,Sun Mar 19 21:36:01 +0000 2017,@notmisha yes, and it was much lower few thousand years ago :) That would be the quite-intelligent subset. Much more unfair if you widen it
843576044372148200,Sun Mar 19 21:32:56 +0000 2017,@ethancaballero It doesn't _really_ make sense to talk about FLOPs in brain, but I saw a few estimates, usually on those orders, 10-1000 PF.
843574901336293400,Sun Mar 19 21:28:23 +0000 2017,Nature is evolving ~7 billion ~10 PetaFLOP NI agents in parallel, and has been for ~10M+s of years, in a very realistic simulator. Not fair.
842107411640987600,Wed Mar 15 20:17:07 +0000 2017,RT @AlexRoseJo: Powerful recurrent neural network or cheap bag-of-words? Blogpost on learning when sentences are complex or easy: https://t‚Ä¶
841837106238431200,Wed Mar 15 02:23:01 +0000 2017,@cholodovskis the pop in ES is resampled so it's fine to apply it in stochastic envs too. Not clear how they compare there. good exp to run
841836590427131900,Wed Mar 15 02:20:58 +0000 2017,@cholodovskis agreed that it's better to do e.g. frameskip ~ U[2,4] on each action to make less det. Seems most people not eager to adopt
841781769288400900,Tue Mar 14 22:43:08 +0000 2017,@krasul you can also standardize the rewards z = (x-mu)/std, before the update.
841760762703953900,Tue Mar 14 21:19:39 +0000 2017,. @DavidVandegrift that's fair :) In our first experiments ES is ~3 orders slower than backprop in SL. The result is mostly relevant to RL.
841741844119605200,Tue Mar 14 20:04:29 +0000 2017,RT @chr1sa: UC Berkeley's fantastic course videos are disappearing tomorrow b/c DoJ decided the charts didn't have enough colors https://t.‚Ä¶
841739832120422400,Tue Mar 14 19:56:29 +0000 2017,@Or_Sharir no because i don't want people gamifying it or abusing the system. precise numbers not a good idea here.
841739127796125700,Tue Mar 14 19:53:41 +0000 2017,You can now understand state of the art AI with before high school math. You forward a neural net and repeat guess&amp;check. works well enough.
841738359537987600,Tue Mar 14 19:50:38 +0000 2017,ES is much simpler than RL, and there's no need for backprop, it's highly parallelizable, has fewer hyperparams, needs no value functions...
841737558232985600,Tue Mar 14 19:47:27 +0000 2017,RL works so poorly that finite differences are only ~10x worse. &amp; much simpler/more scalable. New paper from OpenAI: https://t.co/YckfD8hl0y
841709276468981800,Tue Mar 14 17:55:04 +0000 2017,@Or_Sharir yep, it's the Top tab
841487772552585200,Tue Mar 14 03:14:53 +0000 2017,I've also noticed that my writing style has been drifting over time, likely due to influence of https://t.co/u3LobqQfRf, which I agree with.
841482360369606700,Tue Mar 14 02:53:23 +0000 2017,A quick blog post: ICLR 2017 vs arxiv-sanity https://t.co/9Gw1teNw2G
841408213920628700,Mon Mar 13 21:58:45 +0000 2017,@lukeprog yep, have seen before. btw imo a not usually mentioned effect are incentive structures of those predicting. bias to predict sooner
841353422594961400,Mon Mar 13 18:21:02 +0000 2017,AI experts have agreed for decades that AGI is 20 years away, so I always predict 20 as well. Works nicely. https://t.co/QjME9oMYju [pdf]
840763991513219100,Sun Mar 12 03:18:50 +0000 2017,RT @hardmaru: PyTorch Tutorial: Most of the models were implemented with less than 30 lines of code. https://t.co/ITqbIFs8KF
840327946661314600,Fri Mar 10 22:26:09 +0000 2017,RT @ericoguizzo: How Drive.ai Is Mastering Autonomous Driving with Deep Learning https://t.co/0rSOon8F1g https://t.co/mUiyMsukgt
839395519927496700,Wed Mar 08 08:41:01 +0000 2017,"top notch deep learning framework such as MatConvNet or Soumith Chintala" :D:D. Ok have to stop quoting, there's too much...
839395271612084200,Wed Mar 08 08:40:02 +0000 2017,"Deep generative modelling is probably important (see e.g. Bengio et al. (2013a), ... and (Schmidhuber et al., circa 3114 BC))." LOL.
839394901687070700,Wed Mar 08 08:38:34 +0000 2017,Yes, "Stopping GAN Violence: Generative Unadversarial Networks" https://t.co/7um7uah47z will be the most widely read paper of 2017 :D
839362473593430000,Wed Mar 08 06:29:42 +0000 2017,RT @drfeifei: A tale of 200 American cities, told by deep learning &amp; 50M Google streetview images. Visual census by #AI https://t.co/gPRWe0‚Ä¶
839268444453253100,Wed Mar 08 00:16:04 +0000 2017,Greg is easily the most productive person I know. And across a wide breadth of tasks. And by a very wide margin. +1 https://t.co/xTJ3JdfSSk
838907450132660200,Tue Mar 07 00:21:36 +0000 2017,And also direct link to some comments on the Large-Scale Evolution of Image Classifiers paper: https://t.co/TgHOKvuVzB
838906637482147800,Tue Mar 07 00:18:23 +0000 2017,Squeezed in some time over the weekend to implement discussions for arxiv-sanity (Markdown/LaTeX, tags etc.) w00t!: https://t.co/5fdvE4Wi2V
838671158060863500,Mon Mar 06 08:42:40 +0000 2017,What it feels like to be an open-source maintainer https://t.co/7uDkJ2Y1Fz a sad but true article. And I only experienced ~5% of this
838588310092050400,Mon Mar 06 03:13:28 +0000 2017,RT @poolio: Evolution is catching up to intelligent design for neural net architectures (94.6% vs. 96.7% on CIFAR-10): https://t.co/ZCSjuBO‚Ä¶
838287943596810200,Sun Mar 05 07:19:55 +0000 2017,@tadejtadej i watched a house cat randomly viciously attack and kill a colonist
838131647413248000,Sat Mar 04 20:58:51 +0000 2017,Oh oh, I'm at a high risk of game addiction, having played a bit of RimWorld last night https://t.co/AX8jQjzE68 This can't be happening!
837392294298820600,Thu Mar 02 20:00:55 +0000 2017,@TheReibel posted! ;) thank you!
836974995641229300,Wed Mar 01 16:22:43 +0000 2017,somehow the alarm on my iPhone did not make any sound when it became active this morning. Terrifying. Need to find complete analog solution.
836852861548048400,Wed Mar 01 08:17:24 +0000 2017,"Almost every flight today is slower than in the 60s". Video on how and why the flight times stalled https://t.co/Sf8nz1pusl
834948335614083100,Fri Feb 24 02:09:30 +0000 2017,üëç we need _much_ more of this. https://t.co/S7QJyDRITy
834903906110992400,Thu Feb 23 23:12:57 +0000 2017,Drama between Uber and Waymo regarding self-driving technology IP. Looks quite bad https://t.co/XU7jipdzdr
834838807090335700,Thu Feb 23 18:54:16 +0000 2017,Shake-Shake regularization code https://t.co/5ksl6aQ2rq claims 2.72% on CIFAR-10. Fun - add more stochastic, even "break" backprop.
834491656300687400,Wed Feb 22 19:54:49 +0000 2017,RT @OriolVinyalsML: Working on ICML vs playing with https://t.co/ohdXT7EnX2. #choices https://t.co/aUe4bLLP4J
834276488027394000,Wed Feb 22 05:39:49 +0000 2017,@Ozan__Caglayan ? you always do early stopping based on validation data
834211236971548700,Wed Feb 22 01:20:32 +0000 2017,@humphreysheil i use random search, not grid search (see paper from Bergstra). Never used stuff like Spearmint. As long as it takes :)
834145270229143600,Tue Feb 21 20:58:24 +0000 2017,When you run a big hyperparameter search and discover that your default (guessed at) hyperparams work best. Not sure if :) or :(
833850347806351400,Tue Feb 21 01:26:29 +0000 2017,@joshbegley very cool! there wouldn't happen to be a dataset of these, I assume? (i work on ML). looks like you can purchase on NYT for alot
833771416952533000,Mon Feb 20 20:12:51 +0000 2017,Launch manifest for SpaceX https://t.co/tMtaZkz7cw March: 1st stage reuse flight. May: Falcon Heavy demo ü§ìü§ì
833769284685869000,Mon Feb 20 20:04:22 +0000 2017,@seanmcarroll Wrote a post on VR recently https://t.co/DJlFhDHlFK; see "The features of doing VR properly" section for some recommendations
833432975882661900,Sun Feb 19 21:48:00 +0000 2017,"The Egg" by Andy Weir is still the best short story (per word) I've read so far https://t.co/MPt2Q6Cbem
833432756172361700,Sun Feb 19 21:47:08 +0000 2017,Ted Chiang's "Understand" is still the best short story I've read so far, by a margin https://t.co/k7zj38o0WQ
833403490907025400,Sun Feb 19 19:50:50 +0000 2017,@FerreiraFabioDE possibly negative impact on career :) Stuff took lot of time away from research/papers - most important factor. Meh.
833070610267770900,Sat Feb 18 21:48:05 +0000 2017,@OriolVinyalsML "refuting" bit strong; "supplementing". Could be more careful with "easily fit random", "learn by sheer memorization", etc
833051502025461800,Sat Feb 18 20:32:10 +0000 2017,@EugeneZemtsov you'd be doing everyone a service by essentially "reverse DDOSing" the bots.
833050008710582300,Sat Feb 18 20:26:14 +0000 2017,Hasty-looking but ~good response (https://t.co/mn4rVtyCKZ) refuting some claims of ICLR paper on DNN generalization https://t.co/UoJSXMTeVR
833044883375943700,Sat Feb 18 20:05:52 +0000 2017,Observing raw web server traffic is fun. Seeing ~frequent requests to (non-existing) /phpmanager/, /sql/phpMyAdmin/, etcetc. probing bots.
833023376079806500,Sat Feb 18 18:40:24 +0000 2017,Article on the mirror test which, despite its flaws, is my favorite animal cognition test https://t.co/9b6N58ChiG
832720158909046800,Fri Feb 17 22:35:31 +0000 2017,Next quarter CS231n will be taught by Justin/Serena/Fei-Fei &amp; available on Stanford's SCPD https://t.co/WP1NQQPIu1 (for only $4,800 :))
832517151281942500,Fri Feb 17 09:08:50 +0000 2017,@_onionesque running out of laptop battery is like running out of air. It's hibernating till next breath :)
832514746855206900,Fri Feb 17 08:59:17 +0000 2017,With 2% battery to spare- overnight job started!! thanks to a miraculous midnight intervention by an eng coworker w‚Ä¶ https://t.co/slUTrQCvYf
832502980867862500,Fri Feb 17 08:12:32 +0000 2017,@debarko :D Shhh Everything is FULLY under control
832502363252330500,Fri Feb 17 08:10:05 +0000 2017,Great paper from Justin et al. at FAIR on compositional grounded queries diagnostics https://t.co/R5U8rHWM7B (from Dec!; I had missed)
832501000124510200,Fri Feb 17 08:04:40 +0000 2017,I forgot my Macbook charger at work so I'm racing against time to set up this overnight job.Only 17% battery left! This tweet is a bad idea!
831201644234674200,Mon Feb 13 18:01:29 +0000 2017,Jack (@jackclarkSF) is doing a great job maintaining a weekly newsletter "Import AI" https://t.co/BXl4XC8NGa
830121442146529300,Fri Feb 10 18:29:09 +0000 2017,@brandondamos i'm assuming pytorch copies when it concatenates? you might also have to pull tricks like recomputing parts of fwd pass
830119611727163400,Fri Feb 10 18:21:52 +0000 2017,@brandondamos oops just noticed you used growth rate 12 due to GPU limitations, so gap only ~0.2
830119230989226000,Fri Feb 10 18:20:22 +0000 2017,@brandondamos should it get 3.46%, any idea about the remaining gap?
829518533772054500,Thu Feb 09 02:33:24 +0000 2017,@sguada PyTorch!! But I'm quite sure TensorFlow will do just fine too :)
829422139459526700,Wed Feb 08 20:10:22 +0000 2017,Very nice tutorial from Justin on PyTorch from scratch https://t.co/ZBRHUGa7H2 ,stumbled on from "Practical PyTorch" https://t.co/VXBhHBqbTn
829421615532240900,Wed Feb 08 20:08:17 +0000 2017,Matlab is so 2012. Caffe is so 2013. Theano is so 2014. Torch is so 2015. TensorFlow is so 2016. :D
829417355587432400,Wed Feb 08 19:51:22 +0000 2017,@georgebastille it worked best of things i tried :)
829254976845279200,Wed Feb 08 09:06:07 +0000 2017,@Rob_Bishop you wouldn't by any chance happen to know why fake twitter accounts RTing this paper, right?
829120283327934500,Wed Feb 08 00:10:54 +0000 2017,@Smerity @jackclarkSF absolutely - a planned feature for next hacking session. I remember seeing trendingarxiv and then couldn't find again
829114100143657000,Tue Feb 07 23:46:20 +0000 2017,arxiv-sanity is now migrated &amp; has new feature: sort by hype :p - shows papers that got most tweets over last 5 days https://t.co/VkXqRq301V
828849417528578000,Tue Feb 07 06:14:35 +0000 2017,Created an image, did a full update, set up hostname, timezone, ssh keys, iptables, cron jobs... Achieved accidental sys admin mastery.
828848820456812500,Tue Feb 07 06:12:12 +0000 2017,Migrating arxiv-sanity to more permanent home @ Linode. Quite like the service &amp;their docs are great Linux tutorials https://t.co/FApnNAIXi5
828776789765808100,Tue Feb 07 01:25:59 +0000 2017,@volkuleshov i.e. things that a reviewer might not necessarily catch unless they tried to reproduce the experiments. Hard to protect against
828776635092463600,Tue Feb 07 01:25:22 +0000 2017,@volkuleshov these were concerns raised by people who tried to reproduce very similar experiments and they found more nuanced takeaways
828770135485804500,Tue Feb 07 00:59:32 +0000 2017,@volkuleshov there are a few people I've talked to who would have rejected it too though. high variance process
828723931146227700,Mon Feb 06 21:55:56 +0000 2017,@vo_d_p unless you really want to automatically detect, localize and track toilets, in which case it's great! ;p
828694150023221200,Mon Feb 06 19:57:36 +0000 2017,@TelemaqueDRF I immediately noticed that too, basically what triggered my mini tweet storm there.
828693430054199300,Mon Feb 06 19:54:44 +0000 2017,For image captioning this meant that predicting the single sentence "A giraffe next to a tree" worked very well, accurate for lots of imgs.
828692964700364800,Mon Feb 06 19:52:53 +0000 2017,This was imo a big problem with MSCOCO. Yes it's a lot of data but a third of it were savana animals and another third bathrooms. Strange
828692612848627700,Mon Feb 06 19:51:29 +0000 2017,YouTube-BB dataset: 10.5M inst of 23 classes https://t.co/DWlpMw1Gke great but what's with the fascination with toilets and giraffes in CV?
828092405039632400,Sun Feb 05 04:06:29 +0000 2017,@BrianLester125 @hyperactve yes and this is not super original, heard of ppl doing it 5 years ago, can give 0.5% improvement usually
828056184347168800,Sun Feb 05 01:42:33 +0000 2017,RT @rodneyabrooks: 2/2 https://t.co/5DMzJhbqL0 new essay on End of Moore's Law, quick takes on robot hands, extending DNA alphabet, &amp; two r‚Ä¶
828023868497416200,Sat Feb 04 23:34:08 +0000 2017,Common usage: "I thought I was totally starting to overfit at epoch 17, but there is still hope.". "You need to con‚Ä¶ https://t.co/oz1hiBlhtO
828022882215174100,Sat Feb 04 23:30:13 +0000 2017,Loss addiction: self-destructive behavior of obsessively watching &amp; reading into tiny fluctuations in loss functions of running experiments
827684873846431700,Sat Feb 04 01:07:06 +0000 2017,@EJmz thanks for link! It seems to me that divination should be quite learnable and a serious academic subject.
827680852532359200,Sat Feb 04 00:51:07 +0000 2017,trying to find more books/articles/work on in-retrospect studies of future predictions (e.g. AC Clarke's Profiles of the Future). fave topic
827644920143818800,Fri Feb 03 22:28:20 +0000 2017,[batchnorm conv batchnorm relu conv batchnorm] resnet https://t.co/dXFCWCsScR my head hurts. tldr: more batchnorm and less relu.
827273957447397400,Thu Feb 02 21:54:16 +0000 2017,+the actual talk on YouTube makes this more visual: "The Power of Big Data and Psychographics" https://t.co/ARWLEY6yAs
827271674072490000,Thu Feb 02 21:45:11 +0000 2017,Welcome to the era of big data psychometrics, hyper-targeted advertising, and optimal opinion control https://t.co/uuhgex6T9r
827222216966168600,Thu Feb 02 18:28:40 +0000 2017,@yosit Hi Yosi haha @ hashtag; flattered :) &amp; always great to hear my work was of help. unf not planning trip that far that soon, sorry &amp; ty
826919395242893300,Wed Feb 01 22:25:21 +0000 2017,Wow, a "nightmare inducing robot" indeed, new half-wheeled (?) robot from Boston Dynamics https://t.co/1WCBUVZtWC
826906626393202700,Wed Feb 01 21:34:37 +0000 2017,@yoavgo I did, MLPs overfit too easily in my case. I used sklearn, they have a sublinear_tf that defaults False, worked few pts better@ True
826718223840137200,Wed Feb 01 09:05:58 +0000 2017,@breuderink I only have 1606 users with 5+ libraries. I suspect it's not enough data to do user-based rec. The items have rich features.
826718075424632800,Wed Feb 01 09:05:23 +0000 2017,@hyperactve not too surprising. SVMs often outperform Softmax classifiers. Can also just use the hinge loss in a neural net without 2 stages
826642802054361100,Wed Feb 01 04:06:16 +0000 2017,@nerdherdempire I didn't try LSTMs. This is all on tfidf vectors, I didn't get fancier than that. It already runs for ~hour+
826633931004923900,Wed Feb 01 03:31:01 +0000 2017,@edwk @kireetr simple liblinear through scikit-learn
826631657285263400,Wed Feb 01 03:21:59 +0000 2017,@kooswilt arxiv-sanity has 1606 users with 5+ papers in library. I recommend based on all except 1, then check its rank in list (want low)
826628451708788700,Wed Feb 01 03:09:15 +0000 2017,Naive Bayes, recommendation systems, LSI, MLPs, lots of things didn't work. carefully tuned SVM with log-scaled term frequencies worked best
826628171961282600,Wed Feb 01 03:08:08 +0000 2017,Ran a crossval of arxiv-sanity recommendation alg approaches/params. Increased Recall@20 from 0.25 to 0.31, i.e. probly works bit better now
825092966909767700,Fri Jan 27 21:27:47 +0000 2017,@Imran__R it's on my blog, cognitive discontinuity
825076664400912400,Fri Jan 27 20:23:00 +0000 2017,Automated astroturfing with chat bots (eg on Reddit/Twitter) is technically very feasible and highly concerning  https://t.co/bgU6PbzxXQ
824889843394097200,Fri Jan 27 08:00:39 +0000 2017,I'm (slowly) writing another short story on AI that I'm super excited about. Except I've been stuck on one passage for a few months. Hard :(
824716611152076800,Thu Jan 26 20:32:17 +0000 2017,@yigitdemirag @RaymondRChua errr wait maybe direct link is better because videos etc: https://t.co/f6I8jJLWBn
824716336462913500,Thu Jan 26 20:31:11 +0000 2017,@yigitdemirag @RaymondRChua sure, find slides here: https://t.co/KEkJ9Y2JR6
824707909586071600,Thu Jan 26 19:57:42 +0000 2017,RT @thinkmariya: "I'd like to train an AI to play Tic Tac Toe. No big deal ;P" @karpathy @openai #reworkDL #DL #AI https://t.co/3xSaxP9wA7
824707827776106500,Thu Jan 26 19:57:23 +0000 2017,RT @SophiaViklund: Full house gathered for Andrej Karpathy's talk at Rework DL summit: @openai @karpathy #reworkDL #DL #ML #AI https://t.co‚Ä¶
824707140363264000,Thu Jan 26 19:54:39 +0000 2017,RT @twimlai: Policy reinforcement learning in one slide. The math is actually similar to supervised learning. @karpathy @OpenAI #reworkDL #‚Ä¶
824706713349615600,Thu Jan 26 19:52:57 +0000 2017,@katyanna_q better to email
823663751542911000,Mon Jan 23 22:48:35 +0000 2017,It took 50 years for the world to install the first million industrial robots. The next million will take only eight https://t.co/MxzUGwkrSW
823326755255513100,Mon Jan 23 00:29:29 +0000 2017,Aww the Google Self Driving Car project is already part of the Computer _History_ Museum? https://t.co/gBgZug8DSl
822600464034308100,Sat Jan 21 00:23:28 +0000 2017,@sherjilozair @gwern +1 basically my impression too
822563606344695800,Fri Jan 20 21:57:00 +0000 2017,Everything I know about design of ConvNets (resnets, bigger=better, batchnorms etc) is useless in RL. Superbasic 4-layer ConvNets work best.
821996951705034800,Thu Jan 19 08:25:19 +0000 2017,@AndrewDixonSo @TheNickWalsh wow. It is beautiful &amp; rare that you discover something you know you will use for the rest of your life.
821986890358263800,Thu Jan 19 07:45:21 +0000 2017,Dear @AmericanExpress, I got the 100 mails with your AMAZING credit card offer. They aren't just getting lost. Please stop the torture.
821872938764767200,Thu Jan 19 00:12:32 +0000 2017,@_AntreasAntonio keeps it EXCITING! :)
821841568675942400,Wed Jan 18 22:07:53 +0000 2017,w00t MIT's Deep Learning for Self-Driving Cars class uses ConvNetJS. DeepTraffic: https://t.co/mg2Oexao9T &amp;DeepTesla https://t.co/0Gr5IY6oGH
821807382183317500,Wed Jan 18 19:52:03 +0000 2017,Imperative, dynamic graph construction is going strong recently, also with recent &amp; v nice looking minpy https://t.co/KULCPjN6yd, DyNet, etc
821806844385468400,Wed Jan 18 19:49:54 +0000 2017,Excited to see PyTorch (a new Deep Learning library) released! Tried it for few days, it is awesome: imperative!, f‚Ä¶ https://t.co/S7SR96AFmc
821580929621639200,Wed Jan 18 04:52:12 +0000 2017,"Personally, I do not trust paper results at all. I tend to read papers for inspiration" A correct rant. https://t.co/mQOY7hj4QS
821454515505217500,Tue Jan 17 20:29:53 +0000 2017,Wrote up some thoughts on VR (long interest of mine) in a blog post: "Virtual Reality: still not quite there, again" https://t.co/xog6XV4ReM
821035588476280800,Mon Jan 16 16:45:13 +0000 2017,@deanpomerleau I don't buy the simulation stuff, too human centric. can accept a QM cellular automaton with us as just some funny pattern
821034702257594400,Mon Jan 16 16:41:41 +0000 2017,@deanpomerleau sure, it's a special case of the Fermi paradox.
820879892627628000,Mon Jan 16 06:26:32 +0000 2017,@sameersoi it's more of a special case of the Fermi paradox
820879126961668100,Mon Jan 16 06:23:29 +0000 2017,I don't understand why Earth over last few B years was not an easy target for an alien superintelligence when galaxy is only ~100k LY across
820044990034251800,Fri Jan 13 23:08:55 +0000 2017,@soumithchintala For this reason I also wouldn't endorse as far as working from home, because you do miss on many in-person comms.
820044753173524500,Fri Jan 13 23:07:59 +0000 2017,@soumithchintala I still get lunch/dinner/go to various meetings daily. I have a suspicion that this is enough &amp; rest is mostly fun fluff
820033589853069300,Fri Jan 13 22:23:37 +0000 2017,RT @rajatmonga: Last day for applications to #GoogleBrain Residency for 2017 https://t.co/byPmiFGR7U
819996598499348500,Fri Jan 13 19:56:38 +0000 2017,I sequestered myself in a conference room last week (was ill) instead of open seating &amp; RescueTime shows 1.8x more productivity. Interesting
819979435222798300,Fri Jan 13 18:48:26 +0000 2017,Greg's post on past/present/future of OpenAI https://t.co/ZCIplL6bdB including fun stories of OpenAI early days
819974453345955800,Fri Jan 13 18:28:38 +0000 2017,@juddydotg @DARPA yes.
819265714850668500,Wed Jan 11 19:32:22 +0000 2017,@ashiq @adamajm a quick/ugly/temporary hack brought it back. i'll have to properly sit down at some point and fix everything.
819239944711307300,Wed Jan 11 17:49:58 +0000 2017,@adamajm uh oh. with growing library of papers and my fairly lazy code the serving process started running out of memory over time. Panic!!!
819235853020983300,Wed Jan 11 17:33:42 +0000 2017,RT @OpenAI: GTA V + Universe: https://t.co/2bpZ6QNv4R
818953099221954600,Tue Jan 10 22:50:08 +0000 2017,Not clear why TF still really likes `reduce_` syntax bloat, or `keep_dims` vs numpy's `keepdims`, etc.
818952023064182800,Tue Jan 10 22:45:52 +0000 2017,TensorFlow 1.0.0-alpha https://t.co/crOlSAId9C many numpy API compatibility changes are very welcome, seems could still go even further
817879177823039500,Sat Jan 07 23:42:46 +0000 2017,@soumithchintala seems like quite a difficult and tricky technical problem that companies are not thinking through nearly enough.
817877986108051500,Sat Jan 07 23:38:01 +0000 2017,TV anchor says "Alexa order me a dollhouse" on live TV, Alexas in people's homes activate and go on shopping spree https://t.co/2FLReeKHfZ
816369309635051500,Tue Jan 03 19:43:05 +0000 2017,RT @goodfellow_ian: A tech report summarizing my NIPS tutorial on GANs https://t.co/v1rAvkjMC1
816097355086729200,Tue Jan 03 01:42:26 +0000 2017,@kenstruys @jrheard replied, hope it helps!
815042254381334500,Sat Dec 31 03:49:50 +0000 2016,Local news from Mission SF https://t.co/WfF6TsavgB each time: "[something terrible] @ [a place I walk by all the time]. no arrests made."
813990829517848600,Wed Dec 28 06:11:51 +0000 2016,@tryolabs looks great! i've never actually done the batch norm gradient derivation, it looks long and painful ;)
812832694233137200,Sun Dec 25 01:29:50 +0000 2016,Fun fact 27/120: There are nuclear submarines out there carrying 40 nuclear warheads controlled by a computer running Windows XP.
812832056669507600,Sun Dec 25 01:27:18 +0000 2016,People aren't anywhere nearly enough scared shitless about the world's aging nuclear arsenal and its problems  https://t.co/3fFu2He0ZP
812818685954052100,Sun Dec 25 00:34:10 +0000 2016,@bjorn @onkarjoshi I have no choice they insist. They have applications they are familiar with and unwilling to hear about a switch
812814377061584900,Sun Dec 25 00:17:03 +0000 2016,Doing an annual clean up of my parents' windows laptop. A Wild West of adware/garbage accumulated, each very unwilling to be uninstalled
811659053038522400,Wed Dec 21 19:46:12 +0000 2016,V amusing read on cat-proofing feeder "The trick is to be smarter than the animal with a brain the size of a walnut" https://t.co/ekNNURLDvs
810935694168207400,Mon Dec 19 19:51:50 +0000 2016,A short/quick blog post: ‚ÄúYes you should understand backprop‚Äù https://t.co/fOsrsiU2HA
810557818843570200,Sun Dec 18 18:50:18 +0000 2016,@naivebayesian @yoavgo Also have a higher level recent talk that could have some good fit https://t.co/Fx7E7Qlu7r
810556608111591400,Sun Dec 18 18:45:29 +0000 2016,w00t, up to 10x faster fp16 gemm kernels than cuBLAS, from @scottgray76 https://t.co/8TbzBF1GXl
809895766584098800,Fri Dec 16 22:59:32 +0000 2016,@dvigneshwer sorry, i mean it's for strong (web) engineers first. Experience with AI/ML certainly a plus.
809893047924310000,Fri Dec 16 22:48:44 +0000 2016,@dvigneshwer we are creating web environments benchmarks to get AIs to understand &amp; navigate buttons/forms/etc., complete tasks.
809889309775925200,Fri Dec 16 22:33:53 +0000 2016,+We are looking to hire engineers to help us create more web environments for AI agents. Ping me at karpathy@openai.com if interested!
809889202120884200,Fri Dec 16 22:33:27 +0000 2016,More on Mini World of Bits project (agents learn to use the web) at OpenAI and how to use it with Universe:‚Ä¶ https://t.co/PoBbisb7BL
808947712070586400,Wed Dec 14 08:12:18 +0000 2016,@yazinsai Planning to give it a try over the winter break! :)
808798530382929900,Tue Dec 13 22:19:31 +0000 2016,Finally finished Rhodes' tome "The Making of the Atomic Bomb". Great but a bit loooong. Review/summary/comments: https://t.co/PXLrypyl3X
807260390182752300,Fri Dec 09 16:27:29 +0000 2016,John Schulman's slides from today's "nuts and bolts of RL", great practical advice for getting RL to work https://t.co/HYgL68Ropb
807229184271589400,Fri Dec 09 14:23:29 +0000 2016,There are surprisingly many surprisingly aggressive security guards at this years #NIPS2016
807037054173450200,Fri Dec 09 01:40:02 +0000 2016,Best party of #nips2016 award goes to #rocketai (https://t.co/RfOFeqxBLx). Definitely a company to watch closely.
806885058212757500,Thu Dec 08 15:36:03 +0000 2016,@knormand29 was down, brought it back up. we had a planned outage.
806856417600766000,Thu Dec 08 13:42:15 +0000 2016,@yigitdemirag RNN!!
806520315522084900,Wed Dec 07 15:26:42 +0000 2016,@drewvolpe "readers also liked" - good, easy to add idea. hmmm
806519637840199700,Wed Dec 07 15:24:00 +0000 2016,Marc Raibert of Boston Dynamics gave a very nice talk @ NIPS on robots. +fun pointers, e.g. swearing robot spoof: https://t.co/EoBa1rLJEv
805831733237182500,Mon Dec 05 17:50:31 +0000 2016,Also, I'm really hoping to start seeing pretrained agents on Universe, similar to the pervasiveness of pretrained ConvNets on ImageNet.
805828033047363600,Mon Dec 05 17:35:49 +0000 2016,Also very excited the ease of collecting human demonstrations on any env in Universe. RL alone doesn't make sense when SL data is near free.
805827094215295000,Mon Dec 05 17:32:05 +0000 2016,With near infinite supply of envs that all "look the same" in Universe, I'm really hoping we can finally see convincing results on transfer.
805826367698911200,Mon Dec 05 17:29:12 +0000 2016,In case you missed it, OpenAI released Universe: https://t.co/4NBbMyIqtd AI agents remote desktop into Docker containers. Really awesome
805190096592851000,Sat Dec 03 23:20:53 +0000 2016,We're going to NIPS to talk about ICLR papers
805149687556673500,Sat Dec 03 20:40:19 +0000 2016,‚ÄúDeep Learning the Stock Market‚Äù by @thetalperry https://t.co/stP5TpWSyI. I often enjoy posts from ppl newish to DL - diff ways of thinking
804383574413623300,Thu Dec 01 17:56:03 +0000 2016,Google Earth Timelapse: see 1984 -&gt; 2016 https://t.co/NyKTib2NSe extremely depressing. cancer cities, massive deforestation, ice melting
804052953740869600,Wed Nov 30 20:02:17 +0000 2016,Most of us at OpenAI watching this now. https://t.co/gtmQSJj15X
803809794167435300,Wed Nov 30 03:56:03 +0000 2016,@bleyddyn LOL. absolutely.
803726442282434600,Tue Nov 29 22:24:51 +0000 2016,@michael_nielsen our bodies are too damn efficient. A really good feature until recently, a cruel bug since.
803725415214760000,Tue Nov 29 22:20:46 +0000 2016,I ran for 20 minutes yesterday and burned 260 cals. That's 11 square blocks of my favorite chocolate in our microkitchen. cruel world :(
803348072302571500,Mon Nov 28 21:21:20 +0000 2016,@AndrewYNg The Making of the Atomic Bomb by Rhodes
802654482836242400,Sat Nov 26 23:25:15 +0000 2016,This year's NIPS (happening in a week!!!1) will be:
801694597009113100,Thu Nov 24 07:51:01 +0000 2016,@karpathy (i just wanted to make sure that people understand that this is a joke...)
801621764144971800,Thu Nov 24 03:01:36 +0000 2016,3e-4 is the best learning rate for Adam, hands down.
800967315357515800,Tue Nov 22 07:41:03 +0000 2016,@TimHaines Cafe Venetia and Old Union are both highly suspicious. I visited each 5 times max last year but I have 16/18 charges from them
800963074635116500,Tue Nov 22 07:24:12 +0000 2016,I also discovered that a Palo Alto cafe charged me 18 times except I went there ~twice ever. Multiple for same amount ($7.94). What.
800958760877314000,Tue Nov 22 07:07:04 +0000 2016,Downloaded my bank data as csv &amp; hacking out plots. They don't make it easy. They export addresses (which have commas) in CSV files. Great.
800907474794491900,Tue Nov 22 03:43:16 +0000 2016,RT @cvondrick: Fantastic conditional GAN results by Isola et al https://t.co/omdWEyfGF6 https://t.co/zRmknPgoTu
800840801311854600,Mon Nov 21 23:18:20 +0000 2016,Following World Chess Championship a bit. All 7 games so far were draw (https://t.co/TZHiJqPe49). 8th live stream: https://t.co/MGmWkPcx3U
800587700583551000,Mon Nov 21 06:32:36 +0000 2016,Finished Black Mirror season 3. Favorite eps: 6 &gt; 1 &gt; 4 &gt; 5 &gt; 2 &gt; 3. Black Mirror is sadly too relevant today.
800200101905899500,Sun Nov 20 04:52:25 +0000 2016,@sguada oh. Yeah. Good point :)
800148834491867100,Sun Nov 20 01:28:42 +0000 2016,@hardmaru :) imo there can be quite decent visual improvements for every 0.01 when you're that far down.
800148515292708900,Sun Nov 20 01:27:26 +0000 2016,Also worth trying the PixelCNN as the decoder in all the things instead of "vanilla" deconv stack; it's powerful. Except slower to sample :(
800146521501012000,Sun Nov 20 01:19:31 +0000 2016,Btw ~week ago we released PixelCNN++, a nice/efficient multi-GPU TensorFlow code, SOTA generative model on CIFAR-10 https://t.co/afq8UTHmEd
799497839244091400,Fri Nov 18 06:21:53 +0000 2016,@LesGuessing I went through the same experience exactly. Was ready to be superman and instead was a weird gozilla with restricted vision
799477451302715400,Fri Nov 18 05:00:52 +0000 2016,@VahidK I did, I liked it. Except it was 5 minutes and the team seems to have disappeared since.
799477310214709200,Fri Nov 18 05:00:18 +0000 2016,@jackclarkSF not too much but I think they're still missing some critical features. It's like what Paint is to Photoshop. Oh &amp; multiplayer!!
799475276799352800,Fri Nov 18 04:52:14 +0000 2016,@karpathy so far my viscerally interesting favorites with potential are Tilt Brush, AudioShield/HoloPoint, and AltspaceVR
799474784413196300,Fri Nov 18 04:50:16 +0000 2016,Tried out Google Earth VR in Vive. Had high hopes but it's a half-baked "kinda cool" tech demo I won't go back to. Like most other things VR
799197974173651000,Thu Nov 17 10:30:20 +0000 2016,@karpathy a core yelp functionality appears to be `if comment.substring(query): return comment`.
799189705812156400,Thu Nov 17 09:57:28 +0000 2016,when you search "best ribs" on Yelp the first result is a place with someone's review that says "Not the best ribs I've had...". great.
799093071782654000,Thu Nov 17 03:33:29 +0000 2016,RT @DeepMindAI: Introducing UNREAL, our UNsupervised REinforcement &amp; Auxiliary Learning agent! Results on Labyrinth &amp; Atari https://t.co/Gc‚Ä¶
798950557784232000,Wed Nov 16 18:07:11 +0000 2016,@gwern yeah but I still can't quite internalize that it should be that "dumb" and work fine
798806811360960500,Wed Nov 16 08:35:59 +0000 2016,monster Multilingual MT system https://t.co/UZWrw4eQFp 3 weeks on 100 GPUs. Just append target language token to source sentence  ¬Ø\_(„ÉÑ)_/¬Ø
797969915521007600,Mon Nov 14 01:10:28 +0000 2016,(my very top recommendations have been rainfall videos for the last month because I tried it out once for coding)
797969636390105100,Mon Nov 14 01:09:21 +0000 2016,If you play ambiance music on YouTube once be prepared to be recommended more forever. It thinks you *love* it after "watching" it for hours
797512649550405600,Sat Nov 12 18:53:27 +0000 2016,Watched Arrival last night and didn't like it, probably because I read the short story (which is MUCH better/consistent/believable) first.
796847789246279700,Thu Nov 10 22:51:32 +0000 2016,Visiting Stanford briefly today. In case you were wondering where arxiv sanity lives, my old box picture :D should‚Ä¶ https://t.co/xLkBmG8Gvx
796775341100412900,Thu Nov 10 18:03:39 +0000 2016,@egrefen this is my pet peeve chart. The y-axis starts at 58M. Arbitrarily misleading visualization.
795830483166732300,Tue Nov 08 03:29:07 +0000 2016,Looking forward to guest lecture at Stanford's "Minds and Machines" class on Thursday https://t.co/jX65ie5tqN the course slides are nice!
795701286393888800,Mon Nov 07 18:55:44 +0000 2016,RT @shivon: The Current State of Machine Intelligence 3.0! https://t.co/bmsnNjbwAG @jamescham https://t.co/BvYG2MZoDm
793713111794540500,Wed Nov 02 07:15:26 +0000 2016,A wonderful passage on Quora (https://t.co/Lr14TllX0U) about reading/writing books, become a part of an meme medium‚Ä¶ https://t.co/qSwwNfd1dW
793708512643657700,Wed Nov 02 06:57:10 +0000 2016,@_onionesque @michael_nielsen Zomg I had lost the link to that post, so wonderful to re-discover it!
793295058518745100,Tue Nov 01 03:34:15 +0000 2016,RT @nalkalchbrenner: New neural net for Language and Machine Translation! Fast and simple way of capturing very long range dependencies htt‚Ä¶
793208032075264000,Mon Oct 31 21:48:26 +0000 2016,Awesome work by @crizcraig on DeepDrive: https://t.co/anhUMikPjM Using GTA 5 simulator to benchmark self-driving car models. Fun videos
792470411292266500,Sat Oct 29 20:57:24 +0000 2016,RT @alexjc: #NeuralEnhance lets you apply 4x super-resolution to your photos CSI-style in only 340 lines of code! https://t.co/Ki9jRyQlDP #‚Ä¶
791792103533666300,Fri Oct 28 00:02:02 +0000 2016,@HBaoViet nope, all graduated.
791781241880055800,Thu Oct 27 23:18:53 +0000 2016,@prasanna in order of increasing interest, I assume? Only watched 1,2,3 so far, liked 1 best because of high Black Mirror meme potential
791359531980689400,Wed Oct 26 19:23:09 +0000 2016,@cstromblad I'm only ~10 hours and 2 games in but so far like it! Seems like an improvement over 5 imo.
791131251465982000,Wed Oct 26 04:16:03 +0000 2016,@accesspattern haha good point! unless the intermediates are also processed along the way in their own ways :)
790974490788393000,Tue Oct 25 17:53:08 +0000 2016,@AndrewJRibeiro much of this is due to numpy arrays' (h,w) order.
790971590229889000,Tue Oct 25 17:41:37 +0000 2016,If you're lazy with handling the order of x,y coordinates in your code n times you will regret it O(2^n) times.
790604469884981200,Mon Oct 24 17:22:48 +0000 2016,@deanpomerleau it doesn't crash, I just have to keep it alive manually every 2 days and I forget. Better solutions coming soon hopefully
789571283079995400,Fri Oct 21 20:57:18 +0000 2016,I wish we had a list of numpy error translations. E.g. "TypeError: data type not understood" -&gt; "99%: You forgot to use a tuple in np.zeros"
789303620617445400,Fri Oct 21 03:13:42 +0000 2016,@yieldthought this is Awesome, well done!
789301761789997000,Fri Oct 21 03:06:19 +0000 2016,RT @yieldthought: Last week I parallelized @karpathy's policy gradient and ran it on 1536 cores. Learns to beat Pong in 3.9 minutes! https:‚Ä¶
789222357105647600,Thu Oct 20 21:50:47 +0000 2016,RT @zoyathinks: My summary on, and pondering of, ECCV 2016 and its research trends: https://t.co/2fH1MxaORS
788493837047955500,Tue Oct 18 21:35:54 +0000 2016,@aminert oops server crashed. resetting, should update in 1hr
788261668782379000,Tue Oct 18 06:13:21 +0000 2016,@cstromblad LOL classic Civ
788255989409587200,Tue Oct 18 05:50:47 +0000 2016,@adamgdunn I'm so glad I dodged that bullet. It smelled like a Spore repeat so I didn't spend time looking forward to it. Best decision ever
788255718616870900,Tue Oct 18 05:49:43 +0000 2016,@adamgdunn Haha, nice - well done! :)
788253954375245800,Tue Oct 18 05:42:42 +0000 2016,Civilization 6 is coming out in 3 days. I have to keep calm. Spent many hours in Civ 2, bit less Civ 3/4, then quite bit Civ 5. Deep breaths
788067455973281800,Mon Oct 17 17:21:37 +0000 2016,Another nice post in Distill on techniques for avoiding checker artifacts during upsampling ops https://t.co/hGaaAciDxA TLDR: nn-resize conv
788060779291353100,Mon Oct 17 16:55:05 +0000 2016,RT @rsalakhu: Excited about joining Apple as a director of AI research in addition to my work at CMU. Apply to work with my team https://t.‚Ä¶
786982637734809600,Fri Oct 14 17:30:56 +0000 2016,RT @wattenberg: t-SNE seems to magically map high-dimensional data. How to read those maps correctly:  https://t.co/WCm1EcbVIw (with @viega‚Ä¶
786755390205726700,Fri Oct 14 02:27:56 +0000 2016,RT @fchollet: Awesome project from @transcranial: Keras.js - run trained models in the browser, with GPU support via WebGL. https://t.co/Pb‚Ä¶
786356629755134000,Thu Oct 13 00:03:24 +0000 2016,Except a lot of asterisks are attached to that number. I imagine that‚Äôs the case for many of the other numbers in such high-level summaries
786356525010780200,Thu Oct 13 00:03:00 +0000 2016,Turns out my 5% ImageNet error rate ended up in the federal government's "Prepraring for the Future of AI" report https://t.co/VOsGouC5gQ
786332449751994400,Wed Oct 12 22:27:20 +0000 2016,@kchonyc @hardmaru @fchollet that and/or raw audio. characters are a fake abstractions. the only thing that really exists is sound and light
786332180595089400,Wed Oct 12 22:26:15 +0000 2016,@kchonyc @hardmaru @fchollet boring - characters are so 2016. Lets just use rendered characters in pixels.
786301639426658300,Wed Oct 12 20:24:54 +0000 2016,DeepMind's Neural Turing Machine (NTM) has evolved into "Differentiable Neural Computer" (DNC), now in Nature: https://t.co/DSz7m4gAsI [pdf]
786249056217473000,Wed Oct 12 16:55:57 +0000 2016,The National Artificial Intelligence Research and Development Strategic Plan https://t.co/moFpZzoCaY pdf| interesting global look at AI tech
786012539700125700,Wed Oct 12 01:16:07 +0000 2016,Footnotes are a complete UX disaster - breaking flow, getting people to search, scan, scroll due to fomo, remembering where they were, ugh.
785912139399565300,Tue Oct 11 18:37:10 +0000 2016,Lots of fun analysis on World Population https://t.co/XYHUxXrWBp "6.5 percent of all people ever born are alive right now."
784212363062816800,Fri Oct 07 02:02:51 +0000 2016,Coworker on RL research: "We were supposed to make AI do all the work and we play games but we do all the work and the AI is playing games!"
783346744125861900,Tue Oct 04 16:43:12 +0000 2016,RT @alexjc: Justin released his fast-neural-style source code in #Torch. https://t.co/V2ShTiHTjy With TitanX can do 4 models in real-time!‚Ä¶
783107961690296300,Tue Oct 04 00:54:22 +0000 2016,Awesome Google Research blog post on scaling up robotics https://t.co/ZzLJA1WGYw
782369093663862800,Sat Oct 01 23:58:22 +0000 2016,hmm. if you were creating a 4D cellular automaton universe simulation and running a hyperparameter sweep, what would be the objective?
782314226610163700,Sat Oct 01 20:20:20 +0000 2016,@Plinz any good pointers to a collection of serious critiques?
782298808172490800,Sat Oct 01 19:19:04 +0000 2016,@AndrewLBeam great pointer, thank you!
782298751234822100,Sat Oct 01 19:18:51 +0000 2016,@SKRHardwick you can be right and simply too early.
782297891595432000,Sat Oct 01 19:15:26 +0000 2016,"An extraterrestial intelligence, on first seeing the earth would conclude that the automobile was the dominant form of life" -Arthur Clarke
782294458117173200,Sat Oct 01 19:01:47 +0000 2016,(argues that 1) one must work on full-stack agents, 2) work in the real setting and avoid abstraction, 3) pitches the subsumption approach)
782292781624533000,Sat Oct 01 18:55:08 +0000 2016,"Intelligence without Representation" (Brooks 1991) https://t.co/Wa96tUeO43 great read on a particular approach/philosophy towards AI.
781529543299379200,Thu Sep 29 16:22:17 +0000 2016,"the most demonically clever computer security attack" https://t.co/g9pCeca5ie fun read; compromised chip gives sudo through a piece of code
781185969080807400,Wed Sep 28 17:37:03 +0000 2016,Google Research releasing YouTube-8M: large and diverse labeled video dataset https://t.co/agXqobX87C +1.5TB of inception-v3 features. neat!
781178224726319100,Wed Sep 28 17:06:17 +0000 2016,Interesting: there was a parallel branch of development of CNNs in ~1989 independent of LeCun. Neocognitron+Backprop https://t.co/hQl2omvIN9
780346094119026700,Mon Sep 26 09:59:41 +0000 2016,Looks like winner might be a large ensemble of Inception/Inception-ResNet/Wide ResNet/others. i.e. not clear how much new we'll learn.
780344674611449900,Mon Sep 26 09:54:03 +0000 2016,ImageNet ILSVRC 2016 results are out https://t.co/Gj9KzvI8vh congrats to Trimps-Soushen (0.02991 error), &amp; FAIR team with 0.03031.
780148493813846000,Sun Sep 25 20:54:30 +0000 2016,Ghost Robotics' Minitaur Quadruped: awesome looking agile robot https://t.co/HKQcsTBZwS cost: ~$10K, hoping this might go down quickly
779844549950656500,Sun Sep 25 00:46:44 +0000 2016,@icrtiou sure! perhaps trying to reproduce the cifar-10 numbers is a better exercise than ILSVRC.
779828937073434600,Sat Sep 24 23:44:41 +0000 2016,@icrtiou they will be up on baylearn website shortly i believe.
779820235918495700,Sat Sep 24 23:10:07 +0000 2016,More awesome hints of what Photoshop++ will look like in the future https://t.co/qhj61HYR9g + paper https://t.co/JD043GCC3g
779810457066479600,Sat Sep 24 22:31:15 +0000 2016,Reinforcement Learning bible book from Richard Sutton now has a new 2nd, updated edition https://t.co/4YXDMTF0bn [455-page PDF link]
779776392586072000,Sat Sep 24 20:15:54 +0000 2016,RT @bradleypallen: @karpathy at #bayareadlschool says: don't be a hero - reuse other people's architectures when doing DL https://t.co/s4SR‚Ä¶
779408937657315300,Fri Sep 23 19:55:46 +0000 2016,@jrk thanks! yep I'm prepared :)
779125558219186200,Fri Sep 23 01:09:43 +0000 2016,Making slides for my Saturday lecture @ https://t.co/2J17OZpbJC. I know I complained about slide making while ago, but now I miss it. a bit.
779107418236067800,Thu Sep 22 23:57:38 +0000 2016,Also related, the paper: "ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement Learning" https://t.co/YY5YYcSvmP
779085877913882600,Thu Sep 22 22:32:02 +0000 2016,Doom AI deathmatch competition https://t.co/6EIqTvRTBF very cool! Looking forward to seeing more AI competitions
779011973463674900,Thu Sep 22 17:38:22 +0000 2016,@ylecun other options include moving restroom, room conveyor belt system (to get ppl to mingle), music, or a "fun robot" mobile platform
779010795501789200,Thu Sep 22 17:33:41 +0000 2016,RT @googleresearch: We‚Äôve made the latest version of our image captioning system available as an open source model in #TensorFlow - https:/‚Ä¶
778779271560958000,Thu Sep 22 02:13:42 +0000 2016,Great discussion today at dinner @ OpenAI on measuring fun of a party with cameras/microphones and then maximizing fun. Action space TBD.
778333415871348700,Tue Sep 20 20:42:01 +0000 2016,"Where will Artificial Intelligence come from?" https://t.co/z3zMRWl0Mf very nice blog post with fun pointers I missed, from back in April
778286393441169400,Tue Sep 20 17:35:10 +0000 2016,Transcript of Surreptitiously Taped Conversations among German Nuclear Physicists at Farm Hall, August 1945 https://t.co/IKQfYKvsRu
778131795137224700,Tue Sep 20 07:20:51 +0000 2016,Video of DQN playing Doom deathmatch https://t.co/FBUZ8NgAJG fun to watch! Superhuman aim is well within DQN capabilities
777274700099485700,Sat Sep 17 22:35:04 +0000 2016,Tried out Oculus VR for a while. Was meh. Realized that all my favorite HTC Vive games use controllers in fun ways &amp; are impossible here.
776885599605170200,Fri Sep 16 20:48:55 +0000 2016,RT @notmisha: Twitter just open sourced torch-twrl, a framework for rl in torch that integrates with the @OpenAI gym https://t.co/h3ZGkfmIlV
776864849292775400,Fri Sep 16 19:26:28 +0000 2016,finally a one-liner for this (curtesy of john schulman): `def discount(x, gamma): return scipy.signal.lfilter([1],[1,-gamma],x[::-1])[::-1]`
776586916166635500,Fri Sep 16 01:02:03 +0000 2016,"requirements proposed would require [us] to implement extremely expensive measures to make these resources available to public for free."
776585890155987000,Fri Sep 16 00:57:59 +0000 2016,The Department of Justice is after UC Berkeley for posting educational materials https://t.co/VjiIrHufw1 (in violation of Disabilities Act)
776109836601667600,Wed Sep 14 17:26:19 +0000 2016,@aminert I'm aware, sorry about that. there are technical difficulties outside of my control and i'm working on it.
776109183221411800,Wed Sep 14 17:23:43 +0000 2016,+1 for visual languages for Neural Net architectures https://t.co/VzsHaf0wPu We'll have tools to create/edit nets like in chip manufacturing
776108078815064000,Wed Sep 14 17:19:20 +0000 2016,RT @_onionesque: Generative Visual Manipulation on the Natural Image Manifold (using GANs) https://t.co/h6MbgUfxCt Video: https://t.co/XAHD‚Ä¶
775794233588355100,Tue Sep 13 20:32:13 +0000 2016,Nice posts on building/running a Deep Learning GPU machine by @graphific Part 1: https://t.co/e1ADJuLWAa and Part 2: https://t.co/rkmNkPpleU
775723478875975700,Tue Sep 13 15:51:04 +0000 2016,@bbabenko haha i'd love to see a list of those topics. I think they also include Universal Basic Income, simulation hypothesis, Soylent, ...
775608488374394900,Tue Sep 13 08:14:08 +0000 2016,A convo over the weekend has convinced me that general anesthetic (unlike sleep) actually kills you and someone else wakes up. a new pid :(
775378801702244400,Mon Sep 12 17:01:26 +0000 2016,@aac yeah wasn't clear if bugs or fraud but apparently author was implicated in other shady kickstarter stuff, so possibly latter
775373605211299800,Mon Sep 12 16:40:47 +0000 2016,the suspicious pretraining paper I tweeted about ~week ago was withdrawn https://t.co/W7N6M28nIb looks like they trained on test set...
774047111599886300,Fri Sep 09 00:49:47 +0000 2016,Ended the Quora session (https://t.co/0uoOErpxZv). Apologies to everyone whose question I wasn't able to get to &amp; ty to @QuoraSessions.
773951333493674000,Thu Sep 08 18:29:11 +0000 2016,WaveNet: A Generative Model for Raw Audio https://t.co/Nf709Snt94 very nice work from DeepMind, fun samples!
773945954638508000,Thu Sep 08 18:07:49 +0000 2016,Starting Quora session in 1hr https://t.co/0uoOErpxZv somewhat intimidating number of questions...
773920549454032900,Thu Sep 08 16:26:52 +0000 2016,RT @genekogan: neat work (+code) generating video snippets with GANs. the babies are terrifying though https://t.co/qjxwJzSawy https://t.co‚Ä¶
773614881765339100,Wed Sep 07 20:12:15 +0000 2016,New blog post: "A Survival Guide to a PhD" https://t.co/VxECVyix8O
772957020165025800,Tue Sep 06 00:38:09 +0000 2016,New OpenAI office. I think we went from an org with highest AI researchers per sq meter to lowest. Got lost twice. Claimed a floor as mine.
771872604055404500,Sat Sep 03 00:49:04 +0000 2016,@karpathy also some paradoxically missing baselines; e.g. what accuracy does VGGNet obtain when trained for the same amount of time?
771823326687703000,Fri Sep 02 21:33:15 +0000 2016,@karpathy wait a second you get VGGNet-level accuracy on ImageNet with a layerwise process and this doesn't even make it into the abstract?
771822553903923200,Fri Sep 02 21:30:11 +0000 2016,A paradoxically highly unassuming paper with hard-to-believe results https://t.co/5XuvB7Ds1d might bring back pretraining if true
771748979449004000,Fri Sep 02 16:37:49 +0000 2016,The Google Brain residency program applications for 2017 are now open: https://t.co/19iDZ3yse1 I hear great things!
771466613270847500,Thu Sep 01 21:55:48 +0000 2016,Stanford's AI100 panel has produced their first study titled "AI and Life in 2030" https://t.co/VTovHC4SFR [27 page pdf]
771447001103773700,Thu Sep 01 20:37:52 +0000 2016,I'll be doing a Quora Session next week on Thursday  https://t.co/0uoOErpxZv excited!
770664754977263600,Tue Aug 30 16:49:30 +0000 2016,Misread news title "Victory for Net Neutrality in Europe" as "Victory for Neural Nets in Europe" and got simultaneously excited and confused
770659751579443200,Tue Aug 30 16:29:37 +0000 2016,New OpenAI post on our Deep Learning / experiments infrastructure https://t.co/EvbrhZOZN5 most of which I'm busy learning right now :) :( :|
768570985008078800,Wed Aug 24 22:09:36 +0000 2016,@_onionesque imo "solving intelligence" is sufficiently sensible. Seems concrete to me what it should look like and that we're not there
768567501563174900,Wed Aug 24 21:55:46 +0000 2016,@_onionesque it's just that "on a quest to make progress towards some specific aspects of intelligence in some settings" sounds worse :)
768556642178740200,Wed Aug 24 21:12:37 +0000 2016,post from @j_gauthier on meaninglessness of "solving" language https://t.co/vkQ6qRP3rD
768514967888801800,Wed Aug 24 18:27:01 +0000 2016,The intro chapter of the Deep Learning book has a nice and thorough exploration of history and trends https://t.co/I7nYC0reLh
768490583211946000,Wed Aug 24 16:50:07 +0000 2016,Videos from 2016 Deep Learning Summer School in Montreal are up https://t.co/EttBKRlhna and slides https://t.co/YRNXRABHIU
767890507338965000,Tue Aug 23 01:05:38 +0000 2016,RT @PatrickOmid: Deep Deterministic Policy Gradients in TensorFlow by @patrickomid  https://t.co/KvAA9fnxYh
766082367798648800,Thu Aug 18 01:20:44 +0000 2016,@sguada yep i'm using slim atm and like it!
765952742519025700,Wed Aug 17 16:45:39 +0000 2016,@simonb83 carefully tune the regularization strength (or better, the dropout rate) and learning rate and watch it go 80+ :)
765756521225388000,Wed Aug 17 03:45:56 +0000 2016,dismayed with how much boring/basic furniture is out there &amp; how hard it is to find alternatives. Why get a lamp you can't even ssh into
765756205344043000,Wed Aug 17 03:44:41 +0000 2016,shopping for furniture. eg my lamp must either be actuated/arduino  controlled https://t.co/8J5n91DYx0 or levitating https://t.co/T58cyjR0EE
765735838680424400,Wed Aug 17 02:23:45 +0000 2016,E.g. we use TensorFlow at OpenAI but it seems that we all like different frameworks over it, some of us also roll custom code. sigh
765734518594547700,Wed Aug 17 02:18:30 +0000 2016,I hoped TensorFlow would standardize our code but it's low level so we've diverged on layers over it: Slim, PrettyTensor, Keras, TFLearn ...
765721820431388700,Wed Aug 17 01:28:03 +0000 2016,Chatbot lawyer that overturned 170,000 parking tickets now helps fight homelessness https://t.co/xr0b3d8jqA interesting.
765720972926210000,Wed Aug 17 01:24:41 +0000 2016,Thyme: new tool to track productivity similar to ulogme https://t.co/jE3SYCcMpH looks great, eager to check out
765717219883880400,Wed Aug 17 01:09:46 +0000 2016,@beyang i like Thyme. Curious if you saw ulogme? https://t.co/Vjpg5kAtRz
765681445637533700,Tue Aug 16 22:47:36 +0000 2016,Having lots of fun playing the spot-the-human-readable-error-description in Tensorflow's 200-line stack traces
765588117508108300,Tue Aug 16 16:36:45 +0000 2016,More incredible people joining us at OpenAI! With our current office that's a lot of awesome per square meter. https://t.co/DHN3MKb9rZ
765467889038008300,Tue Aug 16 08:39:01 +0000 2016,@brandondamos Looking at https://t.co/wYpSpfXCB8 curious as to what happened on May 21? :D
765464042500612100,Tue Aug 16 08:23:44 +0000 2016,RT @brandondamos: Just released a new blog post and code! Image Completion with Deep Learning in TensorFlow https://t.co/RoBKv6tdbe https:/‚Ä¶
765263792594784300,Mon Aug 15 19:08:00 +0000 2016,RT @nvidia: We proudly gave @OpenAI our NVIDIA DGX-1 supercomputer to work on #AI's toughest problems. https://t.co/dRPXyAx3lC https://t.co‚Ä¶
764960122544148500,Sun Aug 14 23:01:20 +0000 2016,@rbhar90 @TheEconomist surprisingly low. BuzzFeed low.
764638124668362800,Sun Aug 14 01:41:49 +0000 2016,Found some time to read "Value Iteration Networks" paper - embeds a differentiable planner into agent policy. Neat. https://t.co/Z1WKfuSOyH
764140526647947300,Fri Aug 12 16:44:33 +0000 2016,RT @abursuc: In other news, ~700 / 2500 submissions at #NIPS2016 were on Deep Learning or Neural Networks https://t.co/1cQxfTLcCP https://t‚Ä¶
764139462670495700,Fri Aug 12 16:40:19 +0000 2016,Google Brain AMA on Reddit https://t.co/fEdStO3uEF a lot of good reading by a lot of awesome people
763877083634217000,Thu Aug 11 23:17:43 +0000 2016,Ian Goodfellow is answering question on Quora today: https://t.co/tzYgsN6ZXm
763472612060266500,Wed Aug 10 20:30:30 +0000 2016,RT @notmisha: AETROS Trainer: An interactive tool for designing neural networks https://t.co/5JkknXjM0S
763289615071522800,Wed Aug 10 08:23:20 +0000 2016,Haven't played No Man's Sky yet but reviews make it sound like a Spore repeat. Luckily didn't sink too much time into waiting for it.
763131184280801300,Tue Aug 09 21:53:47 +0000 2016,RT @nervanasys: Breaking news! #Nervana is planning to join #Intel!! Read the full story in this post by our CEO: https://t.co/3gC4l4Pvof @‚Ä¶
763130044990365700,Tue Aug 09 21:49:15 +0000 2016,RT @elonmusk: Would like to thank @nvidia and Jensen for donating the first DGX-1 AI supercomputer to @OpenAI in support of democratizing A‚Ä¶
762726311525625900,Mon Aug 08 19:04:58 +0000 2016,Zenbooth manufactures soundproof booths for open offices where you can disappear and concentrate: https://t.co/tyGniC8unj sounds great
762718841168236500,Mon Aug 08 18:35:17 +0000 2016,Another "finally got to read this paper" &amp; "might as well post my notes" on Matching Networks for One Shot Learning https://t.co/XAADtcecji
762703237380055000,Mon Aug 08 17:33:16 +0000 2016,@ilblackdragon nope :( i wish
762703142345551900,Mon Aug 08 17:32:54 +0000 2016,@keira1412 @shortscienceorg @hugo_larochelle shortscience did not have this paper in their database :(
762446608155803600,Mon Aug 08 00:33:31 +0000 2016,The new WikiReading dataset looks impressive https://t.co/29qBtbc9oQ ‚Ä¶: 18M text reading comprehension instances across ~50% of wikipedia.
762446236360151000,Mon Aug 08 00:32:02 +0000 2016,Read Google Brain WikiReading paper (https://t.co/n6s5kq0i5J); nice read, took some notes, might as well post them: https://t.co/Ah7OaPbisl
761974356348022800,Sat Aug 06 17:16:58 +0000 2016,"The LHC ‚Äúnightmare scenario‚Äù has come true." - i.e. Higgs and that's it. Maybe we live in an ugly universe https://t.co/PCsqDx0yKH
761973146303893500,Sat Aug 06 17:12:09 +0000 2016,You know how there are words in one language with no equivalent in another? Emoji has tons and everyone "speaks it" https://t.co/PXmpNvI46b
761735670876344300,Sat Aug 06 01:28:30 +0000 2016,Some of the slides from this year's Deep Learning summer school in Montreal are now up: https://t.co/YRNXRABHIU
761698013748138000,Fri Aug 05 22:58:52 +0000 2016,@datarade there isn't :( and it's a problem.
761635453590130700,Fri Aug 05 18:50:17 +0000 2016,hah, OH from friend: "papers are often written in a way to hide embarrassing/sloppy details and the fact that the ideas are very simple"
761113342723235800,Thu Aug 04 08:15:36 +0000 2016,@glouppe return y_i sampled uniformly from the training dataset of (x_i,y_i)?
760933349086990300,Wed Aug 03 20:20:22 +0000 2016,@_onionesque haha yeah anyone can apply now (I did as well for lols).
760925542195433500,Wed Aug 03 19:49:21 +0000 2016,I have a soft spot for alife sims because I spent a lot of time in previous life coding similar ones e.g. Scriptbots https://t.co/303GWHg1kx
760925316399247400,Wed Aug 03 19:48:27 +0000 2016,Neural Networks and Unwanted Pregnancies in Evolv.io https://t.co/rHD1FmdZPZ very nice looking evolution sim of artificial life
760573714597457900,Tue Aug 02 20:31:18 +0000 2016,Elon opens Tesla Gigafactory https://t.co/ChddSWQSj0 fun video. "Physics is true. Everything else is debatable."
760526496133881900,Tue Aug 02 17:23:41 +0000 2016,@jwan584 that's fair :)
760514770223050800,Tue Aug 02 16:37:05 +0000 2016,That's awkward. Instagram just cloned Snapchat stories and forgot to change the name of the feature.
760290420345573400,Tue Aug 02 01:45:36 +0000 2016,Nice blog post on "Dreaming of names with RBMs" https://t.co/CXXNCHdfiz
760221446886928400,Mon Aug 01 21:11:31 +0000 2016,@juschuetze no :( couldn't, after Microsoft shut down their API
760186076111646700,Mon Aug 01 18:50:58 +0000 2016,A general statement can only be understood as profound after one encounters some of its special cases. Including this one. Unless it isn't.
760183354264203300,Mon Aug 01 18:40:09 +0000 2016,@gwern wanted to read up more on American history, thought People's history... looked good but I see you only gave it 2 stars on goodreads?
759876008962957300,Sun Jul 31 22:18:53 +0000 2016,RT @evanmiltenburg: @karpathy Always good to check @Neuro_Skeptic after reading such pop-sci articles. They deflate all the hype. See: http‚Ä¶
759848356944359400,Sun Jul 31 20:29:00 +0000 2016,About 40,000 fMRI studies published in the scientific literature called into question due to a bug https://t.co/8ThHg46qyL wonderful
759839302343733200,Sun Jul 31 19:53:01 +0000 2016,@drenerbas i'm not snob enough to evaluate. It keeps me awake just fine :)
759829122335936500,Sun Jul 31 19:12:34 +0000 2016,Multiple friend recommendations did not disappoint. @WorkshopCafe: an awesome place in SF to set up a camp, order food/drinks (on app) &amp;work
759638125681389600,Sun Jul 31 06:33:37 +0000 2016,@soumithchintala my gradient estimator is unbiased and of very low variance. i'm going to optimize the loss function and fast. believe me.
759465097374740500,Sat Jul 30 19:06:04 +0000 2016,RT @jackclarkSF: Sign up for my artificial intelligence newsletter here. https://t.co/GzihdhdhZp First one comes out on Monday!
759136956282351600,Fri Jul 29 21:22:09 +0000 2016,@themoosemind Dynamic Programming, not Dynamic Progaming :) I see that many people are misreading my misread title :)
759114878976004100,Fri Jul 29 19:54:25 +0000 2016,I saw a book on "Dynamic Progaming and Optimal Control" and became very excited/interested and then realized I misread the title :(
758737142616961000,Thu Jul 28 18:53:26 +0000 2016,@nwerneck have you ever tried downloading an app on your couch?
758736626885333000,Thu Jul 28 18:51:23 +0000 2016,How can a couch (a block of wood/soft stuff/cloth) be worth $2K when a top of the line iPhone (a marvel of nanoengineering) is $1K.
757986282630815700,Tue Jul 26 17:09:47 +0000 2016,Soylent blog making a strong case for pro-GMO https://t.co/ETjAfs8rEN +nice collection of links on the topic
757615941345685500,Mon Jul 25 16:38:10 +0000 2016,On climate change https://t.co/BSz35KcLf9 one of more detailed (and scary) posts. Feedback loops, time lags, extinction events
757228281485680600,Sun Jul 24 14:57:45 +0000 2016,Stanford AI's SAILORS summer camp 2016 has concluded. Comprehensive blog: https://t.co/6KKgjAXxGz &amp; main site: https://t.co/0hAyKlnw6r
756384592953761800,Fri Jul 22 07:05:14 +0000 2016,Hanging out in Siciliy this week for #ICVSS2016. Talks (I gave one on Images &amp; Language), posters, sun, tours https://t.co/QJf9DzivoX
756247652719857700,Thu Jul 21 22:01:05 +0000 2016,RT @drfeifei: Now everyone will know what my first startup was (and it's not in Silicon Valley) ;)  @CNN @CarnegieCorp  https://t.co/rrLOTu‚Ä¶
756035012433154000,Thu Jul 21 07:56:08 +0000 2016,Most of my Uber rides involve some kind of fumbling around at pickup trying to find each other in traffic and instructions for dropoff
756034714478182400,Thu Jul 21 07:54:57 +0000 2016,Tesla Master Plan 2 https://t.co/Nk6J56j5nD all reads good except fully autonomous taxis seem quite tricky due to pickup/dropoff complexity
756028099628785700,Thu Jul 21 07:28:39 +0000 2016,@junligu :D
755344585539346400,Tue Jul 19 10:12:37 +0000 2016,Virtual Worlds as Proxy for Multi-Object Tracking Analysis https://t.co/0a8YZFZ8eD impressive; converts real data to virtual worlds
754919640090996700,Mon Jul 18 06:04:02 +0000 2016,Falcon 9 first stage landed! Again. It's so exciting that it's so boring. Maybe it will soon be boring to be excited about it being boring.
753730925314224100,Thu Jul 14 23:20:30 +0000 2016,You can‚Äôt copy money. Like really, it‚Äôs not just illegal, you just can‚Äôt do it on a photocopier https://t.co/CwTboh23Z3 (v good channel too)
753622883016978400,Thu Jul 14 16:11:11 +0000 2016,@gwern gadgets getting out of hand!
753426974396198900,Thu Jul 14 03:12:43 +0000 2016,Haha, when I get a call my iPhone lights up, iPad on my desk lights up, Macbook lights up, (Apple watch used to light up)... Complete chaos
753282924355563500,Wed Jul 13 17:40:19 +0000 2016,10 Papers from ICML and CVPR https://t.co/OGz0sGbi3M nice roundup!
752744424229134300,Tue Jul 12 06:00:30 +0000 2016,Talk comparing trajectories of space flight, CPUs, and the web https://t.co/Lf64oMBdIi disagree with few things but fun read nonetheless
752633585002123300,Mon Jul 11 22:40:04 +0000 2016,I have too many things that need charging. There's also a charging hierarchy where things charge in things that charge. I charge every day.
752176603392712700,Sun Jul 10 16:24:11 +0000 2016,@gwern could be that only old optimization approach is? This is the feedforward NeuralStyle from Johnson et al (labmate). Different, faster.
752017566302744600,Sun Jul 10 05:52:14 +0000 2016,@nekosch good find! It's very fast then.
752009044437590000,Sun Jul 10 05:18:22 +0000 2016,Prisma app https://t.co/smso96Ev0C looks like Neural Style, but since it's so fast probably done with the forward trick version, on device.
751975301526147100,Sun Jul 10 03:04:17 +0000 2016,@bhaaratcrckt paper or audible
751878872866566100,Sat Jul 09 20:41:07 +0000 2016,Finished reading Arthur C. Clarke's "Profiles of the Future" (1960!); 5/5 An excellent read on predicting the future https://t.co/0pMamd2HUO
751129652857479200,Thu Jul 07 19:03:59 +0000 2016,@MadSctnt all Gym does is abstract away the game of Pong and its hardcoded AI player. I wouldn't want to code that from scratch in Python.
750576813538172900,Wed Jul 06 06:27:12 +0000 2016,Haha, it looks like @dribnet is on a roll with amusing generative model results on faces (e.g. see @smilevector).  https://t.co/UJZJZMWQhD
750452534657978400,Tue Jul 05 22:13:21 +0000 2016,Came across a useful doc on "Mac OS X Dev Setup" https://t.co/raRvWB6GYq for setting up a new Mac. Takes few hours to do
750366226442883100,Tue Jul 05 16:30:24 +0000 2016,@sdavidmiller :'(
750235054505226200,Tue Jul 05 07:49:10 +0000 2016,If it takes 10K hours to become an expert, then spending 50 years at 8hr/day on a thing =&gt; can become expert at ~15 things. Not bad.
750232417131114500,Tue Jul 05 07:38:41 +0000 2016,There are ~500K books on Amazon (sensible estimate of total reasonable books), so in your lifetime you can hope to read about 1% of books.
750230733143158800,Tue Jul 05 07:32:00 +0000 2016,If you assume average reading time of 2hr/day and that 1 book is ~10 hrs, then in 50 years (~lifetime) you can read ~5K books. Not a lot.
749526466023395300,Sun Jul 03 08:53:29 +0000 2016,Poverty Inc. on Netflix https://t.co/P4PuveJzD1 a documentary on the "poverty industry" questioning effectiveness of aid. Food for thought.
749480116179251200,Sun Jul 03 05:49:19 +0000 2016,Bingewatched Coursera class on Health and Food https://t.co/2c1ZpZYm2C interestingly highq production but too fluffy; Pollan's book in video
749089810359341000,Sat Jul 02 03:58:22 +0000 2016,RT @harrymccracken: If we just restrict automobiles to a reasonable speed limit like 7 MPH, they'll be safe. https://t.co/jlcp52ngac
749052715108438000,Sat Jul 02 01:30:58 +0000 2016,@RisaWechsler @briandnord for now yes because it was built with one community in mind, otherwise would get noisy. Scaling also tricky
749018167733723100,Fri Jul 01 23:13:41 +0000 2016,https://t.co/Em3vNpuvHY on upcoming ArXiv overhaul https://t.co/0cOMKjuhvl Arxiv Sanity Preserver gets a shoutout!! :) hope they're careful
748999364849209300,Fri Jul 01 21:58:58 +0000 2016,@genekogan these videos are hilarious :)
748999261564473300,Fri Jul 01 21:58:34 +0000 2016,RT @genekogan: deepdream densecap. talk about adversarial nets! says theres lots of dogs. i hadn't noticed https://t.co/Z7mwvebY61 https://‚Ä¶
748998348531568600,Fri Jul 01 21:54:56 +0000 2016,RT @genekogan: dense captioning boston dynamics atlas robot w/ @j26774 @karpathy @drfeifei's densecap. tl;dr motorcyle on snowboard https:/‚Ä¶
748281812200259600,Wed Jun 29 22:27:41 +0000 2016,Nice new blog post from Nervana on the details of their super-efficient (2x+) Winograd kernels for ConvNets https://t.co/K0rg604o8E
747485850502467600,Mon Jun 27 17:44:49 +0000 2016,At #cvpr2016 this week. The poster session is right next to huge expo session with flashy VR demos etc. Can't concentrate! :)
746553559118839800,Sat Jun 25 04:00:13 +0000 2016,Preparing my talk for deep-vision workshop at CVPR next week. it's ~30min talk but I have 120 slides. I can go fast but maybe not this fast.
746432204239102000,Fri Jun 24 19:58:00 +0000 2016,@georgwiese it's a beauty.
746212128344801300,Fri Jun 24 05:23:30 +0000 2016,@davidguera yep... Economic foresight 0/10
746025939000242200,Thu Jun 23 17:03:39 +0000 2016,New Boston Dynamics introducing SpotMini https://t.co/ld3Xl7vlQp looks awesome! Love the ending :D
745868691288506400,Thu Jun 23 06:38:48 +0000 2016,Tabs vs. Spaces scene from Silicon Valley is basically why I love this show so much https://t.co/0azrTRud1m
745428989401980900,Wed Jun 22 01:31:35 +0000 2016,Finding a place to live in SF is becoming a nightmare. Either it's too far away from work, too expensive, or too sketchy/dangerous.
745101516596346900,Tue Jun 21 03:50:19 +0000 2016,@natalieasis :'(
745086951103946800,Tue Jun 21 02:52:26 +0000 2016,I really hope I'm living in the universe where Independence Day 2 is a good movie. Out this Friday!!!11
744980301911187500,Mon Jun 20 19:48:39 +0000 2016,Results of the 2016 Soylent Eaters Survey https://t.co/u4QudZYFTe interesting study/results on an interesting trend
743866795027619800,Fri Jun 17 18:03:58 +0000 2016,RT @DeepMindAI: PixelCNN 2.0: New state of the art generative model for conditional natural image synthesis https://t.co/2agVAzdsbB https:/‚Ä¶
743633476545458200,Fri Jun 17 02:36:51 +0000 2016,I also can't remember how I lived without Twitter/iPhone. What do you do if you really want to tweet something without these?
743633177860673500,Fri Jun 17 02:35:40 +0000 2016,I can't remember how I lived with Uber. What do you do if you want to get from some A to some B without it?
743536776510214100,Thu Jun 16 20:12:36 +0000 2016,``You and Your Research'' by Richard Hamming https://t.co/GO8XLCTukq good stuff
743498125243883500,Thu Jun 16 17:39:01 +0000 2016,RT @OpenAI: Our first research results are now live: https://t.co/YrZtcGhIQT!
742893968090746900,Wed Jun 15 01:38:18 +0000 2016,"Towards an integration of deep learning and neuroscience" https://t.co/QRXA07t5xP [pdf]; Good review article
742437379475046400,Mon Jun 13 19:23:59 +0000 2016,So, Emoji seems popularüí•üî•. Trying to üëÄüëålinguistic studies of the trend. Works with my prediction that we'll use rendered text for NLPüòÇüîë‚ú®‚òù
742437379475046400,Mon Jun 13 19:23:59 +0000 2016,So, Emoji seems popularüí•üî•. Trying to üëÄüëålinguistic studies of the trend. Works with my prediction that we'll use rendered text for NLPüòÇüîë‚ú®‚òù
742196469071941600,Mon Jun 13 03:26:42 +0000 2016,Went through my commencement today - I'm (almost) a doctor! End of an era :) https://t.co/6ZurSOW0tG
741833746094030800,Sun Jun 12 03:25:22 +0000 2016,"This is unbelievable. This is amazing. This is really big!" I know mom, I've been reading that for 3 years on Reddit.
741833310725251100,Sun Jun 12 03:23:38 +0000 2016,My parents/sister are over at Stanford for my commencement. I'm showing them VR (HTC Vive) and they can't believe we have the technology :D
741743646551117800,Sat Jun 11 21:27:20 +0000 2016,Paper reviewing is probably the most amount of work I've done in my life for the least amount of incentives. Surprised the system ~works.
741688569509486600,Sat Jun 11 17:48:29 +0000 2016,@karpathy there are no rows for ideology, value added across society, or brand recognition over decades on a balance sheet
741688015567786000,Sat Jun 11 17:46:17 +0000 2016,Sad to witness the hype curve of MOOCs playing out. Pivoting, steering, ideology and economics. https://t.co/F9zsyL9VbK
741148210757009400,Fri Jun 10 06:01:17 +0000 2016,Just watched Warcraft. Sadly it was Terrible. Really really bad. Huge fan of the games and now this. Ohhhhhh
741030275581284400,Thu Jun 09 22:12:40 +0000 2016,@jmcorgan @erfannoury it's the least popular one by far. looks like people don't think so :(
741018263761485800,Thu Jun 09 21:24:56 +0000 2016,Also while we're at stats here's my blog as well for fun, annotated with post titles. It's hovering at ~3K ppl/day https://t.co/wHvhi7q22o
741015167157182500,Thu Jun 09 21:12:37 +0000 2016,https://t.co/AktZYxom0e update: 1600 accounts added 14,000 papers to their libraries. 500 users/day. micro-growth :p https://t.co/K1sUWvTeT1
740998184340623400,Thu Jun 09 20:05:08 +0000 2016,Style transfer without color https://t.co/mGO31nvoNC these look great; better without the color transfer
740993174974267400,Thu Jun 09 19:45:14 +0000 2016,Spotted on Stanford campus: JackRabbot out exploring https://t.co/Y0WyfUETGf
740968572856340500,Thu Jun 09 18:07:28 +0000 2016,@sleepinyourhat @google arxiv-sanity is few hours! w00tw00t!
740767256066555900,Thu Jun 09 04:47:31 +0000 2016,@garretthonke @DrLoveBC @boydgraber except it's a bit of a strawman because I'd never claim/expect that the model should work for this image
740736730337136600,Thu Jun 09 02:46:13 +0000 2016,"Why the Future Doesn‚Äôt Need Us" https://t.co/alKiNFdGpU an essay from 2000 worth reading.
740206615605841900,Tue Jun 07 15:39:44 +0000 2016,@eatclub hi Eat Club, i like you but your item selection is confusing. It's unclear if ADD button adds the item above it or below it. thx
740045174634516500,Tue Jun 07 04:58:13 +0000 2016,Zoneout for regularizing RNNs https://t.co/GVQ1PGHJGE nice idea and fun title! except ~1 line of code difference and 11 authors? :)
739734647760789500,Mon Jun 06 08:24:18 +0000 2016,@jeaneis oh yeah all the time :)
739694481084055600,Mon Jun 06 05:44:41 +0000 2016,@karpathy the results look almost suspiciously interesting and like something you'd like to find
739693625945133000,Mon Jun 06 05:41:17 +0000 2016,New cool results on ConvNets vs Brain https://t.co/YoHBB9NZ5Z VGGNet accuracy grows monotonically but correlation to human peaks at layer 10
739582536519536600,Sun Jun 05 22:19:52 +0000 2016,@egrefen haha. my experience is that biases are surprisingly useless in many cases. mostly chose to exclude for brevity in the post
738160894014718000,Thu Jun 02 00:10:46 +0000 2016,Comprehensive looking document on "What should we learn from past AI forecasts?" https://t.co/i4vZRn4tQX that I wish I had time to read
738111506068344800,Wed Jun 01 20:54:31 +0000 2016,"Deep Learning Trends @ ICLR 2016" https://t.co/z7kRjvaTD9 nice set of pointers. Agreed that ICLR is at a very comfortable size right now.
737780033368916000,Tue May 31 22:57:21 +0000 2016,New blog post: "Deep Reinforcement Learning: Pong from Pixels" https://t.co/4WIHOGwr3Z on policy gradients https://t.co/mFsiKpXd8h
737740651702296600,Tue May 31 20:20:52 +0000 2016,"Control of Memory, Active Perception, and Action in Minecraft" https://t.co/XvEetGYecL 3D mazes; nice paper. I welcome Minecraft benchmarks
737440603076595700,Tue May 31 00:28:35 +0000 2016,Zenbo the home robot from ASUS concept video https://t.co/TavdaTwJl1 Very painful to watch. I hope it's a bad joke or a horror movie trailer
737055043153580000,Sun May 29 22:56:30 +0000 2016,FractalNet: Ultra-Deep Neural Networks without Residuals. Interesting. https://t.co/PlIZKcZRR9
736983819517988900,Sun May 29 18:13:29 +0000 2016,Haha, yay my "Cognitive Discontinuity" AI short story has produced its first fan fiction! :) Like the chatbot idea https://t.co/HbZ913vjTo
736981963534307300,Sun May 29 18:06:07 +0000 2016,@pkmital lol initialization
736638829801537500,Sat May 28 19:22:37 +0000 2016,RT @DeepSpiker: Could a neuroscientist understand a microprocessor? https://t.co/o09MyZLdEI
736119740775555100,Fri May 27 08:59:57 +0000 2016,@paolo_galeone perfect.
735709450619650000,Thu May 26 05:49:36 +0000 2016,@soumithchintala I'm done predicting it's just embarrassing. :p
735700569436786700,Thu May 26 05:14:19 +0000 2016,@Pg_Fonseca yes https://t.co/1gDUFgc7K0
735699386693390300,Thu May 26 05:09:37 +0000 2016,¬Ø\_(„ÉÑ)_/¬Ø &lt;--- me seeing all the new 96% accuracy on CIFAR-10 ConvNets when I only got 94% &amp; predicted 5 years ago we wouldn't go above 90%
735559087522357200,Wed May 25 19:52:07 +0000 2016,@golan haha :) great, left some thoughts! Thanks for putting this together and nice writeup - exciting area!
735512601816223700,Wed May 25 16:47:24 +0000 2016,RT @kcimc: new work w @golan @workergnome via @creativeinquiry https://t.co/242dIgsvTH is search by image for satellite photos https://t.co‚Ä¶
735511520461750300,Wed May 25 16:43:06 +0000 2016,Except when you extrapolate the data precision (in both space and time) a bit it also makes you feel a little nervous.
735511280484655100,Wed May 25 16:42:09 +0000 2016,Terrapattern https://t.co/vIQxOgqZFw wow, very nicely done. ConvNets + satellite data = huge (mostly untapped) treasure trove of insight
735242613775700000,Tue May 24 22:54:33 +0000 2016,@dh7net nice! Also can get cleaner results if you play with (Lower) temperature in the sampling code. See char-rnn sampling code to see how
735196272831828000,Tue May 24 19:50:25 +0000 2016,@amoselberg yes i deleted the data because i thought noone was using it...
734925008300974100,Tue May 24 01:52:30 +0000 2016,@CraigGidney btw I'm physics major used to want to do Quantum Computing, later switched to AI. QM was taught "wrong way" in my school :(
734898290370613200,Tue May 24 00:06:20 +0000 2016,Goldmine of awesome Quantum Circuit pointers https://t.co/unIKSRV9Ie very nicely presented &amp; explained e.g.: https://t.co/mZLMitn8uw
734414990262702100,Sun May 22 16:05:53 +0000 2016,@brdskggs probably wouldn't merge into master at the moment (hard to say), but the fork hanging around might be useful to others.
734145998239342600,Sat May 21 22:17:00 +0000 2016,Keynote from energy summit on Energy Storage, Electric Vehicles, Self-driving Cars, Solar PV https://t.co/yeu4aJTbU0 "Boom! Disruption." :p
733871623854379000,Sat May 21 04:06:44 +0000 2016,No company has gone from "best company ever" to "worst company ever" in my eyes as quickly as Oculus https://t.co/Huv8gexG32
733720090890371100,Fri May 20 18:04:36 +0000 2016,@genekogan hmm, that doesn't even seem too crazy. You train on YouTube then finetune in gallery. It's just an LSTM GAN something something
733718143714091000,Fri May 20 17:56:51 +0000 2016,@genekogan neat! mirrors that merely reflect 100% reality are so 20th century.
733543154343759900,Fri May 20 06:21:31 +0000 2016,The original toilet paper patent, from 1891 https://t.co/AdER7uWqUN also note: it was meant to hang over not under. that's settled.
733467045379985400,Fri May 20 01:19:05 +0000 2016,New series of 4 lectures on Deep Reinforcement Learning from John Schulman https://t.co/dEnjQCwi7I (recorded @ MLSS 2016 in Cadiz)
733453204952735700,Fri May 20 00:24:05 +0000 2016,@BobCulley ooooooooooo!!! 10/10.
733452985250938900,Fri May 20 00:23:13 +0000 2016,@patrickshafto quite related indeed, awesome! :)
733450752807444500,Fri May 20 00:14:20 +0000 2016,@benhamner that's just the problem, I could tweet random numbers I generated which would be super surprising. Needs redefinition.
733450573018632200,Fri May 20 00:13:38 +0000 2016,Also when people tell you TMI ("Too Much Information") what does that mean exactly, in math? Now I want to work on social information theory
733447961770790900,Fri May 20 00:03:15 +0000 2016,But it's subtle. Eg. I just generated a rand float &amp; it's 0.7213113698657708 but this doesn't have 32 bits of info because noone cares. Hmmm
733447842317000700,Fri May 20 00:02:47 +0000 2016,Working through Information Theory changes you. Makes me very conscious of how surprising (informative) everything I say is to others.
733373126508171300,Thu May 19 19:05:53 +0000 2016,"for any program to handle letterforms with the flexibility that human beings do, it would have to process full-scale general intelligence"
733373084971851800,Thu May 19 19:05:43 +0000 2016,"The central problem of AI is the question: What is the letter 'a'?" Hofstadter 1985, Metamagical themas. https://t.co/plPrg2zv2Q
733106495894642700,Thu May 19 01:26:23 +0000 2016,Robots have been about to take all the jobs for more than 200 years https://t.co/4yVm4oxpjf nice collection of articles
733060606257815600,Wed May 18 22:24:02 +0000 2016,OpenAI CTO @gdb's Quora Session https://t.co/cCyelnxEKp discussing (Open)AI future
733055241080295400,Wed May 18 22:02:43 +0000 2016,@notmisha read Randezvous with Rama, quite enjoyed, thanks (again) for another great recommendation! https://t.co/xABFl7Twch
731999014338465800,Mon May 16 00:05:39 +0000 2016,@mdreid these all look quite great, thank you!
731987862875299800,Sun May 15 23:21:20 +0000 2016,@AndrewLBeam description sounds very intriguing! Thanks!
731987362897481700,Sun May 15 23:19:21 +0000 2016,@virtualsteve I really liked chapter 1 and then really hated the rest (esp the dogs)
731981205801820200,Sun May 15 22:54:53 +0000 2016,More +ves: Understand and The Story of Your Life (short stories) from Ted Chiang. And yes of course, The Martian (if not under sci-nonfi :))
731978506729455600,Sun May 15 22:44:10 +0000 2016,@dputtick yeah I think I have to re-read Permutation City. I had a first bad impression I think mostly due to audio narrator. Thx!
731977933464604700,Sun May 15 22:41:53 +0000 2016,@rave78 interesting, thanks :) cc @janexwang btw
731977174970859500,Sun May 15 22:38:52 +0000 2016,@trochee bleh screwed up the word, indeed, thank you!
731976700599242800,Sun May 15 22:36:59 +0000 2016,@brdskggs I loved The Martian but I was hesitant to include it under sci-fi, since it's too sci-nonfi :) In a good way!
731976521401798700,Sun May 15 22:36:16 +0000 2016,@fchollet not yet, thanks! any one you think I should start with?
731974553878958100,Sun May 15 22:28:27 +0000 2016,So far +ve: Fiasco, Ready Player One, The Black Cloud, Contact, A Fire Upon the Deep (chap 1) -ve: Foundation, Hyperion, The Player of Games
731974308696756200,Sun May 15 22:27:29 +0000 2016,Hating on Asimov's Foundation in a review: https://t.co/H2b3gWfCyZ my (surprisingly difficult) search for interesting sci-fi continues
730818845863215100,Thu May 12 17:56:05 +0000 2016,RT @fhuszar: my notes on Dilated Convolutions and Kronecker-factored Convolutions: exponential savings in # of parameters.  https://t.co/VH‚Ä¶
730085549780803600,Tue May 10 17:22:14 +0000 2016,@dna_nerd he's a contrarian. He can't not do it!
729816506524016600,Mon May 09 23:33:09 +0000 2016,Nice blog post from @robinsloan on "Writing with the machine" https://t.co/hwIc5aX46H i.e. char-rnn autocomplete for creative writing
729814605204049900,Mon May 09 23:25:35 +0000 2016,John Oliver's much needed segment on "Scientific Studies" https://t.co/GA5i0tZRqD Good analogy to science reporting as a game of telephone
729460381073088500,Sun May 08 23:58:02 +0000 2016,@randal_olson looks nice for small-to-mid ML problems! Most deep nets too large/tricky for automatic cv methods imo. Wouldn't trust them :)
729451038948757500,Sun May 08 23:20:54 +0000 2016,@brendan642 I don't think we're on the same page. I may have misunderstood your first tweet too.
729186528170156000,Sun May 08 05:49:50 +0000 2016,When I published that one video CNN paper a long time ago I didn't realize I'd get asked to review hundreds of video papers forever onwards.
729084720269561900,Sat May 07 23:05:17 +0000 2016,(not explained _too_ well; just conv kernels don't have to be contiguous but have stride.  Can merge info over space faster in fewer layers)
729082742328033300,Sat May 07 22:57:26 +0000 2016,Dilated convolutions are a very good idea. Expecting this to become standard https://t.co/joZrTq3TXh already supported by Torch/Tensorflow
729024003096993800,Sat May 07 19:04:01 +0000 2016,A lot of core challenges ahead are not just in Machine Learning but Machine Teaching https://t.co/AUTPHYLE4f [pdf]
728752296352325600,Sat May 07 01:04:21 +0000 2016,NVIDIA Special Event live stream at Twitch https://t.co/zmLM6b4lk0 so excite! Maybe we'll get more compute.
728678762426994700,Fri May 06 20:12:09 +0000 2016,@yoavgo correct. e.g. in char-rnn forward pass is done "properly", but backward pass only one time step :)
728649695883452400,Fri May 06 18:16:39 +0000 2016,Fun fact/puzzle: You can train an RNN even if back-propagating only one time step (e.g. seq_length 1 in char-rnn). Works quite well in fact
727742406276321300,Wed May 04 06:11:25 +0000 2016,Flattered to see such strong/broad reaction RE CS231n videos. We are trying to work with university to bring them back up. Thank you all.
727622433046335500,Tue May 03 22:14:41 +0000 2016,@jackclarkSF they sent list of 6. Closed captions, forms for students/invited speakers, potential copyright material, "quality/brand", ...
727620126296539100,Tue May 03 22:05:31 +0000 2016,To give a sense of 1 of many reasons, consider case of MIT/Harvard getting sued for videos without closed captions https://t.co/D9KdaILVWS
727618058471112700,Tue May 03 21:57:18 +0000 2016,I regret to inform that we were forced to take down CS231n videos due to legal concerns. Only 1/4 million views of society benefit served :(
727394695391768600,Tue May 03 07:09:44 +0000 2016,@alexjc nice job Twitter-optimizing the original tweet with buzzfeed title and eye candy. Maximum retweet potential reached! :)
727384492927647700,Tue May 03 06:29:11 +0000 2016,Terrain-Adaptive Locomotion Skills Using Deep Reinforcement Learning https://t.co/Nnpc3z4VOX v nice learned motions for dogs/goats/raptors
727275109556297700,Mon May 02 23:14:32 +0000 2016,OpenAI party: @gdb handing out swag. Open door, open invitation, open bar :) https://t.co/KS2erZmHmp
727184880698835000,Mon May 02 17:16:00 +0000 2016,Are you at ICLR? Join us at the OpenAI party 6-9 tonight at Palmeras (Caribe Hilton)
727152198912757800,Mon May 02 15:06:08 +0000 2016,RT @alexjc: Artistic Style Transfer for Videos https://t.co/jXqLyK1liw Video is pretty good! https://t.co/xFamBcldUf https://t.co/3EKlJBTqFw
726161226116399100,Fri Apr 29 21:28:22 +0000 2016,Neat talk by Geoff Hinton https://t.co/e0xUq6eXP7 "STDP is the signature of backprop using temporal derivatives as error signal". hm.
726098740881150000,Fri Apr 29 17:20:04 +0000 2016,@TheDudeFromCI @deepselfie it was shut down :( too expensive to operate, but was fun while it lasted
725926326280953900,Fri Apr 29 05:54:57 +0000 2016,Nice YouTube playlist of 60+ videos by now from @karoly_zsolnai on papers from a variety of disciplines https://t.co/Z06IOdGSDp nicely done!
725885025300803600,Fri Apr 29 03:10:50 +0000 2016,@kastnerkyle wouldn't be surprised if it's not tens/hundreds of thousands of hours of society loss and hundreds of StackOverflow posts.
725883920584052700,Fri Apr 29 03:06:27 +0000 2016,@kastnerkyle I'm okay with these (it happens) but **provided** that the error messages mention these super-common mistakes. They don't.
725883645852934100,Fri Apr 29 03:05:22 +0000 2016,@kastnerkyle I know, I keep making this mistake all the time. The error message is similarly unhelpful in that case as well.
725845976351543300,Fri Apr 29 00:35:40 +0000 2016,@sedielem are there crazy thunderstorms? And rain?
725842080900096000,Fri Apr 29 00:20:12 +0000 2016,@sedielem sorry i got a bit over-excited there. 2 more days for me, flying in early sunday.
725842007856312300,Fri Apr 29 00:19:54 +0000 2016,@sedielem OMGOMGOMOMG MEMEME
725757203706060800,Thu Apr 28 18:42:55 +0000 2016,@jhaberstro I disagree. This is a very simple if statement that numpy should have in their code and deliberately choose to not include.
725744165045203000,Thu Apr 28 17:51:07 +0000 2016,`np.zeros(5,5)` gives "Error: data type not understood". Example of everything that is wrong with error messages (must be `np.zeros((5,5))`)
725600960551092200,Thu Apr 28 08:22:04 +0000 2016,@karpathy (this tweet followed the one on data-driven fluids i.e. under assumption that ~inf data can be generated by compute heavy process)
725600353144574000,Thu Apr 28 08:19:39 +0000 2016,@egrefen @chris_brockett that quote was followup to my fluid simulation link, assumed settings where data can be infinite ~easy generated.
725559672346832900,Thu Apr 28 05:38:00 +0000 2016,Unexpectedly fun/educational to watch! https://t.co/I6GRXmC3Er
725516987665797100,Thu Apr 28 02:48:23 +0000 2016,1. find a compute-intensive problem that needs solving often/fast, 2. train a large neural net on problem instances 3. ??? 4. profit.
725516827166564400,Thu Apr 28 02:47:45 +0000 2016,Shared this a while ago but worth sharing twice: Data-Driven Fluid Simulations https://t.co/8GOxu6H32Y
725396519243784200,Wed Apr 27 18:49:42 +0000 2016,@recurseparadox @open_ai haha, I wish that were true! @gdb is quite significantly a better guarantee :)
725372365174132700,Wed Apr 27 17:13:43 +0000 2016,Announcing OpenAI Gym: a toolkit for standardizing RL environments and evaluation https://t.co/SCQiWHFquC +blog post https://t.co/tKyp7Ftnqw
725012083960483800,Tue Apr 26 17:22:05 +0000 2016,Pieter Abbeel (@pabbeel) is joining us full-time at OpenAI! Woohoo!! https://t.co/zXxx5hV4ma
724403245372731400,Mon Apr 25 01:02:47 +0000 2016,Sad to watch Oculus' continued betrayal and alienation of its early adopter enthusiasts playing out on r/oculus https://t.co/NgjXVO9iQz
724287404148817900,Sun Apr 24 17:22:28 +0000 2016,@iandanforth it is! &lt;&lt; favorite game so far on vive, most of my playtime
723929709726167000,Sat Apr 23 17:41:07 +0000 2016,@hashtag_deepak hah I thought no one was using it (the post is old!) and it was taking a lot of space so I erased few days ago. Sorry :p
723374274510114800,Fri Apr 22 04:54:01 +0000 2016,Finally got my HTC Vive today. Especially like Audioshield; has to be one of the best things I've experienced so far. Quite a workout too
723180561301311500,Thu Apr 21 16:04:16 +0000 2016,RT @seanmcarroll: The always-interesting Scott Aaronson on quantum mechanics, computers, gravity, utopia, and hard problems. https://t.co/J‚Ä¶
723051904008249300,Thu Apr 21 07:33:02 +0000 2016,RT @bradleyvoytek: @karpathy check this out (5 (!) year old post of mine about this paper): https://t.co/GNEfwGWbmS
723025389702901800,Thu Apr 21 05:47:40 +0000 2016,You can split the brain in half (corpus callosotomy) and it's fine. You can also take out 90% of it and it's fine https://t.co/aT4KPywxoj
722843451113365500,Wed Apr 20 17:44:43 +0000 2016,The code uses Torch/Lua. The release includes pretrained models, lot of docs, eval code, live webcam demo etc. Worked on release for while
722843005959311400,Wed Apr 20 17:42:57 +0000 2016,Justin and I just released code for our CVPR2016 paper DenseCap: joint detection+captioning https://t.co/yZAemhubfx https://t.co/P9GCOZARp6
722561390775377900,Tue Apr 19 23:03:54 +0000 2016,Unfortunately slides only. We made this "mistake" last year with CS231n. Glad we decided for videos this year; easier to digest, more info
722560779862474800,Tue Apr 19 23:01:29 +0000 2016,Shared this already but now much more content: Stat212b: Topics Course on Deep Learning https://t.co/0XYJaG0BJg from Joan Bruna at Berkeley
722492725635842000,Tue Apr 19 18:31:03 +0000 2016,yay https://t.co/AktZYxom0e has reached 1,000 registered users! Growing few dozen a day.
722229000370671600,Tue Apr 19 01:03:06 +0000 2016,@junligu thanks! probably won't publish slides. but yep - also these are not emails but conversations (usually multiple emails) :)
722228523994189800,Tue Apr 19 01:01:13 +0000 2016,UofT's "CSC321 Winter 2015: Introduction to Neural Networks" class https://t.co/vLSWsot4NC by Roger/Nitish; nice notes for week8
722199264034574300,Mon Apr 18 23:04:57 +0000 2016,@LH thank you! :)
722162820855402500,Mon Apr 18 20:40:08 +0000 2016,RT @drfeifei: Andrej successfully defended his PhD! Turns out I've sent him 2000+ emails during his PhD. :-) Congrats @karpathy https://t.c‚Ä¶
722136573957918700,Mon Apr 18 18:55:50 +0000 2016,woohoo! thanks :) https://t.co/EBMzBiVaIz
721917652927549400,Mon Apr 18 04:25:55 +0000 2016,@junligu @petewarden I'm not; I assume Pete is
721843012846821400,Sun Apr 17 23:29:20 +0000 2016,Nice talk from MobileEye cofounder/CTO on self-driving cars &amp; feasibility of (or lack there of) end-to-end approach https://t.co/Oy3Y34ZnLA
721835242361737200,Sun Apr 17 22:58:27 +0000 2016,Embedded Vision Summit https://t.co/RpF3gTU2CB coming up in 15 days in Santa Clara. An exciting area! (via @petewarden)
721004794731626500,Fri Apr 15 15:58:33 +0000 2016,@floryanscherer that makes perfect sense :) soft max layer is fine to init at zero because grad of loss has asymmetry. Hidden layers aren't
720837251492544500,Fri Apr 15 04:52:47 +0000 2016,RT @maxpumperla: Run your own Go bot with BetaGo, using #deeperlearning  with #keras in  #python: https://t.co/JmVfUhcTc3 https://t.co/8CuG‚Ä¶
720832180918718500,Fri Apr 15 04:32:39 +0000 2016,RT @niru_m: Great writeup on `np.einsum` a useful little function in numpy for linear algebra operations: https://t.co/L0swCqyw7N
720695247739551700,Thu Apr 14 19:28:31 +0000 2016,RT @michael_nielsen: Shocked and very saddened to hear that David MacKay has passed away: https://t.co/VmpfbXtsyi
720694964540219400,Thu Apr 14 19:27:24 +0000 2016,RT @ryan_p_adams: RIP David JC MacKay, a scientific giant of our times.
720643634521968600,Thu Apr 14 16:03:26 +0000 2016,@gnperdue only have few untested ideas. right now preferred hackfix is to use reflection padding instead of zero padding (see Soumith tweet)
720642926070530000,Thu Apr 14 16:00:37 +0000 2016,@amiconfusediam yes reflection padding is the best hack quickfix patch "solution" I'm aware of right now. Very unsatisfying imo.
720622989289644000,Thu Apr 14 14:41:23 +0000 2016,Zero padding in ConvNets is highly suspicious/wrong. Input distribution stats are off on each border differently yet params are all shared.
720036089604534300,Tue Apr 12 23:49:16 +0000 2016,yay, very nicely done: "Tinker with a Neural Network in Your Browser"  https://t.co/cHdFCo5Syp (&amp;very nice of them for shoutout!)
718908443071918100,Sat Apr 09 21:08:24 +0000 2016,@shazow Their website broke otherwise I would have been at :01. I'm going to throw a tantrum.
718906392040513500,Sat Apr 09 21:00:15 +0000 2016,@shazow I got order confirmation email 7:11am. used visa. Sigh.
718873225946488800,Sat Apr 09 18:48:27 +0000 2016,@shazow didn't we order at the same time? How come you got yours so quickly? :( I didn't even get a shipping notification yet
718840317567303700,Sat Apr 09 16:37:41 +0000 2016,@francislee2020 my algorithms simple, or something like that
718546574649897000,Fri Apr 08 21:10:28 +0000 2016,Big congrats SpaceX!! (I watched all other (failed) barge landings but couldn't make this one in real time. May have jinxed all times prior)
718263481204666400,Fri Apr 08 02:25:33 +0000 2016,@shazow they are in corners of the room looking down. Seemed fine to me. Actually I think it may have been the controllers losing battery.
718251622288240600,Fri Apr 08 01:38:25 +0000 2016,Building Machines That Learn and Think Like People https://t.co/2rgK1y71yn +1, a very nice review paper on making progress in AI
718241592650436600,Fri Apr 08 00:58:34 +0000 2016,@karpathy seeing several tracking glitches, manual is very sparse, buggy environments. A bit of an overall confusing experience.
718233846416851000,Fri Apr 08 00:27:47 +0000 2016,We're playing around with HTC Vive demos at Stanford. Can't wait to get my own at home. Any day now... https://t.co/Nc677afoNu
718218849074704400,Thu Apr 07 23:28:12 +0000 2016,@dna_nerd yeah but in pinterest I can't drag and drop in 2D grid or zoom around or something. so constrain
718186447459606500,Thu Apr 07 21:19:26 +0000 2016,@EmilMikhailov thanks for link, does look like it!
718183713553535000,Thu Apr 07 21:08:35 +0000 2016,I could use an app for building a virtual billboard of images/links/notes + pan/zoom. Google maps of idea space. Don't think exists?
718134303910006800,Thu Apr 07 17:52:14 +0000 2016,adnn: very nice looking new Torch-flavored Javascript library for neural networks https://t.co/MEdxr4NlP0
717453355107295200,Tue Apr 05 20:46:24 +0000 2016,@LH I'm not convinced :)
717440651059601400,Tue Apr 05 19:55:55 +0000 2016,@shazow ML going strong. VR decidedly creeping in, positive slope. Wasn't a thing last year at all now had several mentions in keynote
717434777876365300,Tue Apr 05 19:32:34 +0000 2016,@bakiii_ee bleh
717432593415675900,Tue Apr 05 19:23:54 +0000 2016,Woohoo so much compute! https://t.co/yldirqgSlS
717430653042622500,Tue Apr 05 19:16:11 +0000 2016,Hanging out at NVIDIA's #gtc16. Ironically their processing of VR demos is surprisingly serial https://t.co/CDME8rCEPW
717404740141719600,Tue Apr 05 17:33:13 +0000 2016,@jackclarkSF ResNets. 1202 on CIFAR10 at least
717359806286139400,Tue Apr 05 14:34:40 +0000 2016,@m09__ the license is on syllabus page. Go ahead
717100807749918700,Mon Apr 04 21:25:30 +0000 2016,RT @RichardSocher: I'm excited to announce that @MetaMindIO got acquired by @Salesforce more on our website https://t.co/YFMNQayqoh
716321029430255600,Sat Apr 02 17:46:56 +0000 2016,@BrunswickHorace OF course it is. That's where it matters.
716319600430821400,Sat Apr 02 17:41:15 +0000 2016,IBM's TrueNorth chip now achieving 82.5% CIFAR-10 accuracy at 1191 FPS and with 226mW (note - milli W!). Looks nice https://t.co/GxPnftxxQv
716037203869061100,Fri Apr 01 22:59:07 +0000 2016,wondering what impact Robin has on global GDP. very fun experiment
715968312220454900,Fri Apr 01 18:25:22 +0000 2016,RT @hardmaru: Neural Net Dreams Up High Res MNIST Digits at 1080p https://t.co/mcPmZBIVcA #Generative #TensorFlow https://t.co/2iPSy4Ba0B
715961686939844600,Fri Apr 01 17:59:02 +0000 2016,Y Sequoia https://t.co/BkF5vrrvhD "The new YC logo will be changed from orange to green as it is the color of sequoia leaves and money" :D
715803205700034600,Fri Apr 01 07:29:17 +0000 2016,Meanwhile in bio: programming language for design of computational circuits in living cells https://t.co/lsPFfNfo9u
715791114276614100,Fri Apr 01 06:41:15 +0000 2016,@davederiso it's a very deep learning class now :D
715785914035863600,Fri Apr 01 06:20:35 +0000 2016,At one point ConvNets made sense. You transform image to higher-level representations with each layer. Edges, circles, shapes etc. Now what.
715783663426908200,Fri Apr 01 06:11:38 +0000 2016,I have a feeling that CS231n next year will look completely different.
715783334719266800,Fri Apr 01 06:10:20 +0000 2016,That's odd. ResNets and papers like this https://t.co/abUPKIGEHw (stochastic depth!) challenge the conventional view of how ConvNets work.
715647177469534200,Thu Mar 31 21:09:17 +0000 2016,Q&amp;A video #3 with CGPGrey https://t.co/Bux174KrPg , one of my favorite YouTubers and also a general favorite person.
715618813748744200,Thu Mar 31 19:16:35 +0000 2016,Paper title meme. "Show and Tell". "Show, Attend and Tell". "Listen, Attend and Spell". "Attend, Infer, Repeat."; Read, Sigh, Facepalm. :D
715589436025614300,Thu Mar 31 17:19:51 +0000 2016,RT @open_ai: The OpenAI team is growing: https://t.co/xFrpYSBhGR. Welcome, everyone!
715395446227607600,Thu Mar 31 04:29:00 +0000 2016,Bash is coming to Windows? https://t.co/PeliyP7kvP wat. Not an onion article? Waaait it's too close to April 1. Ha ha good one Microsoft
715322878640586800,Wed Mar 30 23:40:38 +0000 2016,Cool video on glove tracking for operating virtual physics-based environments https://t.co/tJJAYOiDel mmm delicious data
715232915936792600,Wed Mar 30 17:43:10 +0000 2016,@bhaavan I will never switch to Python 3 as a matter of principle. I do not condone developer bullying for sport.
715232619584073700,Wed Mar 30 17:41:59 +0000 2016,@NathanBenaich this information is not part of the arxiv metadata, so no.
715088550455193600,Wed Mar 30 08:09:30 +0000 2016,On subject of unicode, this PyCon 2012 talk is often linked around and worked very well for me too https://t.co/GM16zNTMWx
715086067368472600,Wed Mar 30 07:59:38 +0000 2016,Most annoying utf-8 gotcha: When you print utf-8 string to console it works fine. but if you pipe to file it breaks https://t.co/VwqVH9SVaj
715076717501526000,Wed Mar 30 07:22:29 +0000 2016,Attend, Infer, Repeat: Fast Scene Understanding with Generative Models https://t.co/9f9IC8OOCl + nice video https://t.co/QrrRYvADzY
714909499518091300,Tue Mar 29 20:18:01 +0000 2016,@nnnnicholas what other parts would you like?
714909154679230500,Tue Mar 29 20:16:39 +0000 2016,@jasonpriem +1. Very important point, not sure many people realize this benefit. Big kudos to arxiv for friendly API and good docs.
714713443199225900,Tue Mar 29 07:18:58 +0000 2016,@bwwinthehouse My main was human mage, back in the days Molten Core and Onyxia. Was also very fond of a priest alt. you?
714686648580251600,Tue Mar 29 05:32:29 +0000 2016,"Here's What Happens When an 18 Year Old Buys a Mainframe" https://t.co/18txx1o2HZ v fun talk! When I was 18 I played World of Warcraft :s
714673693931253800,Tue Mar 29 04:41:01 +0000 2016,@shazow yep +1 almost definitely :)
714670494952370200,Tue Mar 29 04:28:18 +0000 2016,One day we'll be talking about good old "hand-crafted" films and instead the norm will be watching AI-generated (infinite) content on demand
714559795043246100,Mon Mar 28 21:08:25 +0000 2016,RT @gwern: @karpathy Update on my char-rnn metadata idea: https://t.co/mHtBDowWmC Sort of works! If you're patient enough to train it, anyw‚Ä¶
714549216308174800,Mon Mar 28 20:26:23 +0000 2016,Might be my nostalgia for undergrad: the buzz or new classes, assignments, schedule. I kinda miss it :(
714548557638860800,Mon Mar 28 20:23:46 +0000 2016,It's first day of the spring quarter!!! Somehow very excited, even if mostly irrelevant to me. My 19th quarter at Stanford :o
713493155136430100,Fri Mar 25 22:29:58 +0000 2016,@akaDavidGarrett not necessarily but they should be normalized reasonable. In fact better if they are zero mean.
712775504961507300,Wed Mar 23 22:58:17 +0000 2016,@sedielem hahah! :D
712771287148441600,Wed Mar 23 22:41:32 +0000 2016,At last - this year's 130/200 CS231n Final Course Project Reports are now posted! https://t.co/B2nBW5Z0Rh big congrats to students!
712770497709088800,Wed Mar 23 22:38:23 +0000 2016,@genekogan @p5xjs hah! nicely done :)
712770444512759800,Wed Mar 23 22:38:11 +0000 2016,RT @genekogan: live demo of neural network classifying images https://t.co/O0jRzjxv57 made with @p5xjs ++ @karpathy‚Äôs convnet.js https://t.‚Ä¶
712734885429915600,Wed Mar 23 20:16:53 +0000 2016,@majortal hmmm not sure how I feel about making it seq to seq trained with artificial noise. But nice work :)
712701079683600400,Wed Mar 23 18:02:33 +0000 2016,Many bool variables you make you'll wish were ints later. Many int vars you make you'll wish were strings. Eventually: wish it were a dict.
712113845972574200,Tue Mar 22 03:09:05 +0000 2016,@drsxr with what end? you can certainly zero out random parts of the networks and look at what happens to accuracy. not sure if interesting
711736172712595500,Mon Mar 21 02:08:21 +0000 2016,@j_gauthier I think a large number of things we do (or don't do!) are morally concerning. So I'm ok smoothly striving for best over time.
711728240109310000,Mon Mar 21 01:36:50 +0000 2016,Common mistake I see ppl make: forcing a step to 100% vegan. You can go 90% vegan. It's 90% as effective. And much easier.
711727325327396900,Mon Mar 21 01:33:12 +0000 2016,I already went kind-of-mostly-vegan; First because my mom made me. Then later because of health concerns. And now maybe for sustainability.
711727286609809400,Mon Mar 21 01:33:03 +0000 2016,I was in mood for Leonardo DiCaprio movie, but ended up watching Cowspiracy, a documentary he helped bring to Neflix https://t.co/fnmf8eR9gw
711312033631699000,Sat Mar 19 22:02:59 +0000 2016,It's fun watching the innovations made in binarizing ConvNets  https://t.co/LU5dWTQz7x binary is the way to go eventually.
711285779478151200,Sat Mar 19 20:18:39 +0000 2016,@SriniKadamati can't do static pages - there are user accounts involved
711275899488854000,Sat Mar 19 19:39:23 +0000 2016,arxiv-sanity was posted on HN. I'm looking at logs, seeing strange error messages at random, and wishing I knew more about scaling websites.
711088176308166700,Sat Mar 19 07:13:27 +0000 2016,The antropomorphization is done in v interesting ways. E.g. the trash can bot obviously "wants" to eat garbage; A person presumably wouldn't
711087186574094300,Sat Mar 19 07:09:31 +0000 2016,Neat research on how people respond socially to roomba trash can https://t.co/jnPnvnTRfp also reminds of reactions to kicking Atlas robot
710527534107000800,Thu Mar 17 18:05:39 +0000 2016,Google Puts Boston Dynamics Up for Sale in Robotics Retreat https://t.co/ZG56dZe1HZ interesting glimpse into internal turmoil and dilemmas
710519126603608000,Thu Mar 17 17:32:15 +0000 2016,RT @sedielem: New ResNet results from He et al.: put ReLU/batchnorm before weight layers instead of after! https://t.co/Pz69rAw8Yv https://‚Ä¶
710018200075763700,Wed Mar 16 08:21:45 +0000 2016,@F_Vaggi @sknthla @drfeifei also can design deep learning architectures for interpretability. E.g. https://t.co/0JFEP1D6fz among many others
710017415476740100,Wed Mar 16 08:18:37 +0000 2016,@F_Vaggi @sknthla @drfeifei yes, e.g. this lecture might be especially relevant https://t.co/XauMbME5wk . But it's only scraping surface
709991410066432000,Wed Mar 16 06:35:17 +0000 2016,The Hydraulic Press Channel on YouTube. https://t.co/xk6lX3KU8z thank you, internet.
709833121496039400,Tue Mar 15 20:06:18 +0000 2016,And we lost badly :) I used to play when I was 15 in a school club but haven't played since. https://t.co/6xk7YA4X36
709785521740877800,Tue Mar 15 16:57:10 +0000 2016,Ted Chiang's novelette "Understand" is one of the best things I've read in a long while (making my way though Story of Your Life and Others)
709513693340381200,Mon Mar 14 22:57:01 +0000 2016,@akaDavidGarrett Threw them out yesterday. I'd rather have thin library that ~works than bloated library that is weird. No time to maintain
709465955223543800,Mon Mar 14 19:47:19 +0000 2016,BatchNorm, STN, DCGAN, DRAW, soft/hard attention, char-rnn, DeepDream, NeuralStyle, TensorFlow, ResNet, AlphaGo.. a lot happened over 1 year
709230102622683100,Mon Mar 14 04:10:07 +0000 2016,@bjoseph i don't use any, I usually roll my own code.
709220900176928800,Mon Mar 14 03:33:33 +0000 2016,Actually I put up the GAN demo here if anyone else wants to play: https://t.co/PM2B2u2VDn looks like quite an unwieldy dynamical system!
709214484896723000,Mon Mar 14 03:08:04 +0000 2016,Having some fun training an Generative Adversarial Network on mixture of 2 gaussians. In raw Javascript, of course. https://t.co/AaZZbU9ekZ
708943940485914600,Sun Mar 13 09:13:01 +0000 2016,I cannot believe this. Somehow AlphaGo losing today must be optimal for winning more frequently over next few thousand years.
708748132985602000,Sat Mar 12 20:14:57 +0000 2016,@sdavidmiller good question! maybe if you need a very precise control over the output value in large range and gaussian assumption holds too
708538983978917900,Sat Mar 12 06:23:52 +0000 2016,@sedielem yep, though I think not the case in most applications. Or at least newbies eager to regress often don't appreciate the subtlety
708480082831024100,Sat Mar 12 02:29:49 +0000 2016,not-widely-enough-known-protip: Do not use L2 loss (regression) in neural nets unless you absolutely have to. Softmax likely to work better.
708100234816061400,Fri Mar 11 01:20:26 +0000 2016,Haha, someone packaged neuraltalk2 into an iOS app: https://t.co/PWIgr0WBxJ works nicely when you point it at MSCOCO-like images :)
708075344364843000,Thu Mar 10 23:41:32 +0000 2016,@iandanforth not really right now. also not exactly sure what causes it (except I know one cause is when the paper is way too long)
708074167296393200,Thu Mar 10 23:36:51 +0000 2016,Someone also got the core code running for High Energy Physics, hosted at https://t.co/eVciPmI7Qs phew, happy to see it generalize easily
708073685567967200,Thu Mar 10 23:34:56 +0000 2016,Preparing https://t.co/AktZYxom0e for avalanche of ECCV/ACL papers. Now have 400 accounts &amp; 2500 papers added in libraries. 300 sessions/day
707995389970886700,Thu Mar 10 18:23:49 +0000 2016,@SameerTrikha almost definitely :) it's already begun at least a bit with the calculators, GPS, etc.
707995150056759300,Thu Mar 10 18:22:52 +0000 2016,@ChrisBaldassano in long term agreed. in short term maybe we can do something to constraint ourselves to interpretable architectures maybe
707991375816446000,Thu Mar 10 18:07:52 +0000 2016,We approach problems (eg Go) with cognitive pros/cons and that constraints us to some policies. Different pros/cons give different policies.
707990611635273700,Thu Mar 10 18:04:50 +0000 2016,Curious to what extent is there a necessary trade off between something working very well and something being interpretable by us.
707990395821555700,Thu Mar 10 18:03:58 +0000 2016,AlphaGo is an interesting glimpse of a likely future - of AIs working extremely well in various tasks and us mostly confused about how.
707761014230503400,Thu Mar 10 02:52:30 +0000 2016,RT @cs231n: The CS231n team during our class-nearing-to-an-end debrief, exhausted right after the poster session :) https://t.co/cEo2p0WuPq
707544888699650000,Wed Mar 09 12:33:41 +0000 2016,I love this a lot: "Google Research Blog: Deep Learning for Robots: Learning from Large-Scale Interaction" https://t.co/hmBDoeqZJi
707470523626815500,Wed Mar 09 07:38:11 +0000 2016,RT @shakir_za: Congratulations on a fantastic and groundbreaking win for AlphaGo and DeepMind, winning the first Go Challenge Match this mo‚Ä¶
707414514975772700,Wed Mar 09 03:55:38 +0000 2016,One of my favorite activities by far: tipsy and talking to physicists about QFT/GR/ arrow of time/entropy/consciousness. Fun guaranteed
707062427297386500,Tue Mar 08 04:36:33 +0000 2016,@pwais yep!
707021291673493500,Tue Mar 08 01:53:06 +0000 2016,Super excited for CS231n poster session this Wednesday at 2pm! https://t.co/fuyjRtSyjR 200 awesome projects from 300 awesome students! :)
705571153750790100,Fri Mar 04 01:50:46 +0000 2016,@DeepDrumpf OUCH! hahahahaha
705558159964803100,Fri Mar 04 00:59:08 +0000 2016,char-rnn trained on Donald Trump's tweets: https://t.co/pkpTXQN1XI of course, should have seen this coming :)
704111563305648100,Mon Feb 29 01:10:53 +0000 2016,@mryanbell neither do I, at all. But that's irrelevant :)
704109261106753500,Mon Feb 29 01:01:44 +0000 2016,Vive preorders in 14h! Got Rift&amp; must have Vive too. Haven't been this excited since Glass/Apple Watch; Both of which I don't use anymore ;p
704098387499462700,Mon Feb 29 00:18:31 +0000 2016,SpaceX is doing a take 3 on SES-9 launch right now, after a hold due to troll ship. https://t.co/MJVGDED6Cq emotional rollercoaster
704061906642862100,Sun Feb 28 21:53:34 +0000 2016,@amiconfusediam whoops I just noticed someone else already pointed this out
704061790330552300,Sun Feb 28 21:53:06 +0000 2016,@amiconfusediam you can disable image/video preview in the settings apparently.
704053568454529000,Sun Feb 28 21:20:26 +0000 2016,Nice Planet Money ep on checking presidential candidate's promises with economists https://t.co/Wl41sLuNEu surprised this isn't more common
704014344997068800,Sun Feb 28 18:44:34 +0000 2016,RT @michael_nielsen: New essay: "Toward an exploratory medium for mathematics"   https://t.co/vhc5leU18M
703840916298018800,Sun Feb 28 07:15:25 +0000 2016,@catzdong truly destined for great things. All that ConvNet knowledge paying off :)
703688021829267500,Sat Feb 27 21:07:52 +0000 2016,@hankejh you have a problem so you use PayPal. Now you have two problems. :)
703651850424193000,Sat Feb 27 18:44:09 +0000 2016,@alirg1 thanks! of course :)
703650501217235000,Sat Feb 27 18:38:47 +0000 2016,Had credit card replaced due to possible data compromise. Great. Now I just have to log in to 50 websites and enter in my new number.
703521802467745800,Sat Feb 27 10:07:23 +0000 2016,Spent last 2 months mostly making slides for lectures/talks. In serious need of a looooong vacation from dragging arrows &amp; color coding text
703003266049667100,Thu Feb 25 23:46:54 +0000 2016,SES-9 launch abort on T-1m . There goes the highlight of my day.
702941499013468200,Thu Feb 25 19:41:28 +0000 2016,@djpardis this is just the saddest thing.
702939350535811100,Thu Feb 25 19:32:55 +0000 2016,@genekogan Okay. I forgive you. :)
702939173523566600,Thu Feb 25 19:32:13 +0000 2016,Imo it's up to Twitter to protect its users from companies with strong incentives to take over all your pixels. And they're failing.
702938710929616900,Thu Feb 25 19:30:23 +0000 2016,@genekogan this is not helping, RE my tweet just now. :)
702937450465742800,Thu Feb 25 19:25:22 +0000 2016,My twitter is turning into a picture-filled Tumblr. The few media I follow tweet often and always images for engagement. Lots of scrolling
702811910870175700,Thu Feb 25 11:06:31 +0000 2016,@Shmuma nope :D it's the simplest signup form. Pros and cons :)
702777420252729300,Thu Feb 25 08:49:28 +0000 2016,@jorenvs not right now. i'll keep in mind for potential future features
702769063726985200,Thu Feb 25 08:16:16 +0000 2016,@glouppe ah! that would make sense :) how long does it take? I could increase the threshold
702763720028483600,Thu Feb 25 07:55:02 +0000 2016,@JanStette @papers_we_love I did at one point. I like but found it a bit too bloated. I only have a few use cases and I want them perfect
702762380762050600,Thu Feb 25 07:49:42 +0000 2016,@glouppe the line of code is here https://t.co/kii5l0zVn0 basically imagemagick "convert" fails on it. Any idea why?
702667799194267600,Thu Feb 25 01:33:52 +0000 2016,Fun short story on brain interfacing future where personalities become immortal, distributed through bodies https://t.co/j3XtJRA31y
702640571110666200,Wed Feb 24 23:45:41 +0000 2016,@anthonygitter @biorxivpreprint actually thinking about it more, I do make quite a few assumptions about arxiv ids, e.g. versioning, etc.
702639934478295000,Wed Feb 24 23:43:09 +0000 2016,@yoavgo I'm a deep believer in the right tool for the job :)
702639694576660500,Wed Feb 24 23:42:12 +0000 2016,@anthonygitter @biorxivpreprint well as long as they provide an API that gives similar to information as Arxiv then it could be "swapped in"
702617620063744000,Wed Feb 24 22:14:29 +0000 2016,@carrasqu problem is if i'm from outside of the field it's hard to judge the results, etc.
702617570986238000,Wed Feb 24 22:14:17 +0000 2016,@carrasqu the code is ready to run - it's plug and play, would involve simply changing the search query to the appropriate arxiv sections
702599794947063800,Wed Feb 24 21:03:39 +0000 2016,@genekogan my guess is that tSNE is a nice eye candy but noone actually wants to meddle with the precise 2D / nav in the space.
702591241184149500,Wed Feb 24 20:29:40 +0000 2016,Also if anyone knows ppl from outside CS/ML &amp;excited about meta-research I'd be eager to chat/see if arxiv-sanity can help other communities
702589608744190000,Wed Feb 24 20:23:10 +0000 2016,Right now it's a bit funky since I have to rebuild SVMs manually for all accounts in batch (not done live). Can enhance later maybe
702589195236220900,Wed Feb 24 20:21:32 +0000 2016,I've been beta testing with labmates and everyone loves it. I can exist in peace knowing I'm not missing some recent related arxiv papers
702588927903858700,Wed Feb 24 20:20:28 +0000 2016,Superexcited: https://t.co/AktZYxom0e now can add papers to library, trains you a tfidf SVM, then recommends papers (all or over last week)
702402940280184800,Wed Feb 24 08:01:25 +0000 2016,@ivoflipse5 1.5% was images that I considered as clearly incorrect labels in a test data.
702393667919732700,Wed Feb 24 07:24:34 +0000 2016,@debasishg see my lecture in CS231n on RNNs, near the end
702385984919511000,Wed Feb 24 06:54:03 +0000 2016,Also Inception + ResNet combo now gives 3.08% top 5 error on ImageNet https://t.co/RxCUqwHpTJ just to put this in context, that's VERY LOW
702383661748977700,Wed Feb 24 06:44:49 +0000 2016,I think this is probably the first robot video where I can squint and extrapolate enough that it really hits me
702381227773468700,Wed Feb 24 06:35:08 +0000 2016,Wow, it looks like Boston Dynamics' Atlas robot is making a lot of progress https://t.co/oiYWR34g7r
702001196043644900,Tue Feb 23 05:25:02 +0000 2016,You know how sometimes you have to work on something but you reeeally don't want to. But you do it anyway. Because you have to #deepthoughts
701525018212053000,Sun Feb 21 21:52:52 +0000 2016,@jdkarmitage yeah I love this concept, had similar story in mind as basis for my next short story. Thanks!
701514795179085800,Sun Feb 21 21:12:15 +0000 2016,Sad story about high lead discovered in water of Flint https://t.co/L6U6TNsdw9 wider story on failure of academia's incentive structure
701513475730747400,Sun Feb 21 21:07:00 +0000 2016,@mdreid there were parts of Permutation City that I didn't get / annoyed me. But I had audiobook &amp; terrible narrator. Have to reread book
701508859895029800,Sun Feb 21 20:48:40 +0000 2016,Finished Stanislaw Lem's "Fiasco" yesterday; review: https://t.co/THUBjtoPm5 Properly done hard sci-fi, looking around for more like it
701507188733313000,Sun Feb 21 20:42:01 +0000 2016,Top notch char-rnn fun: @lexiconjure trained dictionary; invents&amp;defines words. eg: "fengler a person who fengles or shares a fengue." lol
701140738164195300,Sat Feb 20 20:25:53 +0000 2016,Black mirror ep about Twitter: What should be about ppl connecting becomes opposite: echo chambers of anger/outrage, witch hunts &amp; trolling
700609119619682300,Fri Feb 19 09:13:25 +0000 2016,Graphing when your Facebook friends are awake. https://t.co/tkxlZMCZXA I'm a fan of the writing style. It's some educational comedy genre
699778106148585500,Wed Feb 17 02:11:16 +0000 2016,(i.e. this should become the default code base to use now if you're interested in training character-level RNN language models) nicely done!
699778033893257200,Wed Feb 17 02:10:59 +0000 2016,Justin (@j26774) reimplemented my char-rnn code base from scratch, with a much nicer/smaller/faster implementation https://t.co/oFKSqjuEL6
699746197083258900,Wed Feb 17 00:04:28 +0000 2016,@gwern haha I'm a Ph.D. student! I barely make enough money for a shitty apartment and basic food.
699717671907102700,Tue Feb 16 22:11:07 +0000 2016,@karpathy just to clarify - I do not own one! (I wish). I happened to get a ride in one
699689925243895800,Tue Feb 16 20:20:52 +0000 2016,I was not prepared for the awesomeness of Tesla Model S P90D self-driving and Ludicrous mode; heart rate*=10. It's a rocket on wheels. wow
699338355662663700,Mon Feb 15 21:03:51 +0000 2016,@shazow I did not, I don't have the phone, and don't want it. I want high quality VR experience, no compromises. Don't need it mobile.
699337999977283600,Mon Feb 15 21:02:26 +0000 2016,@shazow I'm also late May I think. Why would I cancel? OCULUS. John Carmack. What's wrong with you. I'm a proper fan boy.
699337715825770500,Mon Feb 15 21:01:19 +0000 2016,@shazow pre-ordered.
699337500150493200,Mon Feb 15 21:00:27 +0000 2016,@shazow doh. Already got my Rift. I'll get a Vive too though I think. I don't follow the space as close as you do, would like to hear more!
699336995156287500,Mon Feb 15 20:58:27 +0000 2016,@shazow are you getting both Rift/Vive?
699003903950467100,Sun Feb 14 22:54:52 +0000 2016,More RNNs composing music by @maraoz:  https://t.co/gMJFeOp2m8 nice results here
698977829824802800,Sun Feb 14 21:11:15 +0000 2016,@BrendanShilling stat.ML (and also cv.NE) are now served too! thanks for suggestion
697536501903544300,Wed Feb 10 21:43:56 +0000 2016,Another good recent idea: using ConvNet activations to compute perceptual similarity loss for generative models https://t.co/ljpeuZdFIj
697523590149775400,Wed Feb 10 20:52:37 +0000 2016,Nice line of work on Binary Deep Nets https://t.co/bmWNaISKlb (incl. paper from yesterday). Constrain weights/activations to -1,1, use XORs
696436766216056800,Sun Feb 07 20:53:58 +0000 2016,RT @amiconfusediam: GPU cloud computing is soooo in shambles. 4x Titan-X GPUs in the cloud at $2k a month (CirraScale). One can assemble a ‚Ä¶
695832228295606300,Sat Feb 06 04:51:45 +0000 2016,This looks like current state of the art in Deep Reinforcement Learning applied to laundry and other household tasks https://t.co/PG2uQl9Spm
695521212412223500,Fri Feb 05 08:15:53 +0000 2016,Unintended/unsupported wish list Google Hangouts use case: ability to chat with self. For copy&amp;paste/sending pictures between computers
695397888013119500,Fri Feb 05 00:05:51 +0000 2016,"We are releasing the ResNet-18, 34, 50 and 101 models [for everyone]. We will release the 152-layer model when it finishes training." lol
695396156549955600,Thu Feb 04 23:58:58 +0000 2016,And another nice article in mxnet docs on training Inception-BN nets on full ImageNet (14M images, 22K classes) https://t.co/a3A9G1MLUJ
695395395975774200,Thu Feb 04 23:55:56 +0000 2016,Also a very nice writeup on Torch blog about various ResNet experiments &amp; training protocol implementation details https://t.co/fzUeN9vcz9
695392360973226000,Thu Feb 04 23:43:53 +0000 2016,Very nice code release from Facebook re-implementing Kaiming He et al. Residual Networks (+pretrained models) https://t.co/64lD3zxvwZ
695333687060070400,Thu Feb 04 19:50:44 +0000 2016,@BrendanShilling hmm not a bad idea. My code right now scales to ~10K papers, but maybe not 100K papers. Could look into it!
695152876683788300,Thu Feb 04 07:52:15 +0000 2016,@cs231n whooa that's a large image of my face. Fun lecture to give though :)
695074046778552300,Thu Feb 04 02:39:01 +0000 2016,@abhishake85 good :)
695049629038039000,Thu Feb 04 01:01:59 +0000 2016,REWORK Deep Learning summit summaries (from last week). In notes https://t.co/HJQngUAK1L &amp; in tweets https://t.co/vixfoYPEBj
694959082529161200,Wed Feb 03 19:02:11 +0000 2016,Caffe pretrained models for Deep Residual Networks are now up    https://t.co/WdcRZfAdsG (Kaiming He et al. ILSVRC 2015 winning ConvNets)
694957836355276800,Wed Feb 03 18:57:14 +0000 2016,@abhishake85 but dL/dx1, dL/dx2 are zero! is that a problem? :)
694790592216244200,Wed Feb 03 07:52:40 +0000 2016,@grobstein 0/2 :)
694746355575558100,Wed Feb 03 04:56:53 +0000 2016,(had to take that one out because I think it's a little too mean, but it's fun)
694746333773586400,Wed Feb 03 04:56:48 +0000 2016,Writing CS231n midterm; True/False fun: It's sufficient for symmetry breaking in a Neural Net to init all W to 0, provided biases are random
694706859119239200,Wed Feb 03 02:19:56 +0000 2016,Mind Meld: First-person Teleoperation of a PR2 through Virtual Reality and Motion Capture https://t.co/VmJ1sPJqrr sooo coool
693937703704858600,Sun Jan 31 23:23:35 +0000 2016,@fchollet btw while at DeepMind I checked with Karen about preferred naming and he likes VGGNet over OxfordNet. Didn't check VGG16
693936010133024800,Sun Jan 31 23:16:52 +0000 2016,RT @fchollet: New blog post: how convolutional neural networks see the world https://t.co/Q8RrOM0GiA
693915172851691500,Sun Jan 31 21:54:04 +0000 2016,@siddharthm83 Nice - this was also my first choice after a brief search (before the tweet).
693898981701603300,Sun Jan 31 20:49:43 +0000 2016,Curious: What is your favorite branch of math? (thinking about switching some bedtime random reading time to bedtime random deriving time)
693868489228968000,Sun Jan 31 18:48:33 +0000 2016,RT @sedielem: More residual learning experiments: https://t.co/WjWY6Nblxn -- interesting conclusions about where to put batch norm (before ‚Ä¶
693563813564579800,Sat Jan 30 22:37:53 +0000 2016,Pushed updates to https://t.co/AktZYxom0e now serving ~13,000 papers from last ~3 years of arxiv CS.CV|LG|CL. This project makes me happy
693527952013721600,Sat Jan 30 20:15:23 +0000 2016,Very nice looking class on Deep Learning from Joan Bruna at Berkeley https://t.co/2dH8q1CAG9 focused on mathematical/statistical perspective
693137178545647600,Fri Jan 29 18:22:35 +0000 2016,On a related note, we're now 7 lectures into our ConvNets class (CS231n) https://t.co/0CjQYneaUt
693137094865059800,Fri Jan 29 18:22:15 +0000 2016,At REWORK Deep Learning summit. Amazed at breadth of successful applications of ConvNets in industry. Wish many more could wield the tech.
692873034953150500,Fri Jan 29 00:52:59 +0000 2016,RT @ArnoCandel: Awesome #DeepLearning RNNs generating sequences https://t.co/hdmnJnab2B by @karpathy #reworkDL @teamrework https://t.co/WtK‚Ä¶
692427536039546900,Wed Jan 27 19:22:43 +0000 2016,Judging by my Twitter timeline everyone already heard about DeepMind's AlphaGo :) https://t.co/tPAFi1JL2g Big congrats to team @ DeepMind!
692061440019071000,Tue Jan 26 19:07:59 +0000 2016,RT @amiconfusediam: Pixel RNNs - 2D RNNs that spit out pixel values. Pretty cool stuff from DeepMind. https://t.co/ySB4RnAbSy https://t.co/‚Ä¶
692059762456793100,Tue Jan 26 19:01:19 +0000 2016,RT @drfeifei: RIP, Marvin Minsky, one of the founders of AI. His gen. created the AI dream for us; it's our job to carry it thru. https://t‚Ä¶
690616660244303900,Fri Jan 22 19:26:57 +0000 2016,Robot Control with Distributed Deep Reinforcement Learning https://t.co/L20w4YQpyj nice visualization/env of 2D top down self-driving cars
690417238545854500,Fri Jan 22 06:14:31 +0000 2016,@yoavgo :)
690417150868197400,Fri Jan 22 06:14:10 +0000 2016,@yoavgo "Imagine there's no meetings It's easy if you try no emails to reply to noone to notify Imagine all your hrs Reading books in peace"
690312851236347900,Thu Jan 21 23:19:43 +0000 2016,Re-stumbled by a classic - "How to Write a Great Research Paper" https://t.co/b2HKZChBdq
690284167775453200,Thu Jan 21 21:25:45 +0000 2016,I have a recurring fantasy of disappearing completely for 1 week and quietly reading/doing research. no emails, meetings, commitments, todos
689387069957791700,Tue Jan 19 10:01:00 +0000 2016,@akaDavidGarrett not at all :) one link, two link, three link, low branching factor. high probability event ;)
689382790245146600,Tue Jan 19 09:43:59 +0000 2016,Quite painful to think about our impact on the planet. In Thailand saw pristine beaches littered with plastic bottles/junks. 11/10 tragic.
689381664275869700,Tue Jan 19 09:39:31 +0000 2016,Aww, nice video about saving a stick insect species from extinction https://t.co/zrm8XVbPXE didn't think I'd ever root for an ugly ant thing
688881883246006300,Mon Jan 18 00:33:34 +0000 2016,@MarkTrovinger no, topics too new. We'll be reading papers more recent than 1 year later in the class
688803779022471200,Sun Jan 17 19:23:12 +0000 2016,It's okay #SpaceX, these 1st stage recoveries have their ups and downs
688572046746325000,Sun Jan 17 04:02:23 +0000 2016,RT @fchollet: Very poetic video of Boston Dynamics' Atlas doing household chores: https://t.co/2ZOZ8s4WU4
688560626872926200,Sun Jan 17 03:17:00 +0000 2016,@NeuroStats i see, thanks. I think I'm too much of an outsider, merely trying to get a sense of the broad strokes of the development
688557924600315900,Sun Jan 17 03:06:16 +0000 2016,@NeuroStats Clearly I'm missing some back story context for the article
688556450990264300,Sun Jan 17 03:00:25 +0000 2016,@giessel nope, haven't heard of anything related to this
688525473031143400,Sun Jan 17 00:57:19 +0000 2016,Too many things to know, not nearly enough time, not nearly enough recall. A most depressing thought https://t.co/Tae093ch0u
688516968895254500,Sun Jan 17 00:23:32 +0000 2016,"[Bullshit] is the junk food of experience" https://t.co/qQKLZJKfbE
688117594071564300,Fri Jan 15 21:56:33 +0000 2016,Ryan Kiros ran char-rnn on all ICLR reviews - very amusing results :)  [1] https://t.co/afF2KnNy0P  [2] https://t.co/mSKQkZmQDw
688107026942013400,Fri Jan 15 21:14:34 +0000 2016,Visualizing CNN architectures side by side with mxnet https://t.co/4DLjHsNM6E &amp; Visual cortex: https://t.co/eelUcMIFyp almost there
687820768512639000,Fri Jan 15 02:17:04 +0000 2016,RT @shazow: I wrote a post about 3 fantastic recent advancements in VR applications: https://t.co/aCjrOYn7DV
687696349714747400,Thu Jan 14 18:02:41 +0000 2016,@deepdishio only part missing imo from yours is a concrete example with numbers. In my experience people like that quite a bit in beginning
687696156831256600,Thu Jan 14 18:01:55 +0000 2016,@deepdishio good write up taking what I think is right approach. Like. Can check my lecture slides on direction I ended up going. Similar
687695431552217100,Thu Jan 14 17:59:02 +0000 2016,@floryanscherer used to be the case, not so much anymore. These days much more code/docs around. My cs231n notes are attempt to enumerate
687694524374581200,Thu Jan 14 17:55:26 +0000 2016,@busonvallaha send me email I can try look. Haven't accessed in while maybe not
687539025683415000,Thu Jan 14 07:37:32 +0000 2016,IPython notebook tutorial: "Adversarial image generation in Tensorflow" https://t.co/YEkuaQxjNR Looks nice/short/sweet. Funny delivery
687464705762279400,Thu Jan 14 02:42:12 +0000 2016,@drfeifei @cs231n mission ~accomplished, btw. Kinda. Not sure. haha :)
687086945172717600,Wed Jan 13 01:41:07 +0000 2016,RT @benhamner: Recognizing &amp; localizing right whales with extremely deep neural nets (2nd place on @kaggle) https://t.co/YofxOLUtfd https:/‚Ä¶
687029683200770000,Tue Jan 12 21:53:35 +0000 2016,"The Falcon has landed" | Recap of Falcon 9 launch and landing https://t.co/fsF8aw595O ouch - this stuff really hits the feels
687014554555912200,Tue Jan 12 20:53:28 +0000 2016,@kswersk agreed but it's a bit more tricky because we rarely ever form the full Jacobian in practice, I think this point sometimes confuses
686850156197630000,Tue Jan 12 10:00:12 +0000 2016,@ojtwist looks quite nice and haven't seen this one before - thanks for link!
686828190996627500,Tue Jan 12 08:32:56 +0000 2016,@mdreid in my mind backprop is very simple, and I can't find a way to... quite distill the understanding to one "doh" diagram or something
686828042665103400,Tue Jan 12 08:32:20 +0000 2016,@mdreid I usually love Michael's stuff, but this section I thought had too many symbols and not enough visualizations / exact numbers.
686813770673291300,Tue Jan 12 07:35:37 +0000 2016,Preparing class slides for backprop lecture. Any links/recommendation on best explanation of backprop people have come across?
686501452882116600,Mon Jan 11 10:54:35 +0000 2016,@yoavgo @fastml_extra :D:D
686437677659369500,Mon Jan 11 06:41:10 +0000 2016,Trippy hypnotic Neural Style zoom https://t.co/x4E8icThIs (from @mtyka 's experiments https://t.co/UmKqSRkTaJ)
686122372160598000,Sun Jan 10 09:48:15 +0000 2016,Palmer Luckey interview on Oculus while rushing to the airport https://t.co/t1kOWpehjR well that's an uncommon format. Also respect++
685548333163663400,Fri Jan 08 19:47:14 +0000 2016,I really dislike checking my email in the morning. It's like you get a TODO list sampled from the universe every morning.
685545946483011600,Fri Jan 08 19:37:45 +0000 2016,RT @genekogan: Machine learning for artists. About my upcoming class at @ITP_NYU: https://t.co/Cm8YyII28g https://t.co/RWC7q8hldy
684976697666441200,Thu Jan 07 05:55:45 +0000 2016,@iandanforth lol right
684952264713240600,Thu Jan 07 04:18:40 +0000 2016,But if a new hot gadget comes around you don't look at price, you just know you must have it and the rest you'll figure out. Right? no? ok
684952083351511000,Thu Jan 07 04:17:57 +0000 2016,I see complaints about Oculus Rift $599 price. As someone who said byebye to $1600 for Google Glass I feel very happy in comparison.
684427235386732500,Tue Jan 05 17:32:23 +0000 2016,RT @genekogan: super mario levels designed by a recurrent neural net, awesome description by @ageitgey https://t.co/ghIeLllOP8 https://t.co‚Ä¶
684427089613684700,Tue Jan 05 17:31:48 +0000 2016,@gwern @ageitgey :D i didn't thanks for pointer!
684150848142704600,Mon Jan 04 23:14:07 +0000 2016,Our first lecture of @cs231n (ConvNets class) - intro by @drfeifei today. 300 enrolled! We'll have videos this year. https://t.co/PVgOAxz7gi
684101824308088800,Mon Jan 04 19:59:19 +0000 2016,@fchollet yes but as long as the rejection rate is not a function of Google / not Google then this isn't a concern
684099608151105500,Mon Jan 04 19:50:31 +0000 2016,@fchollet a good way to approx. quantify might be, e.g. looking at NIPS attendees ratio and NIPS papers by Google ratio.
684098132221661200,Mon Jan 04 19:44:39 +0000 2016,@jamisjohnson google drawing
683619322581794800,Sun Jan 03 12:02:02 +0000 2016,@hardmaru evolution is the outer loop over reinforcement learning inner loop of the optimization process of life.
683592037682171900,Sun Jan 03 10:13:36 +0000 2016,@janexwang @notmisha I think Carl Sagan read His Master's Voice, then dumbed it down for general masses and gave it a happy ending.
683591899358220300,Sun Jan 03 10:13:03 +0000 2016,@janexwang @notmisha agreed but Master's Voice is yet another step even on top of the book. movie &lt;&lt; book &lt;&lt; HMV. :)
683474605319716900,Sun Jan 03 02:26:58 +0000 2016,Finished first Stanislaw Lem book "His Master's Voice"; unique, fun, like! https://t.co/ypVJxz9Cqv (thanks for the recommendation @notmisha)
683079796918624300,Sat Jan 02 00:18:09 +0000 2016,@marek_rosa @GaryMarcus if a classifier looks at carrot and says orange, whether it "worked" depends on if carrot was a class in data.
683078775504896000,Sat Jan 02 00:14:05 +0000 2016,@marek_rosa @GaryMarcus ie recognition part works perfect. But if ppl run ImageNet pre trained model on data you must be aware of its data
683078385547923500,Sat Jan 02 00:12:32 +0000 2016,@marek_rosa @GaryMarcus goes to my point. misunderstanding of ImageNet's labels. There's no person class. Seatbelt class has many ppl.
682869672333582300,Fri Jan 01 10:23:11 +0000 2016,2016 Edge question: "What do you consider the most interesting recent [scientific] news?" https://t.co/qoRy4puYy0 good reading
682454436808114200,Thu Dec 31 06:53:11 +0000 2015,@michael_nielsen thank you! Special case of "do things you wish others did too" :)
682453806240657400,Thu Dec 31 06:50:41 +0000 2015,@michael_nielsen not sure if I'm up to a 3rd Einstein Bio, but maybe in a few years, the feeling comes and goes :)
682440851373584400,Thu Dec 31 05:59:12 +0000 2015,When using a selfie stick my shame is inversely proportional to the number of people in the picture.
682414685266817000,Thu Dec 31 04:15:14 +0000 2015,Although with P(y|x) model the first point is about awareness of statistics of x in the training data and second about stats of y.
682413989838598100,Thu Dec 31 04:12:28 +0000 2015,Also E.g. an ImageNet model will be superhuman with dog types but classify people as seatbelts, and that‚Äôs okay - working as intended.
682413849409130500,Thu Dec 31 04:11:54 +0000 2015,A misconception I repeatedly run into with NeuralTalk is from ppl who expect it to work on non-MSCOCO-like images. Non-intuitive I suppose
681990211438395400,Wed Dec 30 00:08:31 +0000 2015,@RyanKeisler also barely mentions UNIX and C. Definitely focused on some aspects more than others. Owell
681856620339433500,Tue Dec 29 15:17:41 +0000 2015,Finished reading "The Idea Factory", a history of Bell Labs. Got a bit carried away with review https://t.co/V0fL0QTUyd v nice read though!
681719477927477200,Tue Dec 29 06:12:43 +0000 2015,"You can't build a working computer whose radius is more than 20 billion light years or whatever. It's depressing, but true" -Scott Aaronson
681707789723410400,Tue Dec 29 05:26:17 +0000 2015,Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow https://t.co/C18nAkjSjG by @hardmaru nicely done!
679627058511654900,Wed Dec 23 11:38:12 +0000 2015,4. The seemingly highly reproducible quantity of number of days of vacation before I really kind of wanna get back to work.
679626496705560600,Wed Dec 23 11:35:58 +0000 2015,@ogrisel @lawrennd +1 agreed it's a point less emphasized than should be. Compute, data, algorithms. The trinity needed for progress :)
679120021201678300,Tue Dec 22 02:03:25 +0000 2015,RT @zackkanter: Shots fired.  https://t.co/wG1qr66mQN
679118957207400400,Tue Dec 22 01:59:11 +0000 2015,Happened to watch the SpaceX live stream with my parents. Amusing discrepancy between my excitement and their complete confusion. Sigh
679115102960808000,Tue Dec 22 01:43:52 +0000 2015,RT @SpaceX: The Falcon 9 first stage landing is confirmed. Second stage continuing nominally. https://t.co/RX2QKSl0z7
678763147923091500,Mon Dec 21 02:25:19 +0000 2015,@dschnr I KNOW! Witnessed it yesterday for the first time, wow! :)
678544005949337600,Sun Dec 20 11:54:32 +0000 2015,Searching "imax" on google maps while in Thailand returns a result in random place in Florida. Go home Google maps, you're drunk.
678422914874478600,Sun Dec 20 03:53:22 +0000 2015,Spending a tropical christmas in Thailand, hunting mosquitos, riding motorcycles/speedboats, gorging on $1 ice cream and scuba diving.
677223205442981900,Wed Dec 16 20:26:09 +0000 2015,A bit depressing article on funny dynamics of progress in science https://t.co/WM4eunp0Vk "does science advance one funeral at a time?"
677046643519131600,Wed Dec 16 08:44:33 +0000 2015,I was going to tweet about how weird/foreign it is to read your own code from long ago. But I already tweeted about that once before so nvm.
676939619762589700,Wed Dec 16 01:39:16 +0000 2015,@vral looks quite nice &amp; useful! thanks for link :)
676934995655684100,Wed Dec 16 01:20:54 +0000 2015,Last time we offered the class it took 110% of my time. Doing the math, this year is on track to taking ~300% of my time.
676933776690253800,Wed Dec 16 01:16:03 +0000 2015,The enrollment for our CS231n class for next quarter is filling up alarmingly quickly with hundreds of students. Yay. Wait, I mean, gulp.
676638461751758800,Tue Dec 15 05:42:35 +0000 2015,Our lab released a new dataset we've worked on for a while (e.g. 4.3 million region captions). Glad to see it out https://t.co/2vYZuzNZLo
676106000990994400,Sun Dec 13 18:26:46 +0000 2015,Worth knowing about and tracking: CRISPR https://t.co/QkmJHnpHOg
676083088762404900,Sun Dec 13 16:55:44 +0000 2015,@SebastienBubeck nice post &amp; thx! My understanding is we wanted more cohesion while we get started, but we'll branch out more over time.
676077663870554100,Sun Dec 13 16:34:10 +0000 2015,RT @SebastienBubeck: Some thoughts on @NipsConference and @open_ai  https://t.co/CFSFWnSasc
675438620258496500,Fri Dec 11 22:14:50 +0000 2015,RT @NandoDF: Rich Sutton locked out of the RL workshop at #nips2015 because it's too full :) https://t.co/VutJwIAYW0
675433547738554400,Fri Dec 11 21:54:41 +0000 2015,RT @mappingbabel: OpenAI: "This collection of people is stunning" https://t.co/GAzzOcNfRC Ilya Sutskever, @karpathy , etc. Potential for hu‚Ä¶
675215784277319700,Fri Dec 11 07:29:22 +0000 2015,..and 1st layer 7x7 stride 2, bottleneck conv 1x1-3x3-1x1. Final 152-layer model is 11.3 vs. 19.6B FLOPS in VGG-19. Can‚Äôt wait to try it out
675215606732427300,Fri Dec 11 07:28:40 +0000 2015,Deep Residual Learning for Image Recognition https://t.co/dxje3GHMnM nice 2am read :) Identity shortcut connections, BatchNorm, AvgPool, SGD
675005557082751000,Thu Dec 10 17:34:00 +0000 2015,There is a website I'm currently struggling to load/use (not pointing any fingers), but https://t.co/Z5aoTPCGif always comes to mind
675000756508868600,Thu Dec 10 17:14:55 +0000 2015,ImageNet2015 results https://t.co/JWhWEvBsnS big congrats to @MSFTResearch team with 3.6% top5 error. 150 layers! looking forward to details
673905764134608900,Mon Dec 07 16:43:49 +0000 2015,Haha this doesn't make me look very good :) https://t.co/a4oArLRw7U
673721360208687100,Mon Dec 07 04:31:04 +0000 2015,@fchollet haha, perhaps that's a slight exaggeration :)
673313410021384200,Sun Dec 06 01:30:01 +0000 2015,@iandanforth even pull requests are hard to review and can take a lot of time to.
673231724461953000,Sat Dec 05 20:05:25 +0000 2015,@abhijatbiswas VERY WRONG TIME TO ASK. haha
673231631243604000,Sat Dec 05 20:05:03 +0000 2015,@jhaberstro My goal is usually to make my research accessible usable and easy to learn from. Reproducing numbers in a table not as important
673227496414822400,Sat Dec 05 19:48:37 +0000 2015,In theory you can choose to ignore issues and not respond to emails asking for help, but in practice you feel like a jerk if you do.
673227371286147100,Sat Dec 05 19:48:07 +0000 2015,Releasing code sounds great until you're suddenly spending hours every day doing various edge case code maintenance instead of research.
672659555789049900,Fri Dec 04 06:11:50 +0000 2015,Squeezed in an hour to create this year's NIPS 2015 papers in nice LDA format https://t.co/MVQRhtnOwq excited for the conference next week!
672535238447226900,Thu Dec 03 21:57:50 +0000 2015,@petewarden ordering my 5 candidates was taking extra time/effort so I was relatively eager to not have to worry about it. Bad in retrospect
672535095949979600,Thu Dec 03 21:57:16 +0000 2015,@petewarden Unfortunately no :( Olga told me ImageNet doesn't do top1, so halfway through I started ignoring my order among top 5 :(
672534973711183900,Thu Dec 03 21:56:47 +0000 2015,@ChrisBaldassano probly close. &amp; I think with an ensemble of trained/dedicated people I wouldn't be surprised if we could go down a bit more
672491926889742300,Thu Dec 03 19:05:44 +0000 2015,@jigarkdoshi I think if we had an ensemble of a few very well trained and careful labelers we'd still be able to outperform it.
672490947179974700,Thu Dec 03 19:01:50 +0000 2015,recall: my performance was ~5% and I tried quite hard (https://t.co/OOGaHaiTzz). So, 3.46% is very very good.
672490811875975200,Thu Dec 03 19:01:18 +0000 2015,New paper from Google team with more details/changes on the Inception CNN architecture https://t.co/YvVHVTw6aa 3.46% top5 error on ImageNet
672226518819471400,Thu Dec 03 01:31:06 +0000 2015,@stephenjaoates @deepselfie bleh i have to keep restarting it and forget about it. let me start it up again.
672211101933637600,Thu Dec 03 00:29:50 +0000 2015,Now that it has a domain name it's a certified serious project :)
672211025417003000,Thu Dec 03 00:29:32 +0000 2015,Moved arxiv sanity visualization page to a more permanent location at https://t.co/AktZYxom0e Going to build this up over time.
672199876348809200,Wed Dec 02 23:45:14 +0000 2015,@azizt_o raw html/css/js written from scratch in an editor. "system"
672191877068619800,Wed Dec 02 23:13:26 +0000 2015,RT @drfeifei: At Andrej @karpathy's PhD thesis proposal today. Here he's showing @chrmanning our latest DenseCap real-time demo. https://t.‚Ä¶
672142699806392300,Wed Dec 02 19:58:02 +0000 2015,@yoavgo here it is https://t.co/rzKAVOoeDr (165MB), 10400 papers from last ~3 years of arxiv CS/LG/CL (from txt folder wrt. repo code)
672124651904962600,Wed Dec 02 18:46:19 +0000 2015,@yoavgo certainly, busy for few hours but can put them up in a bit. Didn't notice Lstm rnn are not included, needs bigger vocab
672106596365934600,Wed Dec 02 17:34:34 +0000 2015,RT @engadget: I taught a computer to write like Engadget https://t.co/rhDVnBPNoi https://t.co/N9SgPxdLng
671959418905358300,Wed Dec 02 07:49:44 +0000 2015,It has not escaped our notice that the pairing we have postulated immediately suggests a possible copying mechanism for the genetic material
671959164562759700,Wed Dec 02 07:48:43 +0000 2015,Molecular Structure of Nucleic Acids https://t.co/wrfT66Lte4 Watson &amp; Crick, Nature 1953. Fun reading famous original texts.
671764166454083600,Tue Dec 01 18:53:52 +0000 2015,@CharlesOllion @ogrisel At least compared to what I'm used to ("similar to" in Scholar), tfidf is huge improvement. Looks near perfect to me
671763886954045400,Tue Dec 01 18:52:46 +0000 2015,@CharlesOllion @ogrisel interesting. Hard to compare these results, I just eyeball it and current seems to work ok. Could try finetuned STV
671763553418797000,Tue Dec 01 18:51:26 +0000 2015,@curious_reader @t3kcit I don't actually know how I feel about these social network wrapper ideas. It's very easy to implement though
671552559367123000,Tue Dec 01 04:53:01 +0000 2015,@mohamedmansour My Research Lei https://t.co/hoLnqeoZVB was powered by Microsoft API, but had to discontinue it when they were taken down
671533940310597600,Tue Dec 01 03:39:02 +0000 2015,@etzioni The hard to extract and most interesting part is the citations graph
671533674077143000,Tue Dec 01 03:37:59 +0000 2015,@etzioni Microsoft Academic API used to be very nice. I used it to build Research Lei https://t.co/hoLnqeoZVB but had to discontinue since
671529822661709800,Tue Dec 01 03:22:40 +0000 2015,@etzioni I looked around for a while on both https://t.co/5gMYaUJDFZ and https://t.co/8tJXDPxcUj but can't find a link.
671502149289828400,Tue Dec 01 01:32:42 +0000 2015,@titipat_a thanks, I have these too. In fact I have 7000 papers from CVPR/ICCV/NIPS/ICML/ECCV/BMVC, used for https://t.co/IK96UIlSxA
671427014411337700,Mon Nov 30 20:34:09 +0000 2015,It's alive! Serving 10400 arxiv papers in cs.[CV|LG|CL] over last 3 years. Search / sort papers by tfidf similarity https://t.co/dfBJtbogsN
671242572203991000,Mon Nov 30 08:21:14 +0000 2015,@gchrupala +1 :'(
671231222236975100,Mon Nov 30 07:36:08 +0000 2015,@jorenvs arxiv has great API, hats off to them. But they don't keep track of citation counts, or build graph of citations more generally
671220948352278500,Mon Nov 30 06:55:19 +0000 2015,@tom_hartley they worked out all kinds of deals with the music industry, notorious for their insanity. If there's a will there's a way
671220430859051000,Mon Nov 30 06:53:16 +0000 2015,@tom_hartley It's in Google's culture to stand for innovation and it boggles my mind that they let this slide, turn a blind eye to Scholar
671219988427067400,Mon Nov 30 06:51:30 +0000 2015,@Reza_Zadeh I tried adding all kinds of randomness, and waited minute+ between queries. I used uniform(), but doubt this would be issue?
671219388100583400,Mon Nov 30 06:49:07 +0000 2015,The state of academic search/discovery is sad. Microsoft API shut down. Google Scholar is what it is. Progress of entire fields is hampered.
671217679555027000,Mon Nov 30 06:42:20 +0000 2015,Was trying to get citation counts to enrich the arxiv interface a bit. But I give up now. You win Google Scholar, keep your data.
671217283910488000,Mon Nov 30 06:40:45 +0000 2015,Google Scholar goes to great lengths to ensure that no scripts can run automated queries. Aggressive rate limits, bans, obfucscations... boo
671116898285649900,Mon Nov 30 00:01:51 +0000 2015,@arnicas I'm scaling it up to 10K papers from LG/CL/CL over last 3 years. Takes a while to process it all but should be nice and useful
671034268370509800,Sun Nov 29 18:33:31 +0000 2015,@notmisha also people differ in what methods they use, finger tricks they like, etc. So lucky scramble for one may be unlucky for another
671034068130246700,Sun Nov 29 18:32:43 +0000 2015,@notmisha right, but that's mostly irrelevant because people don't solve along anywhere near optimal path to solution.
671029842016604200,Sun Nov 29 18:15:56 +0000 2015,@notmisha it's controlled for in competition but not across competitions. Mean is common to look at, or # at sub-X  https://t.co/uqTosXOXe9
671019896336072700,Sun Nov 29 17:36:24 +0000 2015,Two records in Rubik's cube established on same day, now 4.90s. Fun to watch reaction in vid. I miss speedcubing :\ https://t.co/ixF1x9FGyF
671015886099054600,Sun Nov 29 17:20:28 +0000 2015,@neurobongo that's me :( unwillingly. There aren't exactly books/articles on the topic?
670771471304810500,Sun Nov 29 01:09:15 +0000 2015,@tomcoates @atduskgreg I'm with Tom on this :)
670669095197614100,Sat Nov 28 18:22:27 +0000 2015,char-rnn implemented in Tensorflow https://t.co/RNzLJ1dtOq haven't tried running, but looks nice/compact.
670660117990387700,Sat Nov 28 17:46:47 +0000 2015,Planet Money episode on hoverboards https://t.co/VRAS8FUpGh rly enjoying watching its popularity blow up  https://t.co/lWrgIjmfBb want one
670481275745095700,Sat Nov 28 05:56:07 +0000 2015,yay, I have the arxiv interface running on Terminal https://t.co/dfBJtbogsN serving last 3 months of CV/LG papers. well that was fun
670468943530876900,Sat Nov 28 05:07:07 +0000 2015,it's really gross code but I put it up in case anyone else wants to play. Works well for me. Sorting by tfidf similarity is powerful.
670468854666174500,Sat Nov 28 05:06:46 +0000 2015,hacked together a quick flask webserver that lets you sort by similar/search arxiv papers in a nice interface https://t.co/66JUTiihdh
670451870150864900,Sat Nov 28 03:59:16 +0000 2015,@etzioni Should scale fine. Ended up coding today on a web app for my use case. Browsing arxiv papers of last 3 months in that format now ;p
670399569738371100,Sat Nov 28 00:31:27 +0000 2015,@mdreid :D yes I will take the blue pill, please :)
670381508801114100,Fri Nov 27 23:19:41 +0000 2015,@yoavgo @kastnerkyle The issue is you can't easily spot the good ones in the sea of those that aren't as relevant to you.
670381329997938700,Fri Nov 27 23:18:58 +0000 2015,@korirotti  was here https://t.co/6s5T4VlVnY . For DL I'd get CPU with more PCIe lanes. And motherboard that can support 4GPUs
670363270331527200,Fri Nov 27 22:07:13 +0000 2015,@etzioni doesn't exactly address my use case. I'd like to get an overview, sort by similarity, etc. Similar to https://t.co/l8FEY4axFC
670362732923719700,Fri Nov 27 22:05:04 +0000 2015,@dijkstracula no, a google doc
670362675994452000,Fri Nov 27 22:04:51 +0000 2015,@busonvallaha there isn't, so i'm writing it right now. had enough
670349424464281600,Fri Nov 27 21:12:11 +0000 2015,@CaldenWloka Yep! Very frequent as well. It's a complete disaster
670349102496936000,Fri Nov 27 21:10:55 +0000 2015,I have 26 paper on my toread list and I'm about to do another pass through my arxiv rss feed with 532 unread abstracts. Bit out of hand
670334161652088800,Fri Nov 27 20:11:33 +0000 2015,labhacks tumblr https://t.co/X7TygCEUir . Especially "The $25 scrunchable scientific poster" https://t.co/5SlL2OI39Y brilliant
670300232446414800,Fri Nov 27 17:56:43 +0000 2015,RT @teamrework: Interview:Deep Learning with Andrej Karpathy https://t.co/lPq4m1Mz32 @karpathy #reworkDL #deeplearning https://t.co/dvLpnR6‚Ä¶
670283663737618400,Fri Nov 27 16:50:53 +0000 2015,"What is that?". "It's a watch". "Cool! What does it do?" #2015
669956546818797600,Thu Nov 26 19:11:02 +0000 2015,@LH at same time I wonder if it's too naive to expect that we ever will
669951241867280400,Thu Nov 26 18:49:57 +0000 2015,Turing on AI in 1950 https://t.co/iZvTHA9cbm estimated that ~60 programmers over 50 years can implement a child AI. Interesting
669949500232876000,Thu Nov 26 18:43:02 +0000 2015,RT @haldaume3: groan. biggest problem with GOFAI wasn't hand coding: it was not using real data. let's please not repeat that :(. https://t‚Ä¶
669593677560320000,Wed Nov 25 19:09:07 +0000 2015,@kastnerkyle reminds me of https://t.co/depCTf2Foe fun
669584061397008400,Wed Nov 25 18:30:55 +0000 2015,Every morning feels like christmas: my workers diligently trained overnight and it's time to check crossvalidation performances!! squeek
669272252341338100,Tue Nov 24 21:51:54 +0000 2015,So Awesome and beautiful: https://t.co/qGNZv9Kdyo the universe of arxiv papers. I didn't realize CS was such a tiny cluster
668858657971433500,Mon Nov 23 18:28:25 +0000 2015,@amiconfusediam @AlecRad do a DCGANLAPGANSTCNNRNN
668837200583225300,Mon Nov 23 17:03:09 +0000 2015,@amiconfusediam @AlecRad all the other images look as though they were trained larger. Except ImageNet was 32x32?
668837046375444500,Mon Nov 23 17:02:32 +0000 2015,@amiconfusediam @AlecRad thanks soumith, I can right click on images too, but it's still small. I can Ctrl+ too, but then too grainy. :p
668829646394277900,Mon Nov 23 16:33:08 +0000 2015,Ah thanksgiving break. A time when walking through the campus/department feels like being in a deserted postapocalyptic zombie movie
668828456126279700,Mon Nov 23 16:28:24 +0000 2015,@AlecRad i like the imagenet generations best, wish they were larger :p hard to see. Or maybe that's what I like them? can't spot flaws haha
668828156174839800,Mon Nov 23 16:27:13 +0000 2015,Nice work from @AlecRad on training Generative Adversarial Nets https://t.co/1zTKxf0HDt v nice samples. +code soon @ https://t.co/IK6AixXpyk
668551014371356700,Sun Nov 22 22:05:57 +0000 2015,The comments in an HN submission on Neuraltalk2 turned into a Q&amp;A about Image Captioning https://t.co/lG33rwJqQp
668466644138655700,Sun Nov 22 16:30:42 +0000 2015,@rs9000 use batch size 1
668340180026167300,Sun Nov 22 08:08:10 +0000 2015,@buzzganesh there's no advantage only disadvantage, since with embedding you're effectively stacking two linear layers on top of one another
668337206658863100,Sun Nov 22 07:56:21 +0000 2015,@buzzganesh when you're in char setting this is not much of an issue. In word settings with many thousand words I'd use an embedding.
668312227062018000,Sun Nov 22 06:17:06 +0000 2015,@buzzganesh 1hot is an embedding. what's the problem? :)
668191118605979600,Sat Nov 21 22:15:51 +0000 2015,@joyfuldroid haha don't think anytime soon too much other stuff to worry about. Maybe one day :)
668154466785341400,Sat Nov 21 19:50:13 +0000 2015,@rs9000 ok i pushed an update: a script to convert checkpoints to cpu and a link to CPU only checkpoint. See if it works for you
668122111081222100,Sat Nov 21 17:41:39 +0000 2015,@kcimc ew! haha. It's a cool functionality to bake into the library, but not like this :) I'll be on a lookout though - fun use case
668111054124089300,Sat Nov 21 16:57:42 +0000 2015,@kcimc also was it difficult to adapt the code to run online/on camera? If you found a nice way I might like to include it in docs etc
668108806115561500,Sat Nov 21 16:48:46 +0000 2015,@rs9000 I can create cpu checkpoint instead. Easy to do. Might be slow to run but can try
668108544013549600,Sat Nov 21 16:47:44 +0000 2015,@kcimc also it's interesting the things it works on or not are well aligned to what kinds of images happen to be in mscoco. Not best variety
668108310248185900,Sat Nov 21 16:46:48 +0000 2015,@kcimc hahah nicely done! I'm hoping to release higher accuracy models, I rushed this one to release before it fully converged. Still fun :)
668107851341000700,Sat Nov 21 16:44:59 +0000 2015,RT @kcimc: neural net descriptions generated in realtime during a brief walk around amsterdam https://t.co/V35fZ1uVlC using neuraltalk by @‚Ä¶
667563342316204000,Fri Nov 20 04:41:18 +0000 2015,The quest for AI: A history of ideas and achievements by Nils J. Nilsson https://t.co/O0Hng06XYd nice looking reference
667551626433945600,Fri Nov 20 03:54:44 +0000 2015,Flashforward 20 years forward: writing NeuralTalk9 on a quantum computer, warping fabric of reality for "red stop sign with a sign on it"
667550500359794700,Fri Nov 20 03:50:16 +0000 2015,@beaucronin :D
667549433270153200,Fri Nov 20 03:46:02 +0000 2015,@beaucronin do you enjoy reimplementing the same code over and over in different libraries?
667548383343542300,Fri Nov 20 03:41:51 +0000 2015,@Raaka_elgupo well, right now thinking never :)
667547650799996900,Fri Nov 20 03:38:57 +0000 2015,coming up soon: another Image Captioning reimplementation in Tensor Flow? :( Too depressing to think about right now, drawing line here.
667547468486193200,Fri Nov 20 03:38:13 +0000 2015,this code is quite a bit more efficient than original NeuralTalk (~100x+), and works signficiantly better due to the finetuning.
667546906814361600,Fri Nov 20 03:35:59 +0000 2015,Released NeuralTalk2 RNN Image Captioning code in Torch https://t.co/mm7lPYAjLB batched training on GPU, supports CNN finetuning
667218882772381700,Thu Nov 19 05:52:32 +0000 2015,@antonmil no, i haven't checked in a while, since a bit after CVPR deadline. Since then :\
667214650405056500,Thu Nov 19 05:35:43 +0000 2015,Okay. Only 326 new arxiv papers unread in my rss feed. Here we go
667136492737683500,Thu Nov 19 00:25:09 +0000 2015,@kanishkaugee it's all vanilla html/css. I don't like platforms
666332257968193500,Mon Nov 16 19:09:24 +0000 2015,RT @TorchML: [blog] Generating faces via Adversarial Networks. Comparison with variational approaches.... https://t.co/JzX33Aw3xA https://t‚Ä¶
666007929049366500,Sun Nov 15 21:40:38 +0000 2015,RT @cdixon: Lessons from the PC video game industry https://t.co/ySPKgC5e03
666003857705603100,Sun Nov 15 21:24:28 +0000 2015,RT @ylecun: A new paper by Christopher Manning on the coming deep learning tsunami over natural language understanding. https://t.co/1xqjDX‚Ä¶
666002774388162600,Sun Nov 15 21:20:09 +0000 2015,RE my yesterday story on AI there's a lot of great related work in animal shaping https://t.co/9ubEQBm5BH (as pointed out by a commenter)
665955569677668400,Sun Nov 15 18:12:35 +0000 2015,@dribnet @janexwang yep! I should probably expand that acronym out somewhere in the story :) will fix
665634328081141800,Sat Nov 14 20:56:05 +0000 2015,@matsiyatzy notable recent exception being The Martian which I think was quite technical but people loved it all the same. Want more of that
665634119380955100,Sat Nov 14 20:55:15 +0000 2015,@matsiyatzy thanks! It's intended to be nice and technical, just for us to geek out about :) Also an aspect I usually miss in other scifi
665624395696635900,Sat Nov 14 20:16:37 +0000 2015,@altscifi_ @kcimc alright :)
665623279873355800,Sat Nov 14 20:12:11 +0000 2015,@kcimc interesting, thanks for the pointer!
665621222235902000,Sat Nov 14 20:04:00 +0000 2015,@kcimc @Michcioperz Perhaps. For some reason I don't like the idea of spelling it out. I'll see if I can find some subtle ways to clarify
665615165086236700,Sat Nov 14 19:39:56 +0000 2015,Fluid simulation with Machine Learning https://t.co/zNWKJ0dB0P formulates physics-based fluid simulation as a regression problem
665614741289635800,Sat Nov 14 19:38:15 +0000 2015,@Michcioperz I see, I think it's partly intended to be at least a little bit of a puzzle that gets revealed over time, but might be too much
665613593426006000,Sat Nov 14 19:33:41 +0000 2015,@Michcioperz haha it is? oh man.... hahaha, why so?
665607520593965000,Sat Nov 14 19:09:33 +0000 2015,Appropriately, names of 2 main characters (Merus, Licia) were sampled from my earlier list of RNN-generated names :) https://t.co/mw9mPGm1it
665606372478726100,Sat Nov 14 19:05:00 +0000 2015,New blog post: Shaking things up a bit with a short story on AI, "A Cognitive Discontinuity" https://t.co/tiStoOBCi8
665212271618973700,Fri Nov 13 16:58:59 +0000 2015,@halilakin they will, next quarter
664566830061621200,Wed Nov 11 22:14:13 +0000 2015,@yigitdemirag @amiconfusediam I did, but I don't draw any conclusions from it. It's an early release, obviously will be improvements in time
664527101500874800,Wed Nov 11 19:36:21 +0000 2015,@vkrakovna great to hear, fully onboard with the cause!
664521845282963500,Wed Nov 11 19:15:28 +0000 2015,@vkrakovna hey Victoria! Nice to see you on Twitter - hope you and Janos are well, it's been a few years :)
664507471055077400,Wed Nov 11 18:18:21 +0000 2015,@yigitdemirag Still can't comment on TF. The whitepaper has good ideas, but I haven't worked with it yet. Can see some red flags already
664236274509852700,Wed Nov 11 00:20:43 +0000 2015,@deanpomerleau was amusing to see few pesimistic tweets in your timeline, e.g. Tesla. Would be eager to read more of your thoughts somewhere
664226836201652200,Tue Nov 10 23:43:13 +0000 2015,@KaiLashArul @kcimc @sedielem Agreed - the fact that ConvNetJS is near top is kind of terrifying but also quite misleading :)
664226523126206500,Tue Nov 10 23:41:58 +0000 2015,RT @kcimc: 2010-2014: a new deep learning toolkit is released every 47 days. 2015: every 22 days. tensorflow &amp; caffe top github https://t.c‚Ä¶
664201029341188100,Tue Nov 10 22:00:40 +0000 2015,@deanpomerleau Read through your way-ahead-of-its-time phd thesis linked from https://t.co/XOavfzyn26 Fascinating to see these ideas in 1992
664156407655043100,Tue Nov 10 19:03:21 +0000 2015,Skimmed through Marvin code. Quite like the idea of microframeworks that do one important thing well &amp; with little code and few dependencies
664152870858588200,Tue Nov 10 18:49:18 +0000 2015,Marvin: A minimalist GPU-only N-dimensional ConvNet framework https://t.co/uTDCPVHj4C All code lives in two files (marvin.hpp and marvin.cu)
663911442467303400,Tue Nov 10 02:49:57 +0000 2015,TensorFlow launch party / hackathon session we ran today. Quite a bit of interest it seems :) https://t.co/PgJWUGxLwb
663839385222180900,Mon Nov 09 22:03:37 +0000 2015,@yoavgo true, but it doesn't look like this is a fundamental constraint. Maybe more of a simplifying assumption for first iteration
663811466059845600,Mon Nov 09 20:12:41 +0000 2015,Many great ideas / design principles within &amp; hopefully with well done implementation. Or to quote @j26774 "It's like Christmas came early"
663810909270208500,Mon Nov 09 20:10:28 +0000 2015,You can't be in Deep Learning, read through the TensorFlow whitepaper https://t.co/lJKg3Wr4uV and not experience multiple nerdgasms
663788003681112000,Mon Nov 09 18:39:27 +0000 2015,@mappingbabel @derektmead @adrjeffries Just planning to put it up on my site. Expecting it to be bad first time around and that's okay :)
663783433110315000,Mon Nov 09 18:21:17 +0000 2015,Tensorflow is here! https://t.co/hRzxPIz7oh complete with a blurry background, upbeat music, and a dose of fluff video :)
663156170916401200,Sun Nov 08 00:48:46 +0000 2015,RT @samim: New Experiment: Regressing 24 Hours in New Orleans: https://t.co/dtLzCh0v6A https://t.co/yOkKhMQ6cL
663155665209167900,Sun Nov 08 00:46:46 +0000 2015,@rateldajer interesting! didn't hear about it, no
663155561215606800,Sun Nov 08 00:46:21 +0000 2015,@thereal_cos I'm doing the opposite - Writing it out linearly from top to bottom, making up stuff on the spot :D
663155351915663400,Sun Nov 08 00:45:31 +0000 2015,@benhamner I don't expect to actually work on them :) I just come up with them, obsess over them for a year, and think about working on them
663155071438352400,Sun Nov 08 00:44:24 +0000 2015,@benhamner haha no. I had the idea for short story for ~year, or different versions of it. There were 3 other ideas just before deadline :)
663121717515042800,Sat Nov 07 22:31:52 +0000 2015,Working on a short story on AI that has been on my mind for while. I'm terrible. I do code writing, paper writing, but not creative writing.
662917761006342100,Sat Nov 07 09:01:25 +0000 2015,@aittalam yep. had to drop in and reinstall as well. except for some reason the aptget version really did not want to work
662829503337500700,Sat Nov 07 03:10:43 +0000 2015,I have a good idea - I'll just update my Ubuntu, how bad could it be. If you're using NVIDIA drivers, apparently very very bad.
662767411829960700,Fri Nov 06 23:03:59 +0000 2015,RT @notmisha: Autograd for torch https://t.co/948YpIySDq (h/t @hugo_larochelle)
662339765153370100,Thu Nov 05 18:44:40 +0000 2015,Coool: Lytro announces Lytro Immerge for capturing VR video. Records full 4D Light field: light+direction in 360deg https://t.co/E9Zx5ZdyEk
662337071697166300,Thu Nov 05 18:33:58 +0000 2015,@robibok posted :)
661616329611325400,Tue Nov 03 18:49:59 +0000 2015,@AlecRad @benhamner CVPR due Friday. And yes then ICLR. Lots of "fun" coming up :)
661614517139320800,Tue Nov 03 18:42:47 +0000 2015,@benhamner it's real! I've seen it over and over again. How does that happen.
661614158475997200,Tue Nov 03 18:41:22 +0000 2015,My brain is best at generating and getting obsessed about side project ideas exclusively few days before big deadlines. Thanks brain.
661604627708690400,Tue Nov 03 18:03:29 +0000 2015,Google will begin rolling out automated replies in Gmail, based on encoder decoder LSTMs https://t.co/mDhWEDXNrn "Gmail autopilot"? :)
661247846184693800,Mon Nov 02 18:25:46 +0000 2015,Nice/detailed post on how frames get rendered in GTA V https://t.co/OWXxHNNLVy amazing that this can all happen at 100fps on my machine
661234183465910300,Mon Nov 02 17:31:29 +0000 2015,@karelleternier hi thank you but unfortunately I don't have the bandwidth. Cheers, Andrej.
660726215796326400,Sun Nov 01 07:53:00 +0000 2015,@cohenrap I bet they do! But I also bet they love all the best practices they are allowed to use later, and understand them better.
660725707249586200,Sun Nov 01 07:50:58 +0000 2015,Also why I disapprove when correct programming practices are taught in intro CS classes. I'd want students to see how bad it is without them
660725414566871000,Sun Nov 01 07:49:49 +0000 2015,Experienced this first when I was coding in Pascal as a kid. Kept copy-pasting stuff then discovered a for loop and thought "what a godsend"
660725206244159500,Sun Nov 01 07:48:59 +0000 2015,Very nice article on the problem-solution ordering pattern  https://t.co/m6NF9KmRMb one of few bigger education insights I've had so far
660624815355621400,Sun Nov 01 01:10:04 +0000 2015,Twitch watches Bob Ross' "The Joy of Painting" https://t.co/6OlMyYJDUs quite entertaining.
660560367836237800,Sat Oct 31 20:53:58 +0000 2015,@mappingbabel random comment, sparked by re-stumbling by Igor's paper from earlier tweet. Igor also in Pieter's lab atm
660552205133414400,Sat Oct 31 20:21:32 +0000 2015,Spending extra time tuning my baselines, thinking about how much incentive I have not to, &amp; how this is the reason we can't have nice things
660216413412442100,Fri Oct 30 22:07:13 +0000 2015,I get a small heart attack with each step when I walk without my phone in my pocket, my unconscious brain kicking in, thinking I lost it :s
660207260316995600,Fri Oct 30 21:30:51 +0000 2015,@laubzega sure, evolution will be the outer layer, tuning the (non-differentiable) hyperparameters of the architectures :)
660167977673715700,Fri Oct 30 18:54:45 +0000 2015,@yoavgo @haldaume3 imo there will always be expensive things you want to compute and approximate quickly with shortcuts, but the bar moves.
660159764442185700,Fri Oct 30 18:22:07 +0000 2015,Virtual agents embodied in 3D physics simulations, perceiving rendered virtual worlds &amp; running one big sensorimotor RNN policy in 3,2,1...
660157628446707700,Fri Oct 30 18:13:38 +0000 2015,@haldaume3 that's fair. NNs are my favorite function approximators so that I can in the future plug blobs of them into one another :)
660155286640918500,Fri Oct 30 18:04:20 +0000 2015,In general, the good idea trend is doing expensive compute @ train time &amp; baking it into NN as an approx computational shortcut @ test time
660153403322994700,Fri Oct 30 17:56:51 +0000 2015,More exciting work on interleaving supervised learning &amp; trajectory optimization for learning RNN control policies https://t.co/54MzkPwgol
660141877052571600,Fri Oct 30 17:11:02 +0000 2015,@ChiefExo thank you, unfortunately I don't have the bandwidth.
659944890743156700,Fri Oct 30 04:08:17 +0000 2015,Research secrecy is bad for efficiency &amp; talent acquisition https://t.co/IhUbidG9xp good article by @mappingbabel  https://t.co/CAI2HF9cuQ
659918377545171000,Fri Oct 30 02:22:56 +0000 2015,RT @shakir_za: New post. Machine Learning Trick of the Day (4): Reparameterisation Tricks. On one-line random nums and stoch optim. https:/‚Ä¶
659828942770040800,Thu Oct 29 20:27:33 +0000 2015,@JSRosendahl thank you, sorry not enough bandwidth
659613621199110100,Thu Oct 29 06:11:56 +0000 2015,@JMoMort vanilla REST
659213836218560500,Wed Oct 28 03:43:20 +0000 2015,RT @deepselfie: Related to my existence I was pointed to this research paper on "How to Take a Good Selfie" https://t.co/WMPawLZ5R7
659190581588074500,Wed Oct 28 02:10:56 +0000 2015,@phelixlau it performs generally well often, but labels are very noisy. Humans are probably worse than 60% I'd guess.
659190436708286500,Wed Oct 28 02:10:21 +0000 2015,@ShellyFan my profile picture only got 58.6%, so not so strong :)
658914263361130500,Tue Oct 27 07:52:57 +0000 2015,@cr1901 similar thing happened to me too. I knew I was in a lot of trouble when doing "ls" gave "command ls not found"
658913944954757100,Tue Oct 27 07:51:41 +0000 2015,@mdreid interesting, good idea! Should get into habit of defensive permissions.
658913786783383600,Tue Oct 27 07:51:03 +0000 2015,Still better than a poor student few days ago who wanted "rm *.txt" in her project folder but accidentally slipped in a space. One char.
658913251414011900,Tue Oct 27 07:48:55 +0000 2015,I accidentally opened my dataset file with 'w' instead of 'r', which erased everything. This is why you don't code when tired. One char.
658882741287587800,Tue Oct 27 05:47:41 +0000 2015,There are apps that automatically post on your friends' walls when it's their birthday. And apps that automatically reply to it. Great.
658834050044440600,Tue Oct 27 02:34:12 +0000 2015,@korirotti hahaha wow :) thanks for link! :)
658568782747594800,Mon Oct 26 09:00:08 +0000 2015,Interesting set of videos on a first contact with stone age tribe https://t.co/6fw1wI1CCZ matches, mirrors, recorders. Interest reactions
658501192838869000,Mon Oct 26 04:31:33 +0000 2015,@whereisravi sounds like you've described Generative Adversarial Nets ;) https://t.co/D2ogaPKFRs
658501192838869000,Mon Oct 26 04:31:33 +0000 2015,@whereisravi sounds like you've described Generative Adversarial Nets ;) https://t.co/D2ogaPKFRs
658483573482090500,Mon Oct 26 03:21:32 +0000 2015,@bitpixi @hunterwalk I went back through my code (worked on this few months ago), and realized I remembered wrong how was separated. Fixed.
658477590907252700,Mon Oct 26 02:57:46 +0000 2015,@hunterwalk @bitpixi possible, though not clear. There's some discussion of these subtleties in comments already.
658475812304216000,Mon Oct 26 02:50:42 +0000 2015,@hunterwalk @bitpixi ConvNets just follow the signal. If it were there, it's a reflection of broad statistical patterns present in the data.
658433509694943200,Mon Oct 26 00:02:36 +0000 2015,@EricZeiberg haha interesting :)
658430284640030700,Sun Oct 25 23:49:47 +0000 2015,Haha someone is trying to design a good selfie with help of the selfie bot  https://t.co/FRHfGYdxkD not sure if working :)
658392177249116200,Sun Oct 25 21:18:22 +0000 2015,@aparrish thank you, good point, didn't think this through. fixing.
658372682581323800,Sun Oct 25 20:00:54 +0000 2015,@EricZeiberg there's a lot of different code all over the place - scraping/analysis/bot, many quick scripts. Not one nice codebase
658367079788052500,Sun Oct 25 19:38:38 +0000 2015,@jugander agreed, it seems to me that people are more likely to "Like" a selfie when  perceived effort is higher
658362156744732700,Sun Oct 25 19:19:04 +0000 2015,New blog post: "What a Deep Neural Network thinks about your #selfie" https://t.co/dYOlALiclp this one was fun :)
658223565372690400,Sun Oct 25 10:08:21 +0000 2015,@deepselfie Hey Selfie Bot, how are you, I'm fine thanks. What do you think about my profile picture? https://t.co/hEjXcB529G
658181326265184300,Sun Oct 25 07:20:31 +0000 2015,RT @mdreid: @karpathy Time to run an RNN on your .bash_history then let it loose as root. ;)
658181302760280000,Sun Oct 25 07:20:25 +0000 2015,@mdreid hahahah wow, that is the scariest thing I've heard in a while. "RNN roulette"
658178353447305200,Sun Oct 25 07:08:42 +0000 2015,Except when you zoom in at the commands and it's revealed that a good chunk of it is "cd" and "ls" &gt;.&lt;
658178229425930200,Sun Oct 25 07:08:12 +0000 2015,Typing commands quickly into screen full of consoles and with music playing has still not worn off on me. I feel like such a 1337 h4xz0r
657991959177400300,Sat Oct 24 18:48:02 +0000 2015,@tanner_swett thanks, this is really interesting! Plenty of space for more debugging along similar lines.
657991838918275100,Sat Oct 24 18:47:33 +0000 2015,RT @tanner_swett: @karpathy Trained char-rnn on words repeated twice; I found the results pretty interesting. https://t.co/MgGqBjqaB1
657633349226336300,Fri Oct 23 19:03:03 +0000 2015,Nice video explaining my earlier RNN blog post. From a YouTube series of "two minute papers" https://t.co/pJA87QVu95 https://t.co/oJ8x056GRD
657248695658811400,Thu Oct 22 17:34:34 +0000 2015,@agent_cooper well it's 2012 technology. In their case I'd probably go with InceptionNet
657090317749891100,Thu Oct 22 07:05:14 +0000 2015,My dream finally came true: Yelp has discovered ConvNets https://t.co/NoZoNhKY5A So much value for so little cost. Strangely using AlexNets
656386925989752800,Tue Oct 20 08:30:12 +0000 2015,@poolio what the... how was I not following you. I swear Twitter has some kind of a bug that randomly unfollows a person every month.
656365101109264400,Tue Oct 20 07:03:29 +0000 2015,RT @chrmanning: Embarrassing, but you can now watch my ACL 2015 Presidential Address online: https://t.co/91zOFbJkXz [need Flash!] https://‚Ä¶
656308582401491000,Tue Oct 20 03:18:54 +0000 2015,@vcjha great to hear :) doubt I have the bandwidth unfortunately, but good luck with the competition!
656171980803039200,Mon Oct 19 18:16:05 +0000 2015,RT @sedielem: Here's how you compress VGG16 down to 11MB without accuracy loss http://t.co/tQN6kpHaQr
655902901169066000,Mon Oct 19 00:26:52 +0000 2015,@mdreid more like 17 minutes :)
655884550111821800,Sun Oct 18 23:13:57 +0000 2015,You sketch out a fun model on board and it's just blobs and arrows. 3 weeks later you're 12,000 lines of code in and wondering what happened
655276997766160400,Sat Oct 17 06:59:45 +0000 2015,@hardmaru i mention that in the notes, my preferred way to handle that is with explicit if statement for that case, to not distort relerrors
654897341304991700,Fri Oct 16 05:51:08 +0000 2015,Seemed to me like movie creators also didn't "get it", had simple fun with Steve Jobs character &amp; its perceived quirks
654896360181776400,Fri Oct 16 05:47:14 +0000 2015,Saw new Steve Jobs movie; Really not fan of casting, the personality/way of speaking seemed all wrong. Mix of few fun, mostly tedious scenes
654895358414184400,Fri Oct 16 05:43:15 +0000 2015,@manuchopra42 :O so jelly
654807376306946000,Thu Oct 15 23:53:38 +0000 2015,@mappingbabel @textfiles unfortunately not, most gpu rigs for rent are in cloud, also the specs for gaming/AI would be differently optimized
654750729861656600,Thu Oct 15 20:08:33 +0000 2015,@florianlaws no, at scale compared to others who are in loop mostly in research setting (Mercedes isn't in loop, they ship a fixed product).
654740333025099800,Thu Oct 15 19:27:14 +0000 2015,Iteration loop (data gathering, analysis, tweaking) critical for progress. Tesla not first w autonomous features, but first in loop at scale
654490702563246100,Thu Oct 15 02:55:17 +0000 2015,Another nicer video of Tesla Autopilot https://t.co/5m2ZXrrVC9 I'm trying to find more but there seem to be very few out there so far
654485353772875800,Thu Oct 15 02:34:02 +0000 2015,Tesla takes the wheel: driving a Model S hands-free http://t.co/oYeZ7nxiDt v cool that they pushed it out &amp; over air! It's slowly happening
654460142658805800,Thu Oct 15 00:53:51 +0000 2015,I've seen incorrect code gradcheck, correct code not gradcheck, I've seen code sometimes gradcheck. Certain I haven't seen it all.
654459786059083800,Thu Oct 15 00:52:26 +0000 2015,Gradient checking neural nets is hard, with many amusing subtleties. Updated my cs231n section on it; Now quite long http://t.co/JlEv0QB9FO
654069428959625200,Tue Oct 13 23:01:18 +0000 2015,My new iPhone 6S+ arrived today. Carrying around a 6+/6S+ sandwich in my pocket today. Quite enjoying live photos, they are fun to play with
654012091926380500,Tue Oct 13 19:13:28 +0000 2015,RE @deathbullet, to power a TitanX overnight need 8MJ ~= 100 ng of mass. 1 grain of sand = 1mg so need ~1/10,000 grain of sand of antimatter
653998552255852500,Tue Oct 13 18:19:40 +0000 2015,"This should drive market value of useless journalism down to zero, forcing other producers of useless journalism to produce something else"
653998387604254700,Tue Oct 13 18:19:00 +0000 2015,Very entertaining post on Auto-Generating Clickbait with RNNs http://t.co/rWg39DpEVA "Kim Kardashian Is Married With A Baby In New Mexico"
653997566334365700,Tue Oct 13 18:15:45 +0000 2015,@shazow :O so much GPU runtime RIGHT THERE. :D:D
653995673684062200,Tue Oct 13 18:08:13 +0000 2015,Impressed with quality of OpenFace code release  https://t.co/cMq1B9T2X8, Python/Torch implementation FaceNet paper. Raising the bar
653993819147366400,Tue Oct 13 18:00:51 +0000 2015,TitanX runs at ~200W (0.72MJ/h). In ~12h that's ~8MJ. Energy content of wood is 20MJ/kg, so running 1 TitanX overnight burns 1 pound of wood
653828114506604500,Tue Oct 13 07:02:24 +0000 2015,(Now reading over other people's reviews of the book, which is usually even more fun than the book is.)
653827949565644800,Tue Oct 13 07:01:45 +0000 2015,Finished reading "Why Nations Fail" as part of Mark Zuckerberg's book club :) Good read, interesting topic. More  https://t.co/qZJHyMNWNw
653630090526363600,Mon Oct 12 17:55:32 +0000 2015,UPS woes continue. They claim my package will be delivered 3-7pm today, I get an email at 9am saying they are "sorry they missed me". Really
653628573002035200,Mon Oct 12 17:49:30 +0000 2015,RT @thoughtbacon: I wrote about what happened when I played with @karpathy RNN sample code! Crazy fun!. https://t.co/7AjibGBk7X
653627845617422300,Mon Oct 12 17:46:36 +0000 2015,@ronvohra go ahead of course. sometimes i display work from other papers so you'd cite those.
653488367229780000,Mon Oct 12 08:32:22 +0000 2015,@iburago Depends too much on what you want. i7 5730 for multiple GPUs, have more PCIes. 32GB+, no need for ECC. Solid state drive
653297504767733800,Sun Oct 11 19:53:57 +0000 2015,@JaniKarh holy crap my validation for the updated binary finally passed. That was the least fun I had in a very long time :)
653289408100065300,Sun Oct 11 19:21:47 +0000 2015,Also had to re-figure out the app submission process, and as in 2011, some random blog with 10 steps MUCH better than Apple official guide
653288695567532000,Sun Oct 11 19:18:57 +0000 2015,iOS9 broke an app I put on app store in 2011, resubmitting it turning out to be nightmare- too many new backwards incompatible requirements
653054926478667800,Sun Oct 11 03:50:02 +0000 2015,@ShellyFan well it's coming from IBM, so there's your clue :)
652911496373006300,Sat Oct 10 18:20:05 +0000 2015,Except the FB comments sections which were meant for discussions of each book in the club are an amusing, complete failure.
652908802971320300,Sat Oct 10 18:09:23 +0000 2015,Zuck's "A Year of Books" book club is a nice source for reading material suggestions https://t.co/zdskSuZIy8
652555646886240300,Fri Oct 09 18:46:04 +0000 2015,@ShellyFan I don't often hear that term. Better than what? Hard to list problems with something so general in scope
651991937155657700,Thu Oct 08 05:26:05 +0000 2015,@dragonaire thank you! Yep, i like physical analogies - prefer thinking of training NNs as push/pull struggles than optimization landscapes.
651522554440450000,Tue Oct 06 22:20:56 +0000 2015,Optimizing 3x3 CONV with Winograd‚Äôs minimal filtering alg, speeds up VGG ConvNet by 2.6x http://t.co/6d5NbrOO4h Like.
651102543741784000,Mon Oct 05 18:31:57 +0000 2015,Preparing a talk for NVIDIA @ Stanford event on Wednesday https://t.co/DTvNm4BvZZ looks like a great event if you're around Stanford campus!
650565972047233000,Sun Oct 04 06:59:49 +0000 2015,@chanian haha not this time luckily. Nor did I see anyone make poop this time, just out there on street in broad daylight.
650565488360079400,Sun Oct 04 06:57:54 +0000 2015,Today one guy yelled in Spanish at me with threatening gestures and later three people in masks stared at me as I walked by.
650565377215230000,Sun Oct 04 06:57:27 +0000 2015,Almost every time I go to SF there's at least one moment where I think I'm about to get mugged or killed. Lovely city.
650535382832943100,Sun Oct 04 04:58:16 +0000 2015,Saw The Martian. Did not disappoint, really enjoyed. Stayed close to book except skipped few of my fave parts (dust storm with no comms etc)
650429591081738200,Sat Oct 03 21:57:53 +0000 2015,Very nicely done @yoavgo: A Primer on Neural Network Models for Natural Language Processing http://t.co/M7sHVFPr6c
649712167873155100,Thu Oct 01 22:27:06 +0000 2015,@karoly_zsolnai that's weird, I thought I copied it correctly. It's http://t.co/vloTAxaMY5
649711090503323600,Thu Oct 01 22:22:49 +0000 2015,Normally you'd put LSTM on top of ConvNets, but interesting to make all units in ConvNet recurrent. Also for video processing avoids 4D conv
649709916559507500,Thu Oct 01 22:18:09 +0000 2015,Grasp detection Kaggle winner with Recurrent ConvNets http://t.co/JJVc325uha I missed their cvpr paper (http://t.co/iHmUVrpmU5) looks neat
649640414215999500,Thu Oct 01 17:41:59 +0000 2015,@abursuc Decided nothing good exists. Tried to implement my own but got stuck- arxiv PDFs don't include title/author metadata
649347118130270200,Wed Sep 30 22:16:31 +0000 2015,@ShellyFan I was invited and rejected it because i wasn't sure what it was. haven't looked into list of speakers or program
649345694688346100,Wed Sep 30 22:10:52 +0000 2015,@ShellyFan I think I recall something about it. Don't think I'm going, sounds like some kind of hype hype hype + recruitment event?
649249346060353500,Wed Sep 30 15:48:01 +0000 2015,Cool class at Stanford on CS+Social Good http://t.co/ZNmxQjtann taught by @manuchopra42 &amp; @LawLM wish were standard class in most cs depts
649247201290391600,Wed Sep 30 15:39:29 +0000 2015,@breuderink It's tricky to make good comparisons, but this is not a bad idea. Nothing available right now, but you're free to run it
648970260436029400,Tue Sep 29 21:19:02 +0000 2015,RT @AndrewYNg: New blog post on how to accelerate RNNs (recurrent neural nets) using GPUs! http://t.co/hDz9nMj86u
648943962372177900,Tue Sep 29 19:34:32 +0000 2015,RT @DanielRapp: Learning game of life with #ConvNetJS! Radical! @karpathy  http://t.co/p6rHslpWZc http://t.co/xhlJRAoxYu
648625139714621400,Mon Sep 28 22:27:38 +0000 2015,@mappingbabel :'(
648624454835138600,Mon Sep 28 22:24:55 +0000 2015,I'm jealous. Wasn't this supposed to happen somewhere around here first?
648623349891928000,Mon Sep 28 22:20:32 +0000 2015,This fall Netherlands will have electric driverless shuttles going about on public roads http://t.co/Zw55F3vzRP well, that was fast
648588133194305500,Mon Sep 28 20:00:35 +0000 2015,@bryankramer Hi sorry, I don't think I'll be able to make it. Thank you for the invitation!
648349643672170500,Mon Sep 28 04:12:55 +0000 2015,@MarkTrovinger of course :)
648263066304446500,Sun Sep 27 22:28:53 +0000 2015,@sedielem yeah. Are the lanes a bottleneck in your experience? Did you try running things on 4 or 8 lanes? Haven't seem much written about
648259948233691100,Sun Sep 27 22:16:30 +0000 2015,@sedielem Yeah :( I only have 1 TitanX right now, with longer term plans to insert more over time. Will need to upgrade CPU. And probly PSU
648256986438504400,Sun Sep 27 22:04:44 +0000 2015,Happy with the spec. Esp. the Acer XB270HU monitor. It's 144Hz 27" IPS monitor 4ms response, with G-sync. It's very very nice
648256662554341400,Sun Sep 27 22:03:27 +0000 2015,Several ppl asked for my gaming/deep learning rig build. Here's the part picker spec I used: https://t.co/6s5T4VlVnY
647955049704898600,Sun Sep 27 02:04:56 +0000 2015,@AlecRad bleh yeah I was kind of worried about that... :)
647954404440576000,Sun Sep 27 02:02:23 +0000 2015,@Pawelotti boo laptop :) I think so - I'll build up to 4 slowly; Once I pop in second I'll SLI
647953322805035000,Sun Sep 27 01:58:05 +0000 2015,Assembling new Monster gaming/deep learning rig at home. Space for 3 more TitanX :p time to check if I can run Crysis http://t.co/5gz2tnEpWV
647610204960329700,Sat Sep 26 03:14:39 +0000 2015,@frankchn nope, just new computer parts. but iphone too, soon :)
647605881203396600,Sat Sep 26 02:57:28 +0000 2015,It's 2015 and the best UPS can do is to predict delivery within 4 hour window, and they also get it wrong by 1+ hours.
647605607772500000,Sat Sep 26 02:56:23 +0000 2015,UPS package that needs signature was supposed to arrive 3-7pm. Now 8pm and nothing. How can they expect ppl to be home for such wide ranges
647589001046548500,Sat Sep 26 01:50:24 +0000 2015,Black Mirror revived by Netflix for 12 new episodes http://t.co/NfYgk2nvLw yesyesyes can't wait!
646411045850890200,Tue Sep 22 19:49:37 +0000 2015,@kastnerkyle there aren't good ones, no. It's kind of a maybe target for a blog post that's been on my mind. Except then got distracted
646390163824881700,Tue Sep 22 18:26:39 +0000 2015,Recurrent Model of Visual Attention in Torch http://t.co/XOSdk5ZMsZ Doesn't quite convey how simple REINFORCE update is, but nice post
646293051502039000,Tue Sep 22 12:00:45 +0000 2015,@janexwang :) of course, but for the rest of us with smaller brains there should be something. Doesn't seem like it.
646131858745352200,Tue Sep 22 01:20:14 +0000 2015,Does anyone have an effective solution for keeping track of papers? E.g. Mendeley but something better, preferably web-based, open source?
645920848667258900,Mon Sep 21 11:21:45 +0000 2015,4am. Judging by the absolute silence and darkness I think I am first at work on this fine first day of the quarter. (still on London time..)
645644808149581800,Sun Sep 20 17:04:52 +0000 2015,@pfau probably very well, the dependencies here are very short
645630999166980100,Sun Sep 20 16:10:00 +0000 2015,Some of my favorites include "Baby" (haha), "Killie", "Char", "R", "More", "Mars", "Hi", "Saddie", "With" and "Ahbort". Well that was fun.
645630892010942500,Sun Sep 20 16:09:34 +0000 2015,I was curious if char-rnn can generate new plausible baby names. Got 8K, trained 3layer LSTM, and it works :)  https://t.co/mw9mPGm1it
645367807027228700,Sat Sep 19 22:44:10 +0000 2015,The sky has not a trace of cloud. And I'm back to counting Teslas on the highway. Can't wait to ride my bike again #thelittlethings
645366862574817300,Sat Sep 19 22:40:25 +0000 2015,Back in the land of the free and the home of the brave!  Almost forgot how nice/sunny/warm California is - was rained on in London yesterday
644816755576184800,Fri Sep 18 10:14:29 +0000 2015,RT @Inquisitivists: AutoHarp algorithmic music generator + char-rnn == drum loops. http://t.co/iOKPe4i88s. Strong work, @karpathy
644508475419164700,Thu Sep 17 13:49:29 +0000 2015,"I created a fake business and bought it an amazing online reputation" http://t.co/sYOBKMvQJ3 sad reading. Machine Learning fail
644262876962648000,Wed Sep 16 21:33:34 +0000 2015,RT @j26774: #NeuralStyle now lets you blend multiple artistic styles! #stylenet http://t.co/ydX7davLn8
643922773400809500,Tue Sep 15 23:02:07 +0000 2015,Yummy data! Microsoft Academic Search was awesome API resource until it was taken down a few months ago https://t.co/1VdaFv3a76
643830917891493900,Tue Sep 15 16:57:07 +0000 2015,HUMAN (3 Volumes, 1:30min each) on YouTube https://t.co/UzrNJ5PMeU ; compiled from 2,000 interviews in 60 countries. Looks interesting
643736577592700900,Tue Sep 15 10:42:14 +0000 2015,Our World In Data http://t.co/lp2lnQd2I6 by @MaxCRoser ; Nice visualizations of global trends in poverty/violence/health/education etc.
643735574193532900,Tue Sep 15 10:38:15 +0000 2015,Faster R-CNN (state of the art object detection) on Github https://t.co/0JmQxXLCep runs at 200ms/image. arXiv paper: http://t.co/0qlL9j4aP9
643201477046075400,Sun Sep 13 23:15:56 +0000 2015,Blizzard‚Äôs Final Starcraft II Expansion Lands November 10 http://t.co/QQriKyaSpX **deep breaths**. The game trailer is Blizzard good
642763738949533700,Sat Sep 12 18:16:31 +0000 2015,Most people find this surprising but the mass of trees mostly comes from air not soil (carbon in CO_2 specifically) http://t.co/UDoLJp5s8X
642506349801246700,Sat Sep 12 01:13:45 +0000 2015,"Uber Would Like to Buy Your Robotics Department", nice article on the CMU exodus http://t.co/meoRm23YzT
642487177759342600,Fri Sep 11 23:57:34 +0000 2015,Video from a talk I gave yesterday on "Recurrent Neural Network Escapades" at @deeplearningldn meetup is up https://t.co/73X1vnMs8e
642281190901305300,Fri Sep 11 10:19:03 +0000 2015,@samim There were several ppl involved (not including me for most of it), TED talks are a whole and long  design process with entire teams
642278236915933200,Fri Sep 11 10:07:19 +0000 2015,@samim have you looked at Nervana's neon image captioning demo released few days ago? It's much faster, maybe also works better.
642277919134494700,Fri Sep 11 10:06:03 +0000 2015,(My NeuralTalk is not near state-of-the-art captioner, several more fancy / better engineered models exist, maybe not open source though)
642277369525481500,Fri Sep 11 10:03:52 +0000 2015,NeuralTalk Image Captioning run over videos with some fun results. A post:  https://t.co/STjrTZfOCa &amp; video: https://t.co/HYiqwkaH5X
641546347351547900,Wed Sep 09 09:39:03 +0000 2015,Nervana updated their neon Deep Learning framework https://t.co/alLUJiANo7 , also includes Image Captioning demo 200x faster than NeuralTalk
641304623572209700,Tue Sep 08 17:38:31 +0000 2015,Spatial Transformers are very nice, I expect them to become quite commonly used with ConvNets http://t.co/hO6y85Htkp
641304115490984000,Tue Sep 08 17:36:30 +0000 2015,Achieving state of the art in traffic sign recognition with Spatial Transformers and simpler model/pipeline http://t.co/1CXWt9yPWj
641256311980728300,Tue Sep 08 14:26:33 +0000 2015,RT @TlkngMchns: Help promote leaning about #MachineLearning! We can't make season two without your help. http://t.co/aqrWU2kK4i
641185160600404000,Tue Sep 08 09:43:49 +0000 2015,@samim style weight should be stronger probably. Also base style image might not have strong enough textures
641183869249654800,Tue Sep 08 09:38:41 +0000 2015,@logicbehind Haven't worked with Windows in ages (except for dual booting into it sometimes to play a game); No idea, sorry
640837739366252500,Mon Sep 07 10:43:17 +0000 2015,RT @alexip: New post: Topic Modeling of my Twitter Followers.  http://t.co/TmMLc68K0f #LDA #Gensim #NLP #DataScience #python
640612749005979600,Sun Sep 06 19:49:16 +0000 2015,@shazow tried it; way too slow/melancholic for me :) I require very loud beats to induce hacking spree.
640611229577412600,Sun Sep 06 19:43:13 +0000 2015,@teagermylk Thanks for invite; I have 3 talks scheduled for this week so I'll take it slow outside of those :\ Schedule/links look good!
640588671704518700,Sun Sep 06 18:13:35 +0000 2015,@deathbullet too personal ;)
640585490790543400,Sun Sep 06 18:00:57 +0000 2015,I ruined a really good song yesterday. Listened to it on loop while coding, and today I feel nothing. I've squeezed it out. very sad.
640585257704661000,Sun Sep 06 18:00:01 +0000 2015,Trying to debug psychology of liking songs. My enjoyment usually starts at ~10%, peaks at 100% after ~10 listens then decays to 1% after ~50
640581033105223700,Sun Sep 06 17:43:14 +0000 2015,PetBot - lovely device created by an undergrad friend https://t.co/c8wICl4tVd ConvNets detect your pet, take petselfies. Dispenses treats :)
640228464960868400,Sat Sep 05 18:22:15 +0000 2015,RT @jeremyphoward: Madoko ‚Äì Write full-blown academic articles in Markdown https://t.co/vETOsZzdHZ (&amp; lots of other interesting options in ‚Ä¶
640190440612958200,Sat Sep 05 15:51:09 +0000 2015,@honnibal Thanks! Berlin would be awesome but I doubt there's time, I'm traveling back to Stanford in a bit. Another time :)
640098689894232000,Sat Sep 05 09:46:34 +0000 2015,"Dead Code Should be Buried" http://t.co/AxfZRRz8nB by @honnibal on NLP tools &amp; new Python library spaCy http://t.co/C9f798R3aO looks nice!
639943678488936400,Fri Sep 04 23:30:37 +0000 2015,I spend more time browsing Netflix than watching Netflix
639937510731182100,Fri Sep 04 23:06:06 +0000 2015,@janexwang I'm going to favorite your tweets some of the time, seeing as stochastic reward signal is more addicting
639446941152202800,Thu Sep 03 14:36:45 +0000 2015,@t3kcit quite long, seeing as it takes 5 minutes on a high end GPU
639423792276721700,Thu Sep 03 13:04:46 +0000 2015,Found that channel from this awesome Reddit thread https://t.co/6no7crQHUa , subbed to almost 10 new YouTube channels
639421524764663800,Thu Sep 03 12:55:46 +0000 2015,"Primitive Technology" YouTube channel https://t.co/MMnKA8Vko5 Fascinating. Someone is living a real-life Minecraft
639153548186550300,Wed Sep 02 19:10:55 +0000 2015,@mwakanosya absolutely no idea. Maybe something wrong with data preprocessing? Not clear at all, I rarely ever see stuff like it
639147180696207400,Wed Sep 02 18:45:37 +0000 2015,This Preschool Is for Robots http://t.co/sYw9QQywPF, @mappingbabel's article on Berkeley PR2 robot manipulation learning +Fun embedded video
639137865671278600,Wed Sep 02 18:08:36 +0000 2015,@mwakanosya In fact, do you mind if I include that loss function on http://t.co/1Dy8entusH ? It looks very funny
639137744975982600,Wed Sep 02 18:08:07 +0000 2015,@mwakanosya :) nice. Wonder what happened with the loss there, that is very rare and strange. Definitely not working as intended, haha
639137622368104400,Wed Sep 02 18:07:38 +0000 2015,RT @mwakanosya: Find your Dream Job! | Recurrent Neural Net learns http://t.co/Pfz9uNObT2 Job Postings | @karpathy | http://t.co/pSz0SKSMyW
638871721567780900,Wed Sep 02 00:31:02 +0000 2015,Mocha.jl: Deep Learning for Julia http://t.co/PcYqPNby6h I might just give this a try; Torch/lua is quickly becoming too mainstream
638745472048492500,Tue Sep 01 16:09:22 +0000 2015,@CharlesOllion @syhw @ogrisel hmm that's not right :)
638735163220992000,Tue Sep 01 15:28:24 +0000 2015,@amiconfusediam @j26774 yeah both look "off" to me
638729464705380400,Tue Sep 01 15:05:46 +0000 2015,A nice implementation from @j26774 of neural style https://t.co/LTaGwCP03Q , with VGGNet. Looks almost there
638453390591283200,Mon Aug 31 20:48:44 +0000 2015,RT @drfeifei: This Girls‚Äô Summer Camp Could Help Change the World of AI http://t.co/7GNZzRg2TS via @WIRED @SAILORS
638365139109068800,Mon Aug 31 14:58:04 +0000 2015,Kai Sheng's Torch7 implementation of 'A Neural Algorithm of Artistic Style' https://t.co/cVr2us9e1g seems to work nicely! sometimes :)
638125262677405700,Sun Aug 30 23:04:53 +0000 2015,@phanosd if it must run in browser then perhaps. Otherwise it's for the most part an educational/fun tool.
638122797332607000,Sun Aug 30 22:55:05 +0000 2015,Gill Pratt (PM @ DAPRA) on "Is a Cambrian Explosion Coming for  Robotics?" http://t.co/K9k1LJsDTJ [pdf] about trends in robotics
638117832031641600,Sun Aug 30 22:35:21 +0000 2015,ConvNet benchmarks update https://t.co/I7ybKooIQd CuDNN R3 is catching up to Nervana's kernels &amp; FFT conv becoming competitive with spatial
637740568181874700,Sat Aug 29 21:36:14 +0000 2015,@yoavgo interesting :) I thought the prev one was too abstract, to point where it was hard to recognize him.
637738452545609700,Sat Aug 29 21:27:50 +0000 2015,@kidnamedcory amazing! Which alg is it? Are there any details anywhere?
637619002676768800,Sat Aug 29 13:33:11 +0000 2015,@arnicas @kcimc of course, it's from YiChang, he's an MIT friend. It's nice work, I wonder if I can reproduce similar results with this
637580461301235700,Sat Aug 29 11:00:02 +0000 2015,@kcimc I played a tiny bit with it and liked max pool results slightly better, seemed more abstract. Have to crossval this better
637439168029790200,Sat Aug 29 01:38:35 +0000 2015,@CaldenWloka haha. which one is your favorite?
637438825502015500,Sat Aug 29 01:37:13 +0000 2015,@CaldenWloka single image.
637416924478087200,Sat Aug 29 00:10:12 +0000 2015,@crude2refined @EmWatson wow pollock textures are nice!
637411799827152900,Fri Aug 28 23:49:50 +0000 2015,@janexwang oh hey Jane! The next one will be quite something, at iteration 800/2000 I can already tell
637404571497820200,Fri Aug 28 23:21:06 +0000 2015,@dribnet yep, 19layer VGG, most things are as in paper.
637399418711486500,Fri Aug 28 23:00:38 +0000 2015,@samim haha yes a lot of possibilities here. I want this code to be released of course, but it's not only up to me and will be tricky.
637272151628881900,Fri Aug 28 14:34:55 +0000 2015,@DataRaccoon character-level models are kind of unsupervised learning, there are no explicit annotations. Not a big fan of the term
637254768080093200,Fri Aug 28 13:25:50 +0000 2015,@AlecRad @Luke_Metz beautiful specimen, can I include this on http://t.co/1Dy8entusH ? :)
637254603239768000,Fri Aug 28 13:25:11 +0000 2015,@AlecRad @kastnerkyle your generated album/faces also look nice&amp;sharp, I assume it's a similar Gram matrix matching idea?
637231518960717800,Fri Aug 28 11:53:27 +0000 2015,Last video I'll share on this topic, a 10min interview with the Real Virtuality ppl https://t.co/Xj85hMEn32 staggeringly cool
637229159345979400,Fri Aug 28 11:44:05 +0000 2015,Related links thx reddit: The Void https://t.co/ecfXHDuWMV and Zero Latency https://t.co/DdQ3KuJtRN "Future arcades will be awesome."
637227946361516000,Fri Aug 28 11:39:16 +0000 2015,Real Virtuality is a multi-user immersive platform combining motion capture with VR headsets http://t.co/b2btvztlre very cool videos
637091584249602000,Fri Aug 28 02:37:24 +0000 2015,@WBreadenMadden ha! I wish :) thanks!
636978777613070300,Thu Aug 27 19:09:09 +0000 2015,tbh I'm somewhat stunned by how well it seems to work. I can kind of see how that loss would do something like it, but not this well
636974535431057400,Thu Aug 27 18:52:18 +0000 2015,Whoa, very nice stylized images rendered with ConvNets http://t.co/AUrIMdtse7 needs its own subreddit http://t.co/JcGIztlOCO
636545228862791700,Wed Aug 26 14:26:23 +0000 2015,The Uber endgame: privatized public transit http://t.co/4dueE7vt0Q very interesting trends to watch
636217781990596600,Tue Aug 25 16:45:14 +0000 2015,Yangqing is also trimming/refactoring Caffe; See caffe2 on Github https://t.co/jvhnIeg44N + slides http://t.co/h5e6p1JFhh
636193323502465000,Tue Aug 25 15:08:02 +0000 2015,Worth checking out new Deep Learning library for Python "CGT replicates Theano's API but has very short compile time" http://t.co/x2gY0MVLFT
635898287644614700,Mon Aug 24 19:35:40 +0000 2015,@IgorCarron thanks for the invite! I was only able to afford a brief Touristy appearance over weekend, making it back unfortunately unlikely
635896868975812600,Mon Aug 24 19:30:02 +0000 2015,@zoyathinks who are you and what have you done with Zoya
635896615685988400,Mon Aug 24 19:29:02 +0000 2015,@DirkGor oh neat! I'm in London until 18 Sept, but schedule is already looking worryingly crowded
635891466225721300,Mon Aug 24 19:08:34 +0000 2015,Preparing a 30 min talk for @ds_ldn tomorrow evening. Currently at 110 slides and estimated ~70 minutes. I'm in a pickle!
635808370654617600,Mon Aug 24 13:38:22 +0000 2015,@tanner_swett See Alex Graves' paper he uses a 7layer net on Wikipedia. When you go deep it becomes important to init well. Must be careful
635795416513179600,Mon Aug 24 12:46:54 +0000 2015,@krasul Berlin would have been very very nice but doubt there will be time. Bleh! :)
635791382804865000,Mon Aug 24 12:30:52 +0000 2015,Visited Paris over the weekend. Nice trip except noticed prevalent tourist harassment near famous sites, e.g. forceful selling, various cons
635767554963828700,Mon Aug 24 10:56:11 +0000 2015,@tanner_swett have you read the Readme of the library? E.g. I mention you shouldn't have to use more than 2 or 3 layers.
634103675603013600,Wed Aug 19 20:44:31 +0000 2015,@ShellyFan didn't go (i wish!) , that would be a long trip. Haven't heard of it, but it's from Gordon's lab - friend from UBC.
634042314248298500,Wed Aug 19 16:40:42 +0000 2015,RT @cragcrest: My months-long obsession. Science isn't broken. It's just really fucking hard. http://t.co/WljU0ffJJz w/@RitchieSKing http:/‚Ä¶
633950190433603600,Wed Aug 19 10:34:38 +0000 2015,@askirilov No, I think I used 100, but it's easy to play with. Not sure &gt;100 would improve a lot because there's a lot to model even &lt;100.
633617988797734900,Tue Aug 18 12:34:35 +0000 2015,@sithankanna are you coming to the meetup? Free to chat broef;y before/after my talk
633293772663689200,Mon Aug 17 15:06:16 +0000 2015,I'm starting a new Tumblr on loss functions http://t.co/1Dy8entusH for those of us who stare at them all day. Contributions welcome :)
633213681074106400,Mon Aug 17 09:48:00 +0000 2015,RT @stanfordnlp: All slides from Montreal Deep Learning Summer School available at https://t.co/4qExVswwiK. 9 hours of #nlproc, 3 by @chrma‚Ä¶
632972249012813800,Sun Aug 16 17:48:38 +0000 2015,@karpathy lol spelled this as glympse, finger memory confused by the app glympse. I know it's spelled glimpse :) lol bleh
632880503742447600,Sun Aug 16 11:44:05 +0000 2015,Making Robots https://t.co/thnBn2gcmp [1hr video] nice glympse into where robots are today
632286172530782200,Fri Aug 14 20:22:25 +0000 2015,Goldilocks zone for amount of water for my pet plant HashBang seems very narrow. I don't want to kill a plant but it's not doing well :(
632284628712312800,Fri Aug 14 20:16:17 +0000 2015,@ShellyFan yep, it is! London is very nice, just posted some pictures on fb
632125692327645200,Fri Aug 14 09:44:44 +0000 2015,@ShellyFan yep it just finished. I also started long ago&amp; gave up but then discovered podcast which was more easier/enjoyable to get through
631999225426018300,Fri Aug 14 01:22:11 +0000 2015,Also forgot to recommend Andy Weir's very short story "The Egg"   http://t.co/MPt2Q6TMCW
631994794064130000,Fri Aug 14 01:04:35 +0000 2015,Finished http://t.co/tvhWjtCAD5 I recommend podcast version. Very enjoyable, featuring Harry Potter as scientist/child prodigy. So good. 6/5
631514996283801600,Wed Aug 12 17:18:02 +0000 2015,A Peek into Einstein's Zurich Notebook http://t.co/BJpPWCqhX2 interesting read, glimpse into how theory of GR developed
631409024718798800,Wed Aug 12 10:16:57 +0000 2015,A comprehensive Kalman Filter textbook in format of IPython Notebook, on Github. Intriguing trend https://t.co/ZBBV26wEqQ
630743870691758100,Mon Aug 10 14:13:52 +0000 2015,Tobacco and sugar water are about the two most common worst things you can put in your body. Boggles the mind that people volunteer to
630742202180833300,Mon Aug 10 14:07:14 +0000 2015,Shady coca-cola backed "science". "10 teaspoons of sugar are not that bad if you just get your exercise!" sickening. http://t.co/5PF9VeM2NS
630381626967609300,Sun Aug 09 14:14:26 +0000 2015,RT @yvespeirsman: Since I can't seem to write a good novel, I used #DeepLearning to do it. Read more at http://t.co/0PzKW1KsNz, with thanks‚Ä¶
630170862294028300,Sun Aug 09 00:16:56 +0000 2015,RNNs generating classical music (blogpost+code) http://t.co/bbvwmkJ2qN nice and promising result here! neat
630170862294028300,Sun Aug 09 00:16:56 +0000 2015,RNNs generating classical music (blogpost+code) http://t.co/bbvwmkJ2qN nice and promising result here! neat
630127562707050500,Sat Aug 08 21:24:52 +0000 2015,@niru_m thought about it, but it's not common to gradcheck and it would be a lot of work :\ I touch on subject here http://t.co/JlEv0QSL4o
630118002273464300,Sat Aug 08 20:46:53 +0000 2015,@raidancampbell no, go ahead of course
630115519975309300,Sat Aug 08 20:37:01 +0000 2015,Gradient checking bigger nets is a subtle art. I've now seen ~10+ ways correct code may not gradcheck and 10 where incorrect code does
629687487242371100,Fri Aug 07 16:16:10 +0000 2015,"The Infinite Irish Trad Session" http://t.co/31r2kmIq1h infinite music generated with char-rnn by @boblsturm. +post https://t.co/L7elIcogJv
629686938069504000,Fri Aug 07 16:13:59 +0000 2015,@boblsturm Ah ok I missed the link. It blends in with the other 10 links and it's not obvious that's the most important one :) Nice!
629679718711840800,Fri Aug 07 15:45:18 +0000 2015,@boblsturm nice, are there samples of the results somewehre?
629034899073278000,Wed Aug 05 21:03:01 +0000 2015,@yigitdemirag hmm need much moar GPU memory/compute. Custom machines with hundreds of them, perhaps connected with infinibands etc.
628988108210630700,Wed Aug 05 17:57:05 +0000 2015,@dovgalec I used Bishop paper/book as reference. I think I use y instead of t, stuff like that. I just followed the main idea
628928525387444200,Wed Aug 05 14:00:20 +0000 2015,@ChrisBaldassano check out his AMA and also interview with Adam Savage on YouTube. Then read one of his favorites Ready Player One.
628703755899433000,Tue Aug 04 23:07:10 +0000 2015,@hardmaru Alex graves does in his handwriting RNN. It's in 2D so you can afford. Depends on data I suppose :\
628669997519347700,Tue Aug 04 20:53:02 +0000 2015,@hwassner zero additional cost, it's just a boring neural net as usual
628660891098181600,Tue Aug 04 20:16:51 +0000 2015,Was playing around with mixture density nets; They predict P(y|x) distributions. Wonder why not more commonly used https://t.co/depCTfkgMO
628319114994556900,Mon Aug 03 21:38:45 +0000 2015,@dijkstracula I know! That's like an integral part of the entertainment value of his articles :D
628317992540065800,Mon Aug 03 21:34:17 +0000 2015,Rob's posts always get the controversy going. Blog comment haters love him.
628317957559590900,Mon Aug 03 21:34:09 +0000 2015,"How I Gave Up Alternating Current" http://t.co/e7BCP6LF7d Rob (behind Soylent) on transitioning house to only use 100W from solar panel.
627965874243301400,Sun Aug 02 22:15:06 +0000 2015,@MasExMachina seriously? This is more readable than % notation? Lol
627956633549848600,Sun Aug 02 21:38:22 +0000 2015,@MasExMachina lol i accidentally tweeted to everyone. Anyway I really dislike str.format(). % is so much cleaner and superior
627945887566835700,Sun Aug 02 20:55:40 +0000 2015,@MasExMachina :'( I know. So sorry.
627941500182220800,Sun Aug 02 20:38:14 +0000 2015,Few tens of hours of coding from scratch &amp; I have the same functionality I had 3 days ago. But it's laid out nicer. 3rd rewrite. #codingocd
627830387738284000,Sun Aug 02 13:16:43 +0000 2015,RT @TorchML: We just started http://t.co/8a1dSL66vj . Will cover interesting stuff from the Torch community and have a wide range of guest ‚Ä¶
627440507174654000,Sat Aug 01 11:27:28 +0000 2015,A browser-based foreground/background segmenter neural net trained with convnetjs. Fun use case. http://t.co/xLMa2l3d4b
627126794232156200,Fri Jul 31 14:40:53 +0000 2015,@hardmaru can this be optimized to paint an arbitrary target image? Somewhat in style of http://t.co/zy2EuCsdUQ
626759062991020000,Thu Jul 30 14:19:39 +0000 2015,RT @mtyka: Fantastic work and blog post on #deepdream class visualization by  @matsiyatzy http://t.co/1ybNWufCDP ‚Ä¶  Saxophonist: http://t.c‚Ä¶
626539608990462000,Wed Jul 29 23:47:37 +0000 2015,@TheShubhanshu no idea you'll have to debug piece by piece with prints and stuff
626429221414563800,Wed Jul 29 16:28:59 +0000 2015,@iamtrask also fun story: Hinton tried ~long ago but forgot to scale (like you did) and thought it didnt work. Then later realized &amp; fixed
626428905147224000,Wed Jul 29 16:27:44 +0000 2015,@iamtrask np. I think you want is the inverted dropout formulation. Makes minimal change in your code, just make sure to divide in forw pass
626427895888642000,Wed Jul 29 16:23:43 +0000 2015,@iamtrask you also have to be careful to scale activations at time time or in train time (see Dropout section in http://t.co/zsww8XC8Tp)
626124598178902000,Tue Jul 28 20:18:31 +0000 2015,Stumbled by Reddit thread with 4K upvotes from 16 days ago about ppl using char-rnn to generate Hearstone cards https://t.co/UDbxiscGhi haha
626078555890389000,Tue Jul 28 17:15:34 +0000 2015,It's fun to watch the pretrained agents: PuckWorld agent scared of red circle, or WaterWorld agent skillfully navigating asteroid field
626077883287642100,Tue Jul 28 17:12:53 +0000 2015,Tweeted this while ago but I'll reshare REINFORCEjs http://t.co/tOKLCTp18U . Several fun Reinforcement Learning JS web demos I'm fond of :)
626047995100971000,Tue Jul 28 15:14:08 +0000 2015,@IlyaKava :) that you for writeup. Always nice to improve statistics of what works/doesn't work in real problems. Will improve cs231n notes
625985791521648600,Tue Jul 28 11:06:57 +0000 2015,Another nice trenches report from @IlyaKava on CNNs applied to Kaggle Diabetic Retinopathy challenge http://t.co/Wwprq1CreU very fun reads
625954312217305100,Tue Jul 28 09:01:52 +0000 2015,@mdreid I tried it and it didn't help. Can try yourself maybe I'm missing something
625840713318670300,Tue Jul 28 01:30:28 +0000 2015,Nice post! ConvNet application reports from the trenches :) https://t.co/fk0PdrkTCh
625677963363754000,Mon Jul 27 14:43:45 +0000 2015,Play GTA V in your browser, or on mobile http://t.co/YzBVUs7O8Y uses each as thin clients to server running game. Surprised about smoothness
625650468182708200,Mon Jul 27 12:54:30 +0000 2015,@mdreid great! If you can afford it, making hidden size bigger of course would work better. And then, you should really have LSTM instead ;)
625643634847805400,Mon Jul 27 12:27:21 +0000 2015,@mdreid try now, any better? I now clip gradients, made default h=100, and added Adagrad update. Seems more stable for me.
625625529757134800,Mon Jul 27 11:15:24 +0000 2015,I'm late to the party but very nice/detailed/practical (and long!) intro from @michael_nielsen to Deep Learning http://t.co/XqfK5745Ft
625614165118459900,Mon Jul 27 10:30:14 +0000 2015,@mdreid haha it's not crazy. Also 50 hiddens is very small too, and 20K iters is also very very small. I'll adjust hyperparams
625613273308774400,Mon Jul 27 10:26:42 +0000 2015,@mdreid I'll give it a go on some larger data as well to see if I can reproduce. It overfit my previous ~small dataset well
625613059508277200,Mon Jul 27 10:25:51 +0000 2015,@mdreid hah crap! Since it's using vanilla RNN, no RMSProp it is finicky with learning rate and decay. Needs precise adjustment I suspect
625414004723314700,Sun Jul 26 21:14:53 +0000 2015,For fun I wrote a minimal (but readable) char-rnn demo in Python/numpy. ~100 lines suffices (wish it was less...) https://t.co/mdbTQkYHbB
624519654392905700,Fri Jul 24 10:01:03 +0000 2015,@niksko :D:D
624159807424081900,Thu Jul 23 10:11:09 +0000 2015,Whoa a lot of opinions on "What do you think about machines that think?" over on Edge http://t.co/ctIHo1IPw7 will take while to read through
624143103570616300,Thu Jul 23 09:04:46 +0000 2015,RT @korbonits: New blog post inspired by @karpathy's char-rnn, wherein I train a neural network to generate Joycean prose, and more. http:/‚Ä¶
623973161676222500,Wed Jul 22 21:49:29 +0000 2015,Also, of interest is that Steven Spielberg signed on to direct Ready Player One's film adaptation, author will do screen play. Can't wait
623971399477108700,Wed Jul 22 21:42:29 +0000 2015,Finished "Ready Player One", warmly recommended! Stumbled by it when Andy Weir (author of The Martian) mentioned it as his favorite sci-fi
623586963497615400,Tue Jul 21 20:14:52 +0000 2015,@samim @mtyka I can neither confirm nor deny... :D
623225884657459200,Mon Jul 20 20:20:04 +0000 2015,Nice/fun intro to multi-armed bandit by Ian http://t.co/COPVTFZfla he's very new to blogging but doing it right :)
623071061454811100,Mon Jul 20 10:04:51 +0000 2015,@iandanforth of course. There's also a Harry Potter store right next to 9 3/4 where I get tempted from time to time to buy 100pound wands
623070452496379900,Mon Jul 20 10:02:26 +0000 2015,@kastnerkyle @AlecRad Hmm I'll try other than ReLU. Also I use BCE loss at pixels not MSE so far. Stride inverse conv for deconv works nice
622941356214890500,Mon Jul 20 01:29:27 +0000 2015,Oh and I forgot to report that ~2 weeks ago I visited Oxford. Made sure to visit ALL Harry Potter film set locations. Squeel  #QuestUK
622937918517157900,Mon Jul 20 01:15:48 +0000 2015,@gracevesom thx! Did museum already - was filled with statues of naked men instead of chubby baby angels. Sounds like you know London well!
622937130571067400,Mon Jul 20 01:12:40 +0000 2015,@dovgalec I don't know trees or vases or buildings or something. There are many objects and animals on this planet
622905785790636000,Sun Jul 19 23:08:07 +0000 2015,@minimumnz that's a fine idea. Though I suspect it will lead to similar tweet except replace chubby baby angels with abstract squiggles
622882910903906300,Sun Jul 19 21:37:13 +0000 2015,Visited London's National Gallery. Was nice at first, but 95% of paintings depict Jesus/Mary/Saint/chubby baby angels. Gets kinda old fast.
622768871087448000,Sun Jul 19 14:04:04 +0000 2015,@EricZeiberg can't remember. the validation performance? I think
622394903667077100,Sat Jul 18 13:18:03 +0000 2015,@nylk I'd probably sacrifice seq-length to 50, num_layers to 2, and make rnn-size as big as fits. Probably squeezes more juice out of it
622363890706436100,Sat Jul 18 11:14:49 +0000 2015,@nylk for text this this can probably be as small as 10 (then you ~expect to do no better than a 10-gram model). For e.g. code need more
622363714587619300,Sat Jul 18 11:14:07 +0000 2015,@nylk seq_length is how many time steps back in time the backpropagation goes. It's about how long dependencies the training can "notice"
621731650091810800,Thu Jul 16 17:22:31 +0000 2015,In general technology monotonically increases the amount of possible damage per dollar per person. So as a straight-forward corollary... nvm
621730865756901400,Thu Jul 16 17:19:24 +0000 2015,Drone firing handgun appears in video http://t.co/4GEH9hGvQ6 gulp
621703688797704200,Thu Jul 16 15:31:24 +0000 2015,A Minimal Architecture for Human Journeys to Mars http://t.co/RtHWN0OGtG depressing. I'll probably watch first Mars landings as a grandpa
621083145417400300,Tue Jul 14 22:25:35 +0000 2015,@Moontails yes only text. Can't do other stuff out of the box, but code can be repurpoused in straight-forward way. Requires learning Torch
620960903014576100,Tue Jul 14 14:19:50 +0000 2015,@kastnerkyle @AlecRad yep i saw that paper, but I honestly cannot figure out what Figure 2 is trying to show. kk!
620954998512439300,Tue Jul 14 13:56:23 +0000 2015,@kastnerkyle @AlecRad is perforated the one where you simply place the activation in top left corner of the 2x2?
620915865186365400,Tue Jul 14 11:20:52 +0000 2015,@dribnet :) is this DRAWifiedish?
620898999562805200,Tue Jul 14 10:13:51 +0000 2015,@AlecRad @kastnerkyle btw, any experience with the best CNN Decoder net? Esp for type of unpooling
620896073440231400,Tue Jul 14 10:02:14 +0000 2015,Stumbled by Jon Shlens' "A Tutorial on Principal Component Analysis" http://t.co/v2AX3p60rg I'm told this is The best guide
620323364285083600,Sun Jul 12 20:06:29 +0000 2015,@AlecRad @kastnerkyle YEP! Seeing that here too. Do not like. I want sharp and structured :'(
620293475574108200,Sun Jul 12 18:07:43 +0000 2015,@kastnerkyle Yep I have that, does help quite a bit based on a hasty experiment.
620292135263322100,Sun Jul 12 18:02:24 +0000 2015,@kastnerkyle yep deconv. Still kind of ugly. Tricky to tune the KL regularization. The L2 loss doesn't make sense. Blurry stuff always
620225362157563900,Sun Jul 12 13:37:04 +0000 2015,Playing around with Variational CNN Autoencoder on ImageNet, samples @ epoch 7 below. Reparametrization trick is neat http://t.co/FGZtBUU8OB
619842555577004000,Sat Jul 11 12:15:56 +0000 2015,Finished "The Martian" and loved it (review https://t.co/5b6lG9oaxq), now watching all Andy Weir (author) interviews https://t.co/TLRgHSSyeI
619485007216775200,Fri Jul 10 12:35:09 +0000 2015,RT @ylecun: The Washington Post use ConvNets and inceptionism for political mockery. http://t.co/sr4QUladjI
618772887919407100,Wed Jul 08 13:25:27 +0000 2015,RT @jasonyo: Want to poke around inside a neural net? Try our Deep Vis Toolbox! https://t.co/4GAH4gHf58 Code here: http://t.co/6KZMz2bBOM
618742489713918000,Wed Jul 08 11:24:39 +0000 2015,EngineeringGuy explains how a film projector works. Marvelous, detailed explanation, great design https://t.co/EeTrRv8cDM
618733077708308500,Wed Jul 08 10:47:15 +0000 2015,@mdreid :) Still charmed by its novelty wrt prev "scifi" I read. Cool plot/ideas instead of "beautiful" descriptions of sunsets or whatever
618558914750226400,Tue Jul 07 23:15:12 +0000 2015,@michael_nielsen I don't get how I found out about it this late. How do I miss stuff like this, it's very sad. There could be more!
618547814520483800,Tue Jul 07 22:31:05 +0000 2015,Started reading "The Martian". Only ~10% in but really enjoying it, easily places in my top few scifi so far. It's not afraid to get nerdy.
618520893891956700,Tue Jul 07 20:44:07 +0000 2015,@TorkelD up to you to find the good ones :) They're there
618520787532795900,Tue Jul 07 20:43:41 +0000 2015,@TorkelD Agreed some books should really just be essays. Seems authors just want accomplishment of a "book" and sometimes stretch them out
618496809112047600,Tue Jul 07 19:08:25 +0000 2015,Liking Audible; Nice to squeeze in books in the pauses. Bit worried that it's using cpu cycles that used to go to daydreaming about research
618412617460265000,Tue Jul 07 13:33:52 +0000 2015,RT @samim: The #deepdream animator is addictive, careful! Just released it today, have fun ;-) https://t.co/TDUIUdKbmp http://t.co/O0MJyBEf‚Ä¶
618177158100447200,Mon Jul 06 21:58:14 +0000 2015,What's next, a CNN solving 3SAT as binary classification by taking as input a rendered image of the problem instance?
618175943404843000,Mon Jul 06 21:53:24 +0000 2015,From person behind "One Weird Kernel Trick": Visually Identifying Rank http://t.co/EZ7szOusNp CNN classifies rank of visualized matrix. lol!
617674363895160800,Sun Jul 05 12:40:18 +0000 2015,@humanfromearth @yigitdemirag Saw it of course. Thought it was building up very well, but thought last 1/3 of movie was several letdowns
617658362038239200,Sun Jul 05 11:36:43 +0000 2015,@zoyathinks says Zoya 2 days after she joins Twitter! haha
617656921668087800,Sun Jul 05 11:31:00 +0000 2015,Watched Terminator: Genisys. It was really, really bad as reviews claim. Unfortunately I have to sit through any AI-related movie regardless
617094465761751000,Fri Jul 03 22:16:00 +0000 2015,@iandanforth @yaringal tests??? but... that would imply I make bugs in my neural net implementations. :p
616998342082588700,Fri Jul 03 15:54:02 +0000 2015,@yaringal btw did you see REINFORCEjs? More DQN demos to play with maybe;   http://t.co/Vxp4MJ4jIC and http://t.co/ldqs8IreXW
616993884195934200,Fri Jul 03 15:36:19 +0000 2015,Very nice/long blog post from @yaringal on uncertainty in Neural Networks: "What My Deep Model Doesn't Know..." http://t.co/crVpEaxu2t
616412001577881600,Thu Jul 02 01:04:08 +0000 2015,@mtyka @j26774 Yep. Even small wiggles can help quite a bit in vanilla classification; But didn't think to use it in inceptionism! neat
616410995582500900,Thu Jul 02 01:00:08 +0000 2015,@mtyka @j26774 a fully conv net with stride 1 is transl invar, but the strides and max poolings make it only roughly/approximately so.
616410238690947100,Thu Jul 02 00:57:07 +0000 2015,@mtyka (cc @j26774) agreed; do you consider the random offset wiggle as form of regularization? I see Justin tried several others
616386656212504600,Wed Jul 01 23:23:25 +0000 2015,@mtyka I know, amusing right? Doubt he saw this coming... haha
616383647613108200,Wed Jul 01 23:11:28 +0000 2015,Amusingly, my labmate Justin Johnson just released cnn-vis on Github (https://t.co/tvCyipaowa), reproducing Google's #inceptionism results.
616382040787800000,Wed Jul 01 23:05:05 +0000 2015,RT @mtyka: Ok, folks: The code from our #inceptionism neural network post is now on github: https://t.co/pESzdoDfh4 http://t.co/NI99JYsMhr
616245864550539300,Wed Jul 01 14:03:58 +0000 2015,@eight_io you wouldn't. Characters are plugged in as 1-of-k right now. You want to feed in the trajectories directly as real numbers.
616000468075085800,Tue Jun 30 21:48:50 +0000 2015,Final commit for today: 110 line additions, 420 line deletions, and the model works better. #bliss
615998936327811100,Tue Jun 30 21:42:45 +0000 2015,@SeanMGonzalez @DataVizDC not planning on it right now, thanks though!
615895832156573700,Tue Jun 30 14:53:03 +0000 2015,@samim ::nervous laugh::
615619878737809400,Mon Jun 29 20:36:31 +0000 2015,@yoavgo @deliprao @gideonmann @haldaume3 +1
615618267416252400,Mon Jun 29 20:30:07 +0000 2015,Visual Q&amp;A dataset http://t.co/tbByaMV7d6 good luck computer vision :p
615462258597081100,Mon Jun 29 10:10:11 +0000 2015,@chrisemoody thx, haven't seen before. imo ppl always show off trivial MLP examples. Specify an NTM concisely as Torch and I'll be impressed
615301140939411500,Sun Jun 28 23:29:58 +0000 2015,"Three World Collide" http://t.co/oWFOOoyMLe fun sci-fi short story read on aliens and subjectivity of morality
615276674393972700,Sun Jun 28 21:52:45 +0000 2015,Just learned of the SpaceX launch failure (was without internet most of the day). I don't even
613831180522270700,Wed Jun 24 22:08:52 +0000 2015,@sedielem @317070 i.e. Equation 9 in my paper http://t.co/RCbepl6V8B , but sent encoder = straight up LSTM, last hidden vec for simplicity
613830854591311900,Wed Jun 24 22:07:34 +0000 2015,@sedielem @317070 idea 2: MSCOCO. Finetune VGG16 net on image-sentence max-margin ranking. Max over images maximizing score with sentence
613829623722455000,Wed Jun 24 22:02:41 +0000 2015,@samim @sedielem @317070 http://t.co/5iG4c4sb4S
613829225280335900,Wed Jun 24 22:01:06 +0000 2015,@sedielem @317070 just read blog post too - as for priors you're aware of Jason's recent paper? Several options to try there too.
613828308388724700,Wed Jun 24 21:57:27 +0000 2015,Twitch having fun being hypnotized with zooming inceptionism ConvNet art http://t.co/vyreLb7o54  (fun idea @317070 et al.!)
613773197096394800,Wed Jun 24 18:18:28 +0000 2015,@sedielem here's brassiere. But I was thinking training on different data, eg racy content filter data
613772395250352100,Wed Jun 24 18:15:17 +0000 2015,@sedielem people getting convnets to dream/generate NSFW material in 3,2,1,....
613657354563899400,Wed Jun 24 10:38:09 +0000 2015,Deep Learning singularity: when new cool papers are coming out faster than you can read them
613656286056595500,Wed Jun 24 10:33:54 +0000 2015,DeepStereo: Learning to Predict New Views from the World's Imagery http://t.co/9XggHN3YDm impressive! + video: https://t.co/bE0lAfo2pw
613308608168755200,Tue Jun 23 11:32:21 +0000 2015,Fun ConvNet feature visualizations http://t.co/5iG4c4sb4S + live camera ConvNet vis demo https://t.co/reExpLMTv6 http://t.co/MvoYXnIbSG
613108997621682200,Mon Jun 22 22:19:10 +0000 2015,Neural Nets dreaming natural images http://t.co/06R1ufn5SQ , about the recent FAIR paper. Adversarial nets sound quite tricky to train
612439018983301100,Sun Jun 21 01:56:55 +0000 2015,Fallout Shelter is the first time I'm having fun with mobile game. Thx @BethesdaStudios for not forcing in-app purchases with shady tactics
612031084486881300,Fri Jun 19 22:55:56 +0000 2015,RT @profjsb: So I autogenerated a piano sonata... See blog post "Asking RNNs+LTSMs: What Would Mozart Write?" http://t.co/CwvBMAoXQg Thanks‚Ä¶
612026305438163000,Fri Jun 19 22:36:56 +0000 2015,@mtyka @samim @leopd @rnnbible hah didn't know you guys made the rnnbible, neat :)
612025404539433000,Fri Jun 19 22:33:21 +0000 2015,Almost all good ideas don't work at first.
611578522663055400,Thu Jun 18 16:57:37 +0000 2015,@mtyka Imo CNN + DRAW-like generation something something hand wave good things might happen :)
611538715714953200,Thu Jun 18 14:19:26 +0000 2015,Inceptionism post from Google blew up my Twitter feed :) Btw there's a huge amount of unexplored space here. Future holds much generated art
611465316330270700,Thu Jun 18 09:27:46 +0000 2015,@ideasrapidas not exactly. The RNN is trained to predict the next character, so the hidden state is mostly focused on that particular aspect
611465096901066800,Thu Jun 18 09:26:54 +0000 2015,Inceptionism: Going Deeper into Neural Networks http://t.co/JOfe7JvbHZ Very fun results. Opens doors to Deep Learning Computational Art
610216446594052100,Sun Jun 14 22:45:12 +0000 2015,"We outperform work of [x] (Table y)". Yes, when [x] uses AlexNet and you VGGNet. Consistently omitted in papers. You can't not mention this
610164631596847100,Sun Jun 14 19:19:19 +0000 2015,@sjwhitworth didn't plan any so far
610158769662787600,Sun Jun 14 18:56:01 +0000 2015,Bit disappoint that I didn't see some old looking place with people drinking tea and reading newspaper or something. Was my vision of things
610157693513396200,Sun Jun 14 18:51:44 +0000 2015,Phone showing 20km walked since 10am; I'd say I saw a good chunk of London. With tourist stuff out of way ready to sit down and get to work
609843260580851700,Sat Jun 13 22:02:18 +0000 2015,@kcimc yep, that's right.
609775923781574700,Sat Jun 13 17:34:43 +0000 2015,First time in London! (Starting summer internship at DeepMind). Almost got run over by car- I checked in wrong direction. O/w it's v nice :)
609768804999151600,Sat Jun 13 17:06:26 +0000 2015,@samim descriptors are extracted with the matlab/numpy code in the repo; uses Caffe. The image/sentence data is from AMT
609411825671778300,Fri Jun 12 17:27:56 +0000 2015,@ryan_p_adams sad to have missed you while visiting David - wanted a Talking Machines autograph :) jk, but few of us at Stanford are fans :)
609040831325040600,Thu Jun 11 16:53:44 +0000 2015,@korbonits oh no it's just a very small room!
608989499666919400,Thu Jun 11 13:29:45 +0000 2015,#cvpr2015 one does not simply go to the deep learning workshop http://t.co/ScyXqfLjat
608982422873587700,Thu Jun 11 13:01:38 +0000 2015,CVPR attendees unanimously amused as they woke up early to go to deep learning workshop just to discover that its room sits about 100 people
608844669607403500,Thu Jun 11 03:54:15 +0000 2015,Reddit is revolting the banning of 5 subreddits by Ellen Pao http://t.co/Up6yxxuGjT I'm getting my pitchfork and popcorn.
608744514619105300,Wed Jun 10 21:16:16 +0000 2015,@yoavgo Maybe code is the most formal/precise to look at? I think this is a problem, tried to be thorough in my recent paper. Hard I guess
608718026888855600,Wed Jun 10 19:31:01 +0000 2015,Someone using char-rnn to generate magic cards http://t.co/KDKshVu3XY I never expected the amount of response the code has received. awesome
608267497071120400,Tue Jun 09 13:40:47 +0000 2015,RT @drfeifei: @karpathy presenting our work on image captioning at #cvpr2015 http://t.co/1apCd8c9KI
608127284999024600,Tue Jun 09 04:23:37 +0000 2015,RT @drfeifei: ‚ÄúAI won‚Äôt exterminate us. It will empower us.‚Äù by @etzioni https://t.co/tdeIsJpUq5
608030544610390000,Mon Jun 08 21:59:13 +0000 2015,the button has ended http://t.co/DHThxbYDop one of the most interesting social experiment I've seen
607760835805593600,Mon Jun 08 04:07:29 +0000 2015,@roboticwrestler +iPad for me :(, but that one varies more with day.
607760330639474700,Mon Jun 08 04:05:29 +0000 2015,The number of devices I have to charge every evening is growing linearly and roughly 1:1 ratio with year since 2011. Now at 4.
607526578281545700,Sun Jun 07 12:36:38 +0000 2015,A Compilation of Robots Falling Down at the DARPA Robotics Challenge https://t.co/UxFlWV8kuG "The singularity has been delayed." haha
607362411234869200,Sun Jun 07 01:44:17 +0000 2015,Heading out to Boston for CVPR! In case it's useful &amp; you missed it - this year's accepted papers in pretty format: http://t.co/ZV33Yfsaxp
607244793979138000,Sat Jun 06 17:56:55 +0000 2015,"GPUs to Mars" cool talk from GTC http://t.co/QGjNZfCl8w
606900041542824000,Fri Jun 05 19:07:00 +0000 2015,The DARPA Robotics Challenge Finals live stream  http://t.co/j92tQa63Am simultaneously the most and least exciting thing to watch
606749525114392600,Fri Jun 05 09:08:54 +0000 2015,@samim haha probably word, for anything plain basic English with little structure or formatting
606738949629866000,Fri Jun 05 08:26:52 +0000 2015,DARPA Robotics Challenge Finals: Know Your Robots http://t.co/ClaLG3j7jm DRC finals happening on Friday/Saturday; exciting!
606738189185736700,Fri Jun 05 08:23:51 +0000 2015,RT @abursuc: Training an object proposal network jointly with an R-CNN and getting 5fps quality detection frame rate with VGG-16  http://t.‚Ä¶
606703842936225800,Fri Jun 05 06:07:22 +0000 2015,@cohenrap interesting! it's non-standard in papers I normally read.
606618006949494800,Fri Jun 05 00:26:17 +0000 2015,@samim I'll try to fit in time to get the word-level to work, maybe tomorrow. Word level models work better than char lvl... but less cool
606617517365162000,Fri Jun 05 00:24:21 +0000 2015,@samim I really like the idea of combining datasets across different people and creating hybrids, looking forward to that :)
606616641065992200,Fri Jun 05 00:20:52 +0000 2015,@samim btw did you pull fixes I issued last 2 days? char-rnn works better now. Also, I hope these are big dropouty models trained w GPU?
606616373456871400,Fri Jun 05 00:19:48 +0000 2015,RT @samim: Obama-RNN‚Ää‚Äî‚ÄäMachine generated political speeches: https://t.co/2ZPrmLx43f cc @karpathy
606615638786711600,Fri Jun 05 00:16:53 +0000 2015,@samim haha you're having a lot of fun with this :)
606509415005593600,Thu Jun 04 17:14:47 +0000 2015,@Terrortola @rjcc may I ask that the image be removed from the article?
606333475642175500,Thu Jun 04 05:35:40 +0000 2015,@Terrortola hello, curious why a figure from my NIPS paper is the image used for http://t.co/6V0OnC19NA since it has nothing to do with this
606174234100924400,Wed Jun 03 19:02:54 +0000 2015,@johnplattml Humans at #6?? I've already competed against Google on ImageNet, maybe I should step in &amp; try again on Image Captioning. :p
606172325130567700,Wed Jun 03 18:55:19 +0000 2015,@boydgraber @dna_nerd @drfeifei haha. To be fair, the log probability (-11) is VERY low. The network knows that it doesn't know :)
605893074300960800,Wed Jun 03 00:25:40 +0000 2015,found in our output directory: model.h5, model_new.h5, model_final.h5, model_final_final.h5. And now we need to rerun the models again... :\
605790844235345900,Tue Jun 02 17:39:26 +0000 2015,@MrChrisJohnson this is awesome, hahaha. I welcome our rapping robotic voice overlords. Bigger net! More dropout! More data!
605790342827229200,Tue Jun 02 17:37:27 +0000 2015,RT @MrChrisJohnson: Inspired by @karpathy's recent blog post, I trained a char-by-char RNN on Eminem lyrics then let it generate its own ht‚Ä¶
604724212092174300,Sat May 30 19:01:02 +0000 2015,@Footfish oh, well that's okay then, never mind.
604700347064451100,Sat May 30 17:26:12 +0000 2015,@mattly @grayj_ this is not something I blame Twitter for, it's something I blame Apple for. This should not be possible, or guarded
604508717443194900,Sat May 30 04:44:44 +0000 2015,@Liz90588695 they have my best intentions in mind and just really want to provide me with a better experience. How nice of them
604476624076075000,Sat May 30 02:37:12 +0000 2015,Wait, Twitter is collecting list of applications you have installed on your phone? Isn't that kind of outrageous? https://t.co/kFioTE2wNi
604439058622742500,Sat May 30 00:07:56 +0000 2015,@samim @boblsturm @seaandsailor hmm interesting. This is for test time prediction I assume?
604418382121680900,Fri May 29 22:45:46 +0000 2015,@nylk looks awesome! For 35MB of data I hope you trained a bigger than 100 rnn_size model! Can go plenty higher. Also maybe seq_length 100
604417472339378200,Fri May 29 22:42:09 +0000 2015,RT @nylk: here's the first batch of food recipes made with the char-rnn by @karpathy  :) Happy cooking *coughs*!  https://t.co/Vmjqs9FDl9
604357286274826200,Fri May 29 18:43:00 +0000 2015,@JasonPunyon I love stack overflow but it's a big stretch relative to what I have in mind after graduation. thank you though! :)
604331975285977100,Fri May 29 17:02:25 +0000 2015,"Learning Holiness" http://t.co/nUSqLJzFdm some trained char-rnn on the Bible, fun results.
604329114783227900,Fri May 29 16:51:03 +0000 2015,Jumping robot quadrupeds evoke nostalgia because in my previous life I trained jumping controllers for simulated ones http://t.co/Fa2FDsk7cM
604327988881014800,Fri May 29 16:46:35 +0000 2015,RT @erikbryn: Stop by #MIT's athletic center and you might see a robot cheetah leaping over obstacles http://t.co/axqqKrtXJo #2MA http://t.‚Ä¶
604174467753844700,Fri May 29 06:36:32 +0000 2015,#phdsuperpower Paper Deadline: You become resistant to effects of time of day. All stats improved 2x. After deadline all stats 0.1x for week
603978882836901900,Thu May 28 17:39:21 +0000 2015,Thanks @vakibs for link to Roger Shank's http://t.co/Tc4TJdXfs1 (RE my previous Marvin Minsky link). Interesting read. "AI isn't physics".
603969371220807700,Thu May 28 17:01:33 +0000 2015,RT @googleresearch: Learn the science behind Recurrent Neural Networks, including a tutorial on how to train your own language model, at ht‚Ä¶
603957311908884500,Thu May 28 16:13:38 +0000 2015,RT @the__glu: @karpathy We did some bots using char-rnn: random bible verses @RNN_Bible or in french @RNN_Bible_fr :) https://t.co/NOaidDZK‚Ä¶
603843210725687300,Thu May 28 08:40:14 +0000 2015,I wonder if/how the same will hold 40 years from now, for someone reading our papers/posts in 2055.
603842892755513300,Thu May 28 08:38:59 +0000 2015,Reading through Marvin Minsky's Frames theory https://t.co/L5s5UpgBiY what a vastly different mindset to AI/vision than what we do today
603748411628716000,Thu May 28 02:23:33 +0000 2015,DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving http://t.co/QWuELXXATy Like CNN car racing in simulation, neat
603657302894313500,Wed May 27 20:21:31 +0000 2015,RT @ylecun: The journal Nature just published a review paper on deep learning co-authored by myself, Yoshua Bengio, and Geoff... http://t.c‚Ä¶
603633891438628900,Wed May 27 18:48:29 +0000 2015,@catzdong haha scrolling by I thought you met the actual queen for a second there
603458058287611900,Wed May 27 07:09:47 +0000 2015,Stumbled by a wonderful YouTube channel (Kurz Gesagt) with pretty, educational animations https://t.co/CZkjwWxxTt productivity--;
602887641051242500,Mon May 25 17:23:09 +0000 2015,@nylk that's awesome! I thought about this but couldn't figure out how to get the data. This page seems relevant :) Let me know how it goes!
602887279544111100,Mon May 25 17:21:43 +0000 2015,@arm_gilles can't spot mistakes, maybe learning rate too high?
602886684103999500,Mon May 25 17:19:21 +0000 2015,@unfo hehe no actually, it's just unconventionally introducing a new chapter of docs. Working as intended :)
602707869088133100,Mon May 25 05:28:48 +0000 2015,@sriramk haha - wish it filled you with motivation instead ;)
602588037738991600,Sun May 24 21:32:38 +0000 2015,CVPR 2015 papers are now up so I organized them into my annual pretty interface http://t.co/ZV33Yfsaxp This year: new interactive t-SNE map
602247996814725100,Sat May 23 23:01:26 +0000 2015,@petewarden except activations in neural net are float not {-1,1}, so I tried regularizers that softly encouraged weights/acts to be -1 or 1
602247782838079500,Sat May 23 23:00:35 +0000 2015,@petewarden idea was dot prod w*x when w,x \in {-1,1} = binary_hamming_dist(w,x) when w,x {0,1} (can use SSE XOR/count ops to make fast)
602245013481726000,Sat May 23 22:49:35 +0000 2015,@petewarden I spent some time binarizing convnet forward passes while ago. Idea was to finetune to "prefer" binary activations. Worked ~ok
602197063049195500,Sat May 23 19:39:02 +0000 2015,@psygnisfive @yoavgo have a look at the stack-augmented paper i link to in my blog post from armand joulin and tomas mikolov. You'll like.
602162903907610600,Sat May 23 17:23:18 +0000 2015,@yoavgo we also use order back off based on cross validated threshold which makes it work quite a bit better
602162228096213000,Sat May 23 17:20:37 +0000 2015,@yoavgo v important to look at to understand RNNs, thx. We have exhaustive comparison experiments, but did not post with blog #comingsoon
602158226080043000,Sat May 23 17:04:43 +0000 2015,RT @yoavgo: .@karpathy's RNNs post is great, but generating Shakespeare and Paul Graham isn't that impressive. Generating code is http://t.‚Ä¶
601880975732187100,Fri May 22 22:43:01 +0000 2015,@boblsturm my bar far favorite part about these is that it samples its own names for its masterpieces. I can't stop laughing
601874450854780900,Fri May 22 22:17:06 +0000 2015,@djpardis @seaandsailor @boblsturm gah I'm missing all these beautiful responses to char-rnn left and right. Awesome stuff!
601874302229581800,Fri May 22 22:16:30 +0000 2015,Here's another blog post on using char-rnn to generate music by @boblsturm, very neat! https://t.co/axHbGIhSmQ
601872737099845600,Fri May 22 22:10:17 +0000 2015,This is awesome, @seaandsailor ran char-rnn on Irish folk tunes and then sampled music. Works nicely! :) Want more https://t.co/7QeZVdplEN
601629559906144300,Fri May 22 06:03:59 +0000 2015,@gchrupala (provided of course that you're aware of http://t.co/0KX8nYbpc4 and not doing dropout along the recurrent connections)
601626564032221200,Fri May 22 05:52:05 +0000 2015,@gchrupala it makes everything work better always, no exceptions.
601610943508779000,Fri May 22 04:50:00 +0000 2015,@SamFromKC an RNN would work well i imagine, but then you need some training data. You could use your regex matches as positives perhaps.
601597340412031000,Fri May 22 03:55:57 +0000 2015,@mdreid haha the problem is that with the right tools that corpus is very very small :)
601534327197798400,Thu May 21 23:45:34 +0000 2015,@suchisaria granted :) It gets better when bigger but we need new approaches to shorten backprop paths for more global context. ongoing work
601532341819813900,Thu May 21 23:37:40 +0000 2015,@suchisaria model should be bigger ;)
601475514612736000,Thu May 21 19:51:52 +0000 2015,@notmisha @BrendanShilling interesting, thank you!
601446221845176300,Thu May 21 17:55:28 +0000 2015,Also yes, in case you're wondering, writing this did interfere with working on NIPS  #priorities #backwards
601445867841695700,Thu May 21 17:54:03 +0000 2015,To reproduce experiments in post also releasing code for character-level language models multi-layer LSTMs https://t.co/HvWsOEKWdT
601445381688283100,Thu May 21 17:52:07 +0000 2015,New (epic) blog post on "The Unreasonable Effectiveness of Recurrent Neural Networks" http://t.co/OKkaxvIGnS was immense fun to write
601080980976193500,Wed May 20 17:44:08 +0000 2015,@francislee2020 Hi, I don't have any immediate plans. For the very last few sections look at the slides, not the notes.
600163083860840400,Mon May 18 04:56:44 +0000 2015,(spurred by spotting http://t.co/I5T3DwBFBC on HN) I have a soft spot for people who do stuff, write about it and improve over time.
600163022041022500,Mon May 18 04:56:29 +0000 2015,"Don't compare yourself to others. Compare yourself to you one year ago". Cheesy quotes usually irritate me except I like this one
599825256820318200,Sun May 17 06:34:20 +0000 2015,Time-lapse Mining from Internet Photos http://t.co/6yo70ZfDou
599795351743107100,Sun May 17 04:35:30 +0000 2015,@fchollet thx! I have an implementation of it. Didn't push it because improvements very small. Convnetjs doesn't batch. Would need rewrite
599685029627822100,Sat May 16 21:17:07 +0000 2015,@shazow haha. I was just impersonating new oculus. It's about sharing authentic experiences, JUST like FB. Perfect alignment of goals
599683957626568700,Sat May 16 21:12:51 +0000 2015,@shazow virtual reality is all about connecting people
599249877520879600,Fri May 15 16:27:58 +0000 2015,RT @topher_batty: SIGGRAPH 2015 papers preview video! Very fun, as usual: https://t.co/vFAWCQZuwQ
598932552997449700,Thu May 14 19:27:02 +0000 2015,Entire building suddenly lost power. All my GPU jobs canceled, chrome tabs gone, and I can't remember what I was doing anymore #apocalypse
598752490847277000,Thu May 14 07:31:32 +0000 2015,@Ajay_Talati I didn't try my NTM on the tasks in the NTM paper.
597893535103201300,Mon May 11 22:38:21 +0000 2015,"How We‚Äôre Predicting AI - or Failing To" https://t.co/QjME9oMYju human-level AI is always predicted at ~20 years away, by both experts/non
597634725008646100,Mon May 11 05:29:56 +0000 2015,@tanshawn Yep, in Torch this runs basically instant because there is no silly compilation! Win! :)
597634068616851500,Mon May 11 05:27:20 +0000 2015,@karpathy Bleh, I meant edges are Tensors, nodes are transformations (modules/layers).
597632056391180300,Mon May 11 05:19:20 +0000 2015,Might look scary now but going forward we'll only keep stacking/unrolling these further. I wonder what nets in few years will look like
597631909930242000,Mon May 11 05:18:45 +0000 2015,Computation graph of my (Torch) Neural Turing Machine. Nodes = Tensors, edges = funs. About to unroll this in time :\ http://t.co/ADtIqibp66
597600063628574700,Mon May 11 03:12:12 +0000 2015,@theirf whattt?? Gah, I haven't looked at the code for a while. I remember it working once. It's not too beginner friedly, must know bp well
597559137367560200,Mon May 11 00:29:35 +0000 2015,@hardmaru "mindcraft" - haha! I see what you did there :)
597535659247566800,Sun May 10 22:56:17 +0000 2015,Creatures with RNN brains evolved to avoid moving planks http://t.co/bf7Jv8QNW0 fun JS demo
597487117669797900,Sun May 10 19:43:24 +0000 2015,You drag RNN above several CONV modules, hit craft, and Image Captioning model pops out. Anyone? No? okay
597486971137626100,Sun May 10 19:42:49 +0000 2015,Playing bit Minecraft (late to the party). Fun! Though I keep thinking I want game where you craft Neural Nets. I know doesn't make sense :\
597271914034278400,Sun May 10 05:28:15 +0000 2015,@t3kcit  https://t.co/LuqX4hicVI &lt;3
597203368939892700,Sun May 10 00:55:53 +0000 2015,@josephmisiti not really :\ haha
597191113145888800,Sun May 10 00:07:11 +0000 2015,@josephmisiti haha - no this is the Bostrom book.
597182554681126900,Sat May 09 23:33:10 +0000 2015,Struggling hard to finish the superintelligence book. One 2 chapters left. Must... be... strong...
597145751043485700,Sat May 09 21:06:56 +0000 2015,@bittnt Maybe for ppl who think deep nets are magic sauce. They're not. They are parametric kNN++; ++ depends partly on how boring data is
596872708379451400,Sat May 09 03:01:57 +0000 2015,@bittnt shows COCO data is not very good. RNNs still have huge advantages other than performance
596566773694013400,Fri May 08 06:46:17 +0000 2015,RT @ShellyFan: Why¬†@sciam's Predictions¬†from 10 Years Ago Were So Wrong http://t.co/Y1S6jP81Ls
596386145484705800,Thu May 07 18:48:32 +0000 2015,RT @github: Jupyter/IPython notebooks now render on GitHub. Learn more: https://t.co/LvEHeykDDp
596379477166293000,Thu May 07 18:22:02 +0000 2015,Just noticed that my 2012 post on being far away from AI (http://t.co/iKlti0UHxy) was on HN. Fun breadth of comments https://t.co/7BcMakAxJp
596029027606888400,Wed May 06 19:09:28 +0000 2015,I was just learning Torch and getting comfortable and happy and now I'm confused again
596028764577927200,Wed May 06 19:08:25 +0000 2015,:) @nervanasys is on a roll! Open sources a new awesome-looking Deep Learning framework in Python https://t.co/alLUJijbZx
596027992985370600,Wed May 06 19:05:21 +0000 2015,RT @nervanasys: Our #deeplearning  framework #neon‚Ñ¢  &amp; fastest nervanaGPU kernels are available &amp; open sourced! http://t.co/JcNVSoPf6k @Ven‚Ä¶
594973402076553200,Sun May 03 21:14:47 +0000 2015,Awesome writeup of SGEMM that runs at 98% of Maxwell architecture throughput, achieved with a custom assembler https://t.co/2xaknHBU4e
594906896768761900,Sun May 03 16:50:31 +0000 2015,@samueljohn_de i bought late yesterday and played for half hour or so. So far is fun, but bit terse and high level.
594738507177807900,Sun May 03 05:41:24 +0000 2015,Earth: A primer. http://t.co/lqrs2DlIMQ very cool-looking iOS app for learning about Earth. want
594588347084898300,Sat May 02 19:44:43 +0000 2015,Very sad to hear of @davegoldberg suddenly passing away at 47. I remember many mentions of him in Sheryl's Lean In :( http://t.co/wkYfaMjs8g
594568713073926100,Sat May 02 18:26:42 +0000 2015,@quantombone I don't think language depends on vision. But the prediction is mostly matter of practicality than any principle
594556306486218800,Sat May 02 17:37:24 +0000 2015,ConvNet policies that read rendered text will become standard way of doing NLP. We'll move away from seq of char byte inputs #boldprediction
594553556075548700,Sat May 02 17:26:28 +0000 2015,RT @hmason: This instagram emoji machine learning post is really good, even if you don't love machine learning: http://t.co/drqWlpURdV
594270685234499600,Fri May 01 22:42:27 +0000 2015,@YangGao3 cs231n email address is best (shown on main website) cs231n-winter1415-staff@lists.stanford.edu
594246800250310700,Fri May 01 21:07:32 +0000 2015,@YangGao3 we didn't release these since we may want to recycle some parts in future years
593994069346361300,Fri May 01 04:23:16 +0000 2015,Elon is announcing new Tesla product: live video http://t.co/jRidGPpNGF "we have this handy fusion reactor in the sky called the sun" haha
593959839929249800,Fri May 01 02:07:15 +0000 2015,Ross Girshick's new paper on "Fast R-CNN" http://t.co/c2bPzJflsx super-fast CNN detection @ state of the art performance + Python/Caffe code
593121473126010900,Tue Apr 28 18:35:53 +0000 2015,@StachuDotNet wat. which one
592806228759322600,Mon Apr 27 21:43:13 +0000 2015,The Backwards Brain Bicycle experiment from Smarter Every Day [video] https://t.co/ETiuQ8adgg very fun/interesting
592799634881413100,Mon Apr 27 21:17:01 +0000 2015,Deep Learning for Decision Making and Control  https://t.co/seezNstuSj [video], good talk, awesome opportunities
592193801310974000,Sun Apr 26 05:09:39 +0000 2015,@gchrupala documentation fail :( I used some of val for train, and that's "restval". So train/restval is train, val is val, test is test
592192915419435000,Sun Apr 26 05:06:08 +0000 2015,Putting together my reading list for Quals, which I still have yet to take. yay
592109261875843100,Sat Apr 25 23:33:43 +0000 2015,Project Pigeon during WW2 envisioned pigeon-guided missiles (they peck at target) http://t.co/YT7MTAg8ii Also video: https://t.co/ITz7WGV3DI
592073715971559400,Sat Apr 25 21:12:28 +0000 2015,@gchrupala 8K/30K models used hidden 300-600 as paper says, except for final COCO model that does better with more probably due to data size
592073358407151600,Sat Apr 25 21:11:03 +0000 2015,@gchrupala oops forgot to reply. I ran a very large model (hidden size 1600) over winter break on COCO &amp; it did well. Should have commented.
592044554821308400,Sat Apr 25 19:16:36 +0000 2015,ICRA 2015 (Robotics Conference) Trailer https://t.co/be1I298SLN
591770275827486700,Sat Apr 25 01:06:42 +0000 2015,@UPSHelp UPS followed up with me and told me to contact Apple now. This is Extremely disappointing. I stayed home at my door most of the day
591768066838569000,Sat Apr 25 00:57:56 +0000 2015,My #AppleWatch was delivered by UPS to wrong door, driver left without my (required) signature. I can't find it. They started investigation
591314942814486500,Thu Apr 23 18:57:23 +0000 2015,@arnicas yep saw it but i cant really interpret it :)
591029849365422100,Thu Apr 23 00:04:31 +0000 2015,Writing in the Sciences: A recommended MOOC videos for learning how to write better papers https://t.co/WRcWXhNrGD
590721048523493400,Wed Apr 22 03:37:27 +0000 2015,@AlecRad hey have you ever tried LSTMs with no biases? I've been telling ppl they don't matter but not actually 100% sure ;\
590286668311105500,Mon Apr 20 22:51:23 +0000 2015,Nervana Systems (@nervanasys) kernels give very impressive performance for CONV, ~twice+ speed of Caffe/Torch/cudnn https://t.co/lMtIOlvjKZ
590076079416586200,Mon Apr 20 08:54:35 +0000 2015,@petewarden can a sizable delta be achieved in speed by writing custom CONV instead of reduce to GEMM? (GEMM already less space efficient)
589880490175238100,Sun Apr 19 19:57:22 +0000 2015,There's added things (DQN), and sketches of Policy Gradient methods (stochastic and deterministic). Except they are tricky to get working
589880318972141600,Sun Apr 19 19:56:42 +0000 2015,The library/web demos are basically me going down Richard Sutton's great (free) RL book http://t.co/w9imJJ5l53 &amp; implementing all the things
589880192752980000,Sun Apr 19 19:56:12 +0000 2015,New pet project: REINFORCEjs for Reinforcement Learning http://t.co/X8phS2VOwv I am now starting to exhaust ML algs to implement in JS...
589706218190417900,Sun Apr 19 08:24:53 +0000 2015,DynamicFusion: Impressive live 3D reconstruction of non-rigid scenes [video] https://t.co/5m4JGNqWiX (via @sdavidmiller)
588845322333397000,Thu Apr 16 23:23:59 +0000 2015,List of JS libs I can't live without is dangerously large: jquery jqueryui bootstrap d3js marked highlightjs underscore mathjax flotjs...
588467209741082600,Wed Apr 15 22:21:30 +0000 2015,CRS-6 Stage 1 goes Kaboom on the drone ship, high-res video:  https://t.co/BOS4tSOxGH it's like from Michael Bay movie but real life! :D:D:D
588219032244985900,Wed Apr 15 05:55:20 +0000 2015,I got overconfident. I Implemented a monster model in one go, and now there's some bug I can't find for hours. Serves me well. #icarus
587715258816446500,Mon Apr 13 20:33:31 +0000 2015,CRS-6 weather is no go. Why would they do this to me
587713704159944700,Mon Apr 13 20:27:20 +0000 2015,SpaceX CRS-6 at T-5 min to launch. Will recover first stage at ~T+9min. Live stream http://t.co/kR6ctLuadD &amp; reddit: http://t.co/hpHje1ftnY
587479440914980900,Mon Apr 13 04:56:28 +0000 2015,@AlecRad yep, 0 = max. 872,000 characters in dataset. Don't have a good intuition, haven't trained on other data b4. Probably too small?
587479104020054000,Mon Apr 13 04:55:07 +0000 2015,I'm still not feeling the wisdom coming across. I need to train a bigger model.
587478394675179500,Mon Apr 13 04:52:18 +0000 2015,I put up a whole bunch of other samples from the character-level Paul Graham LSTM here: http://t.co/g6cnaIZXB8
587478162335862800,Mon Apr 13 04:51:23 +0000 2015,"But the most important thing to do it is to sell." - A sample from a 1000-hidden-unit character LSTM trained on Paul Graham's essays. ha ha
587322675925614600,Sun Apr 12 18:33:32 +0000 2015,128-bit SIMD instructions coming to JavaScript in ECMAScript 7 https://t.co/268gNQY5Di Maybe one day we'll have JS Tensors + BLAS-like ops
587321241813389300,Sun Apr 12 18:27:50 +0000 2015,@b_gaijin not when you do it well, apparently! I pulled all kinds of tricks. I don't know which worked/didn't, but nothing happened :p
587184939247865900,Sun Apr 12 09:26:13 +0000 2015,Had farming bot: LUA called WoW API &amp; drew UI elements w/ colors, which I read/decoded from screenshots in C++ &amp; emulated key/mouse actions
587183092009320400,Sun Apr 12 09:18:53 +0000 2015,Last time I was writing LUA was ~10 years ago, working on World of Warcraft mods / extensions :) I made a few that got popular #previouslife
587014706252030000,Sat Apr 11 22:09:46 +0000 2015,@traboukos That's nice but it's not the API that's broken in Theano. It's its symbolic approach. The compilation. The debugging. The magic.
587009697229615100,Sat Apr 11 21:49:52 +0000 2015,Ideal is transparent CPU/GPU Tensor library +fwd/bwd API over Tensor ops in scripting lang. No protos. No symbolics. i.e. Torch but Python
587009599468806100,Sat Apr 11 21:49:29 +0000 2015,Caffe/Theano/Theano mods/Torch- all have pros/cons. I've converged on thinking that Torch gets many tradeoffs/abstractions right. Except LUA
586826552412733400,Sat Apr 11 09:42:07 +0000 2015,Quite enjoying going through "Introduction to Psychology" on Coursera. https://t.co/rpxOoEyZi1 good instructor, topics to know about
586792322345504800,Sat Apr 11 07:26:06 +0000 2015,Reading about human memory. As with other brain/bio stuff I go in confused, spend an hour and emerge more confused
585857671875563500,Wed Apr 08 17:32:08 +0000 2015,"An Empirical Evaluation of Deep Learning on Highway Driving" http://t.co/MKYPELu4gr from Brody et al. in Andrew's lab
585535112789565400,Tue Apr 07 20:10:24 +0000 2015,Videos of PR2 performing a few learned tasks also shown here: https://t.co/cWUAISkxRN
585534988302561300,Tue Apr 07 20:09:54 +0000 2015,Sergey being awesome as usual: End-to-End Training of Deep Visuomotor Policies http://t.co/Xwf2AYL2eC Learns Image-&gt; Raw joint torque policy
585501523947479000,Tue Apr 07 17:56:56 +0000 2015,@peteskomoroch @bethebutterfly haha :) hmm seeing my internet presence pooled together is mix of cool and... concerning *nervous laugh* haha
583845715560026100,Fri Apr 03 04:17:20 +0000 2015,my shell script sshs around and launches my other shell scripts which launch my python scripts which launch my lua scripts :\ hmmm
583425569989079000,Thu Apr 02 00:27:50 +0000 2015,So coool: Recurrent Net learns to play "Neural Slime Volleyball" in JS  http://t.co/OalwLFXmPZ I can't beat it... Lost 20-0
583351215515250700,Wed Apr 01 19:32:22 +0000 2015,@marcelsalathe they are on http://t.co/VVdUvYsQqZ
583062573471264800,Wed Apr 01 00:25:24 +0000 2015,Yay, first time I deployed HITs to AMT! Surprisingly simple to do with my friend Justin's microframework simple-amt https://t.co/WCBrvuOaVA
582826632139817000,Tue Mar 31 08:47:52 +0000 2015,@VorticonCmdr yeah this is possible. This particular case maybe not as likely because you don't have their data and also their CNN
582759501557727200,Tue Mar 31 04:21:06 +0000 2015,@_onionesque don't you think that's pushing it a bit too much. What are you reading?
582745073839800300,Tue Mar 31 03:23:47 +0000 2015,Turns out Linear Classifier achieves ~3% accuracy on ImageNet. &amp; don't miss 1000 learned ImageNet class templates http://t.co/Yiuo5CKcRR
582744737410461700,Tue Mar 31 03:22:26 +0000 2015,New blog post: "Breaking Linear Classifiers on ImageNet" http://t.co/kH5NISrYLz
582703645365420000,Tue Mar 31 00:39:09 +0000 2015,CVPR this year requires everyone to submit an extended abstract with the camera ready :'( #sadness #sorrow #anguish #grief #misery
582671780537471000,Mon Mar 30 22:32:32 +0000 2015,@dwf :) yeah... it should be more directly accessible somewhere, agreed.
582586155314479100,Mon Mar 30 16:52:18 +0000 2015,@arnicas yeah, each assignment has sever notebooks
582465450518270000,Mon Mar 30 08:52:39 +0000 2015,Although it bugs me that we didn't place enough emphasis on doing over reading. Should have had even more IPython Notebooks
582463970772062200,Mon Mar 30 08:46:46 +0000 2015,"Why My MOOC Is Not Built on Video" Good comments. I share sentiment, is why in CS231n I went with notes over vids https://t.co/FcWG2ZgPF4
582378630627467300,Mon Mar 30 03:07:40 +0000 2015,@_onionesque raw images, of course :)
582365375355998200,Mon Mar 30 02:14:59 +0000 2015,Training linear classifier on ImageNet out of curiosity...
582274550269763600,Sun Mar 29 20:14:05 +0000 2015,@jeremyjkun RBF nets are resilient but don't work as well. Ian's paper is required reading for this topic http://t.co/HiZgggWjv5
582260644293935100,Sun Mar 29 19:18:50 +0000 2015,@jeremyjkun some more discussion in HN comments here  https://t.co/Ms7yyoS2S9
582258619636314100,Sun Mar 29 19:10:47 +0000 2015,@jeremyjkun @djpardis Except these results show a problem much more general (e.g. includes linear classifiers) with DL is a special case.
581514272481497100,Fri Mar 27 17:53:01 +0000 2015,@dfarmer I know, of course, just teasing :)
581504748420866000,Fri Mar 27 17:15:10 +0000 2015,RT @abursuc: Videos from NIPS 2014 orals and workshops talks are up https://t.co/kbHw1zhX9K
581503314266693600,Fri Mar 27 17:09:28 +0000 2015,@dfarmer @iandanforth Right- after 1 month of CNN lectures and 4 weeks on a project they should be breaking SOTA left and right
581502205485719600,Fri Mar 27 17:05:04 +0000 2015,@brandondamos I don't :( In my calendar...
581360087177916400,Fri Mar 27 07:40:20 +0000 2015,@iandanforth didn't keep track, but I think a small few
581326870349639700,Fri Mar 27 05:28:21 +0000 2015,Added ability to \star CS231n projects, so best projects could get to top of list. http://t.co/fK4SShOq20 fun hack, but might get rid of
581199826706165800,Thu Mar 26 21:03:31 +0000 2015,Ask HN: Favorite podcasts https://t.co/xxkMKACSYO (via @jeremyphoward) Podcast discovery UI is so broken =&gt; ppl love looking for hidden gems
580901825668202500,Thu Mar 26 01:19:22 +0000 2015,The students had ~4 weeks to work on their projects (among other classes); Impressed with what they've come up with.
580900035996450800,Thu Mar 26 01:12:15 +0000 2015,The CS231n (our ConvNet class) final project reports have been posted! http://t.co/fK4SShOq20 100 ConvNet projects
580116589221019600,Mon Mar 23 21:19:07 +0000 2015,RT @drfeifei: http://t.co/QARBCA4EYD has released my talk about Computer Vision at #TED2015 . http://t.co/UTDuseYuSe
579852309271830500,Mon Mar 23 03:48:58 +0000 2015,@shazow For long while thinking about coding Dwarf-Fortress-like AI sandbox :(. All AI agents based on state of the art RL improve over time
579838848361857000,Mon Mar 23 02:55:28 +0000 2015,I remember training my creature to behave nicely with citizens and to perform and learn to cast spells. Was so satisfying to raise it
579838560624193500,Mon Mar 23 02:54:20 +0000 2015,I wish there were more games that have impressive/ambitious AI component. Black and White (2001) is the only game I'd put in that category
579546079072419800,Sun Mar 22 07:32:07 +0000 2015,RT @j_gauthier: My @cs231n project on drawing human faces with conditional generative adversarial nets (cGAN): http://t.co/JsGgUxNqWR http:‚Ä¶
579486645411434500,Sun Mar 22 03:35:57 +0000 2015,I don't want to give this talk anymore :\ Have to work harder on new project.
579486220096397300,Sun Mar 22 03:34:15 +0000 2015,I squeezed in a short talk during GTC about Image Captioning https://t.co/5UiUlwOtPl similar to previous one &amp; audience was ppl ~new to nets
578971824723116000,Fri Mar 20 17:30:14 +0000 2015,RT @ogrisel: Theano re-implementation of DRAW: A Recurrent Neural Network For Image Generation by J√∂rg Bornschein https://t.co/QpophULBpw #‚Ä¶
578752478939742200,Fri Mar 20 02:58:38 +0000 2015,"It's much simpler than I thought." &lt;- my favorite talk feedback. Destroying people's sense of Deep Learning wonder one talk at a time
578701355449118700,Thu Mar 19 23:35:29 +0000 2015,I reeeeealllly do not like outline slides. Best talks are stories. You wouldn't begin Harry Potter with an outline of what will happen.
578288303637590000,Wed Mar 18 20:14:10 +0000 2015,Grading the course projects for our ConvNet class. Impressed with the average quality, looking forward to releasing the projects in ~week
578072634191020000,Wed Mar 18 05:57:10 +0000 2015,Awesome writeup on classifying plankton with ConvNets http://t.co/stNTCgwZyf (National Data Science Bowl Kaggle Competition winner)
577941828453838800,Tue Mar 17 21:17:24 +0000 2015,Deep Learning is Everywhere at GTC. Interesting to see it go from fringe research to GTC main theme so fast. 5K ppl learning about AlexNets
577902776925040600,Tue Mar 17 18:42:13 +0000 2015,@sdavidmiller it was 5 min demo of few results and quick tour of the model. No GPU :)
577901487809949700,Tue Mar 17 18:37:06 +0000 2015,I have 10 drink tickets but somehow no meal tickets. I can get drunk but I can't eat lunch
577901255231569900,Tue Mar 17 18:36:10 +0000 2015,At NVIDIA's #GTC15, presented a snippet of our Image Captioning work during the keynote
577582904877785100,Mon Mar 16 21:31:10 +0000 2015,Excited for GTC (GPU Technology Conference) tomorrow http://t.co/pbI8osVUSU Except I'll have to wake up at 7am. Very grad-student-unfriendly
577381615820619800,Mon Mar 16 08:11:19 +0000 2015,RT @RyanKeisler: I've been playing around with the t-SNE algorithm lately: t-SNE viz of U.S. News http://t.co/IWjJm4bpyL http://t.co/00bZQq‚Ä¶
577138494234972200,Sun Mar 15 16:05:14 +0000 2015,@keyuan1 hahahah very good point :) I can relate to this too :D
576981798325899300,Sun Mar 15 05:42:35 +0000 2015,@grayj_ hahah yeah that too sometime :D I've impressed myself with my own code from long ago several times.
576977829843189800,Sun Mar 15 05:26:49 +0000 2015,My learning process shows a consistent pattern: 1. Thing makes absolutely no sense. 2. I kinda get it. 3. I implement it. 4. It's trivial.
576874373727924200,Sat Mar 14 22:35:43 +0000 2015,@psygnisfive The bar was very high :(
576873518605869000,Sat Mar 14 22:32:19 +0000 2015,Where was the consistently fast-paced politics, twists, power couple dynamics, Frank one-liners to the camera? &amp; Claire was all wrong. Sigh
576873303966556200,Sat Mar 14 22:31:28 +0000 2015,Finished House of Cards Season 3. Hate to say this but S3 felt like chewing a gum that was once so good, but has since lost original taste.
576586474541305900,Sat Mar 14 03:31:42 +0000 2015,Stanford CS PhD admit weekend today/tmrw. We're taking admits rock climbing &amp; more. Goal: exhaust them before they go to Berkeley on Sunday
576498489686765600,Fri Mar 13 21:42:05 +0000 2015,We just added 14 new GPUs (Titan Blacks,K40s) to our lab's GPU cluster #happiness
576270035565428740,Fri Mar 13 06:34:17 +0000 2015,@ieldanr yeah :\ not sure what's going on, contacting our sysadmins
575485080778358800,Wed Mar 11 02:35:09 +0000 2015,Stanford AI Lab is offering a new 2-week Summer Outreach program aimed at 9th grade girls to encourage interest in AI http://t.co/ZEjuph2XFg
575094943678513150,Tue Mar 10 00:44:53 +0000 2015,A Full Hardware Guide to Deep Learning https://t.co/sS4RVxsTIS tldr get GTX 980 (or 580 on cheap), lot RAM, CPU meh, SSD maybe, PCIe 3.0
575092651264884740,Tue Mar 10 00:35:47 +0000 2015,Raytracing a Black Hole http://t.co/PC1sIbgi6o (as seen in Interstellar)
574992247097155600,Mon Mar 09 17:56:49 +0000 2015,Macro shots of new products against white background, smooth animations and with Jony Ive's voice in background. Works well on me somehow :(
574788902206091260,Mon Mar 09 04:28:48 +0000 2015,Big improvement in Neural Nets have been in setting things to 0. When x&lt;0 (ReLU) or even just at random (dropout). When in doubt drop it out
574682916418007040,Sun Mar 08 21:27:39 +0000 2015,Mercedes-Benz self-driving car https://t.co/qI9RCbJDsL apparently not only 3D rendered, also spotted in SF  https://t.co/R6oCRkHoID
574656835476586500,Sun Mar 08 19:44:00 +0000 2015,@aysen_tatarinov Good to hear :) I'd be happy to hear feedback!
574423868581920800,Sun Mar 08 04:18:17 +0000 2015,@dfarmer  I like fully Convolutional nets from Evan Shelhamer
574395087905427460,Sun Mar 08 02:23:55 +0000 2015,@W0RB1T something fishy going on, perhaps with the preprocessing details etc. t-SNE should have worked just fine in this case.
574365093896396800,Sun Mar 08 00:24:44 +0000 2015,I vectorized a critical piece of code, got 17x speedup and now I'm on an adrenalin high. Time to make my model 17x bigger.
574291924242169860,Sat Mar 07 19:33:59 +0000 2015,Peter Norvig on "Machine Learning for Programming" http://t.co/gv05BMeudx tldr programming could use Much more ML. Like everything else
574128561063206900,Sat Mar 07 08:44:50 +0000 2015,Chappie was not boring, but logically inconsistent and intellectually dull. The "AI" treatment was Hollywood shallow. Missed opportunity
573792692372566000,Fri Mar 06 10:30:13 +0000 2015,I was going to skim it now at 2am but I think I have to come back for a full day &amp; follow up on multiple links I wasn't previously aware of
573792185339920400,Fri Mar 06 10:28:12 +0000 2015,Very nice and long reddit AMA with J√ºrgen Schmidhuber. Lots of RNN and AI food for thought http://t.co/9qcKsn6xhY
573736060036874240,Fri Mar 06 06:45:10 +0000 2015,My ego was shattered during trivia comp. Seems avg person knows MUCH more than me about 1960 movies, cocktails, music &amp; Australian states :(
573663215273410560,Fri Mar 06 01:55:43 +0000 2015,Two Deep Learning classes in a row- we're brewing a strong batch of ML/DL expert undergrads at @Stanford  :)
573662441856311300,Fri Mar 06 01:52:38 +0000 2015,"Deep learning for NLP" new class at Stanford next quarter taught by @RichardSocher  - http://t.co/Rx2gpmL0zK nice web design :p
573619866457874400,Thu Mar 05 23:03:28 +0000 2015,RT @AndrewYNg: Lets stop the AI superintelligence hype! Why I'm not working on stopping evil killer robots: http://t.co/KcZW4vtweI
573390215600996350,Thu Mar 05 07:50:55 +0000 2015,The entire human brain runs on ~30 watts, less than ~one lightbulb. A single K40 GPU is 250W. Time to start optimizing down.
573389448655732740,Thu Mar 05 07:47:52 +0000 2015,In general, there are many axes to measure models on, not just performance: e.g. # params, # FLOPS, raw forward time, memory consumed, ...
573389098271957000,Thu Mar 05 07:46:28 +0000 2015,I like this: "Low-Power Image Recognition Challenge" it's like ImageNet challenge but focus on good power consumption http://t.co/YZfu220cvO
573305144911142900,Thu Mar 05 02:12:52 +0000 2015,My core model fwd&amp;bwd is ~20 lines. But that is wrapped in 1000 lines of logging/vis/sanity checks/optimization/options/checkpoints/etc :\
573277802281082900,Thu Mar 05 00:24:13 +0000 2015,@prasanna oh snap! :D "payback"
573276462335205400,Thu Mar 05 00:18:54 +0000 2015,A robot driving around our Gates building just delivered me a cupcake. The future looks bright.
573200071447072800,Wed Mar 04 19:15:21 +0000 2015,John Carmack is live: http://t.co/5arMeiNIRj fun anecdotes about Virtual Reality landscape
572896459252617200,Tue Mar 03 23:08:54 +0000 2015,@AlecRad @ogrisel That's interesting. I was inclined to think they had a bug, good to see it reproduced. Not very obvious.
572885038414475260,Tue Mar 03 22:23:31 +0000 2015,@AlecRad @ogrisel not sure I understand motivation. Also their interpretation of the negative gradient seems erroneous / confusing at least
572598123782012900,Tue Mar 03 03:23:25 +0000 2015,@iandanforth I don't wanna. I'm tired.
572591049316560900,Tue Mar 03 02:55:19 +0000 2015,CS231n (Neural Nets &amp; ConvNets) notes http://t.co/ZxraiHJaCV takes forever to write. It's ~70% done. Looks like this will end up as book :\
572238829697945600,Mon Mar 02 03:35:43 +0000 2015,RT @openculture: The Feynman Lectures on Physics, Most Popular Physics Book Ever Written, Now Free Online http://t.co/ztt0IgTtrk http://t.c‚Ä¶
572207446376230900,Mon Mar 02 01:31:00 +0000 2015,@notmisha &amp;no "in" to check if table has key, no +=, 1-based indexing, manual collectgarbage() (?), (that's only from 1hr, wonder what else)
572203404560359400,Mon Mar 02 01:14:57 +0000 2015,@notmisha Yeah I stared at that for a while. The core of it is fine. The packaging of it in LUA and all the I/O, init, setup etc is headache
572177150666678300,Sun Mar 01 23:30:37 +0000 2015,@bittnt hmm I thought they were getting rid of dev. Didn't compile on master (which I think has that PR now), but I didn't try any changes.
572175172276396000,Sun Mar 01 23:22:46 +0000 2015,Decided to implement LSTM in Torch/LUA as a fun hack. Turns out one does not simply decide to try out Torch/LUA as a fun hack.
572123485712998400,Sun Mar 01 19:57:23 +0000 2015,@bittnt When I tried to compile Caffe with v2 R3 it gave lots of errors, I assumed there was no support yet. Is there a PR fix I'm missing?
571821004516814850,Sat Feb 28 23:55:26 +0000 2015,Play it again: reactivation of waking experience and memory; Hippocampus-cortex sync is one of coolest neuro findings http://t.co/X9DZdoinvs
571614087437664260,Sat Feb 28 10:13:13 +0000 2015,/r/civ is watching a 42 Deity AIs battle it out in a game of Civ http://t.co/erH0CVEe1V It's now turn 161, Germany/North Korea eliminated.
571438530569773060,Fri Feb 27 22:35:37 +0000 2015,@ton4eg Hmm, didn't know. Sounds iffy. I didn't isolate cuda by itself. I upgraded both driver and cuda at the same time.
571436252639031300,Fri Feb 27 22:26:34 +0000 2015,Surprised that move from HDD-&gt;SDD only gives -30ms. And driver version/ECC/Overclock/cudnn actually make quite a lot of difference each.
571436133780885500,Fri Feb 27 22:26:05 +0000 2015,I ran some optimizing experiments with Caffe AlexNets one step at a time, got K40 from 1800ms/fwdbwd pass -&gt; 950ms https://t.co/Au34sF8XEf
571423625359663100,Fri Feb 27 21:36:23 +0000 2015,@danbri nope
571359014379917300,Fri Feb 27 17:19:39 +0000 2015,Wake up. See "Andrej, House of Cards Season 3 is now on Netflix" in inbox. Get antsy.
571161128983666700,Fri Feb 27 04:13:19 +0000 2015,Older but still good: A bug in Steam script ran "rm -rf /" (erased all) if you moved a file to a different location https://t.co/oaPgtqkTqY
571104514175971300,Fri Feb 27 00:28:21 +0000 2015,@sdierauf in what context?
571067707602243600,Thu Feb 26 22:02:06 +0000 2015,Visited Apple for the first time. Spotted Jony at lunch. #visitsuccess Now I know which Apple Watch band he uses and must get the same
570697445618774000,Wed Feb 25 21:30:48 +0000 2015,@karoly_zsolnai good catch! I didn't even notice on first skim!
570690134682816500,Wed Feb 25 21:01:45 +0000 2015,RT @notmisha: Inside DeepMind http://t.co/LwshJZZaEK
570689674777382900,Wed Feb 25 20:59:56 +0000 2015,"Human-level control through deep reinforcement learning" new Nature paper from DeepMind! http://t.co/WDefOyiWZ3
570521179150090240,Wed Feb 25 09:50:23 +0000 2015,Finally got around to reading in detail the "Memory Networks" paper #mixedfeelings
570489615255150600,Wed Feb 25 07:44:58 +0000 2015,Proving that Android‚Äôs, Java‚Äôs and Python‚Äôs sorting algorithm is broken (and how to fix it) http://t.co/seXOatkekA #formalverificationwin
570431187698602000,Wed Feb 25 03:52:47 +0000 2015,RT @RanjayKrishna: One of the best #data webpages I have ever seen http://t.co/ovgUGRKF2G
570313174173519900,Tue Feb 24 20:03:51 +0000 2015,Fei-Fei (@drfeifei, my adviser) just joined Twitter and is already fluent in #/@ tags! :) Can't complain about research as much anymore :(
570136454531121150,Tue Feb 24 08:21:38 +0000 2015,Intended 45min talk clocks at 1hr 45min :\ Ahh, fond memories of research, when I spent hours coding instead of tweaking slides/colors/fonts
570101405140193300,Tue Feb 24 06:02:21 +0000 2015,RT @ylecun: A nice and mostly accurate article in The Chronicle of Higher Education about the history of neural nets and deep... http://t.c‚Ä¶
570098535695323140,Tue Feb 24 05:50:57 +0000 2015,Evan gave talk on Caffe at @cs231n, impressed with new features, easier use &amp; direction of Python Caffe wrapper, heading closer to Theano
569738732862988300,Mon Feb 23 06:01:13 +0000 2015,@sergecell @_onionesque paper they link to at the end is exactly what prompted me to have a close look and think. *Sqrt(2/n) init obv best
569691593168400400,Mon Feb 23 02:53:54 +0000 2015,Yearly fun puzzle: how to watch the oscars with no TV or cable subscription
569672770117742600,Mon Feb 23 01:39:07 +0000 2015,"We developed this robotic arm to help companies hire fewer people"- from final demo session of a Stanford hackathon #bestpart #awkwardlaugh
569653272065105900,Mon Feb 23 00:21:38 +0000 2015,Did not appreciate initialization. Having stepped through the math carefully not sure how most deep nets train at all without precise init
569402067632005100,Sun Feb 22 07:43:26 +0000 2015,Magic https://t.co/qs1gB5DWQc Like others I like quite a bit. Something profound here... Addresses problem of complexity exhaustion
569324041347006460,Sun Feb 22 02:33:23 +0000 2015,RT @stanfordnlp: Deep learning based question answering is picking up steam! Weston‚ÄîTowards AI-Complete Question Answering #dlearn http://t‚Ä¶
568532646306775040,Thu Feb 19 22:08:40 +0000 2015,Funny to listen to my own talk... I noticed I mix up words sometimes - I consistently find this when I have too much caffeine before talk
568532082948853760,Thu Feb 19 22:06:26 +0000 2015,Gave talk on "Automated Image Captioning with ConvNets and Recurrent Nets" 2 weeks ago at SF ML meetup, video is up: https://t.co/McQjzBvyYU
568220495650295800,Thu Feb 19 01:28:17 +0000 2015,@j_gauthier haha quality quantity tradeoffs!
567813954057031700,Tue Feb 17 22:32:50 +0000 2015,"DRAW: A Recurrent Neural Network For Image Generation" from DeepMind http://t.co/DdaF37HxNm and video of generation https://t.co/EGTOLFOM9M
567571702377230340,Tue Feb 17 06:30:13 +0000 2015,(Only joking btw); I have full faith in nice final projects :) But amusing to see students consistently underesimate amount of project work
567567427899105300,Tue Feb 17 06:13:14 +0000 2015,Students in my class: Project proposal time: "We will solve computer vision" Project Milestone time: "We got stuck on preprocessing data"
567467498044264450,Mon Feb 16 23:36:09 +0000 2015,@johnplattml :D nice,thanks! I have to find some time to go back and polish it a bit more
567463661480845300,Mon Feb 16 23:20:54 +0000 2015,Managed to reduce number of starred emails in my inbox from 18 to 6 in 3 hours. Meanwhile 2 new todo emails appeared. It's like whack a mole
567454985911160800,Mon Feb 16 22:46:26 +0000 2015,DeepWalk: Word2vec for graphs, for embedding nodes. Random walks over graph = sentences. http://t.co/2E5zfms91P cute
566489815831433200,Sat Feb 14 06:51:11 +0000 2015,@bradneuberg random gaussian numbers scaled down by sqrt of incoming connections is usually a good try
566367629057593340,Fri Feb 13 22:45:40 +0000 2015,A terrifying aspect of social media, where a bad joke can ruin your life http://t.co/BeQSx4cy52 this would make a great Black Mirror episode
565728575043956740,Thu Feb 12 04:26:17 +0000 2015,@michael_nielsen I know, right? :D Very amusing. I would have put even more effort into this if I knew it would be taken up so widely
565712068192776200,Thu Feb 12 03:20:42 +0000 2015,RE recent "super-human" ImageNet results https://t.co/tciv7KU1D4 "super-dedicated fine-grained expert human ensemble of labelers is ~3%"
565696276583694340,Thu Feb 12 02:17:57 +0000 2015,4.8% test error on ImageNet with "batch normalization", new paper from Google http://t.co/M4UsW9i0Zo At this rate, we'll see 0% in ~1 month.
565692247673671700,Thu Feb 12 02:01:56 +0000 2015,@petewarden hahah! CIFAR-10 is now at like 0.5 karpathy
565228867011375100,Tue Feb 10 19:20:37 +0000 2015,RT @ChrisBaldassano: @karpathy Humans mistreating AIs will be a more pressing ethical issue than AIs enslaving humans, but only the second ‚Ä¶
565222380578930700,Tue Feb 10 18:54:51 +0000 2015,RE: Boston Dynamics Spot video &amp; people's response to seeing it get kicked. I wonder if "robot cruelty" will be a thing, or "robot rights"
565079762431795200,Tue Feb 10 09:28:08 +0000 2015,The new Boston Dynamics robot (Big Dog descendent) looks good! Agile, stable, quiet. Fast progress http://t.co/OBmkQ3THlR
564986779636224000,Tue Feb 10 03:18:39 +0000 2015,'Paper of "Surpassing Human-Level Performance on ImageNet" should really be "Surpassing Andrej-Level Performance on ImageNet"' - friend. lol
564936532255981600,Mon Feb 09 23:58:59 +0000 2015,@ogrisel @sergecell This is my experience as well, + few people I talked to. And init is very important and I hate the flat Gaussian way.
564895034093215740,Mon Feb 09 21:14:06 +0000 2015,I'm going to squeeze in the MSR result mention into our ConvNet class lecture in 1 hour. Cutting edge undergrad class!
564893287241101300,Mon Feb 09 21:07:09 +0000 2015,Once we squeeze out all the juice from ImageNet, not sure what's next. There isn't a bigger, open, challenge-style dataset. Or detection?
564892854716096500,Mon Feb 09 21:05:26 +0000 2015,That was fast! Combining results from 2 human labelers our optimistic human error was ~3%. At this rate we'll hit that within a few weeks :)
564891968665182200,Mon Feb 09 21:01:55 +0000 2015,MSR achieves 4.94% error on ImageNet, surpassing my human accuracy of 5.1% http://t.co/XVcvVoviaQ (uses learnable leaky ReLU + careful init)
564552106820923400,Sun Feb 08 22:31:25 +0000 2015,SpaceX Falcon 9 launch in ~20 minutes! + Another attempt at first stage recovery coming http://t.co/kR6ctLuadD #soexcite
563572885529190400,Fri Feb 06 05:40:21 +0000 2015,@mxweas extrapolating - I think so!. We'll be selling and buying neural net weights :) ?
563416008430329860,Thu Feb 05 19:16:58 +0000 2015,@kcimc high risk high payoff endeavor! :)
563135966097842200,Thu Feb 05 00:44:11 +0000 2015,Preparing my slides for SF ML meetup talk tomorrow about image captioning with CNN+RNN combo. Looking forward http://t.co/EFPdoN5RMd
562737518760960000,Tue Feb 03 22:20:54 +0000 2015,RT @TEDchris : A year in the making, and here it is...  the TED2015 speaker lineup! http://t.co/WcmMRWKt6m  Fei-Fei in the mix!
562334207960047600,Mon Feb 02 19:38:17 +0000 2015,Backchannel article with Andrew Ng. Good answer for "Do you see AI as a potential threat?" at the end https://t.co/gCKF24IY6D
561324484464898050,Sat Jan 31 00:46:00 +0000 2015,I think I managed to unify Quantum Field Theory with Neural Networks. Wait, I don't know what I'm doing. Nvm
560975642737397760,Fri Jan 30 01:39:50 +0000 2015,@_onionesque thanks. Much more work to be done on tweaking them. I have to write them in only few days now per section. Must finetune later
560946548922531840,Thu Jan 29 23:44:13 +0000 2015,'Rise of the Machines' is Not a Likely Future http://t.co/RZ9zKA6wi9 a drop of sanity in a sea of mess
560881583683428350,Thu Jan 29 19:26:04 +0000 2015,I find it unnerving that at any point in a lecture and for anything you may say, some people are confused and some people are bored. :(
560292907630882800,Wed Jan 28 04:26:53 +0000 2015,Nice talk by John Leonard from MIT/CSAIL on self-driving cars and challenges https://t.co/AydKYAPx7G
559136674005803000,Sat Jan 24 23:52:25 +0000 2015,@crude2refined of course! You always make many epochs over the training data.
558688560711086100,Fri Jan 23 18:11:47 +0000 2015,@ShellyFan Only halfway through. I like it for the thoughts/ideas it triggers but I often don't agree with its conclusions. It's fun
558688221593219100,Fri Jan 23 18:10:26 +0000 2015,@ogrisel Only halfway through. So far I like, if only for triggering thoughts/ideas. But I often don't agree with its conclusions/approach.
558687406870638600,Fri Jan 23 18:07:12 +0000 2015,And then almost certainly staying up overnight to finish ConvNets assignment for the class. Not ideal I suppose
558687118155714560,Fri Jan 23 18:06:03 +0000 2015,Today: Deep Learning reading group. Superintelligence book club. Helping friend w LSTM. AI debate meeting. Happy hour #phdlife #notalawysbad
558139759105937400,Thu Jan 22 05:51:02 +0000 2015,I wonder if this would be a good time to ask for a free Model S.
558139454851121150,Thu Jan 22 05:49:50 +0000 2015,Elon Musk is retweeting today's Wired article about my struggle to compete against Google ILSVRC ConvNet. Now I just have to keep it cool.
558115403491455000,Thu Jan 22 04:14:16 +0000 2015,Caffe now evaluates AlexNet in 24ms / image on mobile GPU (NVIDIA Jetson TK1), on 10W budget, nice. http://t.co/BgooDMCMEV (via @petewarden)
558109265056243700,Thu Jan 22 03:49:52 +0000 2015,When Chris Manning surprise attends your lecture on neural nets and backpropagation #gulp
558083062924587000,Thu Jan 22 02:05:45 +0000 2015,@catzdong :D:D
557761864227381250,Wed Jan 21 04:49:25 +0000 2015,"It's with all of this in mind that my recommended language for teaching beginners is now Javascript." http://t.co/0XFaPElYDs Yes.
557468433407684600,Tue Jan 20 09:23:26 +0000 2015,@korirotti a) yes b) no. Good idea. Oh well, back to regular unflipped classes - I think this is what they want most
557408831055986700,Tue Jan 20 05:26:36 +0000 2015,@grayj_ I had a vision of eager undergrads who read through on their own, 90% made sense and they can't wait to ask about the last 10%. lol
557408064416935940,Tue Jan 20 05:23:33 +0000 2015,@mdreid Yeah I will as well. Seems flipped class only works in theory. When I took Daphne's class she also tried and it didn't work.
557407547980644350,Tue Jan 20 05:21:30 +0000 2015,@ShellyFan they were to submit questions before lecture with Google Moderator. I saw noone submitted anything so prepared basic lecture fine
557406586889457660,Tue Jan 20 05:17:41 +0000 2015,Tried to be hip and flip my class. Students were to read notes before lecture and submit questions. 0 questions asked. #flippedclassfail
557267701555408900,Mon Jan 19 20:05:48 +0000 2015,Group therapy session going on in the lab following the release of CVPR reviews #academia
556877709016449000,Sun Jan 18 18:16:06 +0000 2015,Saw Predestination yesterday. Feels like getting kicked in the brain. Takes a while to process. Like
556612020322050050,Sun Jan 18 00:40:21 +0000 2015,@aneesha I see - certificate. Hm. We'll look into it next year.
556606238180388860,Sun Jan 18 00:17:23 +0000 2015,@aneesha ... it is. What makes a MOOC?
556603068825870340,Sun Jan 18 00:04:47 +0000 2015,@ganeshkgp yeah, thanks -  we should try to find and point to more related references for you guys.
556600255496478700,Sat Jan 17 23:53:36 +0000 2015,@mariana_farinha haha "when it's done"
556599734031233000,Sat Jan 17 23:51:32 +0000 2015,Now I think of it, I don't think I want to start filling this in :\
556597953251377150,Sat Jan 17 23:44:27 +0000 2015,Writing up the most comprehensive guide to Neural Nets (for our class). The outline alone (in bullet form) is 2 pages long :\ oh oh
556548134004748300,Sat Jan 17 20:26:29 +0000 2015,Steven Levy has a few new articles on Google / Deep Learning + Geoff / DeepMind + Demis https://t.co/lKKZJdBStT
556161191957901300,Fri Jan 16 18:48:55 +0000 2015,RT @ch402: meta-SNE can visualize *spaces* of neural networks rather than individual ones, stepping up the ladder of abstraction http://t.c‚Ä¶
556154329447407600,Fri Jan 16 18:21:39 +0000 2015,Video of SpaceX Falcon 9 first stage exploding in failed attempt to land on drone ship https://t.co/10dUeEjHYA
555959618493358100,Fri Jan 16 05:27:56 +0000 2015,ICLR papers are now up http://t.co/l5T0V2bvjw . This year have to use CMT to see/submit comments https://t.co/8pY14n6HqR
555911908163727360,Fri Jan 16 02:18:21 +0000 2015,"Stochastic Optimization for x86 Binaries" https://t.co/S4tXONS9n7 saw this talk at Stanford - fun!
555824003055489000,Thu Jan 15 20:29:03 +0000 2015,@sdavidmiller NICE thanks :) imo was also sad to not see Interstellar in cinematography. Think they accidentally put it in sound mix instead
555816799074136060,Thu Jan 15 20:00:26 +0000 2015,@sdavidmiller I don't know how to feel about http://t.co/noOpg7OOHN and need you to tell me so that I can regurgitate it to my friends
555811990560460800,Thu Jan 15 19:41:19 +0000 2015,@flyfengjie thx! Will fix
555577541050638340,Thu Jan 15 04:09:42 +0000 2015,@sdavidmiller I think so!
555549853690773500,Thu Jan 15 02:19:41 +0000 2015,I'm giving a talk on Feb 5 for SF ML meetup on "Automated Image Captioning with ConvNets and Recurrent Nets" http://t.co/mujjmtY8Rj
555453458002632700,Wed Jan 14 19:56:38 +0000 2015,@ogrisel mentioned in ILSVRC paper: we had two labelers. Not strong because hard to find other person who wants to label 1500 ILSVRC images.
555435028734177300,Wed Jan 14 18:43:24 +0000 2015,@ogrisel Imo likely that ppl will surpass my score next ILSVRC. Based on our experiments, an ensemble human bound is somewhere ~3% error.
555428230677946400,Wed Jan 14 18:16:24 +0000 2015,Baidu gets 6% ImageNet top 5 error (prev state of art 6.6% by Google) http://t.co/YReQXQONY2 lessons: moar GPU, moar data aug, moar ensemble
555167887975923700,Wed Jan 14 01:01:53 +0000 2015,Starcraft AI tournament: 42 AI agents will play 861 games over next 5+ days. http://t.co/bFdr4so2Bq
554873778287570940,Tue Jan 13 05:33:12 +0000 2015,@sdavidmiller wtf I've never even heard of 4/5 of your top5. Dat domain name though - tear in my eye.
554828076815613950,Tue Jan 13 02:31:36 +0000 2015,@duyhtq no but I did consider embedding their faces with t-SNE.
554739213925896200,Mon Jan 12 20:38:29 +0000 2015,@kastnerkyle referring to previous tweet as well - there are relatively few tips and tricks for RNNs about, compared to eg CNNs
554737002013540350,Mon Jan 12 20:29:42 +0000 2015,@kastnerkyle this needs a write up longer than 140 chars ;)
554446886006837250,Mon Jan 12 01:16:53 +0000 2015,Kaggle ran CIFAR-10 competition, fun to see the CNN tricks that ppl came up with. Interview with some winners: http://t.co/wvwA2KkyZS
554446508045512700,Mon Jan 12 01:15:23 +0000 2015,Fractional Max Pooling for ConvNets http://t.co/EjJjOhV9Ur [pdf] quite interesting. Form of pooling and data augmentation at same time
554446215148867600,Mon Jan 12 01:14:13 +0000 2015,Noticing many ppl quoting my blog from few years ago measuring CIFAR-10 human error ~6%. Was from 400 imgs someone should do better job ;\
554426291005321200,Sun Jan 11 23:55:03 +0000 2015,Research priorities for robust and beneficial artificial intelligence [pdf] http://t.co/Zjc54DUIaC
554062862180560900,Sat Jan 10 23:50:54 +0000 2015,Wrote an educational (hopefully ;p) Linear Classifiers JS demo for our ConvNet class: http://t.co/1YaTStUF0I fun to play with (biased)
553850528740810750,Sat Jan 10 09:47:10 +0000 2015,CRS-5 launch in &lt;1 minute! gogo bird 9
553677373883703300,Fri Jan 09 22:19:07 +0000 2015,Michael Bay gifs. My coworkers find this medium funny but I can't stop laughing http://t.co/l8G7KgpQYo
553633726093991940,Fri Jan 09 19:25:40 +0000 2015,@RobTheForager hah. yeah I was and it worked just fine with the Matlab wrapper provided by Laurens.
553614161158996000,Fri Jan 09 18:07:56 +0000 2015,@RobTheForager Barnes Hut SNE for Laurens' website. It took seconds
553274254041415700,Thu Jan 08 19:37:16 +0000 2015,There are several methods for per-parameter learning rates (e.g. ada*) for deep nets. Haven't seen as much on per-parameter weight decays?
553104943112941600,Thu Jan 08 08:24:29 +0000 2015,Reviewing CVPR papers. My adviser is very good at predicting my final score (after few hours) from only ~5 second skim of paper. Dark magic.
552970790505693200,Wed Jan 07 23:31:24 +0000 2015,@jayalan_hack that's right. SUPERVISED pretraining has been very successful though ;) We'll talk about that in class soon.
552970640488005600,Wed Jan 07 23:30:49 +0000 2015,@derTimGerrits Right, I think I used Matlab for it, sorry :\ Someone has done this before using ImageMagick, but I can't remember how
552968452382548000,Wed Jan 07 23:22:07 +0000 2015,@derTimGerrits Yes. The data was preprocessed by me in a way where each image was stretched into a long row. You'd have to do same
552894642627563500,Wed Jan 07 18:28:49 +0000 2015,@derTimGerrits if it's longer question email me instead - email listed on my website.
552618457649262600,Wed Jan 07 00:11:22 +0000 2015,Calculate mode of list a in Python in one line: max(set(a), key=a.count)  #mindblown . Didn't know max can take a key
552571075918168060,Tue Jan 06 21:03:05 +0000 2015,@AlbertMeyburgh :( sorry to hear that! I have a much better pretrained COCO model (after ~3 weeks train) too now should update the model zoo
552519155577282560,Tue Jan 06 17:36:46 +0000 2015,@delliott thx, yeah I've seen it. We'll be making lot of changes for camera ready (if any :p) + workshop at berkeley about this soon.
552323954955026400,Tue Jan 06 04:41:07 +0000 2015,Elon Musk did an AMA today: https://t.co/GCaU7FWo2Y but you already knew that. sorry.
551960658896384000,Mon Jan 05 04:37:30 +0000 2015,@kcimc thanks! I think we found a solution just now, turns out Stanford offers a service for this.
551854353863036900,Sun Jan 04 21:35:05 +0000 2015,@skyberrys haha I should try that! :D
551840590787117060,Sun Jan 04 20:40:24 +0000 2015,Physics lectures on QM/GR/etc from Leonard Susskind http://t.co/VvDXzO0gwQ Sloooowly making my way through GR class inspired by Interstellar
551820429136916500,Sun Jan 04 19:20:17 +0000 2015,@shazow I think it's mostly about the "barrier to write" &amp; lowering it as much as possible. So whenever need strikes the pen&amp;paper is there
551820064085659650,Sun Jan 04 19:18:50 +0000 2015,@shazow I wish there was something more insightful I could say about it. I'd have to think about it more maybe :\
551819806022705150,Sun Jan 04 19:17:48 +0000 2015,@shazow Yep, can't recommend enough! I often need paper for ideas/todolist/etc so I make sure notebook is there&amp;rdy. Not much top down to it
551818370119499800,Sun Jan 04 19:12:06 +0000 2015,@shazow Almost every day, and I date all entries. I always open my current notebook right next to my keyboard so it's low barrier to write
551811995846996000,Sun Jan 04 18:46:46 +0000 2015,Was flipping a bit just now and noticed one sketch reoccurs over 6 years. A problem plaguing my mind for long time. Should get on that :)
551811583609798660,Sun Jan 04 18:45:08 +0000 2015,6 years of my research journal/notes/sketches. Very glad I keep them: lot of fun to flip back and see ideas develop http://t.co/y4pJUycK8z
551490106725367800,Sat Jan 03 21:27:42 +0000 2015,@dijkstracula @topher_batty I'm not so sure, the whole topic seems to me extremely hyper-sensitive.
551462662324764700,Sat Jan 03 19:38:39 +0000 2015,Whoa completely missed this! Walter Levin's excellent physics lectures were removed due to sexual harassment charges http://t.co/L0GG19MYMh
551235787178508300,Sat Jan 03 04:37:07 +0000 2015,This is making rounds: Machine Learning has a podcast now :) "Talking Machines" http://t.co/UERQNHan45 ep1 is up
551206811966009340,Sat Jan 03 02:41:59 +0000 2015,‚ÄúWhy aren‚Äôt we using SSH for everything?‚Äù by @shazow https://t.co/3ALUdEFAMu
551108078607667200,Fri Jan 02 20:09:39 +0000 2015,"Living under permanent surveillance and what that means for our freedom" Paints a bleak, unnerving future ;\ https://t.co/tMHpavQGLu
550865881002438660,Fri Jan 02 04:07:15 +0000 2015,New group of ppl could brag about how they engineered features back in late 2000's, and how it didn't work then because X but now...
550865201483231200,Fri Jan 02 04:04:33 +0000 2015,Wouldn't it be funny if some Computer Vision researcher engineered a really good image feature that beat &amp; deprecated CNNs? ;p
550777118289047550,Thu Jan 01 22:14:32 +0000 2015,@arnicas @AnnaFlagg oh hey it's Anna!!! Long time no see/hear :)
550383002455253000,Wed Dec 31 20:08:28 +0000 2014,@ShellyFan not yet, on my towatch list!
550378954821890050,Wed Dec 31 19:52:23 +0000 2014,"I can't stop comparing everything to Black Mirror | The Verge" &lt;3 black mirror, should be more widely known http://t.co/AKmn7MJXAs
549715588491124740,Mon Dec 29 23:56:24 +0000 2014,@sguada nice, thanks. Did you check about its transfer learning perf on some data? I heard its features were worse than VGG in transfer
549456460523249660,Mon Dec 29 06:46:43 +0000 2014,I rented the movie on YouTube &amp; liked it: "They hate us cuz they anus" &amp; "He's just peanut butter and jealous" are my new favorite quotes
549455897056280600,Mon Dec 29 06:44:28 +0000 2014,The Interview has now grossed ~$15M from online, ~$3M theaters. It cost ~$100M so still long to break even but nice http://t.co/UToPBkJ8pj
549362097616744450,Mon Dec 29 00:31:45 +0000 2014,@jeresig you mean great way to be completely mislead in almost all ways regarding Turing's life, research and legacy? Ok enjoyable though
548617503396474900,Fri Dec 26 23:13:00 +0000 2014,Writing course notes/assignments for our ConvNet class. By far hardest challenge so far: deciding on target audience https://t.co/DdZoP9Bo35
546915168483938300,Mon Dec 22 06:28:32 +0000 2014,Does noone else find it scary that it's so easy to remember huge amount of music? That's represented somewhere in the brain, taking up space
546817936480940000,Mon Dec 22 00:02:10 +0000 2014,@crude2refined no. I'm suggesting depth offers a solution to the problem. If all you have is one layer problem is fundamentally unfixable.
546388093465415700,Sat Dec 20 19:34:07 +0000 2014,Spotted on HN: "Amazon Picking Challenge: Win up to $26,000 and eliminate 30,000 jobs at Amazon" http://t.co/zX9U4tILZE
546380646948425700,Sat Dec 20 19:04:32 +0000 2014,E.g. some ppl I talked to think this is huge problem with deep learning. Wrong. Problem is with our shallow learning, function forms&amp; high-d
546378679853412350,Sat Dec 20 18:56:43 +0000 2014,I like all the recent work on adversarial examples. But I'm worried about confusions/misinterpretations it is causing for ppl outside field
546088621946581000,Fri Dec 19 23:44:07 +0000 2014,@flyfengjie haha definitely not - way too slow for that :)
546067400592855040,Fri Dec 19 22:19:48 +0000 2014,@CorderoRama oh oh. Should have made it cleaner and more commented :\ I wanted to make full blog post on it but severely time constrained
546060824503017500,Fri Dec 19 21:53:40 +0000 2014,@arnicas there are thousands of words so the softmax would be more expensive. Not clear how to handle special chars. Also much less cool :D
546059709409525760,Fri Dec 19 21:49:14 +0000 2014,@arnicas haha, it's... a first step. I think we need a bigger net trained for longer! ;)
546058040588259300,Fri Dec 19 21:42:36 +0000 2014,@arnicas bleh UI fail. I'm pretty sure it loaded the model. you should see perplexities of about 3 almost instantly and better predictions
546057277724033000,Fri Dec 19 21:39:34 +0000 2014,@arnicas sorry that was a mistake i forgot to take out. I didn't prefill it into the area, the button below textarea loads it direct instead
546054227210936300,Fri Dec 19 21:27:27 +0000 2014,The code is not beautifully modularized so far and needs backprop understanding to use, but I'm too swamped with things to fix it right now
546054055705841660,Fri Dec 19 21:26:46 +0000 2014,Yesterday I released code for training Deep RNN/LSTM in Javascript (because why not). Fun sentence-memorization demo: http://t.co/hlrC7ZxPmc
546024172728483840,Fri Dec 19 19:28:02 +0000 2014,This seems very obvious to me as well, and why I find all sci-fi that features biological aliens with bodies intellectually shallow
546023920449511400,Fri Dec 19 19:27:01 +0000 2014,The Dominant Life Form in the Cosmos Is Probably Superintelligent Robots http://t.co/2oLhbUIuqA &amp; don't miss PDF: http://t.co/NPOWMWA6Dt
545815820597989400,Fri Dec 19 05:40:07 +0000 2014,RT @berty38: On the NIPS Experiment and Review Process http://t.co/UUyjZFtnFs
545803619631525900,Fri Dec 19 04:51:38 +0000 2014,@t3kcit http://t.co/Qu1SpERMXr yes :D
545803112552742900,Fri Dec 19 04:49:37 +0000 2014,Notch bought a $70M house in Beverly Hills http://t.co/Ae27ex0oHZ Well, wow. Nice
545768693959901200,Fri Dec 19 02:32:51 +0000 2014,@t3kcit convnet class
545737519040458750,Fri Dec 19 00:28:58 +0000 2014,Do I get to complain multiple times about how much work putting together notes/vids/assignments for an ambitious new class is? No? Okay fine
545635623839617000,Thu Dec 18 17:44:04 +0000 2014,http://t.co/x2anYnon1I : Spin up instances, scale them up/down on fly, collaborate live on them, share them with urls... dark magic.
545486731043016700,Thu Dec 18 07:52:25 +0000 2014,Using convolutional neural nets to detect facial keypoints tutorial ‚Äî Daniel Nouri's Blog http://t.co/6JTakHgVhp
545460750655815700,Thu Dec 18 06:09:11 +0000 2014,Might finally start trading stocks like a pro with Robinhood. Is nice https://t.co/5cfoIvU6Xy btw if u sign up I get bonus kthx :p #honesty
545102510290001900,Wed Dec 17 06:25:40 +0000 2014,Finally watched last Hobbit and... It was bad! As in opposite of good! Last part of journey! Peter, I trusted you! /fallstoknees Ughhgbhvhhh
544619424800456700,Mon Dec 15 22:26:04 +0000 2014,The NIPS experiment: most papers at NIPS would be rejected if one reran the conference review process http://t.co/8kZgbfdrGt
544251978864263200,Sun Dec 14 22:05:58 +0000 2014,Two things hit me immediately on arriving back to Bay Area: 1 wow the weather is so comfy/pleasant and 2, Teslas sightings are back!
543855621523902460,Sat Dec 13 19:50:59 +0000 2014,@shazow Permission denied :(
543393940553338900,Fri Dec 12 13:16:25 +0000 2014,@manujeevaan yeah it's more like a big index than a guide
543228951041028100,Fri Dec 12 02:20:49 +0000 2014,@ShellyFan not sure which one you have but probably yes. Chocolate welcome.
543167945187557400,Thu Dec 11 22:18:24 +0000 2014,My friend Roger is still building up Metacademy: http://t.co/oVZGkqPQSs has grown quite a bit last few years, many references to ML concepts
543115142561804300,Thu Dec 11 18:48:35 +0000 2014,Jeff Dean: "I like your ConvNets in Javascript". Me: "Thank you. I like your map reduce."
542410370644590600,Tue Dec 09 20:08:04 +0000 2014,@zer0nes yep, I know, I think ConvNets are "funnest" models to break because people like to look at pictures. It's more general phenomena
542392370260484100,Tue Dec 09 18:56:32 +0000 2014,Someone is breaking ConvNets again http://t.co/CtYgMyisl4 haven't read yet but looks like another nice paper in Intriguing properties series
542383557671669760,Tue Dec 09 18:21:31 +0000 2014,@dijkstracula in downtown area, conference center. ppl usually speak english okay but the default for everything is consistently french.
542378143223652350,Tue Dec 09 18:00:00 +0000 2014,I thought Montreal was supposed to be bilingual, but really it's 100% french. Luckily only knowing bonjour &amp; merci sufficient for 50% convos
541976470646972400,Mon Dec 08 15:23:54 +0000 2014,@dfarmer you'd be just as productive on your plane ride for something you kinda did 10 times before :) plane coding not fun: raptor hands :p
541975319105011700,Mon Dec 08 15:19:20 +0000 2014,@traboukos lol you can stop that - in at NIPS so pretty busy :) I'll see if I can squeeze in something
541773622994829300,Mon Dec 08 01:57:52 +0000 2014,@yigitdemirag 0.5 similar :)
541758233421963260,Mon Dec 08 00:56:42 +0000 2014,Managed to write RNN/LSTM in JavaScript on the plane though. Makes for very cool character-level language sampling demo. Eager to put up
541757637457477600,Mon Dec 08 00:54:20 +0000 2014,Landed in Montreal for #NIPS2014. In my shirt and light jacket. Forgot how biting Canadian winters are
541343962703728640,Sat Dec 06 21:30:33 +0000 2014,Working with BLEU scores has its tolls. I keep spelling bleu as "blue" in my code and now I start to accidentally spell blue as "bleu" IRL
540941684188540900,Fri Dec 05 18:52:02 +0000 2014,Congrats to good friend @RichardSocher and his new and exciting Deep Learning startup! http://t.co/dH4WtGyOXd a company to watch closely.
540746865210187800,Fri Dec 05 05:57:53 +0000 2014,Well, now that I've kind of given up on ICLR to preserve my sanity, it's time to catch up on some Starcraft 2 replays ;p
539950730002440200,Wed Dec 03 01:14:20 +0000 2014,How to write a good CVPR submission by Bill Freeman. A lot of really good general advice on paper writing! https://t.co/fyn1FuHXPW
539946429192495100,Wed Dec 03 00:57:15 +0000 2014,RT @TeslaMotors: New Consumer Reports owners survey rates Model S the most loved car. 98% would buy again. https://t.co/XARoD5iAI1
539638325833789440,Tue Dec 02 04:32:57 +0000 2014,@fulhack :) Imo deep nets work just fine with nearly-impossible-to-optimize costs. My guess is you'll get low accuracy but it will play well
539619215020290050,Tue Dec 02 03:17:01 +0000 2014,@fulhack nice! Would have loved to see some 1st layer feature vis. Also wish you tried simple softmax for board -&gt; eventual win/loss.
539618070428270600,Tue Dec 02 03:12:28 +0000 2014,RT @fulhack: Deep learning for... chess http://t.co/P37etDtgsC (new blog post)
539216935649439740,Mon Dec 01 00:38:30 +0000 2014,Really looked forward to seeing Imitation game since release date is listed as last Friday. Turns out it's a super-limited release. Not okay
539199698339233800,Sun Nov 30 23:30:00 +0000 2014,@sguada so are LSTMs coming to Caffe? I need to move training to GPU, takes way too long on CPU. Would prefer not to reinvent wheel
539134922158391300,Sun Nov 30 19:12:36 +0000 2014,@johnplattml thanks! :) philosophically/technically I think my more recent approach has more appealing grounding model but same core idea!
538775380828500000,Sat Nov 29 19:23:55 +0000 2014,@mbeissinger no need. The gradients are quite trivial to derive and I don't need to subject code to new dependency and its API. Why should I
538530771850760200,Sat Nov 29 03:11:56 +0000 2014,NIPS2014 papers in pretty format, as I always do: http://t.co/facesRwWpA only takes ~2 hours to put together now, phew.
538470915055435800,Fri Nov 28 23:14:05 +0000 2014,Deep Learning Master Class in Tel Aviv from Nov5,6 http://t.co/thK98Cf1Ph (slides+videos)
538469197546659840,Fri Nov 28 23:07:15 +0000 2014,@sguada Yeah I train ~30+ epochs. You have nice F30K results (59,39,25) ; With code I released now only at ~51,31,15. Trying to close gap
538455687601221600,Fri Nov 28 22:13:34 +0000 2014,@sguada Right now I'm at BLEU 52,33,16. They report 63,41,27 so quite a bit of gap to close. Not sure what to expect in end with VGG feats
538446093818675200,Fri Nov 28 21:35:27 +0000 2014,@sguada no I used Karen's VGG net which achieved similar performance in ILSVRC2014 to GoogleNet. VGGNet is public, GoogleNet isn't.
538414823541731300,Fri Nov 28 19:31:11 +0000 2014,@harthvader haha yeah there's no way without numpy. Also needs GB of data. Maybe once JS has nice/efficient WebGL numpy-ish matrix lib
538412095553818600,Fri Nov 28 19:20:21 +0000 2014,@dfarmer good luck! I'd like to say that this easy... the core is but surrounding it there are also many tedious edge details and subtleties
538410158695526400,Fri Nov 28 19:12:39 +0000 2014,@harthvader :((( wanted this to be in Javascript so bad... :D
538403855348674560,Fri Nov 28 18:47:36 +0000 2014,Also as word of caution I wasn't yet able to reproduce Google with CNN+LSTM (I get close though), so there might be some residual issues
538402354588958700,Fri Nov 28 18:41:39 +0000 2014,Wrote this codebase from scratch over last week so I hope there aren't too many bugs/issues. It gradchecks fine and gives nice final results
538402023930986500,Fri Nov 28 18:40:20 +0000 2014,I open sourced some Python/numpy CNN+LSTM/RNN code for training Recurrent Nets that describe images with sentences https://t.co/8oZlYBKbKL
538210883625685000,Fri Nov 28 06:00:48 +0000 2014,@yigitdemirag Looks like I'll convert my Neural Nets Hacker's guide to Gitbook, like alot.
538210204232323100,Fri Nov 28 05:58:06 +0000 2014,@yigitdemirag Wasn't aware of gitbook, I like it! Right now I'm rolling with a custom Jekyll build &amp; Table of Contents. Not public until Jan
538205891607023600,Fri Nov 28 05:40:58 +0000 2014,Making course notes for the ConvNet class we'll be teaching next quarter. I'm 30% through first week's stuff and it takes forever #trouble
538180839373152260,Fri Nov 28 04:01:25 +0000 2014,@iandanforth yep!
538180839373152260,Fri Nov 28 04:01:25 +0000 2014,@iandanforth yep!
538150376780738560,Fri Nov 28 02:00:22 +0000 2014,Bought tickets for very first and biggest IMAX showing of last Hobbit. Disappointed it's at 7pm instead of mightnight and only 2:30hrs :(
538139734951075840,Fri Nov 28 01:18:05 +0000 2014,@MJcocoChoi Not sure how I feel about all the drop shadows. Bigger fan of the aesthetics of Flat UI. :(
538084912868237300,Thu Nov 27 21:40:15 +0000 2014,@sgsfak haha whoa! Yes, I was :D Hate thanksgiving!
538060058098024450,Thu Nov 27 20:01:29 +0000 2014,Border Patrol Checkpoint Refusal videos https://t.co/Y1poaVa0y3 good coverage of these on recent This American Life podcast.
538043440164909060,Thu Nov 27 18:55:27 +0000 2014,@korirotti haha. I'm just being lazy and dramatic. Biked to PA and got some food :)
538039331718299650,Thu Nov 27 18:39:07 +0000 2014,@ShellyFan I would pay anything. So hungry!
538038222425567200,Thu Nov 27 18:34:43 +0000 2014,Got a snickers bar from basement vending machine. This has to do for breakfast. Now out of coins. #thanksgivingsurvival
538036939866128400,Thu Nov 27 18:29:37 +0000 2014,Stranded on Stanford campus, Everything is closed. Hard to concentrate on code when starving. I'm in a pickle!
537849558878126100,Thu Nov 27 06:05:02 +0000 2014,RT @ylecun: A lot of opinions about the potentials benefits and dangers of AI in the comments to this piece by Jaron Lanier.... http://t.co‚Ä¶
537818659305967600,Thu Nov 27 04:02:15 +0000 2014,@robertsdionne yeah, you just have to be careful about it and have a test for when gradcheck is on or something. Possible, but pain :)
537790431845564400,Thu Nov 27 02:10:05 +0000 2014,@jeremyphoward @peteskomoroch One Google doc :p
537788949402382340,Thu Nov 27 02:04:11 +0000 2014,@Soukhinov yeah, that would probably work to some degree. reminds me of http://t.co/vufHuT0H6x
537782239468089340,Thu Nov 27 01:37:32 +0000 2014,Protip: if you try to gradient check your neural net and forget to turn off dropout, you're going to have a baaaad time. #only1hrwasted
537779623904309250,Thu Nov 27 01:27:08 +0000 2014,@jeremyphoward :D
537732177257979900,Wed Nov 26 22:18:36 +0000 2014,COCO dataset headaches. Many giraffes bathrooms &amp; buses, near-duplicate images (not careful =&gt; training on test), extreme train:val split...
537404478115176450,Wed Nov 26 00:36:26 +0000 2014,There's something funny about writing code to give self achievements &amp; then feeling happy about them. shouldn't work. Loophole to happiness
537404301094563840,Wed Nov 26 00:35:44 +0000 2014,my ulogme gave me an achievement badge for writing more code today than last 3 days put together. (&amp; it's only 4pm - nice!)
537392331792453600,Tue Nov 25 23:48:10 +0000 2014,OpenCV Vision Challenge with $50,000 price pool to update and extend OpenCV on 11 CV tasks http://t.co/boByx7Su1j
536326339687485440,Sun Nov 23 01:12:18 +0000 2014,Cleaning up &amp; re-implementing a codebase from scratch is U-shaped: early enthusiasm, deep depression, retrospective joy. Right now in middle
536234675862110200,Sat Nov 22 19:08:04 +0000 2014,@notmisha haha! Hhmmmm I like that! or a Reddit comments bot, since reddit likes those. Btw coming to NIPS?
536233289275564000,Sat Nov 22 19:02:33 +0000 2014,@notmisha I might implement an LSTM module and make an image sentence generation learning demo, since people seem to go bananas over that :D
536229475348803600,Sat Nov 22 18:47:24 +0000 2014,@notmisha  make sure to check the main site then there are 9 demos :)
536228838020087800,Sat Nov 22 18:44:52 +0000 2014,@notmisha this is from a year ago - you didn't just discover ConvNetJS right? :)
535916172588249100,Fri Nov 21 22:02:27 +0000 2014,One of my takeways was the (unnecessary) coupling between representation size and number of parameters in RNNs. Seems like design flaw
535915838553874400,Fri Nov 21 22:01:07 +0000 2014,We read Neural Turing Machines at reading group http://t.co/hh5HI8HBk6 a lot of subtle details and ideas between the lines. Hard/cool read
535883708910157800,Fri Nov 21 19:53:27 +0000 2014,My friend crushed his dataset not by creating better model but by swapping in more powerful CNN (VGG net). Don't think that's publishable...
535841398671433700,Fri Nov 21 17:05:19 +0000 2014,@mdammers working on it!
535551266500263940,Thu Nov 20 21:52:26 +0000 2014,A quarter million people visited our image-sentence project website yesterday. That seems like a lot of people.
535526447486480400,Thu Nov 20 20:13:49 +0000 2014,@ogrisel thanks, I was going to make it more elaborate at some point: stages of progressively harder problems, multiple agents, etc. one day
535237935030100000,Thu Nov 20 01:07:22 +0000 2014,Jackpot, a 2 paragraph walkthrough of this form found on Yahoo Answers, in English. Thank you, you beautiful anonymous soul on the internet.
535236740920131600,Thu Nov 20 01:02:37 +0000 2014,I wish tax forms and related legal documents were written in English. I had to stumble on a 2-sentence Yahoo answers post to get this one
535224703565463550,Thu Nov 20 00:14:47 +0000 2014,@pchapuis @revolunet @amicel :) I wouldn't say that, these are surface understanding models, not close to what article describes.
535190644109893600,Wed Nov 19 21:59:27 +0000 2014,There are almost 2,000 people on our image - sentence generation website right now, including 1,000+ from Reddit but I can't find the source
534866240716963840,Wed Nov 19 00:30:23 +0000 2014,Someone used my tsnejs library to create a browser demo that embeds music snippets in 2D: http://t.co/lUmuLZ3G64 fun!
534830130820960260,Tue Nov 18 22:06:54 +0000 2014,I missed a nice article about ConvNetJS from a week ago: Browser-Based Deep Learning Will Make Your Tabs Way Smarter http://t.co/av19ZMJO9Z
534794848134365200,Tue Nov 18 19:46:42 +0000 2014,My stack of papers to read is now at ~20. This field should move slower. Lets all calm down for a second.
534751102986489860,Tue Nov 18 16:52:52 +0000 2014,@haldaume3 @brendan642 it was. I now learned a lot about how/why articles like this get written. And it's not at all what I thought it was.
534573841796710400,Tue Nov 18 05:08:30 +0000 2014,@iandanforth haha thank you I will incorporate these! Lucky for me I have the "not a native english speaker" excuse card :)
534554329294716900,Tue Nov 18 03:50:58 +0000 2014,@fchollet there's a huge line of work on generating sentences. I like these models because you can sample, go both ways, finetune all, etc.
534554000872321000,Tue Nov 18 03:49:39 +0000 2014,@sguada @peteskomoroch hey Sergio! I guess so :S. Not sure how they pick, this just popular media / press for you. Looks like Awesome paper!
534553234744934400,Tue Nov 18 03:46:37 +0000 2014,I cataloged these in HN comments section https://t.co/vQmxrG13SW with pointers. I became aware of these works only last week &amp; today.
534552865570709500,Tue Nov 18 03:45:09 +0000 2014,To be fair by the way I'm now aware of 5 separate groups who worked concurrently on closely-related image/text projects. NYT mentions 2/5
534548625779470340,Tue Nov 18 03:28:18 +0000 2014,@mdreid @_onionesque Thanks! I don't feel best about it, now knowing there are 5 groups of ppl who had similar results, and 2 of us get PR
534545620741025800,Tue Nov 18 03:16:22 +0000 2014,@iandanforth unlike all other models mine also tries to describe image regions, so that might work okay. But yeah on fullframe might be hard
534535452468850700,Tue Nov 18 02:35:57 +0000 2014,@kastnerkyle You mean generating images? That would be fun, but seems quite impossible! You'd get blurry color blobs at most :) Yes, joint.
534527392560074750,Tue Nov 18 02:03:56 +0000 2014,Also, Google wrote about their paper with a few more examples on a blog post: http://t.co/jAHaazHCnW
534524142268055550,Tue Nov 18 01:51:01 +0000 2014,@petewarden Definitely! I'm overwhelmed with work on multiple fronts this week, but I'd be happy to sometime before NIPS (dec 7)
534496775168475140,Tue Nov 18 00:02:16 +0000 2014,Our work on using Recurrent Neural Networks to generate image descriptions is featured in a New York Times article: http://t.co/SyMB30qcYg
534494654629048300,Mon Nov 17 23:53:50 +0000 2014,RT @petewarden: Congratulations to my team mates, and @karpathy, for their amazing work on image descriptions, it's really magical! http://‚Ä¶
534494601982119940,Mon Nov 17 23:53:38 +0000 2014,@petewarden thanks :) Recurrent Nets and sequence learning is awesome, I'm working quite a bit on making all of this work better now.
533758871399968800,Sat Nov 15 23:10:06 +0000 2014,@fchollet I feel like any second they could introduce new features and I'll permanently screw up my account &amp; have to reregister :)
533751295513870340,Sat Nov 15 22:40:00 +0000 2014,Worries of what their ML models think of my prefs is something I also experience on Prismatic/Flipboard/YouTube/FB, many sites. #mlanxiety
533750319516094460,Sat Nov 15 22:36:07 +0000 2014,I want to skip this song on Spotify but I'm worried that their ML model will think that I don't like this kind of music. Better let it play
533733292931940350,Sat Nov 15 21:28:27 +0000 2014,Haha Yann is proposing to measure intelligence in units of Paris Hilton: e.g. my neural net is rated at 42 kiloPH :D https://t.co/WPJWWaFCnD
533127748521185300,Fri Nov 14 05:22:14 +0000 2014,The work of blah et al. \cite{blah} actually seems like a really nice idea. And we're not all that different. #honestpapers
533127256382517250,Fri Nov 14 05:20:17 +0000 2014,We set $\alpha = 0.1$ because that's the only number we had time to try and it seemed to work okay #honestpapers
533127218516344800,Fri Nov 14 05:20:08 +0000 2014,Our model works okay in some specific cases, but we wouldn't really use any of this in practice. #honestpapers
532822781738491900,Thu Nov 13 09:10:25 +0000 2014,PhD is a process of building a generative model of your adviser.
532754340432187400,Thu Nov 13 04:38:27 +0000 2014,... so if our eyes could see in the MHz range, would things be relatively dark and our phones would be little pocket lamps?
532638312096219140,Wed Nov 12 20:57:24 +0000 2014,@jayatwork thank you! I'm getting very positive response to it, works nicely to motivate further work. Coming soon!
532604658787704800,Wed Nov 12 18:43:40 +0000 2014,Looks like we landed on a comet! Also this is GIF of trajectory of the mission: http://t.co/ghp0kycu2r Four slingshots around solar system
532441377628377100,Wed Nov 12 07:54:51 +0000 2014,And my labmate just pulled out a toothbrush. That's how you know things just got serious. #midnightatoffice #deadlinetime #phdlife
532344661994905600,Wed Nov 12 01:30:32 +0000 2014,@topher_batty I think the argument is that unnecessary fear mongering is unnecessary. Plenty of more worrying things to worry about
532304289373245440,Tue Nov 11 22:50:06 +0000 2014,Rodney Brooks on AI http://t.co/UwVluQJfgu "Worrying about AI that will be intentionally evil to us is pure fear mongering"
532263415465910300,Tue Nov 11 20:07:41 +0000 2014,@dna_nerd t-SNE is an awesome thing to have in toolbox, I throw it at all the things.
532235210943762400,Tue Nov 11 18:15:37 +0000 2014,@stanfordnlp it was even worse I later found: Gave inflated scores sometimes. They filtered ngram precisions to nonzeros then took geom mean
532013762937487360,Tue Nov 11 03:35:40 +0000 2014,‚ÄúWe‚Äôre so grateful that all of you sucked at sports ... cause if you could throw a football, we‚Äôd all have polio.‚Äù lol
532013284996550660,Tue Nov 11 03:33:46 +0000 2014,Words can't express how awesome this is: Silicon Valley Rolls Out the Red Carpet for Science with Breakthrough Prize http://t.co/CZRc575ixY
531904878348492800,Mon Nov 10 20:22:59 +0000 2014,Geoff Hinton is doing AMA today, just in case you haven't seen this link 1,000 times now http://t.co/da9BL2rlhr
531617210288975900,Mon Nov 10 01:19:54 +0000 2014,@kyloma I know, it grew out of control. A bit :). Thanks for the link!
531532352481030140,Sun Nov 09 19:42:42 +0000 2014,On The Science of Interstellar. Just whoa. I have physics background yet understood ~nothing but that was awesome. http://t.co/yG8Y9wr9Y7
531371106171514900,Sun Nov 09 09:01:58 +0000 2014,Re: my morning overly excited about day tweet. I wrote max-sum inference for factor graph, related work section &amp; fixed a bug #14hrslater :\
531165310397587460,Sat Nov 08 19:24:13 +0000 2014,You sit down at your desk knowing you'll work the next 14 hours. Day is full of possibilities and juicy results. CVPR due Friday &lt;partytime&gt;
530980574358274050,Sat Nov 08 07:10:08 +0000 2014,Interstellar was neat and intense. Except for one comment from Anne Hathaway's character about love as force similar to gravity in universe
530848584929783800,Fri Nov 07 22:25:40 +0000 2014,@hwassner where are you reading -1? Not sure exactly. If you pointed me at something concrete could help more. Or can create Issue on github
530795517140541440,Fri Nov 07 18:54:47 +0000 2014,@hwassner thanks for reporting this! Can't think why off top of my head this would happen. Try to scale features to be in [-1, 1]
530537760302833660,Fri Nov 07 01:50:33 +0000 2014,Vinod Khosla on Machine Learning, future of productivity, abundance and worries of growing income disparity http://t.co/qx8XxSMFQT
530497319540908000,Thu Nov 06 23:09:51 +0000 2014,Ross switched RCNN from AlexNet to (bigger, much simpler) VGGNet, VOC2007 mAP boosted 58.5 -&gt; 66.0 mAP. Nice boost! http://t.co/sLvZQ5cM12
530493742651047940,Thu Nov 06 22:55:39 +0000 2014,World's Craziest Teeterboard Flips http://t.co/2Ol64Vib7L in general been subscribed to Devin's YouTube channel for a while, amazing vids
530144602754273300,Wed Nov 05 23:48:17 +0000 2014,@ogrisel i'm touching on it, but not really in a conventional setting.
530136584796913660,Wed Nov 05 23:16:25 +0000 2014,I spotted a bug in NLTK where they would return BLEU score 1 when it should be 0. It was there for 4 months. Bit scary. It's been fixed now
530072707287638000,Wed Nov 05 19:02:36 +0000 2014,Related would be neat to see OCR adversarial examples: smallest change you have to make to a word to misclassify it as another given word
530071332189257700,Wed Nov 05 18:57:08 +0000 2014,Reverse OCR http://t.co/Yw0p54LSHk neat! Is in theme of taking ML models, treating them as blackbox and messing with inputs in fun ways
529966812771786750,Wed Nov 05 12:01:49 +0000 2014,@ogrisel @kastnerkyle I didn't: my RNNs are not very long so I thought I could get away without. I'll probably end up adding it later
529781730643689500,Tue Nov 04 23:46:22 +0000 2014,@kastnerkyle @ogrisel tried rmsprop overnight on RNN w sparse feature problem and got nice results. I'll fold this into my crossval pipeline
529730861894471700,Tue Nov 04 20:24:14 +0000 2014,@shazow I e maximize the luck surface area. Plan against universe in expectation :)
529443847592345600,Tue Nov 04 01:23:44 +0000 2014,@_onionesque haha. I don't think it will ever be done but it could get more complete :) Paradoxically it being posted makes that more likely
529442460976414700,Tue Nov 04 01:18:13 +0000 2014,@niru_m haha, yeah I was browsing through currently registered students on Axess and spotted you :) Looking forward to it!
529436622350077950,Tue Nov 04 00:55:01 +0000 2014,My hacker's guide to Neural Nets leaked to HN and thousands of people descended on an unfinished tutorial #selfconscious
529409975039176700,Mon Nov 03 23:09:08 +0000 2014,RT @kastnerkyle: Nice paper showing benefits of RMSprop cc @ogrisel @karpathy http://t.co/OIaIsEhfR2
529402734206672900,Mon Nov 03 22:40:22 +0000 2014,@niru_m haha, thank you :). I think it's a jumbled and long mishmash of stuff, but very little time to tweak on it these days. Bleh!
529162847461183500,Mon Nov 03 06:47:08 +0000 2014,Article on Elon's recent quotes about AI and the imminent worse-than-nukes dangers http://t.co/eoV3Xe7BR9
529158490971836400,Mon Nov 03 06:29:50 +0000 2014,Back when I was ~8 yr old I spent countless hours playing The Incredible Machine. Now modernized: Contraption Maker http://t.co/sOe6FxxxiQ
528739690191417340,Sun Nov 02 02:45:40 +0000 2014,@neurobongo odd, i got mine ~month ago or something. I thought it was okay, but stopped using now ;\ not very yummy
528487304558415900,Sat Nov 01 10:02:46 +0000 2014,@petewarden love that show! Hidden gem
528398123794575360,Sat Nov 01 04:08:24 +0000 2014,My adviser forces us to write up a full, 8-page paper draft 2 weeks before deadline. It sounds bad but it actually works really well
528331544000462850,Fri Oct 31 23:43:50 +0000 2014,@neurobongo yeah, good point. Le sigh.
528329846532100100,Fri Oct 31 23:37:05 +0000 2014,I can spend a week doing something that adds 1 sentence to my paper. And I can spend 1 day doing something that adds a whole page.
528329729850736640,Fri Oct 31 23:36:38 +0000 2014,The vast discrepancy between number of days of work and number of words in the paper describing it/the outcome is depressing.
528279871467061250,Fri Oct 31 20:18:30 +0000 2014,@ogrisel nice! rofl @ shoutout :D
528259375136137200,Fri Oct 31 18:57:04 +0000 2014,Virgin Galactic's SpaceShipTwo Crashes During Flight Test, one pilot died. http://t.co/O4vCJ39zbl sad few days for space flight
527731319942311940,Thu Oct 30 07:58:46 +0000 2014,Google Scholar is not very usable. This paper shows that maintaining your list of publications is in fact NP-hard http://t.co/2GZQcBJ1A4
527704648790966300,Thu Oct 30 06:12:47 +0000 2014,Scene Understanding by Labeling Pixels http://t.co/Dd1NpAhF9N Quite amusingly executed video, especially the narration :)
527667640831995900,Thu Oct 30 03:45:43 +0000 2014,Surprised that this nice band comes from Microsoft  http://t.co/ozraOo8vob Hmmm. If I have this on my left hand and an iWatch on my right...
527567699891986400,Wed Oct 29 21:08:36 +0000 2014,Nature explores the most-cited research of all time http://t.co/S52DvQGpeS Only 14,499/58M papers in database cited &gt; 1000 times.
527327087942578200,Wed Oct 29 05:12:29 +0000 2014,Stanford community alert: A mountain lion has been sighted (near where I live). A great time to stay in lab late. #stanford
526645775866949600,Mon Oct 27 08:05:12 +0000 2014,@albert_swart haven't played with CWRNNs yet. Agreed that it would be fun to try. Have to do these one at a time and carefully.
526590695318892540,Mon Oct 27 04:26:20 +0000 2014,@volkancirik Python and numpy
526482738975481860,Sun Oct 26 21:17:21 +0000 2014,@mla_lma Didn't get a chance to read the paper yet but it looks really good and is on my todo list. One thing at a time :)
526480567735296000,Sun Oct 26 21:08:43 +0000 2014,@edersantana Yep, it's a small change once you have the forward direction written up.
526480406569177100,Sun Oct 26 21:08:05 +0000 2014,@jeremyphoward I'll report on how it goes. And yep, it's for NLP stuff, including generation.
526471402707091460,Sun Oct 26 20:32:18 +0000 2014,Implementing an LSTM. Curious if it lives up to some of the hype and does better than my vanilla bi-direcitonal RNN.
526240746228027400,Sun Oct 26 05:15:45 +0000 2014,Secret hobby: using hip apps all the undergrads use, learning all the in jokes and trying to blend in. My yak just got 5 upvotes #soproud
526221169339281400,Sun Oct 26 03:57:58 +0000 2014,I googled "performance tips numpy" and clicked on everything. 1 hour later I'm #facepalm ing for not having done this earlier
525780719826522100,Fri Oct 24 22:47:46 +0000 2014,@iandanforth yeah I don't see a problem. You'd set num_actions = 4 in your example, and then reward you send in backward() is arbitrary
525437705459494900,Fri Oct 24 00:04:45 +0000 2014,Article on rendering scientifically accurate black holes for Interstellar http://t.co/nUCI0QU0qV I really hope this movie wont let me down
525078098740383740,Thu Oct 23 00:15:48 +0000 2014,Another (likely very nice) paper on using Recurrent nets/LSTMs to learn programs http://t.co/Qct6RrIv09 very like
525068250053230600,Wed Oct 22 23:36:40 +0000 2014,@stanfordnlp Yep, I'm using GloVe now instead of word2vec :) But it's funny that stopwords would be the reason!
525054146961879040,Wed Oct 22 22:40:38 +0000 2014,@ivoflipse5 that's a frequently asked question! The answer could be in the FAQ section :D
525053582412746750,Wed Oct 22 22:38:23 +0000 2014,Quite excited about it, I hope to make it thorough, polished and open.
525053138718322700,Wed Oct 22 22:36:37 +0000 2014,I will be co-teaching a Stanford CS class next quarter: CS231n Convolutional Neural Networks for Visual Recognition http://t.co/taI5KzST7k
525046277373845500,Wed Oct 22 22:09:22 +0000 2014,Zuck gave a Q&amp;A at Tsinghua, in Mandarin. https://t.co/ttmDYeZuud impressive :)
525043854177628160,Wed Oct 22 21:59:44 +0000 2014,RT @notmisha: DeepMind unveils broad alliance with University of Oxford http://t.co/FPSVzAoRae
524806139108528100,Wed Oct 22 06:15:08 +0000 2014,What It Took for SpaceX to Become a Serious Space Company http://t.co/FE3pCLuVys nice, long article
524711590281498600,Tue Oct 21 23:59:26 +0000 2014,TweetNLP: tokenizer, a part-of-speech tagger, hierarchical word clusters, and a dependency parser for tweets http://t.co/Cuw91eTuQW nice!
524632777790996500,Tue Oct 21 18:46:16 +0000 2014,@dna_nerd I assume some people are doing that? Read somewhere that ebolavirus doesn't seem to mutate too quickly wonder if there are strains
524631962892238850,Tue Oct 21 18:43:01 +0000 2014,A Neural Turing Machine is a differentiable computer, can learn programs. Superneat  http://t.co/dLqzDeNrHh
524628223817044000,Tue Oct 21 18:28:10 +0000 2014,Another cool company (Firebase) gets snatched up by a big fish (Google) https://t.co/Dg7N1fozoz not a huge fan of this trend.
524378038394294300,Tue Oct 21 01:54:01 +0000 2014,word2vec pretrained word vectors exclude some common stop words like 'a' / 'of' / 'and'. Odd. Breaks my model
524309741749547000,Mon Oct 20 21:22:38 +0000 2014,Fascinating, the genome of the current pandemic strain of Ebola is only 4.7kb. Full sequence here: http://t.co/pq5mpE3kto
524081519208300540,Mon Oct 20 06:15:45 +0000 2014,Super-resolution microscopy http://t.co/3JeYWnQvYp :O
524008050475016200,Mon Oct 20 01:23:49 +0000 2014,btw Steve Jobs famously based the layout of Pixar on that insight http://t.co/guWxZJTzFc (cc @mdreid )
524005808837632000,Mon Oct 20 01:14:55 +0000 2014,The intensity of friendships and collaborations is strongly predictable from whether the two parties share a subset of path to the restroom
524001298828382200,Mon Oct 20 00:56:59 +0000 2014,This looks like an Epic tutorial on visualizing data in Javascript http://t.co/i3HRovvdlj need to have a good look into Flotr2 lib
523991849925492740,Mon Oct 20 00:19:26 +0000 2014,Google has published a cute YouTube video mini-documentary on Neural Nets and Language Understanding https://t.co/SvCY7lPMxF
523926685322735600,Sun Oct 19 20:00:30 +0000 2014,Got carried away a bit in intro. First paragraph talking about Computer Vision, then about AI, and now describing the legacy of our species
523926395190128640,Sun Oct 19 19:59:21 +0000 2014,12 hours to write a 5 page research proposal from scratch. I guess this is what I'm supposed to be good at by now.
523288321166823400,Sat Oct 18 01:43:52 +0000 2014,Chrome begged me to update it, so I did, and now it is completely broken. URL bar doesn't work, things don't render. Lesson: NEVER update.
522989410065739800,Fri Oct 17 05:56:06 +0000 2014,Twitter wants to screw with your timeline Facebook style. They claim users love it. Replies tell a different story https://t.co/NeQLAvZPNy
522551881604689900,Thu Oct 16 00:57:31 +0000 2014,In research that moves fast I keep changing the API of what functions take/return (and number of) and it breaks my code downstream
522551670199164900,Thu Oct 16 00:56:41 +0000 2014,Maybe this is crazy but I'm converging on all my Python functions as taking a single dict and returning a single dict for most flexibility?
522498742427979800,Wed Oct 15 21:26:22 +0000 2014,Quora Keeps the World's Knowledge For Itself https://t.co/mVGcwFu6oZ is why &lt;\3 Quora. No respect: closed, forced login shady growth tactics
522259808464822300,Wed Oct 15 05:36:56 +0000 2014,Very nice / comprehensive tutorial slides on Deep Learning https://t.co/ZIQy3FZp1f from Kyunghyun Cho (via @stanfordnlp )
522259562275950600,Wed Oct 15 05:35:57 +0000 2014,RT @sdavidmiller: @karpathy What's your elevator abstract?
522259553455329300,Wed Oct 15 05:35:55 +0000 2014,RT @mdreid: @karpathy What's your runway? If the MVP is a goes viral you should go for an IPO (i.e., GitHub the source code) ;)
522257771774107650,Wed Oct 15 05:28:50 +0000 2014,@sdavidmiller that's not measured in cores but in sanity.
522231720284680200,Wed Oct 15 03:45:19 +0000 2014,@dijkstracula haha thanks stole that for a modified better version :D
522231640051826700,Wed Oct 15 03:45:00 +0000 2014,I'm the CEO&amp;CTO at the same time in my 1-man hip startup (very lean). I have a website. In stealth until submission. Call to action: cite me
522229979187146750,Wed Oct 15 03:38:24 +0000 2014,Startup language applies well to academia: I'm doing a pivot for CVPR. I'm building something reviewers will love. Got Series A from adviser
521893325792505860,Tue Oct 14 05:20:39 +0000 2014,1M keys on writing code. That's a lot of code :) I wonder what projects/files it all went to. Wait, I cold compute that too... #brb
521893078546669600,Tue Oct 14 05:19:40 +0000 2014,Fun stats from my ulogme project: So far I typed 3M keys over last 155 days (20K/per day). 1M of that on coding, at avg rate of ~1.5key/sec
521403418552713200,Sun Oct 12 20:53:56 +0000 2014,Concept of "Utility Fog" is really cool, should be more pervasive in scifi http://t.co/lPLmeZGGsK thx @michael_nielsen  for pointers
521398920765661200,Sun Oct 12 20:36:04 +0000 2014,@michael_nielsen exactly the position I'm in. I can't get excited about unimaginative stuff. Only cool alien I know is Black Cloud by Hoyle
521398614438854660,Sun Oct 12 20:34:51 +0000 2014,@michael_nielsen I like this a lot. I had similar ideas but haven't come across anyone who has picked it up for a story until now. nice!
521397689506750460,Sun Oct 12 20:31:10 +0000 2014,@michael_nielsen puzzling. Alien race of dogs who breath oxygen, see visible light, have emotions, empathy, etcetc? Usenet? I can't take it
521396275904671740,Sun Oct 12 20:25:33 +0000 2014,@yigitdemirag I haven't, actually :\ I've read several and I can't recommend one.
521392801779437600,Sun Oct 12 20:11:45 +0000 2014,I finished Vernor Vinge's "A Fire Upon the Deep". Reviewed on Goodreads (spoilers): https://t.co/W4ezZlUS8P wonder if others read &amp; thoughts
521392025334063100,Sun Oct 12 20:08:40 +0000 2014,Very nice Oculus Connect keynote talk by Michael Abrash puts VR in context &amp; presents compelling vision of future https://t.co/bwhjuhQLct
521380315848142850,Sun Oct 12 19:22:08 +0000 2014,# of programs begging you to restart computer (Windows/Mac) goes to infinity over time. I'd rather click "Not now" million times than yield.
521024594262499300,Sat Oct 11 19:48:38 +0000 2014,@korirotti 60D, 85D, and P85D will be $89,570, $97,570, and $120,170 respectively. http://t.co/QOkpAp7n46
521017368655323140,Sat Oct 11 19:19:55 +0000 2014,The internet has made defensive writers of us all http://t.co/k5cYTV999o agree with this, it's sad to see.
520746115335876600,Sat Oct 11 01:22:03 +0000 2014,Bigger fan of Google's recent shift in strategy to smaller, redesigned self-driving foam-covered (golf) carts, which can hardly kill anyone
519944836578029600,Wed Oct 08 20:18:03 +0000 2014,Freedom from food: nice article on Soylent http://t.co/Kvw3Y3Vq3Q my Soylent shipment arrives today! Replacement for Twix when hacking @ 2am
519926959120592900,Wed Oct 08 19:07:01 +0000 2014,Yesterday total time thinking about getting a $27 zipcar for groceries trip: 0.1 seconds. Total time spent obsessing about 27 $1 apps: hours
519926208436662300,Wed Oct 08 19:04:02 +0000 2014,It's a mind fallacy we all commit I suppose. I'm ok buying $5 ice cream whenever and barely flinch. But $1 app? Is that _really_ necessary?
519925291389816800,Wed Oct 08 19:00:23 +0000 2014,I reduced the price of one of my iOS apps from $1 to free, went from 200 downloads/month to 3000. Seems like people really can't afford a $1
519648109811343360,Wed Oct 08 00:38:58 +0000 2014,Hacker News releases API (http://t.co/3bwv1PnrkF) and a nice article analysis on HN comments http://t.co/yQgIzOCzp1
519242267723194400,Mon Oct 06 21:46:18 +0000 2014,Conferences are where I go to sell work that I've done 1 year ago, barely remember, and have entirely deprecated with better models since
519013352169676800,Mon Oct 06 06:36:40 +0000 2014,A future with ubiquitous drones is a mix of all kinds of awesome and a hint of terrifying. Long article from NYmag: http://t.co/aTMd6V1j8Z
518876944486506500,Sun Oct 05 21:34:38 +0000 2014,@stanfordnlp thanks! I'll have to work much harder on these to actually live up to this :)
518521868148420600,Sat Oct 04 22:03:41 +0000 2014,@davidjayharris for every _complicated_ model.
518489390050340860,Sat Oct 04 19:54:38 +0000 2014,The _real_ Top unsolved problems in Computer Science: Video Conferencing, Presentation, Printing.
518223845350572000,Sat Oct 04 02:19:27 +0000 2014,For every complicated model there exists a much simpler and faster baseline that gets at least 90% of the performance.
518217077287419900,Sat Oct 04 01:52:33 +0000 2014,Heard interesting analogy: advice was to try build classes that have high volume:surface ratio (volume = functionality, surface = API)
517876439031357440,Fri Oct 03 03:18:59 +0000 2014,@shazow saw this on reddit several times. people make all kinds of recipes.
517747788327571460,Thu Oct 02 18:47:46 +0000 2014,@erensezener tough/undefined question. I think you can get very far with static images and labeled data, but probably not all the way.
517409093451923460,Wed Oct 01 20:21:55 +0000 2014,RT @dkroy: Announcement! MIT x Twitter = Laboratory for Social Machines Follow us at @mitlsm http://t.co/L4lAtMPhoi
517027627484209150,Tue Sep 30 19:06:06 +0000 2014,Re-stumbled by this nice link: "Best Papers vs. Top Cited Papers in Computer Science (since 1996)" http://t.co/mgwimTmtVg
516313453724586000,Sun Sep 28 19:48:14 +0000 2014,Fun read: Mining Bitcoins by hand http://t.co/ixGP9S16Mo achieves 0.67 hashes/day &amp; less energy efficient than ASICs by factor of 10^16.
516011638881652740,Sat Sep 27 23:48:56 +0000 2014,@haldaume3 ImageNet is classification+detection, core problems that large portion of community care about. Not clear something equiv in NLP
516010039614509060,Sat Sep 27 23:42:35 +0000 2014,@haldaume3 no, it's not very narrow. It's a bit narrow :)
515988665806241800,Sat Sep 27 22:17:39 +0000 2014,@ntraft @sanchom good point. Expensive to evaluate in real world which is why I suspect most of our development heavy lifting must be in sim
515981225476231200,Sat Sep 27 21:48:05 +0000 2014,@sanchom my thinking exactly
515973504076746750,Sat Sep 27 21:17:24 +0000 2014,@sanchom there isn't a benchmark for Human Vision either, and we still have super important Computer Vision benchmarks when replicating :)
515972019586727940,Sat Sep 27 21:11:30 +0000 2014,@atduskgreg I think that, interestingly, any _one_ answer is wrong.
515970145508798460,Sat Sep 27 21:04:03 +0000 2014,Strikes me that there isn't a benchmark for AI. Computer Vision : ImageNet = AI : ???
515754246906847200,Sat Sep 27 06:46:09 +0000 2014,At some party but this dance music reminds me of hacking. Which makes me think of code. Which makes me want to write some #partyanimalfail
515688621710405600,Sat Sep 27 02:25:23 +0000 2014,@venusatuluri except ConvNets have over time gotten Simpler. Latest generation, e.g. threw out norm, all kernels same size, works better
515661195819245600,Sat Sep 27 00:36:24 +0000 2014,@stephenroller Of course there are choices, but we've simplified by almost an order of magnitude. Also made them more uniform, of same stuff
515632730068234240,Fri Sep 26 22:43:17 +0000 2014,I'm reviewing this CV paper with 14 pages of features, BOW, clustering, SVMs, pruning, normalizations, PCA, kernels... dying a little inside
515629670080213000,Fri Sep 26 22:31:07 +0000 2014,We do this, then we do this, then we cluster that, then we retrain this if that, etc. etc. replace with "here's a function, train with SGD"
515629523535413250,Fri Sep 26 22:30:33 +0000 2014,Reading Computer Vision papers from pre-Deep Learning era is painful. Pages and pages of pipelines, stages, arbitrary choices, hacks... ew
514847178183823360,Wed Sep 24 18:41:47 +0000 2014,"Prior methods use ugly heuristics. We use fancy joint objective.. Btw it's NP hard, we use greedy search for inference" #hypocriticalpapers
514592493803819000,Wed Sep 24 01:49:45 +0000 2014,@kastnerkyle but what's a nice way to insert a 50x1 column into a 50x50 matrix as 1st column? Can't just slice gives error
514589290810994700,Wed Sep 24 01:37:02 +0000 2014,In numpy land, adding a (50, ) array to (50,1) array gives a (50,50) array. Keeping track of 1D/2D shapes &amp;slices is a nightmare #missmatlab
514539783788318700,Tue Sep 23 22:20:18 +0000 2014,@sama good 1st class! Wished the insights were little more grounded and supported by concrete examples, historical data if any
514510424079736800,Tue Sep 23 20:23:38 +0000 2014,Sam Altman's CS183b startup class is Super way over packed :(
514114090261045250,Mon Sep 22 18:08:45 +0000 2014,One thing changed: bicycle obstacle course in the crowd minigame is back. Almost ran over 2 undergrads this morning. Also no bike park space
514113781773787140,Mon Sep 22 18:07:32 +0000 2014,Yay first day of school at Stanford!! still get really excited even though nothing changes for me anymore day-to-day #nostalgia
514113781773787140,Mon Sep 22 18:07:32 +0000 2014,Yay first day of school at Stanford!! still get really excited even though nothing changes for me anymore day-to-day #nostalgia
513832776685338600,Sun Sep 21 23:30:55 +0000 2014,@kastnerkyle I use exactly what Ilya describes in paper section 2. Vanilla RNN. I hear LSTM is mixed results. Curious for more experiments
513830847691386900,Sun Sep 21 23:23:15 +0000 2014,@kastnerkyle what do you mean by "units"? I just used numpy. I don't use theano, don't like bloat
513784795633971200,Sun Sep 21 20:20:15 +0000 2014,Funny that I wrote it so long ago that re-reading it feels foreign, and like something someone else wrote that I enjoyed reading :)
513784060628316160,Sun Sep 21 20:17:20 +0000 2014,Re-stumbled by my own blog post from while ago on "The state of Computer Vision and AI: we are really, really far". http://t.co/nWmnoc7Su3
513447051070173200,Sat Sep 20 21:58:11 +0000 2014,@fulhack @ogrisel I don't have much experience with RNNs. but http://t.co/agVsZuVnJN to rescue- searching recurrent gives nice cluster :)
513442761106665500,Sat Sep 20 21:41:08 +0000 2014,@memming Good point, didn't know dot() exists in matlab. I thought of it as analog of Matlab *
513427717019025400,Sat Sep 20 20:41:21 +0000 2014,@robertsdionne was looking here https://t.co/qDlKdXoF77 line ~164. Just noticed they normalize by scale, which is right. nvm.
513427475502600200,Sat Sep 20 20:40:23 +0000 2014,@robertsdionne odd. inner prod grad is simple, should be almost exact. Also Caffe check is weird - doesnt check relative but absolute error
513401667266437100,Sat Sep 20 18:57:50 +0000 2014,@bradley_young haha :D I think people are just poking fun at it at this point.
513396798103117800,Sat Sep 20 18:38:29 +0000 2014,watching #OculusConnect keynote. John Carmack on stage. Live stream: http://t.co/tdbYHsy19f
513394719246651400,Sat Sep 20 18:30:14 +0000 2014,"I'm sorry. I stopped listening to you after you didn't say 'deep learning'."- A friend's adviser
513058892993925100,Fri Sep 19 20:15:46 +0000 2014,@tweetsauce re: coincidences video, could have mentioned, e.g. Birthday Paradox: http://t.co/g9uAMNfeQ6
512805201053368300,Fri Sep 19 03:27:42 +0000 2014,@robertsdionne This is great, thanks for the links! So far was using just SGD, ReLUs. Wrote custom backprop. Maybe should use theano
512801857605865500,Fri Sep 19 03:14:24 +0000 2014,Watching Scotland's referendum results come in live at http://t.co/9GgYWAhc8p 49-51% right now! Tense! It's more likely No though.
512801160235741200,Fri Sep 19 03:11:38 +0000 2014,@robertsdionne task agnostic for now, say classification. Sounds nice. I'm on lookout for practical/details sources. Did you find tricky?
512752787315105800,Thu Sep 18 23:59:25 +0000 2014,Implementing a Recurrent Net and training on sentences. Need to more intuitively understand how/when they work and how to best train them...
512725652076625900,Thu Sep 18 22:11:36 +0000 2014,Tweet a program from Wolfram http://t.co/OcofMw5Hec  neat!
512675971510439940,Thu Sep 18 18:54:11 +0000 2014,Microsoft's MSR Silicon Valley is shutting down as part of job cuts.  sad    http://t.co/FFBOyIqMqQ
512410138217431040,Thu Sep 18 01:17:51 +0000 2014,The GoogLeNet architecture (http://t.co/RefhtFyInG) seems bit funky. Philosophically bigger fan of close runner-up http://t.co/NCkMBTWVUb
512402850903633900,Thu Sep 18 00:48:54 +0000 2014,The GoogLeNet paper is out on arXiv now: http://t.co/8vszeKNufC  &amp; their slides (among others) also on workshop page: http://t.co/IzIT7wcLkB
512400586264682500,Thu Sep 18 00:39:54 +0000 2014,Came back from Q&amp;A panel session for our new batch of CS PhD students. Feeling old
511994513242337300,Tue Sep 16 21:46:19 +0000 2014,Curious to talk to people about it: I can see a lot of downloads and traffic to ConvNetJS and site but little idea about how it's used :\
511993649857437700,Tue Sep 16 21:42:53 +0000 2014,I'll be holding a demo session tonight for ConvNetJS at VLAB event "Deep Learning: Intelligence from Big Data" https://t.co/P5EDep4p9S
511972378285314050,Tue Sep 16 20:18:21 +0000 2014,Neat: Sam Altman will teach CS183 "How to Start a Startup" at Stanford this fall, lectures will be online http://t.co/vkkbwVBF05
511937252537434100,Tue Sep 16 17:58:47 +0000 2014,@michael_nielsen hahah, Peter Thiel and 2x2 matrices. Almost every one of his classes had one or two, and 10 min explaining each :D
511664556414742500,Mon Sep 15 23:55:11 +0000 2014,@bradleyvoytek I feel freeee. I have Dictionaries!! so amazing.
511664115350114300,Mon Sep 15 23:53:26 +0000 2014,I thought switch of my entire research code from Matlab to Python would be hard, long and not make things much simpler. wrong, wrong, wrong.
511567179783733250,Mon Sep 15 17:28:14 +0000 2014,Mojang (Minecraft) and Microsoft. These two are not even remotely in the same part of my brain. Reminiscent of Oculus FB acquisition. :((
511399815071006700,Mon Sep 15 06:23:11 +0000 2014,@pieteradejong @solarcity @lazaruslarue  nice!! :) &lt;&lt; big fan of solar city!
511368180053184500,Mon Sep 15 04:17:29 +0000 2014,And speaking of Solar Energy, nice overview talk (1hr) of technologies from a Stanford prof at 2014 Energy Seminar https://t.co/Jj1RsnZiLV
511359152216473600,Mon Sep 15 03:41:37 +0000 2014,Solar Panel Cost Trends http://t.co/0vZnW4kp2L these trendlines all look reeeally nice
510612189586014200,Sat Sep 13 02:13:27 +0000 2014,Programming (well) is the best puzzle. You can have time/space efficiency, modularity, brevity, security, etc etc etc..., pick 15 out of 20.
510557208254230500,Fri Sep 12 22:34:58 +0000 2014,@Miles_Brundage if there is a good way to obtain a lot of training data then yes :) Otherwise no.
510476998431359000,Fri Sep 12 17:16:15 +0000 2014,@nikete wow, interesting! I hope it was just a fun toy dataset. From raw pixels especially, any computer vision researcher would neeever use
510469810577084400,Fri Sep 12 16:47:41 +0000 2014,Btw, my poisonous mushroom classifier app idea tweet was a joke. That's a horrifying proposition. Replies tell me this wasn't obvious :p
510282842828320800,Fri Sep 12 04:24:44 +0000 2014,Open Sourcing a Python Project the Right Way http://t.co/89bnziQgnu Wish I stumbled by more articles like this. Not rly taught at school :\
510237096078888960,Fri Sep 12 01:22:58 +0000 2014,Hmm. An app that lets you take picture of a mushroom and tells you if its poisonous. ( brainstorming some   #visionstartupideas )
510184696731279360,Thu Sep 11 21:54:45 +0000 2014,Peter Thiel AMA http://t.co/IdDLXpKDjr
510126111317966850,Thu Sep 11 18:01:57 +0000 2014,Miegakure looks like an awesome puzzle game, allows you to move through 4D (x,y,z,w) space. http://t.co/fvEqeYpjp8
509940029859180540,Thu Sep 11 05:42:32 +0000 2014,@RichardSocher I guess, but I'd also pour my research billion into really doing a good job with NLP. &amp; my blackbox POS tagger still sucks.
509867904972517400,Thu Sep 11 00:55:56 +0000 2014,Michael Jordan AMA on Reddit http://t.co/XkFMRaxVVU some interesting points; I like his answer on hypothetical $1billion research project
509861790662938600,Thu Sep 11 00:31:38 +0000 2014,A Watch Guy's Thoughts On The Apple Watch After Seeing It In The Metal http://t.co/MN3aAlWujl Nice writeup
509776115460603900,Wed Sep 10 18:51:11 +0000 2014,I bought a road bike for the first time in my life. I hate, hate it. Puts me in very odd positions, hard to break, twists hands in odd shape
509591180049252350,Wed Sep 10 06:36:19 +0000 2014,@escapismisbad hmm, I can't reproduce this. If I put momentum at 0.0, it still runs fairly fast. I also glanced through code seems ok
509415345396785150,Tue Sep 09 18:57:37 +0000 2014,Lets spend 15 minutes on Apple Watch and then 20 minutes on U2 and their new Album. -Apple
509133307422855200,Tue Sep 09 00:16:54 +0000 2014,@ChrisBaldassano Hmm I use neither right now. Just plain scripts/modules and Ipython Notebooks for more visual things.
509125143201722400,Mon Sep 08 23:44:27 +0000 2014,@jgbos @lzamparo yeah, I try hard to factor out modules of generic defs that don't have state, and keep classes small. Sometimes possible.
509085595738447900,Mon Sep 08 21:07:19 +0000 2014,@lzamparo I haven't come across too many of those yet myself. Mostly re-implementing things with numpy, creating classes, module system
509081637607321600,Mon Sep 08 20:51:35 +0000 2014,The time has come: Converting large portions of my research codebase from Matlab to Python+numpy... Not the most fun I've had. #mustbedone
508714451478917100,Sun Sep 07 20:32:31 +0000 2014,NVIDIA announces cuDNN, GPU accelerated Deep Neural Nets library: http://t.co/p6rMgKAucH + integrated into Caffe already
508345890495414300,Sat Sep 06 20:07:59 +0000 2014,Was dragged to my first football game ever. But #gostanford . so exciting. http://t.co/EKBxpdj7O7
507711016554094600,Fri Sep 05 02:05:13 +0000 2014,Very Deep ConvNets with 3x3 kernels &gt; Deep ConvNets http://t.co/ThOPUoqNjD new preprint on arXiv from Karen (VGG team on ImageNet comp)
507658405817765900,Thu Sep 04 22:36:10 +0000 2014,I dream of a Makefile pipeline from raw data to tables/figures and latex paper compile. One day...
507657737879035900,Thu Sep 04 22:33:31 +0000 2014,Good tips: "There is one rule for data processing: Automate everything". I usually try hard  http://t.co/xHDhtzAK5x (via @chrishwiggins )
507570156139081700,Thu Sep 04 16:45:30 +0000 2014,Strongly negative review of Google Glass http://t.co/hwRS5sa3bp Have to admit, I really regret buying mine (for $1750) last year. $1750.
507336150978015200,Thu Sep 04 01:15:38 +0000 2014,I just ran the fastest matrix multiply of my life, parallelized across 4 K40 GPUs with cuBLAS-XT @ 4.5 TFLOPS of double-precision #happiness
507236182208421900,Wed Sep 03 18:38:24 +0000 2014,@fulhack Good question! The probabilities are uniform, this was one of the design decisions in creating ImageNet.
507232043348934660,Wed Sep 03 18:21:57 +0000 2014,@F_Vaggi few weeks, since this will be discussed at length on September 12 at ECCV. Google entered the open track - all will be revealed :)
507231199996039200,Wed Sep 03 18:18:36 +0000 2014,@shazow thanks! It's appreciated - these things take a while to put together. Usually much more than I initially predict.
507230355615539200,Wed Sep 03 18:15:15 +0000 2014,(also don't miss link inside to the labeling interface, if you'd like to see GoogLeNet's predictions and compete against them yourself)
507230185234505700,Wed Sep 03 18:14:34 +0000 2014,New blog post: "What I learned from competing against a ConvNet on ImageNet" http://t.co/OOGaHaiTzz
506995707425722400,Wed Sep 03 02:42:50 +0000 2014,Most of the work was done by Jia Deng and Olga Russakovsky, I contributed a small part (Section 6.4) that analyzes ILSVRC human accuracy
506995450503634940,Wed Sep 03 02:41:49 +0000 2014,Many years in the making: Our paper on the ImageNet Large Scale Visual Recognition Challenge is now up on arXiv http://t.co/BIemhLl242
506281792358207500,Mon Sep 01 03:26:00 +0000 2014,"I ghostwrite Chinese students' ivy league admissions essays" http://t.co/FS2nHM5Xj5 Nicely written, provocative article
506168848546938900,Sun Aug 31 19:57:12 +0000 2014,Financial comparison of owning car / using UberX exclusively https://t.co/Z1HdWYbkm3 I had similar thoughts, also considering Zipcar only
506167444033916900,Sun Aug 31 19:51:37 +0000 2014,@neurobongo haha, the batch took a while to "cook", so high overhead but once you make 1 week of it, lasts long time. Not ideal, agreed :)
506166256433496060,Sun Aug 31 19:46:54 +0000 2014,@neurobongo I made a custom DIY while waiting for my order, out of curiousity. It tastes... okay :)
506165667058294800,Sun Aug 31 19:44:33 +0000 2014,Watching a documentary about Octopus, my favorite animal http://t.co/kFxsWvCQcB  . Unfortunately not best pets :( http://t.co/bqeAAant49
505882898436595700,Sun Aug 31 01:00:56 +0000 2014,I'm suddenly seeing a Ton of app ads on Twitter. Is this because I clicked on one in morning and installed the app? #notcool
505150270293041150,Fri Aug 29 00:29:44 +0000 2014,Google X, among few companies pushing awesome drone tech http://t.co/LqFM3jXDap And FAA doing best to slow it all to crawl with regulations
505052529890054140,Thu Aug 28 18:01:21 +0000 2014,Our lab is getting 130 new machines; Excited to take them for a spin, get Spark running, etc. w00t http://t.co/sjolkxbdKa
504707108982358000,Wed Aug 27 19:08:46 +0000 2014,Technology behind Instagram's Hyperlapse http://t.co/d1hKTYFOyW If I'm reading this right, it's vanilla approach and careful implementation
504491727290265600,Wed Aug 27 04:52:55 +0000 2014,Nice, I like: 38 maps that explain the global economy  http://t.co/ZRKjELkBq6 yay for datavis.
504113299999297540,Tue Aug 26 03:49:11 +0000 2014,So 1 ECCV ~= 6 round trips to Hawaii. (that's my favorite unit of measurement)
504112778802516000,Tue Aug 26 03:47:07 +0000 2014,Was considering spontaneously registering for ECCV. Flight $1400 and registration $750 convinced me not to. $750 to go to few talks. Crazy.
502992547564617700,Sat Aug 23 01:35:43 +0000 2014,@Zipcar can't log in and reserve a car :( @Stanford
502972166564900860,Sat Aug 23 00:14:43 +0000 2014,@foxsnarkltooth I got better at ImageNet classification :) Basically requires you to know very well what the 1000 categories are.
502970635086069760,Sat Aug 23 00:08:38 +0000 2014,Also learning a lot about where CNNs work and where they fail. That has been most interesting. Hoping to quantify and write it up nicely.
502970430706049000,Sat Aug 23 00:07:50 +0000 2014,Manually classifying images into 1000 ImageNet categories since 9am (so ~7 hours now). My brain hurts. Am really good now though #forscience
502695389703577600,Fri Aug 22 05:54:55 +0000 2014,@iandanforth yep that's what I did :) without the loop tho
502687727754555400,Fri Aug 22 05:24:28 +0000 2014,Addicted to Particle Clicker :( http://t.co/kQ8YuUDRfE I have a whole lab now, a team of tenured faculty, etc. #sogood
502598906749124600,Thu Aug 21 23:31:31 +0000 2014,@cbonnett yep, I'm prototyping the labeling interface. We'll have multiple experts  and in various settings (CNN assisted or not etc)
502574848452075500,Thu Aug 21 21:55:55 +0000 2014,Annotating ImageNet test set to get human accuracy. These ~200 different breeds of dog are killing me. #forscience
502269105433763840,Thu Aug 21 01:41:01 +0000 2014,@notthatdsw yeah that's what I'm doing right now. I have the hierarchy. It's... okay ;\ showing sample imgs from train next to each label
502268978924748800,Thu Aug 21 01:40:30 +0000 2014,@michael_nielsen @arfon @orbitingfrog So far building nice web interface, with hierarchical breakdown following imagenet hierarchy. bleh.
502266423428010000,Thu Aug 21 01:30:21 +0000 2014,@djpardis Much more complicated than that. e.g. there are ~100 different fine-grained breeds of dogs. 20 terriers. Things I never heard of
502264175713062900,Thu Aug 21 01:21:25 +0000 2014,I'm trying to evaluate human accuracy on ImageNet test set. Really tricky to make interface to label among 1000 classes... #kindastuck
501558740114366460,Tue Aug 19 02:38:16 +0000 2014,@davidjayharris not yet - will be presented at ECCV in few weeks
501548613923635200,Tue Aug 19 01:58:02 +0000 2014,@iandanforth wish I knew!
501537447428104200,Tue Aug 19 01:13:40 +0000 2014,@edersantana There are abstracts on bottom, and more details will be presented at ECCV in few weeks!
501531933851938800,Tue Aug 19 00:51:45 +0000 2014,Woohoo! New York times about ImageNet 2014 results: http://t.co/tWoFIz7pdp and the raw results page: http://t.co/9nhvXsNZIW very exciting
501460920187375600,Mon Aug 18 20:09:34 +0000 2014,@danbri not really, that was long time ago, and the code is super ugly. I wish I had time though :(
501248124128485400,Mon Aug 18 06:04:00 +0000 2014,Another lol rule: "Do not shoot firearms on a highway or at traffic signs". I presume shooting firearms in other circumstances is ok then?
501230896477786100,Mon Aug 18 04:55:32 +0000 2014,A left u-turn is legal if: "it is across a double yellow line when it is safe and legal". Looks like it's legal when it's legal.
501230446521249800,Mon Aug 18 04:53:45 +0000 2014,e.g. "If you drive for sight-seeing purposes to the scene of a fire, collision, or other disaster, you may be arrested". hah
501230301939380200,Mon Aug 18 04:53:11 +0000 2014,Taking CA driving test in 2 days (though I already have driving licence from Canada). Going through CA driving rules booklet. Several lols:
500778187047960600,Sat Aug 16 22:56:38 +0000 2014,@suyashlunawat12 I'm working and busy right now. You need to practice more that's all, good luck.
500732428537692160,Sat Aug 16 19:54:48 +0000 2014,@suyashlunawat12 common mistake that can be cause is pause in solve. You should have very little, if any. lookahead is super important
500427837040365600,Fri Aug 15 23:44:28 +0000 2014,The ImageNet challenge 2014 submissions are streaming in quickly! 15 minutes left. Many people submitted. Exciting :)
500395186770300900,Fri Aug 15 21:34:44 +0000 2014,@petewarden :O
500368864929017860,Fri Aug 15 19:50:08 +0000 2014,@Miles_Brundage I'm not interested in conclusions as much as the arguments. Enumerating those is hard. I assign my own weights to each :)
500366593897926660,Fri Aug 15 19:41:07 +0000 2014,Looks like a very nice read: "AI, Robotics, and the Future of Jobs" [pdf] http://t.co/f1uUwqyQBP
500348185219325950,Fri Aug 15 18:27:58 +0000 2014,Trying to video chat with sister. Hangouts: All works except my audio. Skype: All works except her video. This is what we get in 2014.
500084475200409600,Fri Aug 15 01:00:04 +0000 2014,@sergecell hey, I recall you were getting good numbers of CIFAR previously. What were you using? Theano? Caffe? What was the best net like?
499718941950746600,Thu Aug 14 00:47:34 +0000 2014,Giving a presentation on Caffe tomorrow. Making it fast &amp; super low level, with 95% spent in code. Hoping to lose everyone on cuBLAS parts
499696068435517440,Wed Aug 13 23:16:41 +0000 2014,@robertsdionne not really. I'm pretty happy with local methods, and in my religion local minima are a myth.
499472633356763140,Wed Aug 13 08:28:50 +0000 2014,Comcast: It‚Äôs ‚Äòinsulting‚Äô to think there‚Äôs anything shady about us paying $110,000 to honor FCC commissioner http://t.co/cUztr96GiC #crazy
499432024742969340,Wed Aug 13 05:47:28 +0000 2014,@suyashlunawat12 Not sure what you're intending. I put a lot of effort into mine. Some vids took week of shooting/edits. Quality &gt; Quantity.
499421458649464800,Wed Aug 13 05:05:29 +0000 2014,@suyashlunawat12 get good hardware, learn the algorithms and practice practice practice. It's not likely that you're missing anything else
499415107151999000,Wed Aug 13 04:40:14 +0000 2014,@suyashlunawat12 Nice! I'm really out of touch with the community :s I learned the hard way with a shitty short text explanation and time :)
499288996078309400,Tue Aug 12 20:19:07 +0000 2014,@abr71310 oh hey! Neat, you work at RiotGames? LoL !
499287547130818560,Tue Aug 12 20:13:22 +0000 2014,Just bought a few thousand dollars worth of hard disks for our GPU cluster. I wonder if this is enough to join the #bigdatatrain funride
499275195631157250,Tue Aug 12 19:24:17 +0000 2014,Google Views is quite a nice timesink https://t.co/uUCJ2CyCkJ I wish there was a "sit back" mode where it just takes you around randomly
499073409285115900,Tue Aug 12 06:02:27 +0000 2014,@robertsdionne also I have 4 K40s in a box. That counts for something :)
499073236106481660,Tue Aug 12 06:01:46 +0000 2014,@robertsdionne CUDA is more established and standard for ops I'm interested in, e.g. ConvNets, Image stuff.
499070388094398460,Tue Aug 12 05:50:27 +0000 2014,@shazow haha, well I've bought a pound of CUDA for 10 sanity today :D
499070051526668300,Tue Aug 12 05:49:07 +0000 2014,@robertsdionne I don't need some library holding my hand and providing abstractions. Real men command GPUs with their own raw kernel code :D
499053999425732600,Tue Aug 12 04:45:20 +0000 2014,Diving deep into CUDA. This makes me simultaneously very happy and very sad. All that compute! But at what cost...
498997133412802560,Tue Aug 12 00:59:22 +0000 2014,"Cat Basis Purrsuit" : Representing faces as linear combination of cats http://t.co/z5zGEmMYaH Hilarious :D (via @quantombone )
498620551372365800,Mon Aug 11 00:02:58 +0000 2014,Restarting an ugly, bloated code base from scratch always &lt;em&gt;seems&lt;/em&gt; like a good idea.
498597504955326460,Sun Aug 10 22:31:23 +0000 2014,RT @syhw: I finally did this "harsh/hands-on intro/tips to deep learning" blog post: http://t.co/5e9ug5xzAY #deeplearning #machinelearning
498582795220820000,Sun Aug 10 21:32:56 +0000 2014,Whoa, Hyperlapse results from Microsoft Research looks quite amazing: http://t.co/7u7cAXuNdN smooth timelapse for egocentric videos
498571679899979800,Sun Aug 10 20:48:46 +0000 2014,@shazow haha I wrote this a while ago. Not sure about the "brilliant", it's just rules of thumb - had ppl disagree about few in past
498556056398610400,Sun Aug 10 19:46:41 +0000 2014,@notmisha @yoavgo cc @RichardSocher
498314248066326500,Sun Aug 10 03:45:49 +0000 2014,@Reza_Zadeh neat! This was sent around our lab - I intended to check it out since our lab is getting 150+ extra machines for our cluster
498250392497451000,Sat Aug 09 23:32:05 +0000 2014,@eakbas2 Yeah if I had a server running that would be trivial but right now it's just a static page with JSON loaded. I don't have a server
498246138739167200,Sat Aug 09 23:15:11 +0000 2014,@eakbas2 It's possible, but the JSON database would likely expand quite a bit because I'd have to maintain a word-&gt;[document,...] index
498237065767571460,Sat Aug 09 22:39:07 +0000 2014,Checked some ScholarOctopus visitor stats and 60% are on mobile (a dreadful experience). Happens when I link to things on weekends...
498229362802454500,Sat Aug 09 22:08:31 +0000 2014,I'm calling the project ScholarOctopus. Academic literature is a pain to explore and get a feel for on holistic level: I want nice tools.
498229076616683500,Sat Aug 09 22:07:23 +0000 2014,Fun hack: I took 7200 papers from 34 CV/ML conferences, and layed them out with t-SNE based on bigram tfidf. Explore: http://t.co/Ub61m7tQ5n
498042054270677000,Sat Aug 09 09:44:13 +0000 2014,Chesscademy teaches chess http://t.co/6WGbg81fS8 Nicely delivered, but less features than http://t.co/4ldRd7rfdH or http://t.co/olr6WHTluj
498018965168209900,Sat Aug 09 08:12:28 +0000 2014,I watched one random video about a Snake playing dead I found on Reddit and now YouTube keeps surfacing gory snake wound videos. #mlfail
497636637988233200,Fri Aug 08 06:53:14 +0000 2014,interesting. 30 yr study: difference ‚Äî between prison/college, success/failure,  life/death ‚Äî are money and family. http://t.co/1p2HN5xqdQ
497503511077060600,Thu Aug 07 22:04:14 +0000 2014,RT @ylecun: My comments on the IBM TrueNorth neural net chip.  IBM has an article in Science about their TrueNorth neural net... http://t.c‚Ä¶
497448490742452200,Thu Aug 07 18:25:37 +0000 2014,from CCV blog: tricks for running convnets on the phone  http://t.co/CUh5jSHPgE
496710999982891000,Tue Aug 05 17:35:05 +0000 2014,Recommending music on Spotify with deep learning http://t.co/4HtMlc3wph nice post from a Spotify intern
496056909808414700,Sun Aug 03 22:15:58 +0000 2014,I recorded 3 months of my computer activity with new pet project ulogme. New blog post: "Quantifying Productivity" http://t.co/WSGtFA10eJ
496041542876819460,Sun Aug 03 21:14:54 +0000 2014,@iandanforth haha. Assuming a good professor perhaps :)
496038424231415800,Sun Aug 03 21:02:30 +0000 2014,"A Contrarian View of MITx: What Are We Doing!?" - I like the drawn distinction btw education and training.  http://t.co/7vMZIXGJRM
495995076510642200,Sun Aug 03 18:10:16 +0000 2014,@prasanna EXCEPTION in thread 'main': ai.main.core.central.critical.UnknownErrrorException, data: dudjenixjeiben73&amp;48jrndu8383
495990212481126400,Sun Aug 03 17:50:56 +0000 2014,@prasanna haha. It wanted to get BACK PROPerly. You know what nvm. I'd rather ppl think I'm powerful strong AI than some dude.
495988417067356160,Sun Aug 03 17:43:48 +0000 2014,@michael_nielsen good point. Imo Weak AI toolkit we're building is necessary but not close to sufficient. Let's see what happens :)
495985686760017900,Sun Aug 03 17:32:57 +0000 2014,@prasanna you should give me Turing Tweet Test and find out :)
495984504985505800,Sun Aug 03 17:28:15 +0000 2014,Hah my AI comment exploded... Don't want to belittle AI research progress. We've made great strides but in weak AI; strong AI not on horizon
495772988361277440,Sun Aug 03 03:27:46 +0000 2014,@elonmusk as an AI PhD student at Stanford, easy to see that AI right now is cheap tricks and regression. Can sleep well for many years
495306270589456400,Fri Aug 01 20:33:11 +0000 2014,The Oculus Rift Made Me Believe I Could Fly http://t.co/QCqeizdM0L a lot of fun trying to extrapolate these technologies few years ahead
495298140157657100,Fri Aug 01 20:00:53 +0000 2014,@michael_nielsen haha yep, no WebGL! (so far). Though I have it in an experimental branch. Only trick is using typed arrays. JS is fast!
494921292097671200,Thu Jul 31 19:03:25 +0000 2014,"IP layer for money" is a powerful idea. I really want something like Stellar to work https://t.co/2BRgrVIx9E
494551978303709200,Wed Jul 30 18:35:54 +0000 2014,RT @Stammy: 10,530 words &amp; 3 wknds worth of writing but here's everything you need to know about drones: http://t.co/FoH5ko9CQH http://t.co‚Ä¶
494544547636998140,Wed Jul 30 18:06:23 +0000 2014,RT @hmason: This looks awesome! ScratchJr for teaching kindergarteners to code: http://t.co/QVVUCO01j1 (via @natematias)
494249101228134400,Tue Jul 29 22:32:23 +0000 2014,RT @clementfarabet: Madbits is joining Twitter! We're really excited about that. Check out our website http://t.co/W3WSKTe9ow.
494244670466048000,Tue Jul 29 22:14:46 +0000 2014,@npinto @clementfarabet interesting - nice :) congrats!
494233551982698500,Tue Jul 29 21:30:35 +0000 2014,According to these ConvNet implementation benchmarks it's very very fast https://t.co/lMtIOlNsZ7 ( I wonder how ConvNetJS compares :P)
494233072628269060,Tue Jul 29 21:28:41 +0000 2014,In case people missed this, Alex Krizhevsky released cuda-convnet2. It's blazing fast, has multi GPU support https://t.co/RlojSwGKNe
493470249824419840,Sun Jul 27 18:57:30 +0000 2014,@edersantana it's a small matlab script. I make a small template image then iterate over pixels and find closest colored img in a collection
493095369031442400,Sat Jul 26 18:07:51 +0000 2014,@ogrisel I have no experience with the nesterov momentum. My guess is negligible improvements since I hear quite little buzz about it
493089776598134800,Sat Jul 26 17:45:38 +0000 2014,@ogrisel :) yeah - though not sure how representative demo is. I've had successes and failures with adaX. SGD with good LR usually best
492431685091614700,Thu Jul 24 22:10:37 +0000 2014,NooOOoo, Google acquiring Twitch for 1B  http://t.co/96pdshXhqh , one of my fave sites. Now it will require G+, merge accounts, other stuff
491994852129644540,Wed Jul 23 17:14:48 +0000 2014,Interesting: an Event Camera models a retina in silicon. No shutter. Doesn't output frames but change event spikes https://t.co/zSg4gXI1Yd
491984308630847500,Wed Jul 23 16:32:54 +0000 2014,@MarsPlus01 not sure which ones you're referring to. But often my figures are made in HTML/CSS, d3js. Browser is a good canvas.
491094217696231400,Mon Jul 21 05:36:00 +0000 2014,Expensive restaurant startup idea: sample platter appetizer &amp; pref questionnaire -&gt; train taste profile model -&gt; personalize meal #bigmoney
490305010291327000,Sat Jul 19 01:19:58 +0000 2014,@michael_nielsen good point. Bit worried about diversity in that case
490265140529336300,Fri Jul 18 22:41:32 +0000 2014,@chessgamescom hello, I'm PhD student at Stanford; I'd like to train Neural Nets to play chess, need data to learn from. Is any available?
490251486274670600,Fri Jul 18 21:47:17 +0000 2014,@atduskgreg niiice! yep my website has my address.
490250775742795800,Fri Jul 18 21:44:28 +0000 2014,Was looking through code of Stockfish (strongest chess engine). Filled with ugly heuristics. Want to train Neural Net. Can't find games data
489913804759654400,Thu Jul 17 23:25:27 +0000 2014,AirDog is a personal quadcopter camera man. Looking forward to when these start to work well.    https://t.co/QPAXzDF9yY
489567364166332400,Thu Jul 17 00:28:50 +0000 2014,Fun problem when NLP and Vision people collaborate: NLP ppl assume vision is solved. Vision ppl assume NLP is solved. Hilarity ensues
489104607281307650,Tue Jul 15 17:50:00 +0000 2014,@briacm yep! That's probably why explaining is so useful for gaining understanding. It's forcing you to tangle through your graph :)
489104095421022200,Tue Jul 15 17:47:58 +0000 2014,Gets even worse since you want to minimize explanation length subject to audience, with some distribution over their prior knowledge... Bleh
489103025953202200,Tue Jul 15 17:43:43 +0000 2014,Explaining things is really hard. It's like taking a messy graph of ideas, having to sort it in topological order and serializing to text.
488721567954653200,Mon Jul 14 16:27:56 +0000 2014,@iandanforth @mblondel_ml I do. It's not as insightful as I'd like. Eg do ppl use it in prod? In projects? In node? For vis? For edu?
488719270298148860,Mon Jul 14 16:18:48 +0000 2014,@mblondel_ml Except I don't have a very good picture of where all the traffic is coming from or how it is used. :s
488551088123957250,Mon Jul 14 05:10:30 +0000 2014,I bought a game on Steam for $59.99 and it just crashes on startup. Well, that was fun
488441022012067840,Sun Jul 13 21:53:09 +0000 2014,I wanted #GER to win but that final waaay-off free kick by Argentina favorite  - Messi - at the very last second... #heartbroke
488405615803236350,Sun Jul 13 19:32:27 +0000 2014,I like how there is always a very strongly opinionated player who contests a referee's decision &amp; it doesn't ever change anything.
488401336631717900,Sun Jul 13 19:15:27 +0000 2014,I'm watching the game surrounded by crowd of Argentina fans, silently rooting for #GER... #awkward
488211867693637600,Sun Jul 13 06:42:34 +0000 2014,@petewarden hah! So, I'm actually implementing CNN in iOS and porting Caffe models... I think you've been there already :) it's... tricky
488206263709212700,Sun Jul 13 06:20:18 +0000 2014,I'm in a little way over my head in OpenglES shader coding insanity. This side project was supposed to be fun.
487731637581381600,Fri Jul 11 22:54:18 +0000 2014,@justinvf haha I was just making it for the most part :D But similar story on high level. Was a pyobjc python package disaster
487365539010867200,Thu Jul 10 22:39:33 +0000 2014,to write this code I need A. Which needs B. Which doesn't compile because C is old version. Which doesn't download because D is needed. #fml
487308662294069250,Thu Jul 10 18:53:33 +0000 2014,RT @teslascience: $1 million from Elon Musk! And a supercharging station! Thank you, Mr. Musk!!!
486731743383134200,Wed Jul 09 04:41:05 +0000 2014,The Most Shocking Result in World Cup History http://t.co/WxmOFGgam8 via @fivethirtyeight
486700659010326500,Wed Jul 09 02:37:34 +0000 2014,@iandanforth imo hardware and low-level control is not nearly there. I understand you'll disagree :)
486697540184600600,Wed Jul 09 02:25:10 +0000 2014,Security researcher finds vulnerability that lets him make API calls on behalf of any Facebook user http://t.co/78pjtd4ogg reward: $20K :S
486682623675101200,Wed Jul 09 01:25:54 +0000 2014,New blog post: Feature Learning Escapades http://t.co/7aQ9pArgO8
486607437600796700,Tue Jul 08 20:27:08 +0000 2014,Wow, this game DELIVERS! #BRAvsGER. So good! :D
486602184058875900,Tue Jul 08 20:06:15 +0000 2014,Computer scientists (my lab) have descended on #BRAvsGER http://t.co/9W7TJCMWbt
485915471745540100,Sun Jul 06 22:37:31 +0000 2014,RT @ch402: Graph of HP fanfiction, colored by ship! See my blog post http://t.co/AZDMVi2Zq8 #math #fanfiction #dataviz http://t.co/rjvpqwhv‚Ä¶
485539900704301060,Sat Jul 05 21:45:07 +0000 2014,@tinnulion haha yep - Red Panda is an ILSVRC class, so the CNN cares about getting it nicely separated from other things :)
485532638078173200,Sat Jul 05 21:16:16 +0000 2014,I extracted CNN codes from 50,000 Imagenet val images and embedded them with t-SNE in 2D. Beautiful/fun results: http://t.co/p99Nu8bThq
485150120720089100,Fri Jul 04 19:56:17 +0000 2014,https://t.co/hYuGCKQOlC by @lessig
485123717823860740,Fri Jul 04 18:11:22 +0000 2014,New York times seems to have access to player position data for World Cup games: http://t.co/VR201joczK Anyone know source? Want.
484859591662923800,Fri Jul 04 00:41:49 +0000 2014,@mdreid not sure why it took me this long :( I now have to convert all ~30 of my Wordpress posts to Markdown. Good news is this is last time
484857933574860800,Fri Jul 04 00:35:14 +0000 2014,@mdreid oh wow, wasn't aware! And I thought this couldn't get any better,
484856847795363840,Fri Jul 04 00:30:55 +0000 2014,I'm switching my Wordpress blog permanently to Jekyll, which I have fallen in love with (hard) yesterday http://t.co/wMSt5X6jwl (cc @mdreid)
484830072486903800,Thu Jul 03 22:44:31 +0000 2014,I also wrote up a fast blog post that documents the creation of the t-SNE demo http://t.co/OWBp8ynnHI (a little technical though)
484829370700152800,Thu Jul 03 22:41:44 +0000 2014,I implemented &amp; released t-SNE (unsupervised visualization algorithm) in Javascript 2 days ago, because why not. http://t.co/giorlGlS56
484739292032290800,Thu Jul 03 16:43:47 +0000 2014,@emil_kattainen what's the error and when
484531531310850050,Thu Jul 03 02:58:13 +0000 2014,@mdreid ty! I didn't like Octopress (too bloated), but found Jekyll to be very lean/nice. Switching everything to it. Not doing Haskell :p
484531531310850050,Thu Jul 03 02:58:13 +0000 2014,@mdreid ty! I didn't like Octopress (too bloated), but found Jekyll to be very lean/nice. Switching everything to it. Not doing Haskell :p
484386808868773900,Wed Jul 02 17:23:09 +0000 2014,Flashy mobile-"optimized" websites are 90% of the time the opposite of optimized. Very annoying.
483671762706505700,Mon Jun 30 18:01:49 +0000 2014,@colinlea btw where did you find abstracts for the papers? I can't find this on cvf. Also I hope you weren't at CVPR? Didn't find you
483667506045800450,Mon Jun 30 17:44:54 +0000 2014,Back from CVPR. Months ahead with no deadlines; Super excited for unrestricted research, crazy idea prototyping, learning and hacking.
483079099460489200,Sun Jun 29 02:46:47 +0000 2014,@united your automated replies do not help. Making sure flights don't get delayed or canceled EVERY. SINGLE. TIME. (Seriously) would.
483051023976517600,Sun Jun 29 00:55:13 +0000 2014,My @united saga continues. Another flight delayed 2 hours and again forced to stay at airport overnight.
483020927156764700,Sat Jun 28 22:55:37 +0000 2014,@neurobongo I thought Microcosm by Zimmerman had done decent job explaining by examples, with ecoli.
482887938569961500,Sat Jun 28 14:07:10 +0000 2014,Johnny Lee (yes, Wii hack one) gave awesome keynote at Embedded workshop on Project Tango. As my friend put it, "he's ultra-knowledgeable"
482623740610883600,Fri Jun 27 20:37:21 +0000 2014,@gsinghc thanks. Caffe, full stop.
482204271891726340,Thu Jun 26 16:50:32 +0000 2014,@labhra89 I don't like them but thanks. Nope never did became too busy with other stuff
482201432515280900,Thu Jun 26 16:39:15 +0000 2014,The CVPR conference has been temporarily suspended because everyone is watching soccer
482014206867562500,Thu Jun 26 04:15:16 +0000 2014,RT @korirotti: Good day at #CVPR2014. @karpathy did a fantastic job with his talk. Very well received. http://t.co/7YdJ10OW1K
481874224492318700,Wed Jun 25 18:59:02 +0000 2014,And conversely with number of images and better, flashy videos and demos.
481873971689029600,Wed Jun 25 18:58:02 +0000 2014,The number of people leaving the talk is directly proportional to the number of math symbols on the slide.
481554703307005950,Tue Jun 24 21:49:22 +0000 2014,Yahoo Labs releases 100 million image a dataset. Total 50TB! Nice. http://t.co/pp3eHS1vqA
481454231216328700,Tue Jun 24 15:10:08 +0000 2014,CVPR 2014 papers in pretty form http://t.co/yiWNUja8TG I also just noticed that Colin put his version up: http://t.co/zZHFBOyyyf #CVPR2014
481117373609431040,Mon Jun 23 16:51:35 +0000 2014,My @united fun flight update. "Slept" stranded at airport. On my 3rd flight now. Maybe canceled again: they don't know where the captain is
481105965207408640,Mon Jun 23 16:06:15 +0000 2014,@stephenroller but I needed a new boarding pass printed to board new flight etc. how do I get that arranged through phone?
480958290948390900,Mon Jun 23 06:19:27 +0000 2014,Never seen this before. My @united flight was canceled after 1hr delay and now I'm stranded on airport in 100-person customer service line
480931718912696300,Mon Jun 23 04:33:51 +0000 2014,En route to CVPR, going through the Video Highlights http://t.co/XfwQ6LP0bC these were a nice idea.
480538585938919400,Sun Jun 22 02:31:41 +0000 2014,My CVPR oral practice talk is 17 minutes and should be 13. But everything I talk about is really important. I'm in a pickle!
480448405718589440,Sat Jun 21 20:33:20 +0000 2014,Starting up my Windows laptop after 1 year of no use. Forgot how much pain Windows is. So many popups, apps begging to be updated, slow, ...
480217509778296800,Sat Jun 21 05:15:51 +0000 2014,@josephmisiti just, no
479689005567455200,Thu Jun 19 18:15:45 +0000 2014,Learning EVerything about ANything (LEVAN) http://t.co/Q4s4hEkB5k is an automated visual encyclopedia. And CVPR paper http://t.co/Mg3Rf8rve6
479684821573058560,Thu Jun 19 17:59:08 +0000 2014,When I watch soccer all I can think of is if a ConvNet could recognize how much trouble the defending team is during an attack.
479439083698012160,Thu Jun 19 01:42:39 +0000 2014,@ivanlubenko yeah looks they nailed it, judging from the popularity of poke.
479328286011453440,Wed Jun 18 18:22:23 +0000 2014,Calling it now: in 1 year: FB in talks to acquire Yo at $10B valuation. Talks fail. 2 months later: FB pushes new app "Hey". Noone cares.
479325216670101500,Wed Jun 18 18:10:11 +0000 2014,Yo fundamenally transforms the nature of communication   http://t.co/pZMwhiMTgL :)
479113096720441340,Wed Jun 18 04:07:18 +0000 2014,@sergecell there's some recent evidence that the CNNs as shown in my paper struggle to take full advantage of motion http://t.co/dfj59fGrvO
479050145741291500,Tue Jun 17 23:57:09 +0000 2014,Facebook is struggling. @romaindillet put it best as "Slingshot is the Google+ of Snapchat". http://t.co/LHrntKtLc8 it's just sad to watch
478986382216417300,Tue Jun 17 19:43:47 +0000 2014,@stephenroller thanks! Yes, very intentionally mobile optimized ;)
478982231549943800,Tue Jun 17 19:27:17 +0000 2014,Added more info about the Sports-1M dataset: 1.1 million YouTube videos, 487 classes., released with my CVPR paper  http://t.co/JYKSYbosTc
478936248736694300,Tue Jun 17 16:24:34 +0000 2014,Solar power FAQs. http://t.co/74snL8t7xG (with math)
478731289705455600,Tue Jun 17 02:50:08 +0000 2014,Baba Yetu is still one of my favorite hacking songs http://t.co/kryQazSmyH it's a mixture of soothing/epic, with elements of Civ4 nostalgia
478668793036546050,Mon Jun 16 22:41:48 +0000 2014,@notmisha yeah there were few along these lines. Interesting that HMO bars jump around a bit. Guess I'd have to actually read the paper :)
478665519088680960,Mon Jun 16 22:28:47 +0000 2014,@notmisha ok. I've definitely seen this ~2 years ago because I remember them asking Adam and I for representations from our network
478665290075471900,Mon Jun 16 22:27:53 +0000 2014,RT @notmisha: "Our evaluations show that the latest DNNs rival the representational performance of IT cortex" http://t.co/DSqFXf1P3v
478664300643368960,Mon Jun 16 22:23:57 +0000 2014,@notmisha didn't i see this already presented almost two years ago? Did they improve on their past results?
478251745106079740,Sun Jun 15 19:04:36 +0000 2014,I like World Cup more now that I'm following @FiveThirtyEight 's coverage. They ruin mystery with stats and I love it http://t.co/e8zx4pZCYO
478229328560275460,Sun Jun 15 17:35:31 +0000 2014,Checking out Stanford commencement, keynote this year by @BillGates http://t.co/7QUHufhfmV
477712416092856300,Sat Jun 14 07:21:30 +0000 2014,@ShellyFan hmmm saw it but didn't follow this much.
477576450124439550,Fri Jun 13 22:21:13 +0000 2014,tweets | grep -Ei --invert-match world\|cup doesn't work...
477290976944205800,Fri Jun 13 03:26:51 +0000 2014,@random_walker yes, if driving there and back took 5 hours for a 1 hour BBQ during which you barely had time to eat a half-cooked burger.
477264880865533950,Fri Jun 13 01:43:09 +0000 2014,PhD life offers variety of fun and non-fun activities. Spent last few days writing Latex and making slides. :\
476802591469223940,Wed Jun 11 19:06:11 +0000 2014,HP bets on memristors http://t.co/Lw23Cj8ubA talk by Williams in 2010 explaining the tech: https://t.co/c3zWBmXtsf (super detailed, nice)
476267514255519740,Tue Jun 10 07:39:58 +0000 2014,@korirotti I did... Unfortunately. :\
