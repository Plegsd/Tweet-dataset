id,created_at,text
1230168755872747500,Wed Feb 19 16:34:21 +0000 2020,RT @YaoQinUCSD: Excited to share our ICLR2020 work with @nickfrosst, @colinraffel, @sabour_sara, Gary Cottrell and @geoffreyhinton   in det‚Ä¶
1220769722637021200,Fri Jan 24 18:05:57 +0000 2020,When I invented adversarial training as a defense against adversarial examples, I focused on making it as cheap and‚Ä¶ https://t.co/yMgUPQ3O4I
1220422817818214400,Thu Jan 23 19:07:28 +0000 2020,RT @dwf: Very glad to share this on arXiv today: one weird trick for getting Q-learning to work when the action space is big and complicate‚Ä¶
1220026779634565000,Wed Jan 22 16:53:45 +0000 2020,@jm_alexia the new causal GAN paper isn't out yet, right?
1220023187578089500,Wed Jan 22 16:39:29 +0000 2020,The quiet semisupervised revolution continues https://t.co/FAY4v9aHbe
1208191007793107000,Sat Dec 21 01:02:38 +0000 2019,@jm_alexia Congratulations!
1202749521928679400,Fri Dec 06 00:40:06 +0000 2019,If you'd like to meet someone from my team at NeurIPS, talk to Shreya! https://t.co/IEtqpgqKqc
1202061877691347000,Wed Dec 04 03:07:39 +0000 2019,RT @liu_mingyu: Woohoo! GauGAN won the Best of What's New Award by Popular Science Magazine!!! If you haven't tried GauGAN, please visit  h‚Ä¶
1194472996594831400,Wed Nov 13 04:32:09 +0000 2019,Colin was a senior research scientist in my team at Google. He's done great technical work, especially on attention‚Ä¶ https://t.co/9pudZwJcos
1194318700364517400,Tue Nov 12 18:19:02 +0000 2019,RT @DorsaAmir: Some of the most interesting mimicry I‚Äôve ever seen ‚Äî the wings of this moth (Macrocilix maia) mimic two flies feasting on b‚Ä¶
1194037925425504300,Mon Nov 11 23:43:20 +0000 2019,Unfortunately, I got sick on Friday and was not able to fly to Uruguay. I‚Äôll still do my talk at @Khipu_AI by video‚Ä¶ https://t.co/5NgzbMFQXi
1192452741299241000,Thu Nov 07 14:44:22 +0000 2019,RT @timnitGebru: Rejected for a visa 2 years in a row. Last year her story was in this article talking about her visa denial: https://t.co/‚Ä¶
1186785290007920600,Tue Oct 22 23:23:57 +0000 2019,RT @jm_alexia: I will be a panelist @reworkdl Montreal Deep Learning Summit on Thursday! üòª The subject will be "How Can We Overcome Challen‚Ä¶
1185207083756470300,Fri Oct 18 14:52:43 +0000 2019,@PaulMyersBBC Sure
1184623703478325200,Thu Oct 17 00:14:34 +0000 2019,I‚Äôm heading to Uruguay next month to teach about generative models at https://t.co/fXC2gYii8W
1182491746262929400,Fri Oct 11 03:02:56 +0000 2019,RT @yaroslav_ganin: Wanna play around with SPIRAL but the installation seems complicated? I've just built a Docker image to make the experi‚Ä¶
1181356607730401300,Mon Oct 07 23:52:18 +0000 2019,RT @NandoDF: Two recent works @DeepMindAI on generating embodied behaviour with GANs. https://t.co/WUXE693VXb and https://t.co/2a84XMrmwj h‚Ä¶
1180545503747956700,Sat Oct 05 18:09:16 +0000 2019,RT @mldauber: Chanel Miller gives a devastating interview to  @chronicle about her devastating betrayal by  @Stanford when Persis Drell ref‚Ä¶
1179556054436180000,Thu Oct 03 00:37:33 +0000 2019,@gwern @dwf I am especially confused because I have generally enjoyed our previous interactions, reading your blog, etc
1179555725120393200,Thu Oct 03 00:36:14 +0000 2019,@gwern @dwf I also don‚Äôt really understand why you react with so much hostility to people who think that... more sh‚Ä¶ https://t.co/4LXLLeKr34
1179553922622427100,Thu Oct 03 00:29:04 +0000 2019,@gwern @dwf I support barriers as a solution with greater than zero effectiveness, but I absolutely do not want Uof‚Ä¶ https://t.co/63PtNbZSlj
1179553488616878000,Thu Oct 03 00:27:21 +0000 2019,@gwern @dwf You seem to be insisting that we use the word ‚Äúactual‚Äù to mean ‚Äúanything that has greater than zero eff‚Ä¶ https://t.co/EtNsO7fRdd
1179552655615508500,Thu Oct 03 00:24:02 +0000 2019,@gwern @dwf I have written 2 tweets with my own words on the subject and the 2nd one was the one correcting your mi‚Ä¶ https://t.co/7I7DyGtAiO
1179550237674725400,Thu Oct 03 00:14:26 +0000 2019,@gwern @dwf In case it isn‚Äôt clear, neither @DWF nor I is saying ‚Äúdon‚Äôt add safety barriers‚Äù. We‚Äôre saying ‚Äúsafety‚Ä¶ https://t.co/UslD36tGmF
1179548207119863800,Thu Oct 03 00:06:22 +0000 2019,@gwern @dwf Pretty sad that an actual UofT prof liked this...
1179424280876081200,Wed Oct 02 15:53:55 +0000 2019,RT @dwf: This is heartbreaking and infuriating. Suicide barriers are not an actual solution. https://t.co/kJoPQWYM2l
1178702165868572700,Mon Sep 30 16:04:30 +0000 2019,RT @AidanNGomez: These dead kids are trying to tell you something @UofTCompSci. It has nothing to do with building safety.
1177295376405033000,Thu Sep 26 18:54:25 +0000 2019,Signed https://t.co/lefI2ZAdFz
1177074217491132400,Thu Sep 26 04:15:37 +0000 2019,RT @triketora: Stanford emerges as a sharp example of institutional cowardice: its failure to meaningfully follow up after it became clear‚Ä¶
1176979466775515100,Wed Sep 25 21:59:06 +0000 2019,@icansayyes @ghc I‚Äôm having a good time!
1176959339619176400,Wed Sep 25 20:39:08 +0000 2019,If you‚Äôre headed to @ghc next week, be sure to talk with Libo Meyers, an inspirational leader I‚Äôm proud to work wit‚Ä¶ https://t.co/Y5VgtQfG1S
1176915829125865500,Wed Sep 25 17:46:14 +0000 2019,@mldauber @Stanford @PersisDrell @reidhoffman @karaswisher I‚Äôm an alumnus and happy to do what I can to stand up to‚Ä¶ https://t.co/hVueINixOJ
1176914743140876300,Wed Sep 25 17:41:55 +0000 2019,RT @mldauber: Stanford University promised Chanel Miller in writing that she would select the quote for the plaque recognizing the attempte‚Ä¶
1174747910732279800,Thu Sep 19 18:11:42 +0000 2019,@askerlee @colinraffel I usually prefer to list the arxiv version of ICLR papers because ICLR takes place a calenda‚Ä¶ https://t.co/vcU9T6lCTQ
1174450053466820600,Wed Sep 18 22:28:07 +0000 2019,RT @open_phil: Applications are open for the Open Phil AI Fellowship!  This program extends full support to a community of current &amp; incomi‚Ä¶
1173318958138577000,Sun Sep 15 19:33:33 +0000 2019,@re_mahmoudi @AndrewYNg @geoffreyhinton @demishassabis @karpathy @AnimaAnandkumar @drfeifei @Miles_Brundage Difficu‚Ä¶ https://t.co/a9DHStyBOb
1172657361049145300,Fri Sep 13 23:44:36 +0000 2019,@GloriaMeltemi Thank you for making the SOCML 2018 report!
1172570424141480000,Fri Sep 13 17:59:09 +0000 2019,@tejuafonja Thank you!
1172570274740330500,Fri Sep 13 17:58:33 +0000 2019,@realSharonZhou Thanks! Will be in touch
1172566004896948200,Fri Sep 13 17:41:35 +0000 2019,Updates about SOCML: 1) I have failed to run a SOCML 2019 2) I‚Äôm not quitting, just having a busy year. I intend to‚Ä¶ https://t.co/34YWUYI5GM
1172210914247856000,Thu Sep 12 18:10:35 +0000 2019,@igoodfel Or another proposal: impersonate me and see if the audience is an effective enough GAN discriminator to tell
1172210731057442800,Thu Sep 12 18:09:51 +0000 2019,@igoodfel I endorse this plan!
1171908550198624300,Wed Sep 11 22:09:06 +0000 2019,RT @DeepMindAI: Congrats to the winners of the recent @kaggle competition on Generative Dog Images (https://t.co/yoSTcckQZL), and to all wh‚Ä¶
1170793875801170000,Sun Sep 08 20:19:46 +0000 2019,@catherinebuk Once when a top university sent someone to recruit me away from my non-academic job, he referred to p‚Ä¶ https://t.co/NNi8aVfYXh
1170792997962698800,Sun Sep 08 20:16:17 +0000 2019,@catherinebuk Exactly!
1170073596196081700,Fri Sep 06 20:37:38 +0000 2019,RT @EricTopol: There's been a lot of buzz about #AI for drug discovery. But I think this is the best case yet: All in 46 days! https://t.co‚Ä¶
1170046148096057300,Fri Sep 06 18:48:34 +0000 2019,@MMKamani7 @BikalpaN @thegautamkamath As someone who organizes other conferences, I‚Äôm interested to know: how does‚Ä¶ https://t.co/r3pXHMbj8Q
1169656003073175600,Thu Sep 05 16:58:16 +0000 2019,RT @danoramas: Excited to embark on my Fall 2019 US Speaking Tour next week! Planned stops include NYC, Boston, Miami, Dallas, SF, Seattle‚Ä¶
1167118699116945400,Thu Aug 29 16:55:56 +0000 2019,@KordingLab That suggests that maybe arxiv is enough for this paper itself, but in order to unlock this paper‚Äôs eff‚Ä¶ https://t.co/xLfJikxmWZ
1167117143432822800,Thu Aug 29 16:49:45 +0000 2019,@KordingLab The ‚ÄúIan reads it‚Äù variable is d-separated from the ‚Äúconference / journal publication‚Äú variable given t‚Ä¶ https://t.co/WEg41HOXKS
1167115627460354000,Thu Aug 29 16:43:44 +0000 2019,@KordingLab Who do you want to read it? How do you want the world to change as a result of the paper?
1164751049627848700,Fri Aug 23 04:07:44 +0000 2019,RT @FeryalMP: Women in Machine Learning Board of Directors is seeking a new member for our Policy and Research Committee! This is a fantast‚Ä¶
1164001783326228500,Wed Aug 21 02:30:25 +0000 2019,@oh_that_hat Which book?
1162404820839366700,Fri Aug 16 16:44:40 +0000 2019,My team at Apple is hiring in Zurich: https://t.co/NzNncDGB5K
1162139693506449400,Thu Aug 15 23:11:09 +0000 2019,@NalKalchbrenner Can it make a better GAN discriminator due to better estimate of D* = p_data / (p_data + p_model)?
1162063770522271700,Thu Aug 15 18:09:27 +0000 2019,@GoAbiAryan https://t.co/dWWrYIdTha
1160692592545161200,Sun Aug 11 23:20:53 +0000 2019,RT @pavolrusnak: I created a #GIMP plugin so you can play with #GauGAN in a fully featured graphics editor. @NvidiaDesign @GIMP_Official #S‚Ä¶
1159651268576465000,Fri Aug 09 02:23:02 +0000 2019,@greyesgt @Apple Congratulations!
1159649452702834700,Fri Aug 09 02:15:49 +0000 2019,RT @yaroslav_ganin: You know how they say it's better late than never? Remember SPIRAL (https://t.co/bLAIjSE10W) from the last year? Well,‚Ä¶
1159642260809515000,Fri Aug 09 01:47:14 +0000 2019,@AndrasRozsa1 @ChrSzegedy Jonathan Uesato wrote the paper introducing it
1159624805378740200,Fri Aug 09 00:37:53 +0000 2019,@AndrasRozsa1 @ChrSzegedy (With the early stopping you won‚Äôt actually run for the full 1000 for most examples, so t‚Ä¶ https://t.co/PVtWB0OvGk
1159624635891064800,Fri Aug 09 00:37:12 +0000 2019,@AndrasRozsa1 @ChrSzegedy 2nd most important is the number of iterations, definitely try at least 1000
1159624342784733200,Fri Aug 09 00:36:02 +0000 2019,@AndrasRozsa1 @ChrSzegedy Most important hyperparameter is early_stop_loss_thresh = 0. This makes it terminate when‚Ä¶ https://t.co/1egztwUPRt
1159623377084006400,Fri Aug 09 00:32:12 +0000 2019,@AndrasRozsa1 @ChrSzegedy You definitely need to do some hyperparameter search to make it a good adaptive attack. B‚Ä¶ https://t.co/FTxfyEnpsJ
1159623050871971800,Fri Aug 09 00:30:54 +0000 2019,@AndrasRozsa1 @ChrSzegedy I was working on streamlining the process as of when I left Google but I didn‚Äôt finish it: https://t.co/3NcdTUcu85
1159620860996538400,Fri Aug 09 00:22:12 +0000 2019,@AndrasRozsa1 @ChrSzegedy So to be clear: (1) I haven‚Äôt been involved in CleverHans development since March and I d‚Ä¶ https://t.co/UFSCWcBIYC
1159574855395659800,Thu Aug 08 21:19:24 +0000 2019,RT @murium9: Check out our new paper reviewing production quality ranking systems! https://t.co/4xImcrcVjR   @KAryafar @sigir2019 @SIGIReCo‚Ä¶
1159526458093478000,Thu Aug 08 18:07:05 +0000 2019,@ChrSzegedy @ch402 I don‚Äôt mean the previous tweet as a criticism of any existing paper. I mean it as an explanatio‚Ä¶ https://t.co/jU2gEQdcGl
1159509544285814800,Thu Aug 08 16:59:52 +0000 2019,@ch402 @ChrSzegedy Also, the checklist is mostly about expectimax adversarial examples. A static model that passes‚Ä¶ https://t.co/2WQ43z6nN1
1159507678177009700,Thu Aug 08 16:52:27 +0000 2019,@ch402 @ChrSzegedy The Google internal release checklist was (is?) much more specific (down to hyperparameter value‚Ä¶ https://t.co/gQkCEO6B6F
1159507277377704000,Thu Aug 08 16:50:52 +0000 2019,@ch402 @ChrSzegedy We wrote this doc in collaboration with other labs: https://t.co/4VK6tdC9km
1159322878606626800,Thu Aug 08 04:38:08 +0000 2019,@ChrSzegedy In general it would be much better if authors of the first defense paper would follow the recommendatio‚Ä¶ https://t.co/pBmWnqRDEN
1159322052039327700,Thu Aug 08 04:34:51 +0000 2019,@ChrSzegedy It looks like they did not evaluate using the SPSA attack, which would have been required before gettin‚Ä¶ https://t.co/aZh4394lgH
1159321296737407000,Thu Aug 08 04:31:50 +0000 2019,@ChrSzegedy Yes, I acknowledge maybe a new twist makes it work. But in this field nearly all apparent positive resu‚Ä¶ https://t.co/lWMosVFVdk
1159318602727579600,Thu Aug 08 04:21:08 +0000 2019,@ChrSzegedy Yes
1159318312301412400,Thu Aug 08 04:19:59 +0000 2019,@ChrSzegedy BN certainly *helps* training but little tiny MNIST models like this don‚Äôt need much help to train successfully
1159318122463027200,Thu Aug 08 04:19:14 +0000 2019,@ChrSzegedy It‚Äôs pretty easy to train networks that apply 1-D tent activation functions to linear transformations.‚Ä¶ https://t.co/0gGVmlaHW6
1159317041632825300,Thu Aug 08 04:14:56 +0000 2019,@ChrSzegedy I mean I used the tent activation, which is their newly proposed defense. AFAICT they don't say batch n‚Ä¶ https://t.co/JD3x2SDWGg
1159313254897733600,Thu Aug 08 03:59:53 +0000 2019,@ChrSzegedy I tried exactly this in 2014 and it didn‚Äôt work. There‚Äôs a small chance they got it to work using a new‚Ä¶ https://t.co/DwMuxRqloG
1159227749849944000,Wed Aug 07 22:20:07 +0000 2019,@Love2Code We share Stevens Creek trail and the Bay Trail with neighboring cities. The Bay Trail is 500 miles long‚Ä¶ https://t.co/uQUDtLnfGP
1159227344231387100,Wed Aug 07 22:18:30 +0000 2019,@Love2Code We have Permanente Creek trail that takes cyclists and pedestrians over the 101 with no traffic lights,‚Ä¶ https://t.co/ezFrwTOVLl
1159226576875077600,Wed Aug 07 22:15:27 +0000 2019,@Love2Code Mountain View is actually a great place to walk or bike! I drive to commute outside of Mountain View and‚Ä¶ https://t.co/zFWRrlTJgB
1158888443306336300,Tue Aug 06 23:51:50 +0000 2019,Check out the call for papers for the Bayesian deep learning workshop at NeurIPS 2019: https://t.co/jb9hdA7isJ
1158434346467905500,Mon Aug 05 17:47:25 +0000 2019,@danijarh I really like having a doc as an object a program can interact with to build the doc procedurally. This i‚Ä¶ https://t.co/ojcFdhgCsp
1158433552930877400,Mon Aug 05 17:44:16 +0000 2019,@danijarh I‚Äôd be interested in seeing this grow to support LaTeX math, output formats other than HTML, some sort of style sheet, etc.
1158433284650487800,Mon Aug 05 17:43:12 +0000 2019,@danijarh Do you plan to make this a community-driven, long term, large scale project?
1158433146456555500,Mon Aug 05 17:42:39 +0000 2019,@danijarh Thanks, this looks great!
1158433033252245500,Mon Aug 05 17:42:12 +0000 2019,This looks like a great way to programmatically create docs with graphs etc. https://t.co/kkTVKEIjRN
1158190730470281200,Mon Aug 05 01:39:22 +0000 2019,RT @siggraph: Congratulations to the ‚ÄúGauGAN: Semantic Image Synthesis With Spatially Adaptive Normalization‚Äù team, winner of the #SIGGRAPH‚Ä¶
1156786904576086000,Thu Aug 01 04:41:04 +0000 2019,RT @shakir_za: Really excited to share our latest paper in @nature today on machine learning for health data to make early predictions of a‚Ä¶
1156633147192123400,Wed Jul 31 18:30:06 +0000 2019,RT @ShreyaR: I missed this when it came out, but I just discovered https://t.co/sLBiGuxyjz  The chapter on transposed convolutions is proba‚Ä¶
1156423814059712500,Wed Jul 31 04:38:17 +0000 2019,RT @liu_mingyu: So happy to share the news that @NVIDIADesign #GauGAN won both best real time live demo award and people‚Äôs choice of best d‚Ä¶
1156344147512422400,Tue Jul 30 23:21:43 +0000 2019,RT @AnimaAnandkumar: Over 500K images have been created with #GauGAN since its release a month ago. This includes leading concept artists,‚Ä¶
1155575916103213000,Sun Jul 28 20:29:02 +0000 2019,RT @liu_mingyu: I will be giving a talk on #GauGAN and its backbone algorithm #SPADE in room 501 at #SIGGRAPH2019 at 2pm today (Sunday 7/28‚Ä¶
1155553367344550000,Sun Jul 28 18:59:26 +0000 2019,RT @maze518: Draw object shapes &amp; the neural networks fill in the details like magic! @NVIDIA‚Äôs GauGAN: Semantic Image Synthesis With Spati‚Ä¶
1154943444223062000,Sat Jul 27 02:35:49 +0000 2019,@mcmillen It‚Äôs also possible in theory
1154883744118870000,Fri Jul 26 22:38:35 +0000 2019,RT @dribnet: ecstatic to share new work done with @YACHT - these prints demonstrate targeting arbitrary categories with üî•custom datasetsüî• h‚Ä¶
1154827863218016300,Fri Jul 26 18:56:32 +0000 2019,Keeping up my trend this week of finding out well known illustrative stories are most likely false, I found @gwern‚Ä¶ https://t.co/jEUXWBFqLJ
1154780646415294500,Fri Jul 26 15:48:55 +0000 2019,@vaibhavsinha75 Do you mean Kotler finds support for the idea of psychological barriers in multiple sports?
1154497229240983600,Thu Jul 25 21:02:43 +0000 2019,RT @danoramas: Elements: A little "back-to-the-basics" collection inspired by one of my all-time favorite artists. Happy 149th Birthday, Ma‚Ä¶
1154211524212248600,Thu Jul 25 02:07:26 +0000 2019,@AndrewCutler13 @gwern (In case it isn‚Äôt clear, I 100% believe in genetic effects and don‚Äôt need any convincing that they‚Äôre large)
1154210687909974000,Thu Jul 25 02:04:06 +0000 2019,@gwern My intro to psych class at Stanford said people will say line A is longer than line B if everyone else in th‚Ä¶ https://t.co/8tc33krmee
1154208883629416400,Thu Jul 25 01:56:56 +0000 2019,@gwern There‚Äôs also a weird self-confirming property of the claim. If we say Rosenthal only showed that experimente‚Ä¶ https://t.co/eU8hzPtrWQ
1154208532700336000,Thu Jul 25 01:55:33 +0000 2019,@gwern I have to say I still feel pretty biased toward believing this one. ‚ÄúPhD students tend to show the outcome t‚Ä¶ https://t.co/xJujbJ90GD
1154202801762791400,Thu Jul 25 01:32:46 +0000 2019,@gwern What are the deeper incentives? Can psychology departments / journals expect to keep getting funding if noth‚Ä¶ https://t.co/jJYoO6KLqB
1154202598024417300,Thu Jul 25 01:31:58 +0000 2019,@gwern That‚Äôs sad but I get what you‚Äôre saying now. The replication crisis isn‚Äôt changing the journals‚Äô priorities‚Ä¶ https://t.co/ndlTM0ryuq
1154200523538436000,Thu Jul 25 01:23:43 +0000 2019,@gwern Thanks. That‚Äôs useful information. There‚Äôs never been a negative reproduction though? I‚Äôd think that a lot o‚Ä¶ https://t.co/MPqCLUi9Nm
1154199283828023300,Thu Jul 25 01:18:47 +0000 2019,@gwern I‚Äôll believe you that that was his motivation for doing the study. But isn‚Äôt it possible that *both* genetic‚Ä¶ https://t.co/aoTeFcfwIs
1154197501500481500,Thu Jul 25 01:11:42 +0000 2019,@gwern Yeah, I didn‚Äôt think it was endorsement. Just surprised to end up interacting with the person hosting
1154192893411676200,Thu Jul 25 00:53:24 +0000 2019,@gwern I think the paper I‚Äôm asking about is this one: https://t.co/gpu2EaDNvO (hosted on your website???) and I th‚Ä¶ https://t.co/P2y89PHZDa
1154189951199674400,Thu Jul 25 00:41:42 +0000 2019,@gwern Thanks. The content of the talk page seems to be about a different issue though. I‚Äôm not asking about whethe‚Ä¶ https://t.co/fWAaGv8gtB
1154188622783893500,Thu Jul 25 00:36:26 +0000 2019,@gwern @AndrewCutler13 Thanks. So you‚Äôre saying the ‚Äúmaze bright‚Äù / ‚Äúmaze dull‚Äù experiment has been repeated without reproducing the result?
1154173677136568300,Wed Jul 24 23:37:02 +0000 2019,@MEetvelde @daniel_bilar I remember the class included A* search, constraint satisfaction algorithms, decision tree‚Ä¶ https://t.co/BwDREECpmz
1154172277430222800,Wed Jul 24 23:31:29 +0000 2019,@TJO_datasci Yes
1154170120471605200,Wed Jul 24 23:22:54 +0000 2019,Question for psychology experts of twitter: do the ‚Äúbright‚Äù rats *actually perform* better because the PhD students‚Ä¶ https://t.co/YPAUA0UhEG
1154169543696121900,Wed Jul 24 23:20:37 +0000 2019,There‚Äôs a famous result in psychology where grad students report that rats are better at mazes if the advisor tells‚Ä¶ https://t.co/cpytFCkVQ0
1154159334143623200,Wed Jul 24 22:40:03 +0000 2019,@BruceTedesco More computation and data has made it possible to solve problems involving high resolution images, et‚Ä¶ https://t.co/9miLJ8GSSM
1154158718960803800,Wed Jul 24 22:37:36 +0000 2019,@daniel_bilar In 2006 if you believed in neural nets then results like Geoff Hinton‚Äôs deep belief nets were reason‚Ä¶ https://t.co/6UfOgprlho
1154158212511256600,Wed Jul 24 22:35:35 +0000 2019,@daniel_bilar When I took my first intro to AI class in 2006 there were no neural nets in the class. At the end of‚Ä¶ https://t.co/Q4t3P4llUO
1154157673392177200,Wed Jul 24 22:33:27 +0000 2019,@Hassle_J I owned the same personal computer / GPU throughout all of my PhD. By the time I graduated it was easy to‚Ä¶ https://t.co/6Qf8rFKlyf
1154157083857571800,Wed Jul 24 22:31:06 +0000 2019,@Hassle_J When I started grad school, the big academic debate in my area was ‚Äúis supervised deep learning broken be‚Ä¶ https://t.co/pNpl37s2es
1154153380945600500,Wed Jul 24 22:16:23 +0000 2019,I think that barriers to the success of deep learning before 2012 were largely psychological and have previously us‚Ä¶ https://t.co/4mctSLTR5Q
1154153001344331800,Wed Jul 24 22:14:53 +0000 2019,For years I‚Äôve believed in the story that after the first person ran a 4 minute mile, suddenly many other athletes‚Ä¶ https://t.co/omW2FQPAJU
1153417050800308200,Mon Jul 22 21:30:29 +0000 2019,@monavernon @etzioni @benedictevans ‚ÄúDeepfake‚Äù is from 2017
1153096862989086700,Mon Jul 22 00:18:10 +0000 2019,@ylecun @tdietterich Sometimes barriers to entry are actually a good thing, e.g. reviewers enforcing valid experiment design.
1153096477121507300,Mon Jul 22 00:16:38 +0000 2019,@ylecun @tdietterich Large community size can indicate low barriers to entry. Sometimes barriers to entry don‚Äôt hav‚Ä¶ https://t.co/6BhOyJUOHA
1153096082022269000,Mon Jul 22 00:15:04 +0000 2019,@ylecun @tdietterich Large *research* community size can indicate that a field is young more than than it is influential.
1153095840543543300,Mon Jul 22 00:14:06 +0000 2019,@ylecun @tdietterich Large community size can be something to be proud of if it‚Äôs caused by high influence or a dem‚Ä¶ https://t.co/Q3EJheJHwr
1152962973465378800,Sun Jul 21 15:26:08 +0000 2019,@ZachWeiner I‚Äôve also found out that it‚Äôs a mild swear word in Mandarin: https://t.co/3DGNnQWFdF
1152405209596907500,Sat Jul 20 02:29:47 +0000 2019,RT @gstsdn: GANs made it into SMBC: https://t.co/VxB14NDKmP
1150973099006840800,Tue Jul 16 03:39:05 +0000 2019,DVD-GAN https://t.co/3Ax26l77Rg
1149838767630405600,Sat Jul 13 00:31:39 +0000 2019,@joapuipe Thanks!
1149777035989905400,Fri Jul 12 20:26:21 +0000 2019,@IAmAtay Sorry to hear that.
1149699266400538600,Fri Jul 12 15:17:20 +0000 2019,@gamaleldinfe Thanks!
1149429779814203400,Thu Jul 11 21:26:29 +0000 2019,I‚Äôm in Fortune‚Äôs 40 under 40: https://t.co/a4cZrJVjvJ
1149034059990835200,Wed Jul 10 19:14:02 +0000 2019,@nsaphra (D) An efffective way to get people to criticize your work
1148395224940499000,Tue Jul 09 00:55:32 +0000 2019,RT @YaoQinUCSD: Very happy to release our work on detecting and diagnosing adversarial images~ https://t.co/w7c7SByE6H
1148258275382530000,Mon Jul 08 15:51:21 +0000 2019,@poolio @hardmaru I‚Äôm hoping someone will make BigAVB
1148256281880227800,Mon Jul 08 15:43:25 +0000 2019,@hardmaru @poolio This is ‚ÄúBigBiGAN‚Äù not ‚ÄúBigBigGAN‚Äù. The second word is ‚Äúbi‚Äù for ‚Äúbidirectional‚Äù meaning it has an‚Ä¶ https://t.co/kVX47Ttnue
1148255925523775500,Mon Jul 08 15:42:00 +0000 2019,It‚Äôs interesting to see the pendulum swing back to representation learning. During my PhD, most of my collaborators‚Ä¶ https://t.co/zyoJnBUEgD
1148255564847181800,Mon Jul 08 15:40:34 +0000 2019,While we were writing the original GAN paper, my co-author @dwf tried to get something similar to BiGAN working for‚Ä¶ https://t.co/yIpn4rjsQr
1147306127547174900,Sat Jul 06 00:47:51 +0000 2019,RT @SteinmetzNeuro: As scientific teams grow, our model of credit assignment (1st author, last, or everyone else) becomes increasingly outd‚Ä¶
1147281012319146000,Fri Jul 05 23:08:03 +0000 2019,@WilliamSAshbee @AndrewYNg @tim_cook Thank you!
1145302410136604700,Sun Jun 30 12:05:47 +0000 2019,@mims Wizard of Earthsea, Redwall
1143977019635642400,Wed Jun 26 20:19:10 +0000 2019,‚ÄúBe careful what you wish for‚Äù https://t.co/DmZXvjXCPv
1143809456242942000,Wed Jun 26 09:13:19 +0000 2019,@polynoamial @techreview @SCSatCMU Congratulations!
1143608782653743100,Tue Jun 25 19:55:55 +0000 2019,@woj_zaremba Congratulations!
1143608706086723600,Tue Jun 25 19:55:37 +0000 2019,@haldaume3 @red_abebe Congratulations @red_abebe !
1143608422652362800,Tue Jun 25 19:54:29 +0000 2019,@Azaliamirh Congratulations!
1142670381066702800,Sun Jun 23 05:47:03 +0000 2019,RT @random_forests: A new CycleGan tutorial is ready in @TensorFlow 2.0. A very cool paper, showing how to create beautiful image transform‚Ä¶
1141129526434398200,Tue Jun 18 23:44:14 +0000 2019,RT @liu_mingyu: In CVPR2019, the #StyleGAN paper won the best paper honorable mention and  #SPADE/#GauGAN paper won the best paper finalist‚Ä¶
1140430470871576600,Mon Jun 17 01:26:27 +0000 2019,@colinraffel Congratulations!
1140074253414330400,Sun Jun 16 01:50:58 +0000 2019,@tqchenml @mldcmu @CSDatCMU @SCSatCMU @uwcse Congratulations!
1139530817934254100,Fri Jun 14 13:51:33 +0000 2019,@m_guerini @doomie If someone sends me something long or otherwise hard to respond to quickly on a messaging app th‚Ä¶ https://t.co/rGAaeKrqQr
1139530600409251800,Fri Jun 14 13:50:41 +0000 2019,@m_guerini @doomie When I‚Äôm in verbal meetings with people I email myself action items. That way the things people‚Ä¶ https://t.co/Ki961teZMQ
1139310279089508400,Thu Jun 13 23:15:12 +0000 2019,RT @liu_mingyu: The #GauGAN beta version is now available to everyone as a web service via https://t.co/B2Ub9mI40y  #NVIDIA AI Playground A‚Ä¶
1139294620959957000,Thu Jun 13 22:12:59 +0000 2019,@BlogPodemos @ForeignPolicy It‚Äôs partly because we originally wrote the outline for the book before DeepMind‚Äôs Atar‚Ä¶ https://t.co/e9V5ikplRC
1139293792639438800,Thu Jun 13 22:09:41 +0000 2019,@doomie gmail classifies my emails to myself as not important
1139017120547688400,Thu Jun 13 03:50:18 +0000 2019,RT @gstsdn: If you want to hear about a fun new way to test neural networks (in the way that you would 'test' software) come to my long tal‚Ä¶
1138984405886615600,Thu Jun 13 01:40:18 +0000 2019,RT @colinraffel: New pre-print! https://t.co/C9HTZtr23K Monotonic Infinite Lookback Attention (MILk): an online attention mechanism which w‚Ä¶
1137056797347369000,Fri Jun 07 18:00:40 +0000 2019,@kaymtye No option for ‚ÄúPI insists on being 1st author‚Äù?
1136787992075358200,Fri Jun 07 00:12:32 +0000 2019,@AlOrozco53 Not yet, but hoping to find time to put it together
1136473433380872200,Thu Jun 06 03:22:35 +0000 2019,RT @pbaylies: Watch the Mona Lisa turn her head, in today's edition of stupid StyleGAN encoder tricks... #StyleGAN https://t.co/ruNaWdl5Ir‚Ä¶
1134842229049028600,Sat Jun 01 15:20:46 +0000 2019,3) Other papers have previously pointed out some of the same problems that Nissim et al 2019 point out.
1134842228386385900,Sat Jun 01 15:20:46 +0000 2019,2) The paper I linked to, Nissim et al 2019, also says that Bolukbasi et al 2019 solve analogies using the parallel‚Ä¶ https://t.co/XW3Nty6ZEP
1134842227711025200,Sat Jun 01 15:20:46 +0000 2019,1) It is true that in Mikolov 2013a, the word "queen" is chosen only if "king" is hardcoded out. In general, it is‚Ä¶ https://t.co/nOAkmEehaK
1134842226863878100,Sat Jun 01 15:20:45 +0000 2019,Some updates on this: https://t.co/cUwW7tbZyM
1133945264606068700,Thu May 30 03:56:33 +0000 2019,@seth_stafford For images, @AlecRad et al showed that linear analogies work, without an output restriction https://t.co/oCCsioEkRu
1133886718673731600,Thu May 30 00:03:54 +0000 2019,@WWRob @yoavgo @chrmanning Curious if @AlecRad has a take, since his DC-GAN paper showed these analogies working for images
1133884764652310500,Wed May 29 23:56:09 +0000 2019,@WWRob @yoavgo @chrmanning I‚Äôm not saying the paper was intended to mislead, but that the examples are famous and p‚Ä¶ https://t.co/FwDe1UH5KX
1133811388793536500,Wed May 29 19:04:34 +0000 2019,@lhenault @ylecun In Montreal many people pronounced my name as ‚ÄúYann‚Äù. Also, Yann Dauphin studied there at the sam‚Ä¶ https://t.co/Pc0e6pAglQ
1133809554293022700,Wed May 29 18:57:17 +0000 2019,@lhenault @ylecun At NIPS 2011 there were buses for people to go see the Alhambra, divided up by last name. The G b‚Ä¶ https://t.co/zQl6gJJJ5q
1133769510085730300,Wed May 29 16:18:10 +0000 2019,@MihaelFeldman I‚Äôm saying analogy tasks don‚Äôt actually serve as evidence that the NLP model from the 2013 paper has‚Ä¶ https://t.co/PRPaAVOy7M
1133528955552534500,Wed May 29 00:22:17 +0000 2019,As far as I know these kinds of analogies actually work in image models. https://t.co/cUwW7tbZyM
1133528189651677200,Wed May 29 00:19:15 +0000 2019,Whoa! It turns out that famous examples of NLP systems succeeding and failing were very misleading. ‚ÄúMan is to king‚Ä¶ https://t.co/ZhcjsIQCs7
1133414590803349500,Tue May 28 16:47:50 +0000 2019,RT @LadyAshBorg: #AgeofGANs Here‚Äôs a case of tech that can fix representation &amp; diversity. Research shows 200-300% increase in intent to bu‚Ä¶
1132850721982779400,Mon May 27 03:27:14 +0000 2019,@roydanroy It‚Äôs especially frustrating because arxiv has consistently refused to include other features that can‚Äôt‚Ä¶ https://t.co/3TsqwIXuq8
1131986491494752300,Fri May 24 18:13:05 +0000 2019,@deliprao @DrHughHarvey @IAmSamFin @OriolVinyalsML Clearly the generative model is trained differently, but it‚Äôs no‚Ä¶ https://t.co/xOMBzC6wWx
1131985805285634000,Fri May 24 18:10:21 +0000 2019,@deliprao @DrHughHarvey @IAmSamFin @OriolVinyalsML For this paper, it‚Äôs the same amount of data, right?
1131979270891327500,Fri May 24 17:44:23 +0000 2019,@DrHughHarvey @IAmSamFin @deliprao @OriolVinyalsML If we pick a new, previously unseen x point, why should a genera‚Ä¶ https://t.co/CDtR7bgGnp
1131944328035594200,Fri May 24 15:25:32 +0000 2019,@deliprao I personally think the point of generative models for synthetic data is mostly to transform the type of d‚Ä¶ https://t.co/xjhD8HEmVA
1131943667961253900,Fri May 24 15:22:55 +0000 2019,@deliprao Skimming the paper a bit I feel like there‚Äôs a big ‚Äúcitation needed‚Äù marker on the claim that dataset aug‚Ä¶ https://t.co/fdntMOHg61
1131942306515378200,Fri May 24 15:17:31 +0000 2019,@deliprao I haven‚Äôt read this particular paper, but in general if you want to reduce generalization error of a clas‚Ä¶ https://t.co/rPbW0iUD9E
1130445846527520800,Mon May 20 12:11:07 +0000 2019,RT @gamaleldinfe: Looking forward to present my work with @jaschasd @goodfellow_ian @thisismyhat @sh_reya @NicolasPapernot @alexey2004 abou‚Ä¶
1130429072423739400,Mon May 20 11:04:27 +0000 2019,RT @D_Berthelot_ML: Another nice blog post, this time from @sanjeev_vadiraj, that describes MixMatch in a very accessible way. https://t.co‚Ä¶
1130192699414523900,Sun May 19 19:25:12 +0000 2019,RT @jackclarkSF: Gonna be real funny in a few years when Canadian government laments the corporate capture of AI and acts like it was inevi‚Ä¶
1130192669836288000,Sun May 19 19:25:05 +0000 2019,RT @dwf: $4m/year for CIFAR was, last year, just under one forty-thousandth of the Ontario budget. Considering the enormous impact that CIF‚Ä¶
1129750850522497000,Sat May 18 14:09:27 +0000 2019,RT @D_Berthelot_ML: Interesting blog post about semi-supervised learning by Vincent Vanhoucke https://t.co/HhYwHkZtKb
1129534405855203300,Fri May 17 23:49:22 +0000 2019,RT @juliacarriew: The Guardian is updating our style guide to accurately reflect the nature of the environmental crisis.  ‚ÄúClimate change‚Äù‚Ä¶
1128828168310181900,Thu May 16 01:03:02 +0000 2019,RT @NicolasPapernot: Code for MixMatch was just released on GitHub by @D_Berthelot_ML   Includes the setup needed to train a PATE student w‚Ä¶
1128828155131641900,Thu May 16 01:02:59 +0000 2019,RT @avitaloliver: Here's the code behind MixMatch, @D_Berthelot_ML's recent semi-supervised learning method.  Big improvements to common be‚Ä¶
1128772311497158700,Wed May 15 21:21:05 +0000 2019,RT @D_Berthelot_ML: MixMatch (https://t.co/kfMnrJ4jBN) code is released https://t.co/M4Yx2mU2lp (Python3, TensorFlow 1.1x). Let me know how‚Ä¶
1128724814712041500,Wed May 15 18:12:21 +0000 2019,RT @svlevine: Congratulations to @chelseabfinn for winning the 2019 ACM Dissertation Award!  https://t.co/710w7ILB1Y
1128712846349459500,Wed May 15 17:24:47 +0000 2019,@jm_alexia Thanks!
1128710626421891100,Wed May 15 17:15:58 +0000 2019,I can‚Äôt find a paper I think I remember seeing. It argued that when there is enough Lipschitz regularization all GA‚Ä¶ https://t.co/xaRyRHu87u
1128366347753144300,Tue May 14 18:27:55 +0000 2019,@OlliNiemitalo Are you claiming your post makes any mention of a z vector / stochasticity / generative modeling?
1128361521397018600,Tue May 14 18:08:45 +0000 2019,@rmarcilhoo No, sparked by several people at ICLR etc asking me for advice about class imbalance and me not having‚Ä¶ https://t.co/BBbPbY2RU2
1127994332416364500,Mon May 13 17:49:40 +0000 2019,ML Twitter, what are your favorite papers / other resources about the class imbalance problem?
1127723454906503200,Sun May 12 23:53:18 +0000 2019,@yoavgo @JohnCooperAI One seed people should not forget about is Michael Gutmann‚Äôs Noise Contrastive Estimation fro‚Ä¶ https://t.co/9ycrkohMtw
1127721841760452600,Sun May 12 23:46:53 +0000 2019,@JohnCooperAI I think it only took about 30 seconds to put the whole GAN idea together. I had the idea during dinne‚Ä¶ https://t.co/ybKus6tyb5
1127718237951516700,Sun May 12 23:32:34 +0000 2019,@JohnCooperAI If you have the precise idea that works and the domain knowledge to recognize that it should work, th‚Ä¶ https://t.co/SdcBfJkCPK
1127715772732547100,Sun May 12 23:22:46 +0000 2019,@roydanroy @JohnCooperAI Do you have a link?
1127714109263188000,Sun May 12 23:16:10 +0000 2019,@gwern @JohnCooperAI It would‚Äôve been pretty trivial to demonstrate it at least on MNIST. I was doing other generat‚Ä¶ https://t.co/dd5I3y1rAx
1127653992085876700,Sun May 12 19:17:17 +0000 2019,@aarlo @JohnCooperAI Thanks!
1127648365259345900,Sun May 12 18:54:55 +0000 2019,@JohnCooperAI That being said people do use z-less GANs for things like pix2pix and it works OK
1127647875918262300,Sun May 12 18:52:58 +0000 2019,@JohnCooperAI They don‚Äôt seem to have the idea quite right anyway. There‚Äôs no mention of the random z vector, so th‚Ä¶ https://t.co/VYbrug51ch
1126969395593433100,Fri May 10 21:56:56 +0000 2019,@Franco_Ouimet Probably best to ask @mitpress , but I didn‚Äôt know of any using an unmodified photo
1126497919903858700,Thu May 09 14:43:28 +0000 2019,@GiorgioPatrini @catherio
1126489910184222700,Thu May 09 14:11:38 +0000 2019,RT @liu_mingyu: Check out our new #GAN work on translating images to unseen domains in the test time with few example images. Live demo htt‚Ä¶
1126254639177982000,Wed May 08 22:36:45 +0000 2019,@egrefen Yes, it‚Äôs not really me
1126215477540343800,Wed May 08 20:01:08 +0000 2019,RT @NicolasPapernot: In addition to reducing the need for labeled data,  developments in semi-supervised learning have made it easier to le‚Ä¶
1126208953354997800,Wed May 08 19:35:13 +0000 2019,RT @_vaishnavh: Visit poster #15 at #ICLR2019 today to learn about our work (with @zicokolter) on deterministic PAC-Bayesian bounds for dee‚Ä¶
1126208880743260200,Wed May 08 19:34:55 +0000 2019,@pavelkovalski The website is by @lucidrains and the specific model is by a team at @NvidiaAI . No need for permission from me
1126114081071562800,Wed May 08 13:18:13 +0000 2019,RT @D_Berthelot_ML: New paper: MixMatch: A Holistic Approach to Semi-Supervised Learning https://t.co/OO6zj9NPci Reduces error rate by up t‚Ä¶
1125972540822835200,Wed May 08 03:55:47 +0000 2019,RT @xbpeng4: We will be presenting a poster of our work on the variational discriminator bottleneck @iclr2019 on Wed 11am #11. Come check o‚Ä¶
1125865271409958900,Tue May 07 20:49:32 +0000 2019,@BedabrataChoud1 @sirajraval It‚Äôs a poster session so not live-streamed (big, crowded, noisy room with many people‚Ä¶ https://t.co/mIqICgU2oY
1125864573737885700,Tue May 07 20:46:46 +0000 2019,@gamaleldinfe ‚Äòs tweet: https://t.co/qVjFZ2EnJe
1125859267200860200,Tue May 07 20:25:41 +0000 2019,@colinraffel ‚Äòs posters: https://t.co/wJuzZhzx9e
1125858948547006500,Tue May 07 20:24:25 +0000 2019,@smnh_azadi ‚Äòs poster: https://t.co/BnAqXJQKu2
1125858524955926500,Tue May 07 20:22:44 +0000 2019,If you‚Äôre at ICLR, my former colleagues will present our recent work in great hall BC today, 4:30-6:30 PM.‚Ä¶ https://t.co/Zeks7ntjVV
1125238357410373600,Mon May 06 03:18:24 +0000 2019,RT @smnh_azadi: Looking forward to #ICLR2019. I'll present our "Discriminator Rejection Sampling" poster (#46) on Tuesday at 4:30-6:30pm in‚Ä¶
1125211709805924400,Mon May 06 01:32:31 +0000 2019,RT @ajmooch: I'll be presenting BigGAN at ICLR2019 Monday morning, at 10:15 in Great Hall AD. I'll also be giving out Dogball stickers all‚Ä¶
1125114982234857500,Sun May 05 19:08:10 +0000 2019,RT @vkrakovna: Looking forward to #ICLR2019 SafeML workshop on May 6, with an awesome lineup of invited speakers and panelists @goodfellow_‚Ä¶
1124751948249387000,Sat May 04 19:05:36 +0000 2019,@Dev_Adrish_1998 @MeysamAsgariC The success of GANs definitely comes with some "first world problems". Of these, th‚Ä¶ https://t.co/PK3FmArP9z
1124751634741882900,Sat May 04 19:04:21 +0000 2019,@Dev_Adrish_1998 @MeysamAsgariC Long time to reply, but overall it feels good. I like seeing my technical work perf‚Ä¶ https://t.co/j2RLrq3F1t
1124742740103680000,Sat May 04 18:29:00 +0000 2019,Scientific American article on GANs: https://t.co/YB8CS43nNg
1124126312103170000,Fri May 03 01:39:32 +0000 2019,@jasontoff Thanks!
1124103252310614000,Fri May 03 00:07:54 +0000 2019,@BootsRiley It kept me as following you
1123070746484400100,Tue Apr 30 03:45:06 +0000 2019,RT @MarioLucic_: Our work on "High-Fidelity Image Generation With Fewer Labels" has been accepted to ICML'19! Thanks to the reviewers and t‚Ä¶
1123067705697812500,Tue Apr 30 03:33:01 +0000 2019,GANs for architecture: https://t.co/qT531EcSk6
1121875792927920100,Fri Apr 26 20:36:47 +0000 2019,Robbie is a real pioneer in AI + art. Do any good art schools have a spot for this fall? https://t.co/Mf1e3Jkx1A
1121839644729958400,Fri Apr 26 18:13:08 +0000 2019,@catherineols Bonus to learning math-French: you can read old timey 1800s French math from the greats like Cauchy and Laplace
1121839225077264400,Fri Apr 26 18:11:28 +0000 2019,@catherineols If you‚Äôre open to learning French (math-French is a very tiny subset of real French, and trivial to t‚Ä¶ https://t.co/A1mV3zVLVi
1121838781273759700,Fri Apr 26 18:09:42 +0000 2019,@catherineols Specific books: hyperreal calculus https://t.co/j1bLHv9s3x (chapter 1 and 2 have the biggest ROI) and https://t.co/rdBT9oZXFn
1121838140480561200,Fri Apr 26 18:07:10 +0000 2019,@catherineols Functional analysis is very useful for ML. A lot of people like to analyze linear regression as a ‚Äúhe‚Ä¶ https://t.co/3ik5nlFBAG
1121824942692003800,Fri Apr 26 17:14:43 +0000 2019,@catherineols Hyperreal numbers and the hyperreal approach to calculus. Very fun, good for seeing how different set‚Ä¶ https://t.co/VvKaBffoim
1121440202856079400,Thu Apr 25 15:45:54 +0000 2019,@DrVeronikaCH So far they‚Äôre just making images of existing clothes. But I want someone to make actual GAN-generate‚Ä¶ https://t.co/Xn6mFoyw9e
1121439819727433700,Thu Apr 25 15:44:23 +0000 2019,@aichip1 I did not patent GANs. Anyone can use them.
1121438640276561900,Thu Apr 25 15:39:41 +0000 2019,https://t.co/OnrSfijYp7, a startup that uses GANs to generate retail marketing images, has raised $17M: https://t.co/msb3fOsGw4
1121260285652639700,Thu Apr 25 03:50:58 +0000 2019,@zacharylipton https://t.co/BBrZRfty1R
1121204815093096400,Thu Apr 25 00:10:33 +0000 2019,RT @phillip_isola: If you are interested in GANs, and around Boston on 5/31, please come check out this workshop we are organizing: https:/‚Ä¶
1121081751739060200,Wed Apr 24 16:01:32 +0000 2019,Nice radio interview with @DrBeef_ : https://t.co/kojbhYGcFJ
1120777296602787800,Tue Apr 23 19:51:45 +0000 2019,RT @CIFAR_News: For #WorldBookDay, a selection of our favourite reads by our fellows and friends from across the physical and social scienc‚Ä¶
1120354354660139000,Mon Apr 22 15:51:07 +0000 2019,@amuellerml @JidinDinesh @pwang You definitely don‚Äôt need real gradients from the model. Just being able to get dis‚Ä¶ https://t.co/zEFckUzkMo
1120353622225612800,Mon Apr 22 15:48:13 +0000 2019,@amuellerml @pwang It‚Äôs reasonably likely that you can overcome those limitations with techniques like https://t.co/uA0ie8lPJ8
1120170887657824300,Mon Apr 22 03:42:06 +0000 2019,"Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition" has been accepted to IC‚Ä¶ https://t.co/1qssUSHc3S
1120170326082510800,Mon Apr 22 03:39:52 +0000 2019,TensorFuzz has been accepted to ICML 2019! Congratulations to @gstsdn ! https://t.co/2sBR7s64X6
1120169996649320400,Mon Apr 22 03:38:33 +0000 2019,We had a long delay between putting SAGAN on arxiv and submitting it to a conference, but it has now been accepted‚Ä¶ https://t.co/DAYrdcpGUq
1120158292683001900,Mon Apr 22 02:52:03 +0000 2019,RT @zacharylipton: Importance weighting is widely used but ***may have no effect on deep nets*** modulo choices regarding early stopping an‚Ä¶
1118347565546688500,Wed Apr 17 02:56:52 +0000 2019,@dtweiseth Someone once sent me an email that accidentally included reply history in which some of his co-authors s‚Ä¶ https://t.co/rpA2Ib9NF7
1118343796050157600,Wed Apr 17 02:41:53 +0000 2019,@volkuleshov Reaching out is definitely better than public attack, and plenty of people are doing the public attack thing
1118266130949271600,Tue Apr 16 21:33:16 +0000 2019,@uPicchini That sounds very nice.
1118193029645504500,Tue Apr 16 16:42:47 +0000 2019,Finally, to help change the norms of the field, I encourage you not to add citations to people who publicly attack‚Ä¶ https://t.co/WAUtRzmowC
1118193028022321200,Tue Apr 16 16:42:47 +0000 2019,I‚Äôve tried both strategies several times and can confidently say starting with private discussion is not only frien‚Ä¶ https://t.co/sYlEtuFWDs
1118193026449453000,Tue Apr 16 16:42:47 +0000 2019,In general, discussing perceived conflicts in private yields better results than starting with a public attack, and‚Ä¶ https://t.co/lV2wLsZWjq
1118193024880738300,Tue Apr 16 16:42:46 +0000 2019,If you start by making a public complaint and then the new author adds a citation, it may not undo the harm of your‚Ä¶ https://t.co/mcJ2378NwY
1118193023115046900,Tue Apr 16 16:42:46 +0000 2019,If you start by making a public complaint, some authors won‚Äôt want to add a citation because they think it will loo‚Ä¶ https://t.co/Y0zAVI8DS8
1118193021332463600,Tue Apr 16 16:42:45 +0000 2019,You also lose a lot of your negotiating leverage. If the new authors don‚Äôt want to cite you, they may agree to cite‚Ä¶ https://t.co/mSKJA7lfeF
1118193019386200000,Tue Apr 16 16:42:45 +0000 2019,If you start by angering the authors of the new paper, they‚Äôre less likely to feel like citing you to be nice.
1118193017653997600,Tue Apr 16 16:42:45 +0000 2019,If you go public first, you may hurt the reputation of someone who doesn‚Äôt deserve it. But you‚Äôre also less likely to get cited
1118193015909171200,Tue Apr 16 16:42:44 +0000 2019,In many cases the authors will just add the citation and they honestly didn‚Äôt know your paper existed.
1118193013132550100,Tue Apr 16 16:42:44 +0000 2019,If you‚Äôre upset that someone didn‚Äôt cite your paper, I strongly recommend contacting the authors privately before m‚Ä¶ https://t.co/cBjMutMZhl
1117939670015365100,Mon Apr 15 23:56:02 +0000 2019,@neurokinetikz I‚Äôll tweet again when it‚Äôs open sourced but I think as a user you just need to change the import
1117929612200120300,Mon Apr 15 23:16:04 +0000 2019,OctConv is a simple replacement for the traditional convolution operation that gets better accuracy with fewer FLOP‚Ä¶ https://t.co/bq5Gw9K2Pb
1117241278792495100,Sun Apr 14 01:40:52 +0000 2019,@adjiboussodieng .@ToniCreswell wrote one in late 2017
1116730908298502100,Fri Apr 12 15:52:51 +0000 2019,CAIS++ (a USC student group) is holding an event to showcase their projects April 22. I had a great time visiting C‚Ä¶ https://t.co/2XNRlgZ7nf
1116524840666660900,Fri Apr 12 02:14:00 +0000 2019,RT @adversariel: Watching an example of @zephoria‚Äôs ‚Äúdata void‚Äù search engine vulnerability materialize in real time is surreal. It bears r‚Ä¶
1116417836790861800,Thu Apr 11 19:08:48 +0000 2019,@roydanroy @tdietterich @deliprao One way the downside starts is when researchers all pursue easily hype-able proje‚Ä¶ https://t.co/fVi5cMyDnb
1115657170366881800,Tue Apr 09 16:46:11 +0000 2019,RT @gstsdn: I'm trying something new: instead of writing another GAN paper, I wrote about topics I'd like to see other people write GAN pap‚Ä¶
1115417129740685300,Tue Apr 09 00:52:21 +0000 2019,@sterlingcrispin @iandanforth @erwincoumans @Cabbibo @quasimondo @mrdoob Do you know the story of Douglas Crockford‚Äôs modified MIT license?
1115407161532620800,Tue Apr 09 00:12:45 +0000 2019,@itamblyn Maybe ask @badfellow_ian
1114301690448990200,Fri Apr 05 23:00:00 +0000 2019,@Geek_Jing @alain_dagher Crescent! Ask for the table in the back left on the ground floor.
1113867255136145400,Thu Apr 04 18:13:42 +0000 2019,@jackclarkSF @OpenAI I‚Äôll be there
1112354318961672200,Sun Mar 31 14:01:50 +0000 2019,@readmeye @tdietterich If you want to find an under-credited Tesla figure in deep learning, I nominate Hochreiter (‚Ä¶ https://t.co/f6XeWZdy39
1111324602393751600,Thu Mar 28 17:50:07 +0000 2019,RT @NicolasPapernot: New #CleverHans blog post that walks you through the few changes that need to be made to stochastic gradient descent t‚Ä¶
1110922874011836400,Wed Mar 27 15:13:47 +0000 2019,RT @geoffreyhinton: @JeffDean @ylecun @TheOfficialACM Thanks to my graduate students and postdocs whose work won a Turing award. Thanks to‚Ä¶
1110380746730950700,Tue Mar 26 03:19:34 +0000 2019,RT @colinraffel: New work w/ @yaoqinucsd, Nicholas Carlini, @goodfellow_ian, and Gary Cottrell on generating imperceptible, robust, and tar‚Ä¶
1109122879646388200,Fri Mar 22 16:01:15 +0000 2019,RT @ajmooch: Want to train your own BigGAN on just 4-8 GPUs? Today we're proud to release BigGAN-PyTorch, a full @PyTorch reimplementation‚Ä¶
1108563836238352400,Thu Mar 21 02:59:49 +0000 2019,RT @karol_kurach: Great work from Brain ZRH team on putting label-hungry GANs on a diet :)  Want to train similar GANs easily? Check out th‚Ä¶
1108520030122065900,Thu Mar 21 00:05:45 +0000 2019,https://t.co/pwPvR22Ynp
1108155551001669600,Tue Mar 19 23:57:26 +0000 2019,RT @liu_mingyu: Check out our #CVPR19 oral paper on a new conditional normalization layer for semantic image synthesis #SPADE and its demo‚Ä¶
1107854020310253600,Tue Mar 19 03:59:16 +0000 2019,RT @liu_mingyu: Check out our #CVPR19 oral paper on a new conditional normalization layer for semantic image synthesis #SPADE and its demo‚Ä¶
1107790434158284800,Mon Mar 18 23:46:35 +0000 2019,RT @jm_alexia: There's a whole community on enhancing the resolution of old #videogames mostly using ESRGAN (which uses Relativistic GANs)!‚Ä¶
1106714859377352700,Sat Mar 16 00:32:38 +0000 2019,RT @liu_mingyu: Glad to see that our #GAN research works enable people to "generate realistic dance videos of NBA players for in-game enter‚Ä¶
1106648927703425000,Fri Mar 15 20:10:39 +0000 2019,@TheRevAlokSingh @fhuszar https://t.co/93UXsglHjd
1106239724757364700,Thu Mar 14 17:04:37 +0000 2019,RT @L_badikho: Many machine learning events happening soon in north/west Africa (I list a speaker/organizer for those who want to ask quest‚Ä¶
1106198627175678000,Thu Mar 14 14:21:19 +0000 2019,Submissions to https://t.co/zQHXW31a5r are due April 12
1106198128229679100,Thu Mar 14 14:19:20 +0000 2019,@jm_alexia I think myth 3 is the most common among the general public
1106024993555603500,Thu Mar 14 02:51:22 +0000 2019,@tarinziyaee cc @GlidewellDental
1106022389643513900,Thu Mar 14 02:41:01 +0000 2019,@RandomlyWalking @MLimericks His thesis was done in 2013 His online trail is not so clean Though his account has no‚Ä¶ https://t.co/p71uGAC9EW
1106019272109613000,Thu Mar 14 02:28:37 +0000 2019,@shamoons @le_roux_nicolas One of the highest-impact things a PhD student could do is build a better online-exclusi‚Ä¶ https://t.co/lq7aoJujPZ
1106018472826306600,Thu Mar 14 02:25:27 +0000 2019,@shamoons @le_roux_nicolas I think you will get better mileage with online activity than attending conferences. Bot‚Ä¶ https://t.co/GtErM225L5
1105920690480275500,Wed Mar 13 19:56:54 +0000 2019,@mschoberml @le_roux_nicolas @_hylandSL There was an online conference called AI @WithTheBest but I believe it is no longer run
1105920229899554800,Wed Mar 13 19:55:04 +0000 2019,@le_roux_nicolas I went to NIPS 2017 (SF-&gt;LA) by train, but then my return train was canceled due to a wildfire. I‚Ä¶ https://t.co/wEtpFuwjgT
1105918812547833900,Wed Mar 13 19:49:26 +0000 2019,@le_roux_nicolas I've seriously cut back on conferences largely for carbon footprint reasons. I haven't noticed any‚Ä¶ https://t.co/WGYttenRxH
1105687851201511400,Wed Mar 13 04:31:41 +0000 2019,RT @sedielem: Likelihood is a great loss fn, it's all about the space you measure it in! Our latest work on hierarchical AR image models (w‚Ä¶
1105535629448732700,Tue Mar 12 18:26:48 +0000 2019,ACAI for modeling drum patterns: https://t.co/zkxv5XaZcK
1103848333204836400,Fri Mar 08 02:42:05 +0000 2019,@deconstructized :) I admit I don't remember that conversation, but it sounds like this was right after I first too‚Ä¶ https://t.co/11Bb3COYeN
1103734061271416800,Thu Mar 07 19:08:01 +0000 2019,I originally thought of GANs as an unsupervised learning algorithm, but so far, to create recognizable object categ‚Ä¶ https://t.co/5M3tw0SfHw
1103726240924557300,Thu Mar 07 18:36:56 +0000 2019,RT @DeepMindAI: We are excited to share the story behind TF-Replicator, a software library that helps developers deploy their TensorFlow co‚Ä¶
1102933156502491100,Tue Mar 05 14:05:30 +0000 2019,RT @doomie: VideoFlow: A Flow-Based Generative Model for Video extends Glow to a new algorithm for multi-frame video prediction with normal‚Ä¶
1101515133803622400,Fri Mar 01 16:10:47 +0000 2019,@vcheplygina Your ‚Äúhow I fail‚Äù series was helpful to me and others
1101492008856768500,Fri Mar 01 14:38:54 +0000 2019,@vcheplygina One of my most popular tweets was a science-relevant cat picture: https://t.co/GBEFw1B0V3
1101180195342508000,Thu Feb 28 17:59:52 +0000 2019,RT @jesseengel: Make music with GANs! GANSynth is a new method for fast generation of high-fidelity audio.  üéµ Examples: https://t.co/xhX9az‚Ä¶
1100869711355498500,Wed Feb 27 21:26:07 +0000 2019,RT @ilyasut: Bill Gates highlights Dactyl as a top ten breakthrough of 2019! Congrats @woj_zaremba!! https://t.co/ltgfkbxVPx
1100811696803737600,Wed Feb 27 17:35:35 +0000 2019,RT @NicolasPapernot: If you're doing research with #CleverHans, an easy and  impactful way to give back to our community is to check the St‚Ä¶
1100527968768520200,Tue Feb 26 22:48:09 +0000 2019,RT @gamaleldinfe: Heading to #COSYNE19 to present our work on human adversarial examples. Looking forward to meet my old friends :)
1100163787863208000,Mon Feb 25 22:41:01 +0000 2019,@jm_alexia Congratulations!
1100046191977390100,Mon Feb 25 14:53:44 +0000 2019,@richardclegg @ederlfern @realhamed My SOCML co-organizers and I moved SOCML to Canada last year hoping that more p‚Ä¶ https://t.co/QQR105Axnz
1100045365967958000,Mon Feb 25 14:50:27 +0000 2019,The arxiv paper for Lingvo is out now: https://t.co/sCu53FM32V
1099154076950917100,Sat Feb 23 03:48:47 +0000 2019,RT @negar_rz: You can apply to be an organizer of the #WiML2019 I personally learnt a lot by co-organizing the @WiMLworkshop and @WiCVworks‚Ä¶
1099068016799637500,Fri Feb 22 22:06:49 +0000 2019,RT @ajmooch: BigGAN has been accepted for oral presentation at ICLR2019! We've uploaded a revision of the paper with an improved architectu‚Ä¶
1098802449341509600,Fri Feb 22 04:31:33 +0000 2019,@IAmSamFin My first computer experience was my dad‚Äôs Zenith in the 1980s. I still configure all my terminals to amb‚Ä¶ https://t.co/YEiJO21F7D
1098642232276471800,Thu Feb 21 17:54:54 +0000 2019,More press for @lucidrains 's StyleGAN sites: https://t.co/dh72ZIovOM
1098401481466638300,Thu Feb 21 01:58:15 +0000 2019,@DrBeef_ Robbie Barrat and Ronan Barrot working together seems like mode collapse in a name generator
1098386416524918800,Thu Feb 21 00:58:23 +0000 2019,@hlntnr it's like making people play as the discriminator in @jm_alexia's relativistic GAN framework
1098375980970737700,Thu Feb 21 00:16:55 +0000 2019,This CVPR workshop is looking for applications of computer vision in developing countries. You don't need to submit‚Ä¶ https://t.co/N7IdpqW3TI
1098006245900841000,Tue Feb 19 23:47:43 +0000 2019,@iamtrask There already is an online machine learning conference: AI @WithTheBest . If you haven't registered for i‚Ä¶ https://t.co/uw6ohaXjc5
1098006041126625300,Tue Feb 19 23:46:54 +0000 2019,@iamtrask Also, less carbon emissions. No need for thousands of people to fly internationally to attend the event
1097873700353765400,Tue Feb 19 15:01:02 +0000 2019,RT @NicolasPapernot: Check out our updated set of guidelines for evaluating adversarial examples defenses: it motivates principles that  gu‚Ä¶
1096621917241397200,Sat Feb 16 04:06:53 +0000 2019,@xgbolakcah You mean to detect near-duplicates? Could hash them based on Inception features and look for collisions
1096620459339042800,Sat Feb 16 04:01:06 +0000 2019,Philip Wang at Uber set up https://t.co/JFox5Zqu69 to show a new imaGANary person every time you refresh the page
1096504890468102100,Fri Feb 15 20:21:52 +0000 2019,RT @vkrakovna: Update: the SafeML workshop paper submission deadline has been extended to March 1, for consistency with other ICLR workshop‚Ä¶
1096477423661506600,Fri Feb 15 18:32:44 +0000 2019,@vcheplygina @JeffDean @trevor_darrell Wait, Trevor‚Äôs account is suspended?
1096477167666397200,Fri Feb 15 18:31:42 +0000 2019,@vcheplygina @JeffDean @trevor_darrell I made my Twitter account while I was working at @OpenAI and I had pretty fa‚Ä¶ https://t.co/meQvfCBPe8
1095761362620362800,Wed Feb 13 19:07:21 +0000 2019,@ChadScherrer @Soph You might like these articles: https://t.co/bbXRNWICsK https://t.co/SwtWWsfZKp Part III of https://t.co/yh28dqzdJv
1095727254057840600,Wed Feb 13 16:51:49 +0000 2019,I emphatically agree. My collaborators' visa restrictions have been one of the largest bottlenecks to our collectiv‚Ä¶ https://t.co/uwy5vamu18
1095542358223933400,Wed Feb 13 04:37:07 +0000 2019,@Robert_Palgrave Spelling rebel: ‚Äústurcture‚Äù
1095326643634073600,Tue Feb 12 14:19:56 +0000 2019,RT @shakir_za: Proud that today we announce the 2019 #IndabaX meetings. Between March and May, Machine Learning will grow across Africa in‚Ä¶
1095167055165177900,Tue Feb 12 03:45:47 +0000 2019,RT @alanyttian: This is *amazingly* great in terms of quality! https://t.co/0bCXUZJRzT
1095149802654814200,Tue Feb 12 02:37:14 +0000 2019,RT @NicolasPapernot: A lecture on security and privacy in ML I recently gave is now available on YouTube. It covers a bunch of open problem‚Ä¶
1095016841355743200,Mon Feb 11 17:48:54 +0000 2019,@FarzaTV Among my own colleagues, @LiamFedus has spent the most time working on text GANs, and probably has more in‚Ä¶ https://t.co/BbUq8YIAQ8
1095016545720315900,Mon Feb 11 17:47:43 +0000 2019,@FarzaTV Part of my comment back then said that I don't see a reason in theory that recurrent GANs would be a probl‚Ä¶ https://t.co/kDT1ZxKzbX
1095016323497701400,Mon Feb 11 17:46:50 +0000 2019,@FarzaTV The main update since back then is that a lot of people (including qualified, credible people) have tried‚Ä¶ https://t.co/UOGUtiLxgE
1095015965161476100,Mon Feb 11 17:45:25 +0000 2019,@FarzaTV The main thing I'd revise given the chance is that before I made it sound like GANs are just not mathemati‚Ä¶ https://t.co/S6yJGoaXQf
1095015769891516400,Mon Feb 11 17:44:38 +0000 2019,@FarzaTV Mostly
1094681418175672300,Sun Feb 10 19:36:02 +0000 2019,RT @SyntopiaDK: GAN's may be evaluated based on how smooth (disentangled) the latent space interpolations are. It is impressive how #StyleG‚Ä¶
1094621611511013400,Sun Feb 10 15:38:23 +0000 2019,@jm_alexia I think you‚Äôre the only ML researcher I know of who does publicly pre-registered trials
1094317503843422200,Sat Feb 09 19:29:59 +0000 2019,@wielandbr Not yet, but I'm curious about that too.
1093994653341311000,Fri Feb 08 22:07:05 +0000 2019,FAIR has released code for the robust ImageNet model by Cihang Xie et al: https://t.co/yB53YRJIUP
1093992173157081100,Fri Feb 08 21:57:14 +0000 2019,The Toronto Deep Learning Series hosted a discussion about ACAI: https://t.co/jYw2DGU3Wl
1093355007259230200,Thu Feb 07 03:45:21 +0000 2019,RT @liu_mingyu: We will present several #GAN works in NVIDIA‚Äôs #GTC19 conference, including #StyleGAN, #vid2vid, and several other new GAN‚Ä¶
1093194787568607200,Wed Feb 06 17:08:42 +0000 2019,@cesncn People still use both together. Check out for example https://t.co/4cLtzLhjTE
1092500527747760100,Mon Feb 04 19:09:58 +0000 2019,@MioMilenkovic I guess check out the dataset and see if you think the faces in the training data score high too:‚Ä¶ https://t.co/9ncdBfwp68
1091739121838485500,Sat Feb 02 16:44:24 +0000 2019,@keefstuart Myth II came with Fear and Loathing
1090424609311055900,Wed Jan 30 01:41:00 +0000 2019,RT @iclr2019: Excited to preview our list of invited speakers for #iclr2019 in New Orleans:  L√©on Bottou, Cynthia Dwork, Ian Goodfellow, No‚Ä¶
1090398201515896800,Tue Jan 29 23:56:04 +0000 2019,RT @pushmeet: Our new results on training verifiably robust neural networks for image classification. https://t.co/YqBw8RJvot
1089187501229523000,Sat Jan 26 15:45:11 +0000 2019,RT @WonderMicky: Machine Learning Crash Course: Genova üáÆüáπ June 17-21. Brought to you by @MIT @UniGenova @IITalk @iaml_it  Apply: https://t.‚Ä¶
1089187166851199000,Sat Jan 26 15:43:51 +0000 2019,More ESRGAN mods of old games: https://t.co/Xel0WzMNP5
1089055411854921700,Sat Jan 26 07:00:18 +0000 2019,RT @NicolasPapernot: Looking forward to be giving talks at @EPFL for the @appliedmldays (Tuesday) and at @GoogleAI Zurich (Wednesday) next‚Ä¶
1088975416197435400,Sat Jan 26 01:42:26 +0000 2019,@peteskomoroch https://t.co/vWegXvr18a
1088841252122980400,Fri Jan 25 16:49:18 +0000 2019,@iamaidang Sell the movie rights for Her II
1088788632331145200,Fri Jan 25 13:20:13 +0000 2019,RT @OriolVinyalsML: Happy that we could share #AlphaStar progress with you all! Good Games @LiquidTLO and @Liquid_MaNa, and @Artosis and @R‚Ä¶
1088128402022907900,Wed Jan 23 17:36:42 +0000 2019,@BerbaFan Here's a paper about denoising using GANs: https://t.co/eXq9d1ctza One of the authors, @zacharylipton , is on Twitter
1087850378568323100,Tue Jan 22 23:11:56 +0000 2019,@JanelleCShane @ForeignPolicy Thanks!
1087846630500548600,Tue Jan 22 22:57:02 +0000 2019,I‚Äôm one of @ForeignPolicy ‚Äòs 100 global thinkers for 2019: https://t.co/mR7h7R9JwR
1087748852176863200,Tue Jan 22 16:28:30 +0000 2019,@hindupuravinash @ForeignPolicy Thanks!
1086415374592008200,Sat Jan 19 00:09:44 +0000 2019,@jm_alexia Wow! What was the cause of the explosion?
1086352229404008400,Fri Jan 18 19:58:49 +0000 2019,@sharongracepjs ‚ÄúEffulgent‚Äù
1086043840207671300,Thu Jan 17 23:33:23 +0000 2019,@AndrewYNg @robot_MD Congratulations!
1085965387131318300,Thu Jan 17 18:21:39 +0000 2019,RT @red_abebe: Thrilled to share that I'll be joining the Harvard Society of Fellows as the 5th computer scientist in the fellowship's hist‚Ä¶
1085648480607952900,Wed Jan 16 21:22:22 +0000 2019,Many people including myself have tried to do this by adding noise at many different layers of the generator, but it didn't work until now
1085648366824972300,Wed Jan 16 21:21:55 +0000 2019,Another great property of style-based generators is that they've finally succeeded in learning multiple levels of a‚Ä¶ https://t.co/nERCdjAqdd
1085646559448977400,Wed Jan 16 21:14:44 +0000 2019,An exciting property of style-based generators is that they have learned to do 3D viewpoint rotations around object‚Ä¶ https://t.co/3mqfYwOiZt
1085591471573495800,Wed Jan 16 17:35:50 +0000 2019,RT @colinraffel: New blog post: "You Don't Know JAX", a brief tutorial which covers the basics of computing gradients, just-in-time compila‚Ä¶
1085270563738665000,Tue Jan 15 20:20:40 +0000 2019,@RichardRVasque1 In the new work, we showed that we're able to make this kind of small pixel change optical illusio‚Ä¶ https://t.co/ZMzPlqOH7d
1085270298809651200,Tue Jan 15 20:19:37 +0000 2019,@RichardRVasque1 We've known since about 2013 that it's possible to fool computer vision systems by making very sma‚Ä¶ https://t.co/R2LVwvuXpy
1085229394459652100,Tue Jan 15 17:37:04 +0000 2019,Our work on adversarial examples for the human vision system has been accepted to #COSYNE19 : https://t.co/jpeYjPuw6D
1085014785488412700,Tue Jan 15 03:24:18 +0000 2019,@arta5313 Many of these are also accepted at conferences
1084976246809780200,Tue Jan 15 00:51:09 +0000 2019,@shyamal_chandra For 3D models, I'm not aware of as much progress. There are these voxel grid models:‚Ä¶ https://t.co/qpO2W0Q9cY
1084975579063935000,Tue Jan 15 00:48:30 +0000 2019,@MrBarrentine Yes, makes sense to do that. Here is some work on that subject: https://t.co/HILKT1ZY7W https://t.co/xNVxUtHdvk
1084973596236144600,Tue Jan 15 00:40:37 +0000 2019,4.5 years of GAN progress on face generation. https://t.co/kiQkuYULMC https://t.co/S4aBsU536b‚Ä¶ https://t.co/bqYV6ZGFTb
1083756130524786700,Fri Jan 11 16:02:51 +0000 2019,Interpretation of a machine learning model by a human involves both the model and the human. Human misconceptions c‚Ä¶ https://t.co/OPnJ9rgX9l
1083191007728947200,Thu Jan 10 02:37:15 +0000 2019,RT @DynamicWebPaige: ‚ú®¬†Applying ESRGANs to the original Doom: priceless. https://t.co/g8A5WDfbov
1083132200634089500,Wed Jan 09 22:43:34 +0000 2019,@timhwang @baobaofzhang Age 73 and older is by far the group most concerned about AI governance?
1083087917264715800,Wed Jan 09 19:47:36 +0000 2019,RT @catherineols: Everyone in ML research complains about the existing peer review tools/systems.  If you're not a researcher, but you ARE‚Ä¶
1083064262170300400,Wed Jan 09 18:13:37 +0000 2019,@_im_sathvik @AndrewYNg do a lot of programming projects :) also a good idea to learn the basics of calculus (espec‚Ä¶ https://t.co/Orsq5FwEeJ
1083063365096751100,Wed Jan 09 18:10:03 +0000 2019,Super-resolution GANs for improving the texture resolution of old games: https://t.co/urDjC6eWSc
1083060375526895600,Wed Jan 09 17:58:10 +0000 2019,@eigenhector There is a good online-only conference, @WithTheBest
1082727468400668700,Tue Jan 08 19:55:19 +0000 2019,RT @_vaishnavh: Uploaded our (with @zicokolter) NeurIPS 17(!) workshop spotlight paper "Generalization in Deep Networks: The Role of Distan‚Ä¶
1081021635258282000,Fri Jan 04 02:56:56 +0000 2019,RT @jchodera: "We find that the effort researchers waste in writing proposals may be comparable to the total scientific value of the resear‚Ä¶
1081004107169554400,Fri Jan 04 01:47:17 +0000 2019,RT @jenheemstra: Mentoring myth: as you advance in your career, you outgrow the need for mentors.   As my career advances, my responsibilit‚Ä¶
1080660953186725900,Thu Jan 03 03:03:43 +0000 2019,RT @doomie: Subsidized child-care resulted in significantly more women joining the workforce and, "generated income taxes to cover more tha‚Ä¶
1079585494294351900,Mon Dec 31 03:50:14 +0000 2018,RT @DrBeef_: My first art show is in Paris this February; in confrontation with French painter Ronan Barrot  BARRAT/BARROT: Infinite Skulls‚Ä¶
1079210865566507000,Sun Dec 30 03:01:35 +0000 2018,RT @AndrewYNg: We cannot abdicate responsibility when two children, ages 7 and 8, die in US custody. The US once said: "Give me your tired,‚Ä¶
1079087651876032500,Sat Dec 29 18:51:59 +0000 2018,@tdietterich @dwf @arxiv My understanding is that it‚Äôs done to lock in credit for completing important steps that a‚Ä¶ https://t.co/wvNH8LNOUH
1076180510072688600,Fri Dec 21 18:20:02 +0000 2018,RT @MarioLucic_: Our work on self-modulation for GANs was accepted to #ICLR2019. Essentially, it is beneficial to directly modulate batch n‚Ä¶
1076180373929812000,Fri Dec 21 18:19:30 +0000 2018,RT @colinraffel: New blog post: "GANs and Divergence Minimization", which covers the perspective of GANs as minimizing an "adversarial dive‚Ä¶
1076159672002916400,Fri Dec 21 16:57:14 +0000 2018,RT @gamaleldinfe: My work with @jaschasd and @goodfellow_ian on Adversarial reprogramming of neural networks (https://t.co/m6rnUSbJqq) is n‚Ä¶
1076116204081692700,Fri Dec 21 14:04:30 +0000 2018,RT @julianibarz: We can now generalize to 70% grasp success on new objects with zero real data, on real robots. And we can reach 91% succes‚Ä¶
1075780320807379000,Thu Dec 20 15:49:50 +0000 2018,Using GANs to learn robot grasping with no real data https://t.co/Ud34u9gwAA
1074824756900159500,Tue Dec 18 00:32:45 +0000 2018,@just_achetan If it's a situation where there were 50X more candidates than spots, they may not have much of a spec‚Ä¶ https://t.co/SF3fmuUYAA
1074824435050328000,Tue Dec 18 00:31:29 +0000 2018,@just_achetan In many cases the prof won't respond, simply because they have literally thousands of e-mails and it'‚Ä¶ https://t.co/vldGuufJAG
1074824269308190700,Tue Dec 18 00:30:49 +0000 2018,@just_achetan Yes, it's fine to do, just be sure the e-mail is polite (not angry that you were rejected, whiny that‚Ä¶ https://t.co/CjcwPvrAig
1073413181190463500,Fri Dec 14 03:03:40 +0000 2018,@sandeepbhutani Yes, they are generated by the neural network
1073294920046145500,Thu Dec 13 19:13:44 +0000 2018,These style-based generator results look great: https://t.co/RL825n0yNP https://t.co/k7UtJMTWhM
1072903792096505900,Wed Dec 12 17:19:32 +0000 2018,@jm_alexia @MILAMontreal Congratulations!
1072862157677580300,Wed Dec 12 14:34:05 +0000 2018,The Eastern European ML Community is teaching a great summer school in Romania this year. Check it out. https://t.co/cp5AvdM3Rg
1072291891658469400,Tue Dec 11 00:48:03 +0000 2018,Deadline extended to Dec 21 https://t.co/SiaoVuN42O
1071396984177811500,Sat Dec 08 13:32:01 +0000 2018,#NeurIPS2018 The number of unique z vectors seen during training turns out to be a way to control capacity and prev‚Ä¶ https://t.co/3HECiO4cIH
1071394087683661800,Sat Dec 08 13:20:30 +0000 2018,RT @dwf: Reminder that you can catch "Unsupervised Control Through Non-Parametric Discriminative Rewards" and "Amortized Q-Learning" at the‚Ä¶
1071169395827896300,Fri Dec 07 22:27:39 +0000 2018,RT @karol_kurach: "Frechet Video Distance" - a new video metric well correlated with human perceived quality. Very useful if you're working‚Ä¶
1071169378958356500,Fri Dec 07 22:27:35 +0000 2018,RT @TomUnterthiner: Our paper on evaluating generative models for video is out! A cool new metric and new datasets to drive progress in thi‚Ä¶
1071054388758634500,Fri Dec 07 14:50:40 +0000 2018,RT @WonderMicky: So excited to be at the 2nd @black_in_ai workshop at #NeurIPS2018! ü§©  Yann Dauphin of @facebookai kicking off the event wi‚Ä¶
1070758844765274100,Thu Dec 06 19:16:16 +0000 2018,Let‚Äôs have a moment of silence at 5:10pm today, to remember the women in tech killed on this day here in Montreal 2‚Ä¶ https://t.co/j0kjbvncOs
1070708839278932000,Thu Dec 06 15:57:34 +0000 2018,#NeurIPS Check out our poster on realistic evaluation of semi-supervised learning, now until 12:45.‚Ä¶ https://t.co/Oq8elsP7Rt
1070668891364429800,Thu Dec 06 13:18:50 +0000 2018,RT @DataScienceNIG: #NeurIPS2018. Inspiring one by a mentor @julius_adebayo etal on Sanity check for Saliency maps! Why? Visual inspection‚Ä¶
1070506114637332500,Thu Dec 06 02:32:01 +0000 2018,@mmm1808 https://t.co/LhmACIDyri
1070281963683110900,Wed Dec 05 11:41:19 +0000 2018,NVIDIA gave me a new T-Rex, signed by Jensen. They are not even for sale yet! Thanks NVIDIA! The pic is with GAN ex‚Ä¶ https://t.co/5dsl740Xbv
1070049206549782500,Tue Dec 04 20:16:26 +0000 2018,@obousquet @facebookai Congratulations!
1069987363546251300,Tue Dec 04 16:10:41 +0000 2018,Come see our poster (#108) on adversarial examples that fool both computer vision and time-limited humans. Room 517‚Ä¶ https://t.co/1OJF1aakBB
1069943276206215200,Tue Dec 04 13:15:30 +0000 2018,@jm_alexia At Google, completion of the residency program is one good way to get on the Research Scientist ladder w‚Ä¶ https://t.co/6MHyCgTyxS
1069923350791798800,Tue Dec 04 11:56:19 +0000 2018,RT @FeryalMP: It's so sad that despite all her hard work organising #WiML2018 workshop, @nunuska didn't get her visa on time to attend the‚Ä¶
1069917292765548500,Tue Dec 04 11:32:15 +0000 2018,RT @dwf: Excited to share "Unsupervised Control Through Non-Parametric Discriminative Rewards" -- with @DeepMindAI colleagues Tom Van de Wi‚Ä¶
1069713850122076200,Mon Dec 03 22:03:50 +0000 2018,RT @liu_mingyu: If you want to drive a #GAN in a virtual city. Please come to #NVIDIA booth in #NeurIPS. We use #vid2vid to convert segment‚Ä¶
1069677449083002900,Mon Dec 03 19:39:12 +0000 2018,@nickfrosst @jeremyphoward @GreeneScientist Fruit flies remember for some time if they have seen a wasp. There is a‚Ä¶ https://t.co/oOZmz1oq1E
1069677272968429600,Mon Dec 03 19:38:30 +0000 2018,@nickfrosst @jeremyphoward @GreeneScientist Fruit flies can communicate with each other to warn about parasitic was‚Ä¶ https://t.co/c5oQyc0R1k
1069677033637187600,Mon Dec 03 19:37:33 +0000 2018,@nickfrosst @jeremyphoward @GreeneScientist told us about a lot of surprising properties of fruit flies: when paras‚Ä¶ https://t.co/TAJV34wY44
1069431711551955000,Mon Dec 03 03:22:43 +0000 2018,RT @demishassabis: Proteins are essential to life. Predicting their 3D structure is a major unsolved challenge in biology and could impact‚Ä¶
1069229293132283900,Sun Dec 02 13:58:23 +0000 2018,Reminder: the submission deadline for the @IEEESSP Deep Learning and Security workshop is fast approaching, Dec 14. https://t.co/FwJoos7IqP
1069048680198611000,Sun Dec 02 02:00:41 +0000 2018,@roydanroy Sorry to hear that, wishing your son a speedy recovery
1068960223988252700,Sat Dec 01 20:09:12 +0000 2018,@hannawallach Sunday evening
1068854364918423600,Sat Dec 01 13:08:33 +0000 2018,@meltemataynsnt @Google @GoogleAI @ThinkwithGoogle You can share it :)
1068695823922413600,Sat Dec 01 02:38:34 +0000 2018,@jm_alexia Very welcome! (And most of the credit goes to Rainier and Jennifer) Thank you for participating!
1068687705796689900,Sat Dec 01 02:06:18 +0000 2018,@phillip_isola Can you make a party spider?
1067972891952775200,Thu Nov 29 02:45:54 +0000 2018,@quantumVerd @Perimeter Thanks to @Perimeter for inviting me!
1067955518331908100,Thu Nov 29 01:36:51 +0000 2018,@WonderMicky @oculus Not VR but all-online: @WithTheBest
1067947053391769600,Thu Nov 29 01:03:13 +0000 2018,@ctnzr @github Would you consider offering temporarily anonymous repos? e.g. github knows who the author is but the‚Ä¶ https://t.co/ubrHL7pZWu
1067936174667456500,Thu Nov 29 00:19:59 +0000 2018,@roydanroy I make the slides for the talk first, then I put them in a grid using Pages. I like Pages for this becau‚Ä¶ https://t.co/i2kQOwmIKH
1067790191363059700,Wed Nov 28 14:39:54 +0000 2018,RT @WiMLworkshop: We are excited to introduce our speakers for #WiML2018 workshop! Our first speaker is Emma Brunskill from Stanford where‚Ä¶
1067782672137752600,Wed Nov 28 14:10:02 +0000 2018,@nsaphra @jeffbigham @roydanroy @JustinTrudeau @VectorInst @MILAMontreal @CIFAR_News A perfect example of this is h‚Ä¶ https://t.co/Mob3iC3VJP
1067781001231896600,Wed Nov 28 14:03:23 +0000 2018,@nsaphra @jeffbigham @roydanroy @JustinTrudeau @VectorInst @MILAMontreal @CIFAR_News Overall I think the median Can‚Ä¶ https://t.co/jnaP4yCaLy
1067779695775756300,Wed Nov 28 13:58:12 +0000 2018,@nsaphra @jeffbigham @roydanroy @JustinTrudeau @VectorInst @MILAMontreal @CIFAR_News I think another part of it is‚Ä¶ https://t.co/HB8VY765xo
1067590168947769300,Wed Nov 28 01:25:05 +0000 2018,RT @RandomlyWalking: Crowdsourcing research dep't: I've been asked to give a talk about how prepublication a la arxiv should affect double‚Ä¶
1067557122630668300,Tue Nov 27 23:13:46 +0000 2018,I've signed this pledge and I encourage other #NeurIPS2018 participants to do so too https://t.co/NSliFGmNSW
1067533260035510300,Tue Nov 27 21:38:57 +0000 2018,@ortizsjesus @ankurhandos Glad you persisted!
1067531001193087000,Tue Nov 27 21:29:59 +0000 2018,@le_roux_nicolas @optiML @WithTheBest SOCML is roughly 50% by invitation and roughly 50% by application. It‚Äôs also‚Ä¶ https://t.co/hFb1ySbzjd
1067528048625340400,Tue Nov 27 21:18:15 +0000 2018,@ankurhandos Yes, in Canada
1067527321249185800,Tue Nov 27 21:15:21 +0000 2018,NeurIPS, Black in AI and SOCML have all lost a lot of participants due to visa issues
1067526807765696500,Tue Nov 27 21:13:19 +0000 2018,@le_roux_nicolas @optiML I personally think we should: 1) separate publishing from conferences (just put a reviewin‚Ä¶ https://t.co/elAeiuDtF6
1067404050977579000,Tue Nov 27 13:05:31 +0000 2018,On my way to Toronto for #SOCML!
1066745659779412000,Sun Nov 25 17:29:19 +0000 2018,RT @ericschmidt: Climate change is real; and will be devastating to a lot of the US soon.   Its much cheaper to act now than to clean up th‚Ä¶
1066711815810236400,Sun Nov 25 15:14:50 +0000 2018,https://t.co/tGyLm20VJe is a fun way to explore the latent space of #BigGAN https://t.co/bm2BWiixKH
1066710038473957400,Sun Nov 25 15:07:46 +0000 2018,RT @phillip_isola: #BigGAN is so much fun. I stumbled upon a (circular) direction in latent space that makes party parrots, as well as othe‚Ä¶
1066164246155714600,Sat Nov 24 02:58:59 +0000 2018,RT @WIREDScience: A massive new federal report describes human-caused climate change resulting in ecological collapse and infrastructural r‚Ä¶
1066008087037804500,Fri Nov 23 16:38:28 +0000 2018,RT @judywawira: Registration for the 2nd @black_in_ai workshop at #NeurIPS2018 is closing in 3 days (Deadline is 26th November 2018 at at 1‚Ä¶
1065384136141992000,Wed Nov 21 23:19:06 +0000 2018,@meltemiatay_AI Thank you for volunteering to be a moderator and a note-taker! I look forward to meeting you
1065318582949572600,Wed Nov 21 18:58:37 +0000 2018,@AwokeKnowing @srvmshr @hardmaru Schmidhuber is also not exactly open about how the conflict over GANs played out.‚Ä¶ https://t.co/HcRYigA9Yi
1065318018748534800,Wed Nov 21 18:56:22 +0000 2018,@AwokeKnowing @srvmshr @hardmaru For many of the people he e-mailed, he asked them to cite something like 7 papers.
1065317904004960300,Wed Nov 21 18:55:55 +0000 2018,@AwokeKnowing @srvmshr @hardmaru Most of the machine learning community is open and friendly but Schmidhuber is not‚Ä¶ https://t.co/b1TIFkK3zY
1065068781448253400,Wed Nov 21 02:26:00 +0000 2018,RT @PManzagol: I wrote this document about respectful behavior at conferences. It's based on my own experience as well as discussions with‚Ä¶
1065068698807918600,Wed Nov 21 02:25:40 +0000 2018,RT @NicolasPapernot: Excited that we released #CleverHans v3.0.0 today! Thanks to the 78 contributors: the library has gone a long way in t‚Ä¶
1065030206971293700,Tue Nov 20 23:52:43 +0000 2018,RT @glagolista: i'm also pleasantly surprised that they chose this piece which is actually one of my recent favorites: GAN-powered mutants‚Ä¶
1064979592581017600,Tue Nov 20 20:31:35 +0000 2018,RT @glagolista: my artwork is featured under I  - i is for‚Ä¶ imagination üòçüòä https://t.co/8V5E8mVM8x
1064977665994612700,Tue Nov 20 20:23:56 +0000 2018,@maosbot Some utility functions *require* randomness to get nonzero values. For example if you want your AI to plan‚Ä¶ https://t.co/WywZFRJOol
1064963050883534800,Tue Nov 20 19:25:52 +0000 2018,@yassersouri @hardmaru After he interrupted my talk at NIPS 2016, NIPS arranged a meeting between the two of us. At‚Ä¶ https://t.co/n057ZM30rr
1064949546373931000,Tue Nov 20 18:32:12 +0000 2018,RT @NatureNews: Specialist visa applications in the US have fallen by one-fifth during @realDonaldTrump's presidency. https://t.co/gxHbp85O‚Ä¶
1064931720401539100,Tue Nov 20 17:21:22 +0000 2018,@hardmaru We don't actually have a way to remove the statements Schmidhuber objects to from the NIPS paper. I've co‚Ä¶ https://t.co/obh22mOxAz
1064930915481083900,Tue Nov 20 17:18:10 +0000 2018,@hardmaru This blog post devotes a paragraph to complaining about things the NIPS 2014 paper on GANs says about PM.‚Ä¶ https://t.co/iewZsowOfn
1064650863954681900,Mon Nov 19 22:45:20 +0000 2018,RT @ACLU: These rules give the White House far too much discretion to avoid real scrutiny. Asking an ‚Äúunauthorized‚Äù follow-up question cann‚Ä¶
1064613695144177700,Mon Nov 19 20:17:39 +0000 2018,RT @LiamFedus: Clear @shortscienceorg paper summary by @decodyng on Language GANs Falling Short  https://t.co/2kqOazWQKr
1063860112165494800,Sat Nov 17 18:23:10 +0000 2018,RT @JeffDean: I'm very happy to see the @NipsConference board work out a great solution that keeps the full name of the conference intact b‚Ä¶
1063856456565370900,Sat Nov 17 18:08:39 +0000 2018,RT @JeffDean: Like carbon tax, if we could somehow figure out ways to charge or credit people for their transportation choices, that would‚Ä¶
1063607423338856400,Sat Nov 17 01:39:05 +0000 2018,RT @lizziejohnsonnn: In a Wal-Mart parking lot in Chico, trailers and tents stretch as far as you can see. It looks like a third-world coun‚Ä¶
1063500297530617900,Fri Nov 16 18:33:24 +0000 2018,@DynamicWebPaige Maybe consider delaying your move a week or so
1063469085541883900,Fri Nov 16 16:29:22 +0000 2018,@VahidK I don‚Äôt actually have this problem personally, because I don‚Äôt work in academia.
1063433359194378200,Fri Nov 16 14:07:25 +0000 2018,@poolio As a reviewer I got an author rebuttal telling me I obviously haven‚Äôt read the Maxout paper
1063256183027290100,Fri Nov 16 02:23:23 +0000 2018,RT @mtyka: Using GANs to generate Master[Finger]Prints that unlock 22-78% phones sensors (dep. on security level of sensor)  https://t.co/K‚Ä¶
1063205650585407500,Thu Nov 15 23:02:35 +0000 2018,RT @elaClaudia: Wooho! Looking for a great ML summer school next year? Check out EEML, next year in Bucharest! https://t.co/xveQKWGvsV
1062922224728830000,Thu Nov 15 04:16:21 +0000 2018,RT @John_Dearie: For years, the United States has benefitted from attracting the world's largest foreign-born student population.  Now, ine‚Ä¶
1062919759816089600,Thu Nov 15 04:06:33 +0000 2018,RT @vmcheung: Honored to have the opportunity to share the story of #Kubernetes at @lyft with the first ever #kubecon China!  It's also my‚Ä¶
1062901250167988200,Thu Nov 15 02:53:00 +0000 2018,@LiangTengyuan @roydanroy Is this summary fair? When designing a GAN we can control the capacity of the generator a‚Ä¶ https://t.co/cDsId8QQG5
1062900962602377200,Thu Nov 15 02:51:51 +0000 2018,@LiangTengyuan @roydanroy Thanks. After reading a later section of the paper I think I understand better.
1062899924080021500,Thu Nov 15 02:47:44 +0000 2018,RT @danoramas: Swiss Dreams: A trio of scenes recently captured in Switzerland, two of which use wonderful "dreaming" styles I've never use‚Ä¶
1062866720702910500,Thu Nov 15 00:35:47 +0000 2018,@rajatsainju @preskill I'm not all that opinionated on the specifics, I just think that using negative adjectives i‚Ä¶ https://t.co/AKxDv1El1r
1062864918360145900,Thu Nov 15 00:28:38 +0000 2018,@nrkcv I think adding superlatives shows more respect to the people doing the work. It's something academia could adopt for free.
1062864645139050500,Thu Nov 15 00:27:33 +0000 2018,@rajatsainju Could call everyone "professor", could start with "professor" and add superlatives, etc.
1062863177250009100,Thu Nov 15 00:21:43 +0000 2018,Industry titles tend to add superlatives: "research scientist" -&gt; "senior research scientist" -&gt; ... -&gt; "distinguis‚Ä¶ https://t.co/8kVSvKBHPK
1062862978054148100,Thu Nov 15 00:20:55 +0000 2018,The "assistant professor" title seems especially galling to me: who exactly is the assistant professor assisting? T‚Ä¶ https://t.co/8q7uc7zgkP
1062862806624555000,Thu Nov 15 00:20:14 +0000 2018,Academic titles tend to begin with negative adjectives and gradually remove adjectives. "Undergraduate student" -&gt;‚Ä¶ https://t.co/9WSx4guf2U
1062833333409730600,Wed Nov 14 22:23:07 +0000 2018,@roydanroy After reading the definition of that term, I'm actually very confused. I *think* that the term is actual‚Ä¶ https://t.co/AimIgiQZeU
1062832657908691000,Wed Nov 14 22:20:26 +0000 2018,@roydanroy High level question: after reading the abstract, I thought "generator / discriminator pair regularizatio‚Ä¶ https://t.co/e6BRIIDySt
1062832496503545900,Wed Nov 14 22:19:48 +0000 2018,@roydanroy I'm finding this paper difficult to read, maybe because I come from a different community with different‚Ä¶ https://t.co/Q6Mtbqz0uw
1062826046746054700,Wed Nov 14 21:54:10 +0000 2018,@RogerGrosse @james_r_lucas Quick question: fig 10, fig 11, and table 3 are all on MNIST right? Are there adversari‚Ä¶ https://t.co/27ndg80hz1
1062815477292912600,Wed Nov 14 21:12:10 +0000 2018,@DynamicWebPaige Before 1800s: calculus is hand-wavily justified using infinitesimals that are not defined clearly‚Ä¶ https://t.co/KGXKCTsFlI
1062083550277656600,Mon Nov 12 20:43:45 +0000 2018,@BruceTedesco @Ronald_vanLoon @kdnuggets @rasbt @AndrewYNg @ChrisBishopMSFT We actually have an infogram in the boo‚Ä¶ https://t.co/1tvv0p12ko
1062083041651187700,Mon Nov 12 20:41:44 +0000 2018,Using differentiable ray tracing to make 3D adversarial example objects: https://t.co/CipRHPNyae https://t.co/ek1xCpc8DL
1062072665983184900,Mon Nov 12 20:00:30 +0000 2018,RT @DeepMindAI: The BigGAN generators from our paper https://t.co/QUYlE9IBsE are now available on TF Hub (https://t.co/GHM9pIgQPw). Try the‚Ä¶
1062025422391529500,Mon Nov 12 16:52:46 +0000 2018,Adversarial examples for perceptual ad-blocking: https://t.co/5I5dSK6fXB
1061780515466821600,Mon Nov 12 00:39:36 +0000 2018,@roydanroy Why direct this comment at industry folks?
1061033316437057500,Fri Nov 09 23:10:30 +0000 2018,RT @wielandbr: Results of the NIPS Adversarial Vision Challenge are in! Common themes are low-frequency versions of the boundary attack, en‚Ä¶
1060979635683348500,Fri Nov 09 19:37:11 +0000 2018,@RC_Grieves @gstsdn @ajmooch https://t.co/649HPLrYso
1060604450329391100,Thu Nov 08 18:46:20 +0000 2018,@crude2refined @gstsdn @ajmooch Definitely diminishing marginal returns but there are still things you could do. Re‚Ä¶ https://t.co/9K24n8Ozep
1060592303859916800,Thu Nov 08 17:58:04 +0000 2018,An updated 2 year progress pic for ImageNet GANs. New pic by @gstsdn includes latest results by @ajmooch et al. https://t.co/ffPWSYMo4V
1060376864537997300,Thu Nov 08 03:42:00 +0000 2018,@raamana_ @earnmyturns @DynamicWebPaige Back in ~2007 when I used traditional ML on top of hand-designed features f‚Ä¶ https://t.co/BZa1bq4cAe
1060371244254515200,Thu Nov 08 03:19:40 +0000 2018,@earnmyturns @DynamicWebPaige Thanks! I actually didn't know about that.
1060211463271284700,Wed Nov 07 16:44:45 +0000 2018,RT @GeekPwn: CAAD CTF was held on #GeekPwn2018 Shanghai. 6 teams are invited. Finally team IYSWIM(Yuxin Wu, Cihang Xie) won 1st place prize‚Ä¶
1060211339056963600,Wed Nov 07 16:44:15 +0000 2018,RT @GeekPwn: The Competition on Adversarial Attacks and Defenses (CAAD 2018) ended. 5 top teams of 3 sub-competiitons shared total prize US‚Ä¶
1060191845198651400,Wed Nov 07 15:26:47 +0000 2018,@DynamicWebPaige I think people rarely use bagging per se with neural nets because there are enough things you can‚Ä¶ https://t.co/wu2yodKqCe
1060191414250664000,Wed Nov 07 15:25:05 +0000 2018,@DynamicWebPaige I think people usually don‚Äôt use boosting with neural nets because boosting is mostly used as a wa‚Ä¶ https://t.co/WR8kSpCC24
1060190726019932200,Wed Nov 07 15:22:21 +0000 2018,@DynamicWebPaige This paper is mostly about the bagging perspective on dropout but it contains some experiments com‚Ä¶ https://t.co/lGxupSFasX
1059974479189659600,Wed Nov 07 01:03:03 +0000 2018,@glagolista GANs n' Roses?
1059848931255799800,Tue Nov 06 16:44:10 +0000 2018,RT @polynoamial: I'm honored to share the second-ever @IJCAIconf Marvin Minsky Medal with Professor Sandholm for our work on Libratus, the‚Ä¶
1059836288893743100,Tue Nov 06 15:53:56 +0000 2018,RT @PMinervini: At #emnlp18 there was a lot of interest in adversarial examples - inputs designed to cause your model to make a mistake. I‚Ä¶
1059671062311403500,Tue Nov 06 04:57:23 +0000 2018,RT @NicolasPapernot: American friends, please vote tomorrow if you are able to!
1059638344169058300,Tue Nov 06 02:47:23 +0000 2018,RT @mattblaze: There‚Äôs currently an organized bot effort to discourage people from voting. Among their ‚Äúarguments‚Äù is that voting machines‚Ä¶
1058418377457160200,Fri Nov 02 17:59:40 +0000 2018,@DynamicWebPaige @JeffDean @fchollet @martin_wicke @MagnusHyttsten @lmoroney @random_forests Welcome and congratulations!
1058392095218589700,Fri Nov 02 16:15:14 +0000 2018,@DrBeef_ Whenever I see a grid of faces on Twitter I assume it‚Äôs CelebA samples but sometimes it turns out to be the team page for a startup
1058145263901016000,Thu Nov 01 23:54:24 +0000 2018,RT @catherineols: Ok, I realize now that   if you didn't do half a PhD studying human vision with fMRI, this quote doesn't make sense; and‚Ä¶
1057832018992554000,Thu Nov 01 03:09:41 +0000 2018,@SussilloDavid @vcheplygina runs a blog that collects posts like these
1057359257647992800,Tue Oct 30 19:51:06 +0000 2018,RT @mer__edith: üì£ AI Now's call for postdocs, now open! üéâ  IMHO, there couldn't be a more urgent and exciting time to illuminate the role o‚Ä¶
1057315976910229500,Tue Oct 30 16:59:07 +0000 2018,@dseabraoliveira @lujobauer @nc2y @realhashbreaker @Google @elie @uf_fics @ECEflorida Congratulations!
1057314991693430800,Tue Oct 30 16:55:12 +0000 2018,RT @colinraffel: The camera ready version of "Realistic Evaluation of Deep Semi-Supervised Learning Algorithms" is now up on arxiv: https:/‚Ä¶
1057069896020897800,Tue Oct 30 00:41:17 +0000 2018,RT @sundarpichai: We‚Äôre announcing our AI for Social Good program, applying @GoogleAI expertise to projects w/ positive societal impact. We‚Ä¶
1056318320230584300,Sat Oct 27 22:54:47 +0000 2018,RT @AnimaAnandkumar: We have now crossed 1000 signatures! If you haven't signed already and believe that a safe and an inclusive environmen‚Ä¶
1055695458427760600,Fri Oct 26 05:39:45 +0000 2018,@TheNerdStation @quasimondo @hardmaru The original loss should work OK: https://t.co/2e1S2jR5aS I suspect a lot of‚Ä¶ https://t.co/q76rTCIqKo
1055658388460253200,Fri Oct 26 03:12:27 +0000 2018,RT @OriolVinyalsML: Between the no name change decision and not doing more to ensure a more fair distribution of the waitlist tickets (othe‚Ä¶
1055658372949729300,Fri Oct 26 03:12:23 +0000 2018,RT @tejasdkulkarni: Why are polls being used here to make the final decision? Isn't it common sense to change the name to create a more inc‚Ä¶
1055595680872378400,Thu Oct 25 23:03:16 +0000 2018,RT @katyanna_q: I'm especially keen to talk to female researchers üëç
1055504909087330300,Thu Oct 25 17:02:35 +0000 2018,@janphigoe In Google Trends, "nips" is a far more common search than "icml". Presumably most people who search for‚Ä¶ https://t.co/l4pNmd7AxI
1055504747816337400,Thu Oct 25 17:01:56 +0000 2018,@janphigoe It's short for "nipples". It's relatively easy to accidentally get NSFW results by searching twitter for‚Ä¶ https://t.co/TeEmwrVBwn
1055485352457060400,Thu Oct 25 15:44:52 +0000 2018,RT @colinraffel: I gave this talk again today to an audience of CS majors who didn't have any ML experience. It's really rewarding to be fo‚Ä¶
1055304076072640500,Thu Oct 25 03:44:32 +0000 2018,@DrBeef_ @hardmaru @quasimondo @artnome @zzznah @alexjc @flakoubay @ahmed_elgammal You‚Äôre at Stanford right? I‚Äôm at‚Ä¶ https://t.co/XMK1nITuhm
1055300272681939000,Thu Oct 25 03:29:26 +0000 2018,RT @laurent_dinh: On a sidenote: why are people so attached to the @NipsConference name? The lab I'm from (@MILAMontreal) changed name midw‚Ä¶
1055296427675406300,Thu Oct 25 03:14:09 +0000 2018,RT @benhamner: The @NipsConference ‚Äúdecision by committee‚Äù to keep its name is pathetic. We do research because we want to improve the worl‚Ä¶
1055293790582239200,Thu Oct 25 03:03:40 +0000 2018,RT @JeffDean: I think enough people are made to feel uncomfortable by the current name that the NIPS board should change the name of the @N‚Ä¶
1055293636001194000,Thu Oct 25 03:03:03 +0000 2018,RT @BeEngelhardt: ML @mxlearn comments about @NipsConference not changing its name are despicable. E.g., "We won this round, now it's up to‚Ä¶
1055282141733371900,Thu Oct 25 02:17:23 +0000 2018,@MFiterau Or even keeping the name Neural Information Processing Systems but calling it NeuroSys or NeuroProc etc for short rather than NIPS
1055279123474526200,Thu Oct 25 02:05:23 +0000 2018,I think changing the name of NIPS is the right thing to do. The majority of women in the poll voted for it, and mor‚Ä¶ https://t.co/ctgTq1uFKw
1055164643922985000,Wed Oct 24 18:30:29 +0000 2018,@mcreed @carpedm20 Happy halloween @D_Berthelot_ML
1055163299916992500,Wed Oct 24 18:25:09 +0000 2018,@KenoFischer @Google Is there a mailing list or something where I can sign up to be notified when the repo is up?
1054919888379105300,Wed Oct 24 02:17:55 +0000 2018,RT @negar_rz: Considering the majority vote when the minorities are mainly affected doesn't sound right to me! @NipsConference
1054799047490396200,Tue Oct 23 18:17:44 +0000 2018,Interested in jump-starting your career in machine learning research? Consider the Google AI Residency Program! App‚Ä¶ https://t.co/Spt4a8qhXP
1054797157297938400,Tue Oct 23 18:10:14 +0000 2018,RT @sama: We need to research more aggressive climate solutions, and YC is ready to fund: https://t.co/7RihCpQRln
1054797063353917400,Tue Oct 23 18:09:51 +0000 2018,Six amazing guest editors are running a special issue of IJCV on GANs. Submissions due in March 2019. More info her‚Ä¶ https://t.co/utdGUeJUg4
1053792199660339200,Sat Oct 20 23:36:53 +0000 2018,RT @InclusionInML: We've just updated the https://t.co/y3ryDIzzq0 webpage to include links for outside childcare providers (recommended by‚Ä¶
1053769025711304700,Sat Oct 20 22:04:48 +0000 2018,RT @AndrewYNg: The new UN Climate report shows our planet is nearing crisis. While individuals tweaking their carbon footprint is a good st‚Ä¶
1053457606214266900,Sat Oct 20 01:27:20 +0000 2018,@mark_riedl https://t.co/wdB83sJYoL
1053347835037405200,Fri Oct 19 18:11:08 +0000 2018,@entralpy Yes, that's one example. Another example I had in mind at the time was image inpainting (condition on som‚Ä¶ https://t.co/K1di1LtCAn
1053120569938333700,Fri Oct 19 03:08:04 +0000 2018,@nsaphra Can they still keep doing the same type of work by weighting each book‚Äôs n-grams by # of books sold?
1053018224650932200,Thu Oct 18 20:21:23 +0000 2018,@heathercmiller It sounds like a good pledge but I'm having trouble understanding it. What does it mean to survivor‚Ä¶ https://t.co/f0f8J8ozaS
1052686063221661700,Wed Oct 17 22:21:30 +0000 2018,@OriolVinyalsML @unsorsodicorda @gstsdn @smnh_azadi @catherineols OK, we're working on updating the arxiv paper.
1052685835882049500,Wed Oct 17 22:20:35 +0000 2018,@unsorsodicorda @OriolVinyalsML @gstsdn @smnh_azadi @catherineols We'll fix it now that we know. I don't think it's‚Ä¶ https://t.co/eJ9OY8C5oX
1052685211891195900,Wed Oct 17 22:18:07 +0000 2018,@unsorsodicorda @OriolVinyalsML @gstsdn @smnh_azadi @catherineols We originally wrote this as an ICLR submission, b‚Ä¶ https://t.co/ny1Ib1v4xh
1052596541305675800,Wed Oct 17 16:25:46 +0000 2018,@rbhar90 The funny thing is, from my point of view, figuring out how to use DL as a building block was what we did‚Ä¶ https://t.co/SNY7L7gtys
1052591831651823600,Wed Oct 17 16:07:03 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel You can refer reviewers to this tweet :) "Dear reviewers, I actually‚Ä¶ https://t.co/1zN8yg8FSG
1052591146159882200,Wed Oct 17 16:04:20 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel You mean there's a paper that was, e.g. posted on arxiv and then acc‚Ä¶ https://t.co/i9dzbUg9wg
1052405028282019800,Wed Oct 17 03:44:46 +0000 2018,@jigarkdoshi @catherineols I only heard about it from people who were in on the joke
1052404764464410600,Wed Oct 17 03:43:43 +0000 2018,RT @smnh_azadi: Apply this simple rejection sampling technique to get rid of the bad samples generated by your GAN model. https://t.co/Mcfi‚Ä¶
1052398262651576300,Wed Oct 17 03:17:53 +0000 2018,Both @catherineols and I set our Google employee profile pictures to the cabbage head sample for a few days https://t.co/wZj2cWJXzj
1052376861567676400,Wed Oct 17 01:52:50 +0000 2018,The discriminator often knows something about the data distribution that the generator didn't manage to capture. By‚Ä¶ https://t.co/1eyne8axqy
1052353164131745800,Wed Oct 17 00:18:40 +0000 2018,@hardmaru Why "reward" in quotes?
1052315470995501000,Tue Oct 16 21:48:54 +0000 2018,PSA. If you‚Äôre a US green card holder, requirements to travel to Canada have changed recently. I imagine many of my‚Ä¶ https://t.co/sXcUfnltbY
1052303545133719600,Tue Oct 16 21:01:30 +0000 2018,@ctphoenix @68kirk @roydanroy @zacharylipton @colinraffel In some cases I don't like GUIs because they're hard to r‚Ä¶ https://t.co/QDNgLSr2oJ
1052303190010421200,Tue Oct 16 21:00:06 +0000 2018,@ctphoenix @68kirk @roydanroy @zacharylipton @colinraffel Partly I don't like GUIs because I have to learn how to c‚Ä¶ https://t.co/MdXFkFmelM
1052302681136480300,Tue Oct 16 20:58:04 +0000 2018,@ctphoenix @68kirk @roydanroy @zacharylipton @colinraffel Partly I don't like GUIs because I can't control them pro‚Ä¶ https://t.co/7QOK58oMVP
1052298361804533800,Tue Oct 16 20:40:54 +0000 2018,@ctphoenix @68kirk @roydanroy @zacharylipton @colinraffel Yeah, I don't like it very much. But I'm very picky about‚Ä¶ https://t.co/cZT2jQjRnO
1052295082810826800,Tue Oct 16 20:27:53 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel Now that I work at Google it's not feasible to share a .bib with all‚Ä¶ https://t.co/xm5uHnMWjv
1052294544304234500,Tue Oct 16 20:25:44 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel The downside to this workflow is that if someone checks a bad .bib e‚Ä¶ https://t.co/I8MtHXzmmO
1052294419150340100,Tue Oct 16 20:25:14 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel The upside to this workflow is that you rarely have to add a .bib en‚Ä¶ https://t.co/tYZT0h4avd
1052293994435108900,Tue Oct 16 20:23:33 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel Today I would recommend making a git repo rather than an svn repo.
1052293889648775200,Tue Oct 16 20:23:08 +0000 2018,@68kirk @roydanroy @zacharylipton @colinraffel While I was a PhD student, in Yoshua's lab, everyone in the lab shar‚Ä¶ https://t.co/gpCPHEbIFp
1051946688904974300,Mon Oct 15 21:23:29 +0000 2018,@entralpy ok, will reply on linkedin
1051648854892765200,Mon Oct 15 01:40:00 +0000 2018,@ericjang11 For all my papers on feature learning for vision in grad school, I used ZCA preprocessing. I had to lea‚Ä¶ https://t.co/Aap32XlMJf
1051648530610237400,Mon Oct 15 01:38:43 +0000 2018,@ericjang11 ZCA is closed form (it's an eigenvalue problem). But for natural image statistics, it's so close to ill‚Ä¶ https://t.co/vpMsY7DXLK
1051646459076997100,Mon Oct 15 01:30:29 +0000 2018,@ericjang11 Back when I actually used to use CPU for anything, it used to be important to compile my own ATLAS BLAS‚Ä¶ https://t.co/VNgSjI33dw
1051645977751212000,Mon Oct 15 01:28:34 +0000 2018,@ericjang11 Circa 2010, I worked on a DARPA-funded collaboration between UdeM and NYU. Koray and I had to get his T‚Ä¶ https://t.co/n2wBAYTvZ1
1051645648460689400,Mon Oct 15 01:27:15 +0000 2018,@ericjang11 In Andrew Ng's lab circa 2008, we had some code for an autoencoder that would learn Gabor filters if ru‚Ä¶ https://t.co/L695I6jXaP
1051645356809670700,Mon Oct 15 01:26:06 +0000 2018,@ericjang11 This definitely caused all kinds of inconsistencies without needing to do anything we'd consider large scale today.
1051645248751824900,Mon Oct 15 01:25:40 +0000 2018,@ericjang11 In the bad old days when deep learning wasn't mainstream yet, I spent a lot of time in labs where somet‚Ä¶ https://t.co/q46S8170jE
1051644996669997000,Mon Oct 15 01:24:40 +0000 2018,@ericjang11 I think people who are newer to ML are somewhat insulated from this effect because today we have big cl‚Ä¶ https://t.co/rbOFtja9pA
1051644721586561000,Mon Oct 15 01:23:34 +0000 2018,@ericjang11 ML results are definitely not hardware agnostic. You should expect to need to retune hyperparameters at‚Ä¶ https://t.co/GpNK9PkQPQ
1050822259827298300,Fri Oct 12 18:55:24 +0000 2018,RT @colinraffel: The slides from my talk "A Few Unusual Autoencoders" which I gave last month at @VectorInst and @nyuMARL are now online: h‚Ä¶
1050594734253568000,Fri Oct 12 03:51:18 +0000 2018,RT @DickeySingh: If you have not read @goodfellow_ian‚Äôs Deep learning book and would like to read it with others, see this https://t.co/xtI‚Ä¶
1050543929370660900,Fri Oct 12 00:29:25 +0000 2018,@parthi292929 @bhutanisanyam1 @AndrewYNg @hackernoon @andrewgelman might tell you you don't need to learn hypothesi‚Ä¶ https://t.co/MqXso2U3lF
1050143053145497600,Wed Oct 10 21:56:29 +0000 2018,RT @gstsdn: The code for Self-Attention GAN is now available here https://t.co/RXfvdwBSk1 https://t.co/1PR9CyhCVp
1049809115055177700,Tue Oct 09 23:49:32 +0000 2018,RT @sh_reya: disclaimer: I‚Äôve never been an AI resident, but I always get questions about the residency program. I‚Äôve learned that most peo‚Ä¶
1049768253407428600,Tue Oct 09 21:07:10 +0000 2018,@vcheplygina @BecomingDataSci @zacharylipton I'm sorry to hear your cat passed away. @junyanz89 has a special inter‚Ä¶ https://t.co/b43ypUUwc4
1049768032795418600,Tue Oct 09 21:06:17 +0000 2018,RT @hugo_larochelle: It's now possible to apply for the 2019 Google AI Residency Program. We'll be taking residents at many locations, incl‚Ä¶
1049053740076916700,Sun Oct 07 21:47:56 +0000 2018,RT @eigenhector: Google 2019 research internships are now open https://t.co/rxmLEPLsir
1048230580448452600,Fri Oct 05 15:17:00 +0000 2018,RT @ajmooch: GANs learn about eyes very early in training, and immediately begin sticking them everywhere. I'd like to think this one would‚Ä¶
1047686846359060500,Thu Oct 04 03:16:23 +0000 2018,@AlecRad @colinraffel Did the GAN give you permission to release the samples? &lt;/s&gt;
1047300173896933400,Wed Oct 03 01:39:54 +0000 2018,RT @DeepMindAI: We present large-scale training of generative models, which sets the new state of the art in image synthesis on ImageNet: h‚Ä¶
1047241353883570200,Tue Oct 02 21:46:10 +0000 2018,RT @junyanz89: We are hosting an IJCV Special Issue on Generative Adversarial Networks for Computer Vision (@elishechtman @liu_mingyu @jank‚Ä¶
1047162681440985100,Tue Oct 02 16:33:33 +0000 2018,@TheNerdStation https://t.co/dqz9NERbpn
1047162367077838800,Tue Oct 02 16:32:18 +0000 2018,@TheNerdStation https://t.co/9Y8meZlxma
1047161549381455900,Tue Oct 02 16:29:03 +0000 2018,@jeffreywestling @PatrickRothfuss No, what‚Äôs Hide the Stone?
1047146146273976300,Tue Oct 02 15:27:50 +0000 2018,RT @svlevine: Imitation directly from images, inverse RL with with transferable rewards, and better GANs can all be enabled by adding an in‚Ä¶
1046878299748687900,Mon Oct 01 21:43:31 +0000 2018,RT @colinraffel: Super happy that our code for "Realistic Evaluation of Semi-Supervised Learning Algorithms" (https://t.co/OspDK6mVGZ) is f‚Ä¶
1046592786928099300,Mon Oct 01 02:48:59 +0000 2018,@DaneMenke Most of it is not very complicated, just jargon-y or needs some context. Let me know if there's anything‚Ä¶ https://t.co/uq4i7rVxob
1046563072133947400,Mon Oct 01 00:50:55 +0000 2018,RT @ajmooch: Large-Scale GAN Training: My internship project with Jeff and Karen.  We push the SOTA Inception Score from 52 -&gt; 166+ and giv‚Ä¶
1046516508401094700,Sun Sep 30 21:45:53 +0000 2018,@DOmidvar There's a tiny probability that we'll figure out the brain is doing everything really inefficiently and w‚Ä¶ https://t.co/YumujFQtQp
1046516006108024800,Sun Sep 30 21:43:53 +0000 2018,@DOmidvar The human brain has at least 10^14 synapses. We're overwhelmingly likely to build many ML models much lar‚Ä¶ https://t.co/SiTEkerCJz
1046515556348616700,Sun Sep 30 21:42:06 +0000 2018,@DOmidvar Often in science and engineering we first learn how to do something at all and later learn how to do that‚Ä¶ https://t.co/5xwu1sOxCb
1046508837300187100,Sun Sep 30 21:15:24 +0000 2018,RT @jeremyphoward: We have fun with WGAN in https://t.co/aQsW5afov6, and I challenge students to try to get something working that's even b‚Ä¶
1046508180920889300,Sun Sep 30 21:12:48 +0000 2018,@AndrewTouchet I might make a github repo, yes, but I don't actually need to track many papers to make this graph.‚Ä¶ https://t.co/cNwP5rBXGO
1046499690802376700,Sun Sep 30 20:39:03 +0000 2018,@dessie5555 https://t.co/OCllCxe23p Fig 1.8, 1.10 and 1.11
1046498143636844500,Sun Sep 30 20:32:55 +0000 2018,@NandoDF Any specific papers you'd like to make sure I hit?
1046497105995399200,Sun Sep 30 20:28:47 +0000 2018,@triketora Thank you for warning us
1046440393825349600,Sun Sep 30 16:43:26 +0000 2018,If you made a big neural net or dataset recently, let me know the # of examples / ‚Äúneurons‚Äù / average # connections‚Ä¶ https://t.co/4nhl5W4PMI
1046182922716213200,Sat Sep 29 23:40:20 +0000 2018,@D_Berthelot_ML Maybe something wrong on just your street? I live not far away and mine works ok https://t.co/qrZu231vkv
1046116064264900600,Sat Sep 29 19:14:40 +0000 2018,RT @OriolVinyalsML: Best GAN samples ever yet? Very impressive ICLR submission! BigGAN improves Inception Scores by &gt;100.  Paper: https://t‚Ä¶
1045729493246042100,Fri Sep 28 17:38:34 +0000 2018,@Sohilnewa We really did send you such an e-mail, including a link to a Discourse forum :)
1045504286845616100,Fri Sep 28 02:43:41 +0000 2018,@woj_zaremba This is also a good argument that consciousness is not merely an epiphenomenon
1045142785576165400,Thu Sep 27 02:47:12 +0000 2018,@rivatez You‚Äôll like https://t.co/ZfXhdMOGor
1044780306748731400,Wed Sep 26 02:46:50 +0000 2018,The current XKCD ( https://t.co/uUKeARZNX9 ) jokingly proposes a time system where the length of a second changes t‚Ä¶ https://t.co/dndFTEL7L3
1044694862237331500,Tue Sep 25 21:07:19 +0000 2018,@lzamparo I can put you on a wait list because there will probably be people who cancel, but it's already oversubsc‚Ä¶ https://t.co/cy3KEKTYCZ
1044454084453888000,Tue Sep 25 05:10:33 +0000 2018,@sirajraval @jeremyphoward @deliprao @srchvrs @dennybritz @distillpub (I‚Äôm on the steering committee for‚Ä¶ https://t.co/PCi0Do96tW
1044449336224960500,Tue Sep 25 04:51:41 +0000 2018,@jeremyphoward @deliprao @srchvrs @dennybritz My main objection is that you're saying the work is neglected because‚Ä¶ https://t.co/EmTfe1emIo
1044448855901712400,Tue Sep 25 04:49:46 +0000 2018,@jeremyphoward @avibryant I agree the book isn't about coding, but that seems like dodging the question of whether‚Ä¶ https://t.co/AbQ7Rf0Ynb
1044448630457790500,Tue Sep 25 04:48:53 +0000 2018,@jeremyphoward @avibryant They do impact the people whose work you're discussing though.
1044448149857689600,Tue Sep 25 04:46:58 +0000 2018,@jeremyphoward @avibryant It's not a huge deal but I do think your claim that you "recommend &lt;my&gt; book and papers a‚Ä¶ https://t.co/vim8bfXIo9
1044442457948078100,Tue Sep 25 04:24:21 +0000 2018,@avibryant @jeremyphoward Formal citations really do have an impact on people's lives---not just job opportunities‚Ä¶ https://t.co/XOkEliGaDW
1044442226586116100,Tue Sep 25 04:23:26 +0000 2018,@avibryant @jeremyphoward When someone writes a PDF article, they want it to be cited in a way that is tracked by G‚Ä¶ https://t.co/Y4TJGM79Jl
1044433450135052300,Tue Sep 25 03:48:33 +0000 2018,@avibryant FWIW I'm not the one who brought up "citing it". Linking to it is not the same thing as "citing it"
1044432747987517400,Tue Sep 25 03:45:46 +0000 2018,@jeremyphoward @avibryant Do you actually recommend my book? Your intro mentions it only to criticize it: "The deep‚Ä¶ https://t.co/BzENB0mQE6
1044410025630810100,Tue Sep 25 02:15:28 +0000 2018,@jeremyphoward @deliprao @srchvrs @dennybritz Let me get this straight: you made a document that has no "references‚Ä¶ https://t.co/0gFVzV6LIC
1044377950483673100,Tue Sep 25 00:08:01 +0000 2018,RT @open_phil: Applications are now open for our second annual AI Fellows Program to support promising PhD students in #ai and #MachineLear‚Ä¶
1044027219121627100,Mon Sep 24 00:54:20 +0000 2018,@vkrakovna I need to check with my co-organizers but I think notifications are likely to go out tomorrow
1043596026613915600,Sat Sep 22 20:20:56 +0000 2018,@tjrileywisc @karpathy I think the right way to frame it is "no longer how long I spending thinking about what to d‚Ä¶ https://t.co/K3Pt1T7f3a
1043531580323446800,Sat Sep 22 16:04:51 +0000 2018,@wielandbr @biggiobattista Yeah, what I think @biggiobattista is saying (and what I'm saying) is that MNIST is a si‚Ä¶ https://t.co/iqRlHsm4RY
1043330573081620500,Sat Sep 22 02:46:07 +0000 2018,@wielandbr @biggiobattista Single centroid RBF nets do get a lot of the visual properties you‚Äôre looking for though‚Ä¶ https://t.co/0PPKy9VfXG
1042246801376436200,Wed Sep 19 02:59:36 +0000 2018,@rctatman I have a different controversial opinion: ML development is a different kind of software development and‚Ä¶ https://t.co/wHTmRErYs2
1041530528585769000,Mon Sep 17 03:33:23 +0000 2018,@kzrt The tweets that bother me are definitely not the ones asking me scientific questions out of genuine interest
1041337615851520000,Sun Sep 16 14:46:49 +0000 2018,@tpbollu @zacharylipton Even if we didn't get green cards to more STEM PhDs, those people would be a lot more produ‚Ä¶ https://t.co/WYnnejgdfT
1040833726245089300,Sat Sep 15 05:24:32 +0000 2018,@kcimc Wake-sleep algorithm from 1995 https://t.co/a9clrxjB0b
1040442950205894700,Fri Sep 14 03:31:44 +0000 2018,RT @gradientpub: ‚ÄúAs my watercolor teacher used to say: let the medium do it. My sketch simply provides the foundation, and then I let the‚Ä¶
1040295150742696000,Thu Sep 13 17:44:26 +0000 2018,RT @GoogleAI: In order to incentivize and measure progress towards the goal of zero confident classification errors in #MachineLearning mod‚Ä¶
1040080553536446500,Thu Sep 13 03:31:42 +0000 2018,RT @chelseabfinn: Enjoyed giving a 3 min talk today at #EmTechMIT, by @techreview, and meeting [some of] the other 34 under 35! Check out m‚Ä¶
1040048880258183200,Thu Sep 13 01:25:50 +0000 2018,RT @vmcheung: Excited to keynote Kubecon again!  Kubernetes has matured so much since my last Kubecon. There's going to be lots to talk abo‚Ä¶
1040048824192880600,Thu Sep 13 01:25:37 +0000 2018,RT @sh_reya: I‚Äôm super stoked to launch Trace, a educational comics platform for computer science. Check it out below!  If you‚Äôre excited b‚Ä¶
1039946359090999300,Wed Sep 12 18:38:27 +0000 2018,RT @viegasf: Check out PAIR's What-If Tool: Code-Free Probing of Machine Learning Models. It allows you to test for multiple ML Fairness me‚Ä¶
1039278953645596700,Mon Sep 10 22:26:26 +0000 2018,RT @adria: We‚Äôre organizing a privacy workshop on Dec. 8th at #nips2018 :)  Invited speakers include @goodfellow_ian @kamalikac and Shafi G‚Ä¶
1039249696508719100,Mon Sep 10 20:30:10 +0000 2018,RT @adversariel: Excellent discussion about using differential privacy for actual situations beyond university whiteboards. Despite deploym‚Ä¶
1039249645946384400,Mon Sep 10 20:29:58 +0000 2018,RT @NicolasPapernot: The census bureau on difficulties with deploying differential privacy: https://t.co/OsLUqgfyga  "With skilled staff an‚Ä¶
1038904266767749100,Sun Sep 09 21:37:33 +0000 2018,RT @liu_mingyu: We will be presenting our work on Multimodal Unsupervised Image-to-Image Translation (MUNIT) on P-1B-06 from 4-6pm on Monda‚Ä¶
1038849792347009000,Sun Sep 09 18:01:06 +0000 2018,RT @DataScienceNIG: We welcome the world to Africa‚Äôs biggest #MachineLearning fiesta, @DeepIndaba. The creme de la creme of the AI space ar‚Ä¶
1038634839732191200,Sun Sep 09 03:46:57 +0000 2018,@iandanforth @dwf @santoroAI Again, I don't think I've ever seen a paper get a 2/10 because the authors weren't fam‚Ä¶ https://t.co/jUCMUynaJ7
1038634205767381000,Sun Sep 09 03:44:26 +0000 2018,@iandanforth @dwf @santoroAI The pool of submissions is growing fast and the pool of experienced reviewers is not.‚Ä¶ https://t.co/lkmCAz9vBH
1038633226548338700,Sun Sep 09 03:40:32 +0000 2018,@iandanforth @dwf @santoroAI I'm not sure how much you've participated in the review process, but it is definitely‚Ä¶ https://t.co/zoLLev31PO
1038632864126914600,Sun Sep 09 03:39:06 +0000 2018,@marwinsegler @santoroAI Reviewers are indeed meant to update their reviews based on the rebuttals, which is sort o‚Ä¶ https://t.co/3W5VtfZApj
1038632378619420700,Sun Sep 09 03:37:10 +0000 2018,@santoroAI I definitely agree with this.
1038632107784908800,Sun Sep 09 03:36:06 +0000 2018,@santoroAI Usually if a paper gets scored a 2, the area chair doesn't need any more info than "this one will clearl‚Ä¶ https://t.co/oRuPFtKG2t
1038631538496135200,Sun Sep 09 03:33:50 +0000 2018,@santoroAI As a frequent area chair, I don't really agree with this. It's *borderline* papers where the area chair‚Ä¶ https://t.co/x0jN1inr7i
1038630675769774100,Sun Sep 09 03:30:24 +0000 2018,@iandanforth @dwf @santoroAI Even if a reviewer wanted to mentor someone who wrote a 2 paper, it's just not feasibl‚Ä¶ https://t.co/N4uXc6dGm8
1038630334831546400,Sun Sep 09 03:29:03 +0000 2018,@iandanforth @dwf @santoroAI A 2 paper usually isn't "research and progress from all quarters". Genuine progress pr‚Ä¶ https://t.co/F5bsXszwWu
1038629608390778900,Sun Sep 09 03:26:10 +0000 2018,@iandanforth @dwf @santoroAI I'm all for inclusion but I agree with @dwf on this one. Submitting a 2 paper to a maj‚Ä¶ https://t.co/Fo7InEUISY
1038577383635222500,Sat Sep 08 23:58:38 +0000 2018,@DynamicWebPaige @timnitGebru did basically what you want: https://t.co/7fmocMNoHp
1038475051870212100,Sat Sep 08 17:12:00 +0000 2018,RT @yaroslavvb: The code to reproduce "Imagenet in 18 minutes" is posted https://t.co/uuPAsSb4id , please let me know if you run into any p‚Ä¶
1038094132428697600,Fri Sep 07 15:58:22 +0000 2018,RT @hamadakoichi: Full-body High-resolution Anime Generation with Progressive Structure-conditional GANs. - Full-body HD anime generation.‚Ä¶
1038052512748589000,Fri Sep 07 13:12:59 +0000 2018,@MILAMontreal @ylecun Research shouldn‚Äôt be about ranking people. But if you‚Äôre going to do it, at least do it in a‚Ä¶ https://t.co/yKy5dFMKII
1038052168044040200,Fri Sep 07 13:11:37 +0000 2018,@MILAMontreal @ylecun The list also doesn‚Äôt seem correct. @AndrewYNg has a high enough h-index to be included but isn‚Äôt in the list
1038051091164741600,Fri Sep 07 13:07:20 +0000 2018,@MILAMontreal @ylecun Most scientists on the list of 100 are there only because they have a high h-index, not becau‚Ä¶ https://t.co/n6SDTWrjNL
1038049251001954300,Fri Sep 07 13:00:02 +0000 2018,@MILAMontreal @ylecun The tweet doesn‚Äôt mention that these stats pre-filter by h-index, which is harder to increase‚Ä¶ https://t.co/gY9HHb2sT1
1037507803500277800,Thu Sep 06 01:08:30 +0000 2018,Congratulations to @julius_adebayo , @_beenkim, @muelly  and @mrtz ! "Sanity Checks for Saliency Maps" (on arxiv so‚Ä¶ https://t.co/nlC1aumUDm
1037506428536119300,Thu Sep 06 01:03:03 +0000 2018,Congratulations to @avitaloliver , @gstsdn , @colinraffel , and @ekindogus ! "Realistic Evaluation of Deep Semi-Sup‚Ä¶ https://t.co/fMtU40GngJ
1037480999536361500,Wed Sep 05 23:22:00 +0000 2018,Congratulations to @gamaleldinfe , @sh_reya , @thisismyhat , @NicolasPapernot , @alexey2004 and @jaschasd ! "Advers‚Ä¶ https://t.co/spQTXLkAUK
1037139706129969200,Wed Sep 05 00:45:49 +0000 2018,@ixmeza We don't plan to offer streaming. We tried it at SOCML 2016 and the in-person participants didn't use it. S‚Ä¶ https://t.co/o94mx6834J
1037134115496022000,Wed Sep 05 00:23:36 +0000 2018,The third Self-Organizing Conference on Machine Learning will be held in Toronto, November 30-December 1. Get more‚Ä¶ https://t.co/t21LCZn8Dq
1037122854083473400,Tue Sep 04 23:38:51 +0000 2018,RT @red_abebe: If you have a free #NIPS2018 ticket as AC/top reviewer, please consider transferring your ticket to @black_in_ai. Many membe‚Ä¶
1037117016316858400,Tue Sep 04 23:15:40 +0000 2018,RT @mer__edith: Everyday inclusion progress: there are now‚ú®FIVE AI conferences that provide childcare‚ú® (ht friends in my mentions for the 4‚Ä¶
1036726480707809300,Mon Sep 03 21:23:49 +0000 2018,RT @hannawallach: Heads-up #NIPS208 attendees: there are childcare grants available this year! https://t.co/Co1zKzwddv
1036647598621261800,Mon Sep 03 16:10:22 +0000 2018,MIT Technology Review article on Everybody Dance Now: https://t.co/CppofyBcrp
1036259995061375000,Sun Sep 02 14:30:10 +0000 2018,RT @WithTheBest: Announcing our final #aiwtb keynote, Ian Goodfellow (@goodfellow_ian), Research Scientist at Google Brain!  Use AIWTB50 fo‚Ä¶
1035693778336505900,Sat Sep 01 01:00:13 +0000 2018,@nitin @jakevdp https://t.co/b6TQFChzV7
1035693067699859500,Sat Sep 01 00:57:24 +0000 2018,@jakevdp This curated list of deep learning papers refers to 2012-2016 as ‚Äúclassic‚Äù and before that as ‚Äúold‚Äù:‚Ä¶ https://t.co/6t454TDpTP
1035585802477002800,Fri Aug 31 17:51:10 +0000 2018,@AKatakkar I like to see GANs moving into the physical world and making meaningful improvements to people's lives,‚Ä¶ https://t.co/ls2SmEWX7y
1035387495343579100,Fri Aug 31 04:43:10 +0000 2018,@sonofsalazar @DynamicWebPaige I didn‚Äôt make the plot. I‚Äôm not sure what the authors used
1035294584824160300,Thu Aug 30 22:33:58 +0000 2018,https://t.co/46MisEZT5n Deep learning for predicting aftershocks of large earthquakes. Besides offering better pred‚Ä¶ https://t.co/nvQKrJ2Ld6
1035293070026141700,Thu Aug 30 22:27:57 +0000 2018,@yudapearl It seems like this tweet hinges on the word "today's" and could be rewritten in many ways that do not us‚Ä¶ https://t.co/0LS9o39WSu
1034993652605415400,Thu Aug 30 02:38:10 +0000 2018,@yudapearl Is there any reason we can‚Äôt have models that are both deep and causal? These seem like independent attributes to me
1034864122414813200,Wed Aug 29 18:03:28 +0000 2018,@AmirRosenfeld My instinct is probably not, but I don't actually know. During GAN training we present the same exam‚Ä¶ https://t.co/jhTYCfj38R
1034854162737942500,Wed Aug 29 17:23:53 +0000 2018,@wrossmorrow It's not on purpose. The creators of CIFAR-10 tried to avoid duplicate images, but these duplicates ar‚Ä¶ https://t.co/lwVk3x7IVN
1034848823682641900,Wed Aug 29 17:02:40 +0000 2018,Investigation of GAN mode collapse revealed that datasets mode collapse too https://t.co/6QMDYw7W5S
1034843107135610900,Wed Aug 29 16:39:57 +0000 2018,@mindnotnull @JoshuaKessler1 Sure, the link would be nice. I saw this article and it didn't exactly fill me with co‚Ä¶ https://t.co/5YwqnFxSyv
1034836157824004100,Wed Aug 29 16:12:21 +0000 2018,@mindnotnull @JoshuaKessler1 Software / tools: Linux desktop, vim, git, TensorFlow, matplotlib, ssh
1034835688951144400,Wed Aug 29 16:10:29 +0000 2018,@mindnotnull @JoshuaKessler1 I‚Äôm looking for a good laptop recommendation myself. I have the touchbar MacBook Pro a‚Ä¶ https://t.co/iANLzQLpDS
1034817116761772000,Wed Aug 29 14:56:41 +0000 2018,@JoshuaKessler1 I did teach some tensorflow GAN coding for @udacity‚Äôs Deep Learning nanodegree. Might do something‚Ä¶ https://t.co/Utf7zN4v9P
1034816608923832300,Wed Aug 29 14:54:40 +0000 2018,@dwf @jm_alexia Oh I see you already said this in another tweet, sorry
1034816430561095700,Wed Aug 29 14:53:57 +0000 2018,@dwf @jm_alexia Can you use NSERC / PGS funding to study a topic of your choice? Or still need to find a PI who will sign off?
1034814988265742300,Wed Aug 29 14:48:13 +0000 2018,@dwf @jm_alexia Yeah, I‚Äôm more thinking about my own experience trying to do a PhD in deep learning in 2009. Exampl‚Ä¶ https://t.co/2QzaFsbP4L
1034812874596659200,Wed Aug 29 14:39:49 +0000 2018,@dwf @jm_alexia A lot of PIs have huge armies of students and don‚Äôt really mentor them at all. The PI just grants t‚Ä¶ https://t.co/iCg2MQk6TD
1034812339336273900,Wed Aug 29 14:37:42 +0000 2018,@dwf @jm_alexia I agree with that (and I think Alexia does too). I‚Äôm saying there should be a mechanism where you c‚Ä¶ https://t.co/1ElvI7Rpt2
1034810865155899400,Wed Aug 29 14:31:50 +0000 2018,@JoshuaKessler1 Any specific content you want? (I do things like https://t.co/2CkX4RlhGL and talks at events etc)
1034807732388257800,Wed Aug 29 14:19:23 +0000 2018,@jm_alexia I agree there should be a program for junior researchers to access funding without having to go through‚Ä¶ https://t.co/Cg8hhsSHVO
1034807202731573200,Wed Aug 29 14:17:17 +0000 2018,@jm_alexia I have mixed feelings about this. In most academic disciplines we train way more PhDs than there are job‚Ä¶ https://t.co/vnWcvstlVY
1034806823273029600,Wed Aug 29 14:15:47 +0000 2018,@jm_alexia The bad politics / bad environment of academia are real. I think there‚Äôs an easy way to fix this: make i‚Ä¶ https://t.co/ZkgE7Z7ZDC
1034806107934359600,Wed Aug 29 14:12:56 +0000 2018,@jm_alexia I don‚Äôt quite understand the relevance of NGOs. You work at an NGO but I didn‚Äôt think your interest in A‚Ä¶ https://t.co/suJqI1Wd21
1034805583784763400,Wed Aug 29 14:10:51 +0000 2018,Thread from a biostatistician at a hospital about how hard it is to participate in the AI research community while‚Ä¶ https://t.co/wIa10HxCIf
1034123724427935700,Mon Aug 27 17:01:23 +0000 2018,Security researchers show that they are able to remotely move a robot in a university research lab. Many robots acc‚Ä¶ https://t.co/uix9ehWEXr
1033378485455081500,Sat Aug 25 15:40:04 +0000 2018,@iamtrask IMO it's better to just save the network to the filesystem and do the analysis in a different script. Far‚Ä¶ https://t.co/3Azc99gTT4
1033377895215841300,Sat Aug 25 15:37:44 +0000 2018,@greglinden @joelgrus I think notebooks are sort of OK for documentation. When you're done editing a piece of code‚Ä¶ https://t.co/a8OfVQZ9q5
1033377310152437800,Sat Aug 25 15:35:24 +0000 2018,@greglinden @joelgrus Joel's talk covers some barriers to effective teaching with notebooks. Also my own first nega‚Ä¶ https://t.co/egfu0nnQcc
1033376893465063400,Sat Aug 25 15:33:45 +0000 2018,@greglinden @joelgrus Joel's talk covers some other barriers to collaboration with notebooks, like how you can't re‚Ä¶ https://t.co/9SK436nd0u
1033376701248467000,Sat Aug 25 15:32:59 +0000 2018,@greglinden @joelgrus Not working with source control is a pretty big problem for collaboration. In general, I thin‚Ä¶ https://t.co/cbMytasK1X
1033357723725791200,Sat Aug 25 14:17:34 +0000 2018,@joelgrus Can I tempt you to do one on sharelatex?
1033355449494528000,Sat Aug 25 14:08:32 +0000 2018,Notebooks often degrade worse on flaky shuttle / airplane WiFi than ssh / screen do
1033355448441696300,Sat Aug 25 14:08:32 +0000 2018,A notebook means I need to set up my environment correctly in two places rather than one (front end and back end)
1033355447221157900,Sat Aug 25 14:08:32 +0000 2018,I can easily run the same bash script 8 times with 8 arguments on an 8 GPU machine. A notebook takes a lot of manua‚Ä¶ https://t.co/YqwRc7fOrk
1033355445325291500,Sat Aug 25 14:08:31 +0000 2018,Some information, such as TensorFlow Prints, gets invisibly printed in the backend rather than in the notebook
1033355444066996200,Sat Aug 25 14:08:31 +0000 2018,Notebooks generally don‚Äôt play very friendly with source control tools such as git
1033355441449787400,Sat Aug 25 14:08:30 +0000 2018,I don‚Äôt like notebooks either. I agree with a lot of @joelgrus ‚Äòs reasons and have a few others of my own https://t.co/D0DxniDyxt
1033048655010324500,Fri Aug 24 17:49:27 +0000 2018,@pgbovine Wrote my own CUDA kernels + used cuBLAS code to implement Boltzmann machines circa 2008 on the first CUDA-enabled GPUs
1033002136441741300,Fri Aug 24 14:44:36 +0000 2018,@RevueInAnalysis @jessesingal @jean_twenge What caused the sudden spike?
1032772522507350000,Thu Aug 23 23:32:12 +0000 2018,GANs for imitating dance moves https://t.co/gNQYP3l4Ni
1032355297472303100,Wed Aug 22 19:54:17 +0000 2018,@BruceTedesco @schmarzo The venn diagram here is basically the same as the one I made for the deep learning textboo‚Ä¶ https://t.co/6YYrNUz1tT
1031927075001626600,Tue Aug 21 15:32:41 +0000 2018,@gabrielpeyre Thanks, I get it. That‚Äôs interesting
1031923379203235800,Tue Aug 21 15:18:00 +0000 2018,@gabrielpeyre Is there a summation sign missing in the statement of the representation theorem?
1031907628832583700,Tue Aug 21 14:15:25 +0000 2018,A Portrait of the Artist as a Young GAN https://t.co/H4Ostx51n2
1031712859720314900,Tue Aug 21 01:21:28 +0000 2018,Video-to-video translation with conditional GANs https://t.co/DDmRSTkpri
1031625916118495200,Mon Aug 20 19:35:59 +0000 2018,@TrainingLuxoft I'm sorry, I'll be too busy to travel for the foreseeable future
1031577887525101600,Mon Aug 20 16:25:08 +0000 2018,Blog post on adversarial reprogramming: https://t.co/jvPdXa9MUw https://t.co/AxgP3E7eTM
1030503764271288300,Fri Aug 17 17:16:57 +0000 2018,@RogerGrosse @roydanroy I believe you, but please try to word more carefully in the future. As faculty at a prestig‚Ä¶ https://t.co/X6YqWojZs7
1030481124764672000,Fri Aug 17 15:47:00 +0000 2018,@C_Glastonbury @roydanroy @RogerGrosse Also ‚Äúexcuses‚Äù implies there‚Äôs blameworthy behavior rather than just a different thought process
1030467429238022100,Fri Aug 17 14:52:34 +0000 2018,@TLesort If you want to use it to evaluate generative models generically, I think there are still some wrinkles to‚Ä¶ https://t.co/D7sbO7Segg
1030466725714776000,Fri Aug 17 14:49:47 +0000 2018,@TLesort If the reason you want a generative model is to make synthetic training data, then this is an example of e‚Ä¶ https://t.co/rjMDvAFR1x
1030461077123788800,Fri Aug 17 14:27:20 +0000 2018,@RogerGrosse I‚Äôm really sick of how hostile the machine learning research community has become but I didn‚Äôt expect‚Ä¶ https://t.co/ax3dBptL5l
1030450784411025400,Fri Aug 17 13:46:26 +0000 2018,@RogerGrosse No, each paper should choose metrics appropriate to the claims it makes.
1030449523611586600,Fri Aug 17 13:41:25 +0000 2018,@RogerGrosse @Yuhu_ai_ I don‚Äôt think it‚Äôs necessary to measure every existing metric for every paper. Only necessar‚Ä¶ https://t.co/jg8Z2Wz1tz
1030448965697851400,Fri Aug 17 13:39:12 +0000 2018,@RogerGrosse It‚Äôs indirect but at least it‚Äôs relevant. Likelihood may not be relevant for your intended use of the model.
1030448622964539400,Fri Aug 17 13:37:51 +0000 2018,@RogerGrosse @Yuhu_ai_ I don‚Äôt think anyone is saying likelihood is useless. We‚Äôre saying likelihood tends not to m‚Ä¶ https://t.co/sLwxKoQ1Cj
1030447853355913200,Fri Aug 17 13:34:47 +0000 2018,@RogerGrosse What do you mean by ‚Äúthe observation model‚Äù in this context? I only know that term in the context of HMMs
1030447584945610800,Fri Aug 17 13:33:43 +0000 2018,@Doctor_Woah @RogerGrosse Yeah, and I don‚Äôt think I‚Äôd call that author list ‚ÄúGANsters‚Äù
1030447385019916300,Fri Aug 17 13:32:56 +0000 2018,@RogerGrosse For what it‚Äôs worth, it wasn‚Äôt GAN people who started the trend of evaluating properties other than li‚Ä¶ https://t.co/glAfRFsJ1Y
1030446650899218400,Fri Aug 17 13:30:01 +0000 2018,@RogerGrosse Personally I think the gold standard is to pick a downstream task and measure performance on that task‚Ä¶ https://t.co/gGdTuQHR5f
1030445820137680900,Fri Aug 17 13:26:42 +0000 2018,@RogerGrosse When I talked with you at NIPS 2010ish, you said one of the biggest obstacles to progress in generativ‚Ä¶ https://t.co/8XH6PuCdRF
1030152619795378200,Thu Aug 16 18:01:38 +0000 2018,@mrtz https://t.co/MeX2XG8gte
1030063725884190700,Thu Aug 16 12:08:24 +0000 2018,RT @HaoLi81: Check out @PinscreenInc's SIGGRAPH 2018 Real Time Live! Presentation showcasing paGAN, our photoreal avatar machine from hell:‚Ä¶
1029994425034960900,Thu Aug 16 07:33:01 +0000 2018,Evaluating generative models by estimating a latent skill variable that explains their performance seems like a pro‚Ä¶ https://t.co/MgEIWTrzXG
1029791386793635800,Wed Aug 15 18:06:13 +0000 2018,@KurutachThanard Thank you for writing it!
1029418233554772000,Tue Aug 14 17:23:27 +0000 2018,@DynamicWebPaige It‚Äôs often easier to look at code if you‚Äôre just reading for ‚Äúok, what does this do at all.‚Äù Math‚Ä¶ https://t.co/o3lylPHO0w
1029417876699209700,Tue Aug 14 17:22:02 +0000 2018,@DynamicWebPaige I think it depends on 1) what the idea is (some are clearer represented as code, some as math) 2)‚Ä¶ https://t.co/b0eDiHJCxh
1029053092862599200,Mon Aug 13 17:12:30 +0000 2018,This anonymous article is part of the conversation around the NIPS name change: https://t.co/8EOCPRZqwo
1029015666223919100,Mon Aug 13 14:43:47 +0000 2018,RT @NandoDF: As someone who made a career publishing at NIPS since 97, I‚Äôm delighted that the acronym is changing. As a dad, I‚Äôm also looki‚Ä¶
1028948167457419300,Mon Aug 13 10:15:34 +0000 2018,Train ImageNet in 18 minutes for just $40. https://t.co/CdLtIS6Y44 By my former colleague @yaroslavvb
1028750718868619300,Sun Aug 12 21:10:59 +0000 2018,@VictorStorchan @ylecun @AndrewYNg Hard to attribute to a single cause but maybe because Scientific American covered DCGANs in June 2016
1027908857346121700,Fri Aug 10 13:25:43 +0000 2018,@li_shuda Sorry to hear that. You might also be able to contact MIT Press.
1027291367196844000,Wed Aug 08 20:32:02 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Make a private github repo and keep track of all your code. Makes sur‚Ä¶ https://t.co/UAktJCik3t
1027290317765189600,Wed Aug 08 20:27:52 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Sounds like you‚Äôre on the right track!
1027283038579974100,Wed Aug 08 19:58:57 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Get enough sleep. It‚Äôs OK to pull an all nighter right before a confe‚Ä¶ https://t.co/2o37ja7L4h
1027282336059215900,Wed Aug 08 19:56:09 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Don‚Äôt follow the herd. Think of something that‚Äôs popular, think of it‚Ä¶ https://t.co/XOgm0mAy16
1027281844650356700,Wed Aug 08 19:54:12 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Apply for lots of these things. I was rejected from several governmen‚Ä¶ https://t.co/JrtMP3y4s9
1027281497324232700,Wed Aug 08 19:52:49 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Get a good source of funding that gives you freedom to work on whatev‚Ä¶ https://t.co/AshHoC8E7b
1027281054661525500,Wed Aug 08 19:51:04 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei Choose an advisor, not a school. You are probably already past this point though
1027280697063612400,Wed Aug 08 19:49:38 +0000 2018,@smbadiwe @ojembaenweilo85 @ram_ssk @drfeifei I did my PhD in Quebec so I can‚Äôt comment as much about the US system‚Ä¶ https://t.co/4kudNVaHFE
1027266657373356000,Wed Aug 08 18:53:51 +0000 2018,RT @red_abebe: Very excited to see that in addition to @black_in_ai, there will also be workshops on:  Latinx in AI: https://t.co/uutr9IGYe‚Ä¶
1026904656117678100,Tue Aug 07 18:55:23 +0000 2018,A few more people have contacted me privately to say that these allegations are false / Pinscreen's results are rea‚Ä¶ https://t.co/FL9f8waMIx
1026856782168301600,Tue Aug 07 15:45:09 +0000 2018,To be clear, we don‚Äôt know if these allegations are true, just that they exist. And the company probably can‚Äôt comm‚Ä¶ https://t.co/4XuSreARSX
1026504891798302700,Mon Aug 06 16:26:52 +0000 2018,Also, someone DMed me to warn me these results could be fake: https://t.co/IFPxKqEf2s
1026500764053774300,Mon Aug 06 16:10:28 +0000 2018,One of the most anticipated GAN names now taken: paGAN. https://t.co/ifUgy40O8t https://t.co/NvxKDwEMZz
1026211392129523700,Sun Aug 05 21:00:36 +0000 2018,RT @meghanml: @drmarenw Deep down I always knew it, but leaving academia #withaPhD confirmed: you can have a fulfilling career without sacr‚Ä¶
1025444117130530800,Fri Aug 03 18:11:44 +0000 2018,@srchvrs You also get years worth of people claiming to have beaten your method by pretending that the easy to anal‚Ä¶ https://t.co/VAXnurMwei
1024768447773720600,Wed Aug 01 21:26:51 +0000 2018,This is how @gstsdn is able to test if some coverage is new coverage without explicitly storing all old coverage fo‚Ä¶ https://t.co/xxhygbwaA4
1024755181181796400,Wed Aug 01 20:34:08 +0000 2018,Congratulations, @junyanz89 ! https://t.co/yd0sEz6xfU
1024696499723096000,Wed Aug 01 16:40:58 +0000 2018,@Ramesh_Basil In my copy, the introduction starts on page 1, and so does the web edition: https://t.co/OCllCxe23p A‚Ä¶ https://t.co/9i2ndbZFXY
1024351509121708000,Tue Jul 31 17:50:05 +0000 2018,@machinaut The API is very general. Of course, we can't guarantee that TensorFuzz will be a lot faster than random‚Ä¶ https://t.co/nSbYIxYhL9
1024351041200869400,Tue Jul 31 17:48:14 +0000 2018,@machinaut Good news: once we open-source TensorFuzz, it will already support this! You basically write your own "u‚Ä¶ https://t.co/dkwlB9bPnu
1024297447739158500,Tue Jul 31 14:15:16 +0000 2018,@RogerGrosse @fhuszar The review process is noisy and each individual person observes only a small sample size, so‚Ä¶ https://t.co/82rQe8UDKC
1024297031932698600,Tue Jul 31 14:13:37 +0000 2018,@RogerGrosse @fhuszar Part of my point is that peer review can worsen the literature via the text of reviews even t‚Ä¶ https://t.co/gDvbaB15Bf
1024296159265714200,Tue Jul 31 14:10:09 +0000 2018,@CsabaSzepesvari @fhuszar @RogerGrosse Yes, I agree with you. I can't prove it either. I think theorists would ask‚Ä¶ https://t.co/fdiEjQpogC
1024108440833024000,Tue Jul 31 01:44:13 +0000 2018,I‚Äôm hoping this will become the basis of regression testing for complicated software involving ML. eg, before rolli‚Ä¶ https://t.co/UnSe0o4efv
1024107726098460700,Tue Jul 31 01:41:23 +0000 2018,https://t.co/hYiWI7ntyk TensorFuzz automates the process of finding inputs that cause some specific testable behavi‚Ä¶ https://t.co/NotmOCFQMS
1024107055097905200,Tue Jul 31 01:38:43 +0000 2018,Neural networks are notoriously hard to debug. @gstsdn has developed a new debugging methodology by adapting tradit‚Ä¶ https://t.co/0OPB7bbb1J
1024005886291791900,Mon Jul 30 18:56:43 +0000 2018,Causal InfoGAN imagining plans for how to move a rope into different positions: https://t.co/pFPcKenx36 https://t.co/VjF7IsaSt1
1024005512826740700,Mon Jul 30 18:55:14 +0000 2018,@NewFolderF Thanks, I'll fix it.
1023739862283735000,Mon Jul 30 01:19:37 +0000 2018,@74Vn0x5 @zacharylipton I think peer review is a good idea in principle, but it‚Äôs important to get the implementation right in practice
1023715802904555500,Sun Jul 29 23:44:01 +0000 2018,@geomblog @zacharylipton I think it‚Äôs good to do peer review but there needs to be an ongoing effort to monitor the‚Ä¶ https://t.co/G0cawLHaSC
1023715139504107500,Sun Jul 29 23:41:23 +0000 2018,@geomblog @alaviers @yisongyue @zacharylipton I don‚Äôt have any quantitative evidence for this, but my impression is‚Ä¶ https://t.co/MdeNukOxls
1023711900381601800,Sun Jul 29 23:28:31 +0000 2018,@CesareMontresor @zacharylipton Yeah, peer review today has become more about choosing papers that are flashy or ex‚Ä¶ https://t.co/blzRtvxSpy
1023673856760852500,Sun Jul 29 20:57:21 +0000 2018,@examachine @Make3333 I think it's important to give reviewers more incentives to do a good job than they have now,‚Ä¶ https://t.co/fpJ5vDYr97
1023646846541910000,Sun Jul 29 19:10:01 +0000 2018,@BrianNorgard @DickeySingh What do non seasoned investors do that causes trouble for the startup? What should they‚Ä¶ https://t.co/hZPP2yjwtF
1023646590668427300,Sun Jul 29 19:09:00 +0000 2018,@BrianNorgard @DickeySingh Should startups still get trophy advisors, just not pay them equity? Or forego the trophy advisor altogether?
1023639782453174300,Sun Jul 29 18:41:57 +0000 2018,@zacharylipton Yeah, I‚Äôm agreeing and adding some of my personal speculation about the causes
1023606450562580500,Sun Jul 29 16:29:30 +0000 2018,Some of the other troubling trends would probably happen without peer review, but I see reviewers basically asking‚Ä¶ https://t.co/M1Iv2YhUF2
1023606448834535400,Sun Jul 29 16:29:29 +0000 2018,(This last one is a bit less consistent than the others. I‚Äôve seen a few science papers get high review scores with‚Ä¶ https://t.co/KFgDNcCJye
1023606447001632800,Sun Jul 29 16:29:29 +0000 2018,Reviewers seem to hate ‚Äúscience‚Äù papers, but it‚Äôs possible to sneak science in the door if add some token amount of new method engineering
1023606445185499100,Sun Jul 29 16:29:28 +0000 2018,Reviewers often see papers that use empirical observations to understand how a system works, and respond with compl‚Ä¶ https://t.co/jIlcU1xNDk
1023606443314823200,Sun Jul 29 16:29:28 +0000 2018,If you do add an explanation, no matter how implausible or unsupported by evidence, that‚Äôs usually enough to placate reviewers
1023606441096040400,Sun Jul 29 16:29:27 +0000 2018,Similarly, reviewers often read a submission about a new method hat performs well and say to reject it because ther‚Ä¶ https://t.co/Uq2FNl6jYq
1023606439086944300,Sun Jul 29 16:29:27 +0000 2018,This is easily addressed by adding useless mathiness. Reviewers generally don‚Äôt call it out for being useless. It p‚Ä¶ https://t.co/bNHdZPSbH1
1023606434976563200,Sun Jul 29 16:29:26 +0000 2018,It‚Äôs very common for reviewers to read empirical papers and complain that there is no ‚Äútheory‚Äù. But they don‚Äôt ask‚Ä¶ https://t.co/1VtNwxWeAn
1023606432812478500,Sun Jul 29 16:29:25 +0000 2018,I frequently serve as an area chair and I manage a small research group, so overall I see a lot of reviews of both‚Ä¶ https://t.co/aU5ZqZuTy2
1023606428966080500,Sun Jul 29 16:29:25 +0000 2018,I suspect that peer review *actually causes* rather than mitigates many of the ‚Äútroubling trends‚Äù recently identifi‚Ä¶ https://t.co/xBnxXLYvTz
1022890496102813700,Fri Jul 27 17:04:33 +0000 2018,@brianrbell It's exponential extrapolation. The y axis is log scale.
1022238303528005600,Wed Jul 25 21:52:58 +0000 2018,@Jovonni 0
1021576836587827200,Tue Jul 24 02:04:32 +0000 2018,RT @delk: It‚Äôs hard to overstate how important Talent Magnets are for building great teams.  Hiring people who draw top talent in to work w‚Ä¶
1021484456333520900,Mon Jul 23 19:57:27 +0000 2018,@Luiz9495 @ChristophMolnar @arxiv_org That's a good point, I hadn't thought about it that way. I'll take it down.
1021425355884617700,Mon Jul 23 16:02:36 +0000 2018,@WMiggg @hindupuravinash It's hard for me to judge quality because I don't need to learn the subject from reading a‚Ä¶ https://t.co/FK0uFnukCn
1021214148875685900,Mon Jul 23 02:03:20 +0000 2018,RT @black_in_ai: We're excited to announce the Call for Participation for the 2nd Black in AI Workshop at #NIPS2018! Submission deadline is‚Ä¶
1020441847213142000,Fri Jul 20 22:54:29 +0000 2018,@dustinvtran @LiamFedus @hardmaru @pathak2206 @_brohrer_ Several people have replied with good refs. Here's one mor‚Ä¶ https://t.co/r9AWEk1xhO
1020368525200830500,Fri Jul 20 18:03:08 +0000 2018,@LiamFedus @hardmaru @pathak2206 @_brohrer_ For a long time, randomly connected RNNs were a popular model. This was‚Ä¶ https://t.co/fI2lSRNdVZ
1020368153145008100,Fri Jul 20 18:01:39 +0000 2018,@LiamFedus @hardmaru @pathak2206 @_brohrer_ Random weights have often been a surprisingly strong baseline. Back in‚Ä¶ https://t.co/nDi9Y1rKd3
1020115131039010800,Fri Jul 20 01:16:14 +0000 2018,RT @genekogan: looks like i found the meme vector https://t.co/Lss9myEEi8
1020106142930702300,Fri Jul 20 00:40:31 +0000 2018,RT @colinraffel: New paper w/ @D_Berthelot_ML Aurko Roy and @goodfellow_ian where we propose an adversarial regularizer for improving inter‚Ä¶
1019405160991223800,Wed Jul 18 02:15:04 +0000 2018,Also https://t.co/2CkX4RlhGL Thank you @matplotlib ! https://t.co/Nqk6UPUZUc
1019063406865707000,Tue Jul 17 03:37:04 +0000 2018,@crazymuse_ai @decodyng @badfellow_ian you‚Äôre famous https://t.co/cpwAjn1Wb4
1019062952526147600,Tue Jul 17 03:35:15 +0000 2018,@jm_alexia  https://t.co/4LhUBWQODa
1018932342566481900,Mon Jul 16 18:56:15 +0000 2018,RT @elaClaudia: Really excited to be part of #TMLSS. The summer school contains a set of great speakers and tutorials and starts today in C‚Ä¶
1018499908897083400,Sun Jul 15 14:17:55 +0000 2018,@1NOnlyBeeflord @kchonyc @RandomlyWalking https://t.co/1KxG639tYl
1018321743369273300,Sun Jul 15 02:29:57 +0000 2018,@kchonyc @RandomlyWalking I could see myself taking either side of this resolution in next year‚Äôs ICML debates: Lap‚Ä¶ https://t.co/DJ97LdjYaH
1018321139020415000,Sun Jul 15 02:27:33 +0000 2018,Also, area chairs: if you see reviewers making criticisms that are too vague to be meaningfully addressed in the re‚Ä¶ https://t.co/fTamKOjUEJ
1018198921238024200,Sat Jul 14 18:21:54 +0000 2018,@PadenAlex Main takeaway?
1018197855406731300,Sat Jul 14 18:17:40 +0000 2018,@APompliano @GeniusMiind @gamaleldinfe @jaschasd Levels of difficulty / indirection: 1) Make the model produce wron‚Ä¶ https://t.co/3nrZX8O430
1017881967851737100,Fri Jul 13 21:22:27 +0000 2018,RT @alexey2004: Training and evaluation code for "Adversarial logit pairing" paper is released: https://t.co/Kz8P3L8Cv7  @goodfellow_ian @h‚Ä¶
1017877645055283200,Fri Jul 13 21:05:16 +0000 2018,RT @TensorFlow: This paper includes 15 TensorFlow Hub modules to generate images using GANs! Check out the colab notebook to try it out ‚Üí h‚Ä¶
1017804538705633300,Fri Jul 13 16:14:46 +0000 2018,RT @ciscaoladipo: Beautiful piece on our Timnit! @timnitGebru  AI Innovators: How One Woman Followed Her Passion and Brought Diversity to A‚Ä¶
1017794927801954300,Fri Jul 13 15:36:35 +0000 2018,I see your joke suggestion, and raise you "Icy ML" https://t.co/vsySt3nSrY
1017794159455817700,Fri Jul 13 15:33:31 +0000 2018,RT @catherineols: UPDATE: Times for the @iclmconf debates workshop have shifted earlier to accommodate the World Cup final! https://t.co/sH‚Ä¶
1017793678633398300,Fri Jul 13 15:31:37 +0000 2018,The latest from the team that brought you "Are GANs created equal?" The new cookbook now endorses some GAN techniqu‚Ä¶ https://t.co/HGiXUe7kLB
1017575559155494900,Fri Jul 13 01:04:53 +0000 2018,RT @tejasdkulkarni: If you are curious about how DeepRL, GANs and program synthesis fit together in the long term, come to our ICML oral at‚Ä¶
1017437517379858400,Thu Jul 12 15:56:21 +0000 2018,RT @dwf: Was just made aware of @randomlywalking's series of blog posts on stress in research. It's really good, particularly part 2. No ti‚Ä¶
1017212727633170400,Thu Jul 12 01:03:07 +0000 2018,@LMescheder Nevermind, I found the code. https://t.co/XbFoL0mKI9 for anyone else who is looking
1017205336531324900,Thu Jul 12 00:33:45 +0000 2018,@LMescheder Is there code available?
1017089936170704900,Wed Jul 11 16:55:12 +0000 2018,RT @wielandbr: Do you have an idea on how to attack neural network models using only a small number of queries? Or do you have an idea on h‚Ä¶
1017049252822859800,Wed Jul 11 14:13:32 +0000 2018,RT @GoogleAI: A lot of @TensorFlow demos at the #ICML2018 Google booth today! ‚Ä¢TF Hub (https://t.co/4AdEsCYNNZ) 10:30-11:00 ‚Ä¢TF AutoGraph (‚Ä¶
1017049025097318400,Wed Jul 11 14:12:38 +0000 2018,RT @GoogleAI: Long day of #ICML2108 talks? Stop by the Google booth from 15:30-16:00 to have fika (https://t.co/fjhkPNqfVp) and learn more‚Ä¶
1017047614083043300,Wed Jul 11 14:07:01 +0000 2018,@LMescheder Thanks!
1016816291041108000,Tue Jul 10 22:47:49 +0000 2018,@LMescheder Do you have any thoughts on the relationship between input noise, gradient penalties, and normalization‚Ä¶ https://t.co/s4AXfqL80p
1016814887513698300,Tue Jul 10 22:42:15 +0000 2018,@LMescheder I like that you've shown the Roth et al gradient penalty can be simplified a lot. That fits with my int‚Ä¶ https://t.co/ZxIzXRgpCC
1016813986547884000,Tue Jul 10 22:38:40 +0000 2018,@LMescheder I see you've provided convergence proofs for a lot of different base losses and a lot of different grad‚Ä¶ https://t.co/7gv6vyGGE0
1016813704791224300,Tue Jul 10 22:37:33 +0000 2018,@LMescheder I see you've proven that NS-GAN doesn't converge. That's an interesting result. Do you know whether NS-‚Ä¶ https://t.co/uDUDsTFEzZ
1016813309364858900,Tue Jul 10 22:35:59 +0000 2018,@LMescheder I like this paper! I have a few questions. I'm sorry if these are already answered in the paper
1016800132228976600,Tue Jul 10 21:43:37 +0000 2018,I'll teach an ACM webinar on adversarial machine on July 24: https://t.co/JLDcl16nIi
1016678596771868700,Tue Jul 10 13:40:41 +0000 2018,@GoAbiAryan @Miles_Brundage Oh, I meant I had bought enough GPUs for deep learning that it was regrettable I didn't‚Ä¶ https://t.co/9cGQWYdywi
1015644004501712900,Sat Jul 07 17:09:35 +0000 2018,Nice GAN results at ICML: https://t.co/eP8dZtdDZS https://t.co/5Zs87JpgOp
1014914270218281000,Thu Jul 05 16:49:52 +0000 2018,@Miles_Brundage This 1795 essay by Laplace is fun to read: https://t.co/AsuW3ngw9h
1014597588232753200,Wed Jul 04 19:51:30 +0000 2018,Adversarial examples for the GRE https://t.co/Sx8h7xTPtr
1014278355707760600,Tue Jul 03 22:42:59 +0000 2018,@jm_alexia Is there a typo in eq 18? I would expect the sign in the case where the input is fake to be flipped, but‚Ä¶ https://t.co/Z3mTPWvSuH
1014277973522780200,Tue Jul 03 22:41:27 +0000 2018,@jm_alexia Do you know if there's a nice closed-form solution for the optimal discriminator? For example for the RS‚Ä¶ https://t.co/v5islYVqt1
1014277789334114300,Tue Jul 03 22:40:44 +0000 2018,@jm_alexia This looks good! I have a few questions
1014277290631413800,Tue Jul 03 22:38:45 +0000 2018,This new family of GAN loss functions looks promising! I'm especially excited about Fig 4-6, where we see that the‚Ä¶ https://t.co/5fxerhYxYj
1014237423889309700,Tue Jul 03 20:00:20 +0000 2018,@jm_alexia Yes, we're reading it today over in Mountain View! The fast learning at the start looks especially good :)
1013626044375433200,Mon Jul 02 03:30:55 +0000 2018,RT @jaschasd: Adversarial Reprogramming of Neural Networks https://t.co/yYrLGNrAJT A new goal for adversarial attacks! Rather than cause a‚Ä¶
1013574366045487100,Mon Jul 02 00:05:34 +0000 2018,RT @dwf: It was my immense pleasure to lecture about GANs at the Machine Learning Summer School in Buenos Aires, an amazing city to which I‚Ä¶
1012819479993045000,Fri Jun 29 22:05:55 +0000 2018,@Make3333 @gstsdn
1012018672955605000,Wed Jun 27 17:03:48 +0000 2018,@GammaCounter @docskalski @DrHenryK Yes, I lead a team of researchers at Google working on defenses against these k‚Ä¶ https://t.co/RBaVrEc95Q
1012008256040886300,Wed Jun 27 16:22:25 +0000 2018,@GammaCounter @docskalski @DrHenryK This particular perturbation is actually just a closed-form algebraic formula.‚Ä¶ https://t.co/aZ1lhYrR6I
1012002137209835500,Wed Jun 27 15:58:06 +0000 2018,@docskalski @GammaCounter @DrHenryK I call it a "perturbation" and not "noise" because there is important structure‚Ä¶ https://t.co/kQTMP3AuC7
1011994688486666200,Wed Jun 27 15:28:30 +0000 2018,Congratulations Chelsea! Tremendously deserved https://t.co/RpqT9AjR2H
1011744938512412700,Tue Jun 26 22:56:05 +0000 2018,@aleks_madry @NicolasPapernot Yes, we did submit it a long time ago. We don't have much control over the time from‚Ä¶ https://t.co/K9S1DSsT0H
1011667818268393500,Tue Jun 26 17:49:38 +0000 2018,RT @NicolasPapernot: Together with @goodfellow_ian and Patrick McDaniel, we wrote a CACM article on making ML robust against adversarial in‚Ä¶
1011635304472514600,Tue Jun 26 15:40:26 +0000 2018,RT @WiCVworkshop: Call for submissions! The 5th Women in Computer Vision Workshop (WiCV) at #ECCV2018 invites all vision researchers to sub‚Ä¶
1011611013945294800,Tue Jun 26 14:03:55 +0000 2018,RT @negar_rz: Excited to announce the FashionGen Text to Image challenge. The task is to generate fashion items based on design description‚Ä¶
1011610793530437600,Tue Jun 26 14:03:02 +0000 2018,RT @CACMmag: "Making Machine Learning Robust Against Adversarial Inputs," by @goodfellow_ian et al., looks at protecting #MachineLearning s‚Ä¶
1011014975953895400,Sun Jun 24 22:35:28 +0000 2018,RT @black_in_ai: Calling all allies! We're setting up a mentoring program and would love to have you all involved.   If you work in AI (def‚Ä¶
1010301362196774900,Fri Jun 22 23:19:49 +0000 2018,Alyosha Efros on ‚Äúreasons to love GANs‚Äù at the #CVPR2018 tutorial on GANs https://t.co/T5TCv990yy
1010292229586341900,Fri Jun 22 22:43:32 +0000 2018,Carl Vondrick on video generation at the #CVPR2018 GAN tutorial https://t.co/f0loDB3FFi
1010267157131743200,Fri Jun 22 21:03:54 +0000 2018,RT @adri_romsor: Carol E. Reiley from @driveai_ joining us remotely for her keynote talk at #WiCV18 #CVPR18. https://t.co/GDyWqlWouW
1010218424989974500,Fri Jun 22 17:50:16 +0000 2018,@geoffreyirving That must be complete agany
1010215868028993500,Fri Jun 22 17:40:06 +0000 2018,I'll present a talk called "Defense Against the Dark Arts" summarizing the state of the art and key research challe‚Ä¶ https://t.co/0hFXS02rLQ
1010209609091465200,Fri Jun 22 17:15:14 +0000 2018,Sanjeev Arora on the theory of finite GANs at the #CVPR2018 tutorial https://t.co/EoizPf3KsK
1010196349927579600,Fri Jun 22 16:22:33 +0000 2018,Taesung Park on CycleGAN at the #CVPR2018 GAN tutorial https://t.co/2waN6cjeod
1010192643467251700,Fri Jun 22 16:07:49 +0000 2018,Jun-Yan Zhu teaches how to do unsupervised image to image translation at the #CVPR2018 tutorial on GANs https://t.co/Ye7ltvnn7C
1010190930635178000,Fri Jun 22 16:01:00 +0000 2018,@VahidK @jigarkdoshi This is why I spend so much of my time studying adversarial examples for AV systems. I have de‚Ä¶ https://t.co/2QWyVbUTtd
1010190209336528900,Fri Jun 22 15:58:08 +0000 2018,@jigarkdoshi The AV problem may be too hard for humans to solve. We may need superintelligent RL agents to solve it‚Ä¶ https://t.co/5Q3GhkqWCl
1010189613745332200,Fri Jun 22 15:55:46 +0000 2018,@jigarkdoshi We have very good narrow AV that can connect specific projectors to specific laptops running specific‚Ä¶ https://t.co/eiJ7VTMUcz
1010189050139930600,Fri Jun 22 15:53:32 +0000 2018,@jigarkdoshi https://t.co/JPZn4GxSfu
1010186120859013100,Fri Jun 22 15:41:54 +0000 2018,@fhuszar @geoffreyirving I think PAGAN is still available. Or someone could do a GANIN homage to @yaroslav_ganin or‚Ä¶ https://t.co/2aFsN0ZMtL
1010185568821510100,Fri Jun 22 15:39:42 +0000 2018,@fhuszar @geoffreyirving LOGAN is taken: https://t.co/qAFCl4ZTod
1010185393247932400,Fri Jun 22 15:39:00 +0000 2018,Phillip Isola on pix2pix at #CVPR2018 GAN tutorial https://t.co/4zbHrDFbxZ
1010172032393273300,Fri Jun 22 14:45:55 +0000 2018,@fhuszar  https://t.co/8RFYO5ZRx5
1009918493565726700,Thu Jun 21 21:58:26 +0000 2018,@yberk0 I'm not planning to write one right now. Not sure if any of the co-presenters are.
1009911282139521000,Thu Jun 21 21:29:47 +0000 2018,#CVPR2018 Check out the all-day tutorial on GANs tomorrow: https://t.co/b4cRQDApVP I'll speak at 9AM giving an intr‚Ä¶ https://t.co/d0DWYoZQgs
1009909797787848700,Thu Jun 21 21:23:53 +0000 2018,Consider submitting papers to ALEC, the symposium on Adversary-Aware Learning Techniques and Trends in Cybersecurity https://t.co/wL50vExrF0
1009571186924183600,Wed Jun 20 22:58:22 +0000 2018,RT @DepthFirstLearn: We just released our newest study guide! Learn all about TRPO from professors @kumarkagrawal and @suryabhupa ‚Üí https:/‚Ä¶
1009564365517815800,Wed Jun 20 22:31:16 +0000 2018,RT @ctnzr: .@tcwang0509 will be presenting an oral presentation Thursday at CVPR on his Pix2PixHD work generating high-resolution synthetic‚Ä¶
1009092231465087000,Tue Jun 19 15:15:10 +0000 2018,RT @GoogleAI: Attending #CVPR2018 this year? Learn more about the computer vision research (and demos!) we are presenting this week in Salt‚Ä¶
1008710312722292700,Mon Jun 18 13:57:34 +0000 2018,#CVPR2018 I will teach an Introduction to GANs at 8:45 AM in Room 150-ABC at the Perception Beyond the Visible Spec‚Ä¶ https://t.co/K2iQ0ZHQZl
1008132476940648400,Sat Jun 16 23:41:27 +0000 2018,RT @SussilloDavid: Most of you know me as a successful neuroscientist / deep learning researcher but I have a story that I want to share br‚Ä¶
1007658349653946400,Fri Jun 15 16:17:26 +0000 2018,Consider submitting papers to the Workshop on Positive and Negative Adversaries in Multimedia: https://t.co/hd9sUDk0lN
1007428144096206800,Fri Jun 15 01:02:41 +0000 2018,@geoffreyirving I think I‚Äôll have to play my ‚ÄúI don‚Äôt know‚Äù card for now. All proposed post-processing strategies h‚Ä¶ https://t.co/1bo2j3t5IQ
1007424020730376200,Fri Jun 15 00:46:18 +0000 2018,@geoffreyirving Suppose the model contains m bits of parameters and the manifold takes n bits to specify. In many c‚Ä¶ https://t.co/RidLEXN1V5
1007422941838000100,Fri Jun 15 00:42:01 +0000 2018,@geoffreyirving There exist models and datasets for which it is impossible to defend because the model has provably‚Ä¶ https://t.co/LzULqIUo0b
1007421968503599100,Fri Jun 15 00:38:08 +0000 2018,@geoffreyirving OK, that makes a lot more sense. I didn‚Äôt realize that defending the human was the primary case you‚Äôre interested in.
1007420640163520500,Fri Jun 15 00:32:52 +0000 2018,@geoffreyirving I‚Äôm sorry. I am interested in your thought process and I am confused about what you meant. I didn‚Äôt‚Ä¶ https://t.co/etcg9UD64K
1007417543093452800,Fri Jun 15 00:20:33 +0000 2018,@geoffreyirving Do you mean you want to get at the conceptual difficulty of why it's hard to defend against adversa‚Ä¶ https://t.co/Xqq2m75kAu
1007415720001486800,Fri Jun 15 00:13:19 +0000 2018,@geoffreyirving The reasoning in your first two tweets seems to be "if you can't specify how to do task T by post-p‚Ä¶ https://t.co/ODxWX2PmIz
1007387345513902100,Thu Jun 14 22:20:34 +0000 2018,@geoffreyirving There is information there, but the barriers to using it are currently more conceptual than computational.
1007365189820244000,Thu Jun 14 20:52:31 +0000 2018,@geoffreyirving I understand that you don't want to increase normal accuracy. I'm making an analogy to the normal a‚Ä¶ https://t.co/KYPHJU8DjO
1007365023058948100,Thu Jun 14 20:51:52 +0000 2018,@geoffreyirving It is possible to make attacks that don't use the data today, but only because our models are bad.‚Ä¶ https://t.co/NE4eUROtPh
1007364740908081200,Thu Jun 14 20:50:44 +0000 2018,@geoffreyirving Most adversarial attacks today do use the dataset. They start with a test set example and test set‚Ä¶ https://t.co/642BjwT5yz
1007364286845354000,Thu Jun 14 20:48:56 +0000 2018,@geoffreyirving The dataset is the only specification of the task you want the model to do. With no dataset, the de‚Ä¶ https://t.co/GbLPzkyFZE
1007304958780178400,Thu Jun 14 16:53:11 +0000 2018,@geoffreyirving Why should it be easy without access to the training data? If I give you access to a trained linear‚Ä¶ https://t.co/SSLdl7lIrl
1007276191722557400,Thu Jun 14 14:58:53 +0000 2018,@dribnet @geoffreyirving The claim in the paper is basically "there exist datasets for which you are forced to make‚Ä¶ https://t.co/0HesZoTQuS
1006937880667697200,Wed Jun 13 16:34:33 +0000 2018,RT @JeffDean: We're continuing to expand our @GoogleAI teams around the world.  We‚Äôll be opening our first research center in Africa in #Gh‚Ä¶
1005993235490017300,Mon Jun 11 02:00:52 +0000 2018,RT @zzznah: https://t.co/Idd5nBCsSv
1004819541048717300,Thu Jun 07 20:17:01 +0000 2018,RT @sundarpichai: Today we‚Äôre sharing our AI principles and practices. How AI is developed and used will have a significant impact on socie‚Ä¶
1004813341599006700,Thu Jun 07 19:52:23 +0000 2018,RT @doomie: AI at Google: our principles: https://t.co/2GOliMcQor. Happy to see this out!
1004754795675070500,Thu Jun 07 15:59:45 +0000 2018,@remi_Delassus Text is still hard for GANs. Since two years ago I have been a co-author of this paper that makes so‚Ä¶ https://t.co/22rWcCTbzB
1004751442190581800,Thu Jun 07 15:46:25 +0000 2018,https://t.co/G2WkI9mx85
1004740450547187700,Thu Jun 07 15:02:45 +0000 2018,RT @yaroslav_ganin: Just learned that our paper "Synthesizing Programs for Images using Reinforced Adversarial Learning" (aka SPIRAL) got a‚Ä¶
1004395008554721300,Wed Jun 06 16:10:05 +0000 2018,RT @DepthFirstLearn: Announcing https://t.co/SAb4OLLRTB! We are building a repository of study guides targeting consequential papers. Check‚Ä¶
1004391229667213300,Wed Jun 06 15:55:04 +0000 2018,@jeremyphoward @ylecun @paleckar @jabawack Pylearn2 (and presumably other frameworks that I'm less familiar with) h‚Ä¶ https://t.co/TdUPDTxgWP
1003677241379733500,Mon Jun 04 16:37:56 +0000 2018,RT @beenwrekt: Do CIFAR-10 classifiers generalize to CIFAR-10? The answer will surprise you! https://t.co/0XzxeZpnwv
1003322537789411300,Sun Jun 03 17:08:28 +0000 2018,@samfin55 @IEEESSP Thanks. I've fixed the link
1002662559890067500,Fri Jun 01 21:25:57 +0000 2018,@aleks_madry @tsiprasd @ShibaniSan @logan_engstrom @alex_m_turner I think you could say you have the first adversar‚Ä¶ https://t.co/kGmnwOd0UE
1002662022176112600,Fri Jun 01 21:23:49 +0000 2018,@aleks_madry @tsiprasd @ShibaniSan @logan_engstrom @alex_m_turner Thanks. I would appreciate it if you would mentio‚Ä¶ https://t.co/QNqyyrzHA7
1002658613356183600,Fri Jun 01 21:10:16 +0000 2018,@aleks_madry @tsiprasd @ShibaniSan @logan_engstrom @alex_m_turner The paper itself discusses only the interpretabil‚Ä¶ https://t.co/7OGhMAHXcQ
1002645392830287900,Fri Jun 01 20:17:44 +0000 2018,@aleks_madry @tsiprasd @ShibaniSan @logan_engstrom @alex_m_turner We've known since at least 2014 that for robust m‚Ä¶ https://t.co/xtVb1cOIc4
1002354350402953200,Fri Jun 01 01:01:14 +0000 2018,@MLFreak1 Alessandro's explanation looks good to me. Let me know if you have any other questions
1002353125720617000,Fri Jun 01 00:56:22 +0000 2018,@docmilanfar @catherineols Open Philanthropy goes through exactly this kind of thought process when making a grant,‚Ä¶ https://t.co/PKKFhevNqg
1002352340458827800,Fri Jun 01 00:53:15 +0000 2018,@docmilanfar @catherineols Open Philanthropy has spent about $20M on vaccines compared to the $1M for this fellowsh‚Ä¶ https://t.co/9CmSCVHZCU
1002349893048909800,Fri Jun 01 00:43:31 +0000 2018,@docmilanfar @catherineols It's about giving students the academic freedom to pursue research projects that are imp‚Ä¶ https://t.co/N4l5DfvEe8
1002271712241582100,Thu May 31 19:32:52 +0000 2018,RT @GeekPwn: Registration for Competition on Adversarial Attacks &amp; DefencesÔºàCAADÔºâis open now! https://t.co/cjVEXGQ6yI
1002251305807593500,Thu May 31 18:11:46 +0000 2018,These amazing students are working hard to make sure that AI is developed safely and responsibly https://t.co/R1edU9X5Da
1001965061806706700,Wed May 30 23:14:21 +0000 2018,Two years of GAN progress on class-conditional ImageNet-128 https://t.co/wkkOs7nRfb
1001867746752086000,Wed May 30 16:47:39 +0000 2018,@zacharylipton For the deep learning book, my co-authors and I chose to offer our own definition: "Regularization i‚Ä¶ https://t.co/4DIMoFPcGJ
1001867463879934000,Wed May 30 16:46:31 +0000 2018,@zacharylipton Yeah, Aaron Courville and I were both surprised by the lack of a good definition when we wrote the D‚Ä¶ https://t.co/TNnxEuJA77
1001828468500250600,Wed May 30 14:11:34 +0000 2018,RT @nikiparmar09: tl;dr Check out our new results on Non Autoregressive MT!! We come very close to a greedy Transformer baseline while bein‚Ä¶
1000241105256857600,Sat May 26 05:03:57 +0000 2018,@koehrsen_will I prefer GANdalf
1000065565208100900,Fri May 25 17:26:25 +0000 2018,Forbes listed GANs as one of the best tech innovations of the last three years: https://t.co/LgjoU2KPIc
999860932355346400,Fri May 25 03:53:17 +0000 2018,@LiamFedus @iamaidang You could build a reviewing layer on top of arxiv and then you could submit anytime
999695882772611100,Thu May 24 16:57:26 +0000 2018,@jhasomesh @IEEESSP Slides with notes: https://t.co/fCcnDo5tib Other formats of slides at https://t.co/Jo1VuFtK0a
999675190484308000,Thu May 24 15:35:13 +0000 2018,I'm speaking at the 1st Deep Learning and Security workshop (co-located with @IEEESSP ) at 1:30 today:‚Ä¶ https://t.co/I9C2eSZ7sk
999360420975599600,Wed May 23 18:44:26 +0000 2018,@anishathalye I also think all the individual examples fit within the old threat model. The only part that‚Äôs proble‚Ä¶ https://t.co/QR48vkZrJr
999359275976687600,Wed May 23 18:39:53 +0000 2018,@anishathalye @sdathath If they replaced the phrase ‚Äúnew kind of attack‚Äù with ‚Äúnew threat model‚Äù would you still ha‚Ä¶ https://t.co/KM7iiWONq0
999358984472559600,Wed May 23 18:38:43 +0000 2018,@anishathalye It‚Äôs also useful to show that a specific formalization of a threat model isn‚Äôt practical or doesn‚Äôt c‚Ä¶ https://t.co/KvfRZyQZVc
999357797266374700,Wed May 23 18:34:00 +0000 2018,@anishathalye I think they‚Äôre pretty clear that it‚Äôs a new set of rules. To show that the new set of rules is inter‚Ä¶ https://t.co/h2EnHVTARC
999123651990573000,Wed May 23 03:03:36 +0000 2018,@roydanroy The intern can build connections between their lab and the internship company that might bring in more f‚Ä¶ https://t.co/DanHiJFY92
999123088515088400,Wed May 23 03:01:21 +0000 2018,@roydanroy The intern can strengthen their international reputation. The first time I got major press coverage was my internship
999122808532680700,Wed May 23 03:00:15 +0000 2018,@roydanroy Their research can have more of a real world benefit. I studied OCR in grad school and it had no practic‚Ä¶ https://t.co/TAvkcomfH1
999119245114990600,Wed May 23 02:46:05 +0000 2018,@poolio @_smileyball Yes, they also ought to cite https://t.co/WlcaKGB0I8 and https://t.co/7nkprklVVo The main thin‚Ä¶ https://t.co/iBrbYeyRcG
999115706577780700,Wed May 23 02:32:01 +0000 2018,@zacharylipton Yeah, I agree with you that learning human preferences is probably not a good safety mechanism. Adve‚Ä¶ https://t.co/6LGeFESRKO
999113218093072400,Wed May 23 02:22:08 +0000 2018,@JoshuaKessler1 @gstsdn Yes :)
999109796392452100,Wed May 23 02:08:32 +0000 2018,@neurokinetikz @gstsdn That's the plan! We're in the process of cleaning it up for release.
999109358876164100,Wed May 23 02:06:48 +0000 2018,Self-attention for GANs. No more problems with losing track of how many faces the generator has drawn on the dog. https://t.co/WOWglD3ft5
999037777474809900,Tue May 22 21:22:22 +0000 2018,@roydanroy @raamana_ @fhuszar At Google the intern goes through "host match" before they have receive an offer, so‚Ä¶ https://t.co/rLHs7wFjGw
999035763596578800,Tue May 22 21:14:21 +0000 2018,This paper shows how to make adversarial examples with GANs. No need for a norm ball constraint. They look unpertur‚Ä¶ https://t.co/WrLsMBzHIR
999002513478058000,Tue May 22 19:02:14 +0000 2018,@roydanroy @fhuszar @theophaneweber I thought Ferenc did a good job of explaining a perception that he had and that I shared.
998616901541482500,Mon May 21 17:29:57 +0000 2018,Interpolating through the latent space of ramen dishes uses a GAN https://t.co/gkBLuDS4ap
998014203079286800,Sun May 20 01:35:02 +0000 2018,@zacharylipton @biggiobattista @ChrSzegedy If you think that board game playing agents make ‚Äúadversarial example‚Äù b‚Ä¶ https://t.co/8UiSPTZQGw
998013763218325500,Sun May 20 01:33:18 +0000 2018,@zacharylipton @biggiobattista @ChrSzegedy Tracing the absolute earliest is hard but I usually start my ‚Äútimeline‚Äù‚Ä¶ https://t.co/uE00ZEs8Jn
997587706753400800,Fri May 18 21:20:18 +0000 2018,GANs can be used to automatically design dental crowns, that are then actually manufactured and used in the physica‚Ä¶ https://t.co/xmAFG0Xswv
997587032435126300,Fri May 18 21:17:37 +0000 2018,RT @GoogleAI: Congratulations to the first set of fellows from the Google Africa PhD Fellowship program! We are committed to advancing cutt‚Ä¶
997514420761718800,Fri May 18 16:29:05 +0000 2018,GANs for generating Mario levels! https://t.co/fIfImwhoQB https://t.co/BeUxvOlaBZ
997345026727276500,Fri May 18 05:15:58 +0000 2018,@WonderMicky My variant of this is ‚Äúit‚Äôs the year 2018, AI is real, and...‚Äù
997268988152328200,Fri May 18 00:13:49 +0000 2018,@m_asgari_c Yes. Also, the story was written in 1904 but set earlier. Also, it's a character who predicts this, not‚Ä¶ https://t.co/PF9LVbIrBi
996895639886676000,Wed May 16 23:30:16 +0000 2018,RT @JeffDean: Nice write-up by Yonghui Wu of the Google Brain team about how the new Smart Compose feature in Gmail works behind-the-scenes‚Ä¶
996855749807562800,Wed May 16 20:51:46 +0000 2018,@DrEigenbastard I was referring to this: https://t.co/xzXP0XEukD  https://t.co/WVddI5eeIY  I don't know the history‚Ä¶ https://t.co/gPAIUuRSPS
996834077725487100,Wed May 16 19:25:39 +0000 2018,RT @woj_zaremba: Moore like law for results in AI: https://t.co/QoOheRQ3SV
996779212231950300,Wed May 16 15:47:38 +0000 2018,@Usunder Yes, some researchers do that. A few examples: https://t.co/AlD3McjQwe https://t.co/0cfrp11AxO https://t.co/YnatzGSfs9
996778160904486900,Wed May 16 15:43:27 +0000 2018,RT @gail_w: couldn't resist  https://t.co/RRLqM61GEN https://t.co/4vBNhtqngo
996559220911718400,Wed May 16 01:13:28 +0000 2018,It is also possible to compute integrals using hyperreal numbers, but I don't personally find as much of an advanta‚Ä¶ https://t.co/vPDiKJ2coE
996559220047675400,Wed May 16 01:13:27 +0000 2018,There are also infinite hyperreals, larger than any real number, but I don't personally find them quite as useful f‚Ä¶ https://t.co/mx5YOfsiS2
996559219041038300,Wed May 16 01:13:27 +0000 2018,Hyperreal numbers formalize some of the intuitions that Newton and Leibniz used without much formal justification i‚Ä¶ https://t.co/XAKiy446gm
996559218302828500,Wed May 16 01:13:27 +0000 2018,It might seem like cheating to just make up infinitesimal hyperreal numbers and say that we can manipulate them wit‚Ä¶ https://t.co/nQXyXoYAPM
996559217497555000,Wed May 16 01:13:27 +0000 2018,This is a lot more "automatic" than setting up a limit as epsilon approaches zero and proving that the limit converges.
996559216746815500,Wed May 16 01:13:27 +0000 2018,For example, let's take the derivative of x^2:  ((x+eps)^2 - x^2) / eps = (x^2 + 2 eps x + eps^2 - x^2) / eps = 2 +‚Ä¶ https://t.co/By40FccEB9
996559215731793900,Wed May 16 01:13:26 +0000 2018,Now we can compute derivatives just by using "plug-and-chug" algebra on the expression f'(x) = real_part(f(x+epsilo‚Ä¶ https://t.co/NlyyXvY24Z
996559214578290700,Wed May 16 01:13:26 +0000 2018,For this trick we introduce a new kind of number, called an infinitesimal hyperreal number. Imagine we have some nu‚Ä¶ https://t.co/IbYdmvJe77
996559213500424200,Wed May 16 01:13:26 +0000 2018,A math trick I like a lot is the approach to taking derivatives using hyperreal numbers. Thread:
996529025131561000,Tue May 15 23:13:28 +0000 2018,@WintermeW Yeah, that's part of what I find interesting about this---being right about the nature of the problem an‚Ä¶ https://t.co/M5YecsBUDi
996527868136968200,Tue May 15 23:08:53 +0000 2018,@KimKLarsen I'm not forgetting civilian deaths, I'm just relying on the word "over" to make sure my sentence is acc‚Ä¶ https://t.co/y0xltQY8HK
996512761554202600,Tue May 15 22:08:51 +0000 2018,A 1904 Sherlock Holmes story predicted that if a great war between European powers came to pass it would result in‚Ä¶ https://t.co/BQzh9dZU8M
996182183134949400,Tue May 15 00:15:15 +0000 2018,Bonus: A great source of related theory hacks is Sec 3.2 of https://t.co/ImqZcggxNj . You can use these properties‚Ä¶ https://t.co/cQgoj2XNzb
996182182266716200,Tue May 15 00:15:15 +0000 2018,My co-authors and I used both theory hack #1 and #2 to derive eq 2 of the GAN paper: https://t.co/SHQPKgPoph
996182180991717400,Tue May 15 00:15:14 +0000 2018,With Theory Hack #2, now optimizing over functions is just a regular calculus problem. Hack #2 is intuitive but not‚Ä¶ https://t.co/sLnyCDxMWo
996182179901202400,Tue May 15 00:15:14 +0000 2018,Theory Hack #2: If you're having trouble thinking about optimizing in the space of all functions, imagine that a fu‚Ä¶ https://t.co/utE5j9cXoW
996182178944892900,Tue May 15 00:15:14 +0000 2018,This is also not too inaccurate of an assumption, especially compared to the linear model assumption. The universal‚Ä¶ https://t.co/POq6hbRPia
996182177933967400,Tue May 15 00:15:14 +0000 2018,The neural-net-as-function metaphor retains the main advantage of the linear model: many interesting problems are c‚Ä¶ https://t.co/OJ9vV1vCcX
996182176935788500,Tue May 15 00:15:13 +0000 2018,Theory Hack #1: Model the neural net as an arbitrary function (so you optimize over the space of all functions f, r‚Ä¶ https://t.co/R6yDIiv4Ci
996182175971131400,Tue May 15 00:15:13 +0000 2018,To get a less complicated model, a common instinct is to use a linear model. This is nice because it makes a lot of‚Ä¶ https://t.co/7OlvWIQZTM
996182174993862700,Tue May 15 00:15:13 +0000 2018,A lot of the time, we want to analyze the optimal behavior of a neural net using algebra / calculus. Neural net mod‚Ä¶ https://t.co/4IDrC21avu
996182173999747100,Tue May 15 00:15:13 +0000 2018,A quick thread on two of my favorite theory hacks for machine learning research
996046703617699800,Mon May 14 15:16:54 +0000 2018,RT @NicolasPapernot: A workshop on Positive and Negative Adversaries in Multimedia (PANAMM 2018) is being organized as a satellite of ACM M‚Ä¶
996046634436849700,Mon May 14 15:16:37 +0000 2018,@biggiobattista I would argue that adversarial ML has existed since at least 1959. (Arthur Samuel's checkers agent)
995353395157352400,Sat May 12 17:21:56 +0000 2018,RT @nikiparmar09: Our paper, Image Transformer got accepted to ICML! üíÉüèªüíÉüèªüíÉüèª https://t.co/HbJfcAJy7J
994998104876183600,Fri May 11 17:50:09 +0000 2018,RT @hamadakoichi: Full-body High-resolution Anime Generation with Progressive Structure-conditional GANs. - Structural conditions on both t‚Ä¶
994997510899843100,Fri May 11 17:47:47 +0000 2018,RT @gstsdn: This paper was accepted to ICML 2018: https://t.co/sV1UuHPjtl
994739819036131300,Fri May 11 00:43:48 +0000 2018,@Jack_Burdick @hevyw8_ The main enhancement I'm aware of is on the attack side. If you find an example that can foo‚Ä¶ https://t.co/IGJPEmTRqK
994739179312431100,Fri May 11 00:41:16 +0000 2018,@Jack_Burdick @hevyw8_ Thanks, but it was @ChrSzegedy who first discovered transfer across architectures: https://t.co/OU25r0oKED
994728327351910400,Thu May 10 23:58:09 +0000 2018,RT @dribnet: @artwithMI  https://t.co/oKBaPCoIxl
994711435870531600,Thu May 10 22:51:01 +0000 2018,RT @snikolov: okay this has probably been done but https://t.co/bdm1cjaOM9
994692849420521500,Thu May 10 21:37:10 +0000 2018,@Miles_Brundage There's no citation to https://t.co/lO2EYq7hil , so presumably no discussion of what is already kno‚Ä¶ https://t.co/0mpOvqB7FQ
994692281767612400,Thu May 10 21:34:55 +0000 2018,@Miles_Brundage There's no citation to Madry et al 2017 / Madry et al 2018, so presumably no benchmark using the st‚Ä¶ https://t.co/z1QQoxPu7K
994692114402312200,Thu May 10 21:34:15 +0000 2018,@Miles_Brundage The abstract proposes replacing a softmax classifier with a generative model using a Gaussian for e‚Ä¶ https://t.co/cCpy7sV9bz
994691979387666400,Thu May 10 21:33:43 +0000 2018,@Miles_Brundage Haven't had time to read in detail, but I see several reasons for skepticism quickly
994668827802722300,Thu May 10 20:01:43 +0000 2018,RT @lucastheis: Thought-provoking paper showing that high perceptual quality is incompatible with low distortion. Counter to intuition, thi‚Ä¶
993694014325968900,Tue May 08 03:28:09 +0000 2018,@catherineols @gdb I'm reminded of this XKCD: https://t.co/XQ8Le9gAHv Now we're at the point where we can tell whet‚Ä¶ https://t.co/PozSQpMjlO
993596199671251000,Mon May 07 20:59:28 +0000 2018,@_dksahuji I don‚Äôt follow this line of work closely. Do you know how many target images were used in ‚Äúaccessorize to a crime‚Äù?
993218672410878000,Sun May 06 19:59:19 +0000 2018,RT @vcheplygina: If you are getting an error while trying to read the How I Fail post by @goodfellow_ian, this URL works https://t.co/LC4up‚Ä¶
992861115360018400,Sat May 05 20:18:31 +0000 2018,@CharlotteHase Oh, to be clear, I don't usually spend a full day coding ideas anymore. But on days when I do write‚Ä¶ https://t.co/HXZNoCKVpV
992830023928238100,Sat May 05 18:14:58 +0000 2018,RT @vcheplygina: How I Fail - Ian Goodfellow (PhD'13, Computer Science) - interview with @goodfellow_ian https://t.co/njmZPKs7uB https://t.‚Ä¶
992472113050075100,Fri May 04 18:32:45 +0000 2018,RT @yasmind: We're hiring! If you are/know someone who enjoys ambiguity, research and technology apply! (And you can maker the world a safe‚Ä¶
992264417671708700,Fri May 04 04:47:27 +0000 2018,RT @NicolasPapernot: I had the great pleasure to talk with @samcharrington about differential privacy with PATE, and how it aligns with ML.‚Ä¶
991785031495442400,Wed May 02 21:02:32 +0000 2018,RT @iamandrewdai: Come see our poster on using gradient penalties for general GANs being presented right now at ICLR. https://t.co/0fRcneOO‚Ä¶
991761119457890300,Wed May 02 19:27:31 +0000 2018,RT @junyanz89: The tutorial will be on Friday, June 22nd. In addition to the organizers, we also have a lineup of awesome speakers who will‚Ä¶
991745459797475300,Wed May 02 18:25:18 +0000 2018,RT @NicolasPapernot: Check out our poster #12 on ensemble adversarial training at #ICLR2018 ! Florian Tramer is presenting our results on p‚Ä¶
991722189752713200,Wed May 02 16:52:50 +0000 2018,RT @annadgoldie: Come visit @Azaliamirh, @JeffDean, and my ICLR poster today from 11am-1pm, Poster #4! https://t.co/OhJGwYChKL
991714743021813800,Wed May 02 16:23:14 +0000 2018,If you will attend #CVPR2018 , check out the tutorial on GANs: https://t.co/b4cRQDApVP (organized by @junyanz89, Ta‚Ä¶ https://t.co/ttYciwVEsc
991673453668266000,Wed May 02 13:39:10 +0000 2018,RT @arimorcos: Thought-provoking work from @julius_adebayo, @goodfellow_ian and others showing that saliency maps don't change much, even w‚Ä¶
991673068140380200,Wed May 02 13:37:38 +0000 2018,RT @codyaustun: The first iteration of DAWNBench is done! We saw a 477x improvement in ImageNet training time and a 23x improvement in cost‚Ä¶
991093175732219900,Mon Apr 30 23:13:21 +0000 2018,@EmmanuelAmeisen @Miles_Brundage I think it‚Äôs fine to call it ‚Äúadversarial training‚Äù. I use that term to describe v‚Ä¶ https://t.co/pmod9MCKjb
990763807373869000,Mon Apr 30 01:24:33 +0000 2018,RT @NicolasPapernot: Privacy and ML: two unexpected allies? Read our new #CleverHans blog post with @goodfellow_ian on how ML researchers c‚Ä¶
990672478547542000,Sun Apr 29 19:21:39 +0000 2018,RT @avitaloliver: Come say hi at ICLR!  We're presenting our work on realistic evaluation of semi-supervised learning algorithms at the wor‚Ä¶
990671540848025600,Sun Apr 29 19:17:55 +0000 2018,RT @colinraffel: I'll (help) present 3 posters @ICLR18: Realistic Evaluation of Semi-Supervised Learning https://t.co/OspDK6mVGZ Mon 4/30 4‚Ä¶
989953744778420200,Fri Apr 27 19:45:39 +0000 2018,RT @SussilloDavid: Google Cloud Platform announces new credits program for researchers  https://t.co/Fge6oWOgSH
989943311434567700,Fri Apr 27 19:04:12 +0000 2018,RT @elaClaudia: Check out our poster at ICLR showcasing our work on GANs on Tuesday. @LiamFedus @balajiln @shakir_za @goodfellow_ian https:‚Ä¶
989876458339188700,Fri Apr 27 14:38:33 +0000 2018,@timnitGebru @zephoria @datasociety Thanks!
989655288813838300,Thu Apr 26 23:59:42 +0000 2018,@Amir_Arsalan_ @samfin55 @AndrewLBeam @zakkohane @NicolasPapernot I don‚Äôt quite understand the threat model. If som‚Ä¶ https://t.co/Sc2pyUgJ7D
989314399084003300,Thu Apr 26 01:25:07 +0000 2018,RT @hardmaru: Using GANs and CMA-ES to procedurally generate Mario levels üéÆ https://t.co/gsfBvgTbdN
989148605696032800,Wed Apr 25 14:26:19 +0000 2018,RT @jennwvaughan: Ok, machine learning people, what are the topics you would be most excited to see covered in a #nips2018 tutorial?
989148298064805900,Wed Apr 25 14:25:06 +0000 2018,RT @dwf: üíØ Pet peeve of mine. You aren't using "only a hundred labeled examples" if you tuned your hyperparameters on very low variance val‚Ä¶
988968386724966400,Wed Apr 25 02:30:12 +0000 2018,@gdb So many traumatic OrderedDict memories from my theano-dev days... since Theano does graph rewriting and codege‚Ä¶ https://t.co/0mckeeZYkk
988937430676914200,Wed Apr 25 00:27:11 +0000 2018,RT @colinraffel: New work on arxiv with @avitaloliver @gstsdn @ekindogus @goodfellow_ian on realistically evaluating deep semi-supervised l‚Ä¶
988842519222878200,Tue Apr 24 18:10:03 +0000 2018,RT @timnitGebru: We need many more women applying to be TAs at Addis Coder this summer: https://t.co/jRN10swJNs 50% of our students will be‚Ä¶
988171065095405600,Sun Apr 22 21:41:55 +0000 2018,@rmpnegrinho @GreeneScientist @adversariel @NipsConference @michaelhoffman @InclusionInML As far as the code of con‚Ä¶ https://t.co/6fwmpbozhQ
988164026529005600,Sun Apr 22 21:13:57 +0000 2018,@rmpnegrinho @GreeneScientist @adversariel @NipsConference @michaelhoffman @InclusionInML I have spent more time ad‚Ä¶ https://t.co/vbw8FTtibx
988105086449602600,Sun Apr 22 17:19:45 +0000 2018,RT @deliprao: Semi supervised learning makes it into Amazon shareholders letter by @JeffBezos https://t.co/9ucDwFUi2h https://t.co/F5eEXnA4‚Ä¶
987764512001413100,Sat Apr 21 18:46:26 +0000 2018,@wielandbr FWIW this contest site does discuss attackers, defenders, safety, etc so it would be more realistic to c‚Ä¶ https://t.co/nMzKbsDemu
987763559286227000,Sat Apr 21 18:42:38 +0000 2018,@wielandbr I agree it‚Äôs a matter of perspective. I‚Äôve tried to scope my tweets with ‚ÄúI personally‚Äù etc. If you can‚Ä¶ https://t.co/LiK40T1s3z
987763027272331300,Sat Apr 21 18:40:32 +0000 2018,@wielandbr @biggiobattista I agree with you that on a lot of datasets all the defenses are so bad that the choice o‚Ä¶ https://t.co/wnv18tPdm5
987762799878201300,Sat Apr 21 18:39:37 +0000 2018,@wielandbr @biggiobattista This is dataset-dependent. On MNIST we are doing well enough that L2 is clearly problema‚Ä¶ https://t.co/1pvShlEM2o
987753644375269400,Sat Apr 21 18:03:15 +0000 2018,@wielandbr The main reason I don‚Äôt like mean perturbation size is that it doesn‚Äôt correspond to any attacker model.‚Ä¶ https://t.co/xz9uaAlKm6
987752992815239200,Sat Apr 21 18:00:39 +0000 2018,@wielandbr Overall it‚Äôs kind of a moot point, because an eps-vs-success rate curve contains the same information as‚Ä¶ https://t.co/tFPvhrDPsy
987752625771757600,Sat Apr 21 17:59:12 +0000 2018,@wielandbr Attack failures like gradient masking can still cause overestimates of the min perturbation size needed‚Ä¶ https://t.co/rDlL7I94Bz
987752385656180700,Sat Apr 21 17:58:14 +0000 2018,@wielandbr I think the right way to fix that is to develop verification methods like reluplex etc and use stronger‚Ä¶ https://t.co/uc95ynq0LK
987751522564882400,Sat Apr 21 17:54:49 +0000 2018,@robotic_hands Yeah, the most straightforward metric is to define a downstream task (not necessarily supervised) an‚Ä¶ https://t.co/9WNDoVZkxd
987748787572494300,Sat Apr 21 17:43:57 +0000 2018,A common theme in ML research the past few years: when we move past supervised learning for labeling the test set,‚Ä¶ https://t.co/wBDRzkVh58
987747939891085300,Sat Apr 21 17:40:34 +0000 2018,I personally agree with this. It‚Äôs the metric I started using in https://t.co/j4Q3KWCxtd. If you want to handle var‚Ä¶ https://t.co/niE0wFZbbB
987747045833244700,Sat Apr 21 17:37:01 +0000 2018,RT @GeekPwn: Four Special Challenges, R U READY??? #DIYrobot #whitehat #hacking #geekpwn https://t.co/bsHe9NvY0n https://t.co/G2aSP2tQgO
987682529036533800,Sat Apr 21 13:20:39 +0000 2018,@GreeneScientist @adversariel @NipsConference @michaelhoffman @InclusionInML Not many people have an opinion on wha‚Ä¶ https://t.co/1kwxKfkMtG
987564920731418600,Sat Apr 21 05:33:19 +0000 2018,RT @2plus2make5: I've been thinking about mental health/quality of life among PhD students recently. If you are or were a PhD student, plea‚Ä¶
987551204929556500,Sat Apr 21 04:38:49 +0000 2018,RT @math_rachel: 1 in 3 heart surgeons refuse difficult operations to avoid poor mortality ratings, survey shows https://t.co/4nbX07f7Gm h/‚Ä¶
987415311518392300,Fri Apr 20 19:38:50 +0000 2018,Blog post about Google talks by @elie and me about ML and security at @RSAConference yesterday: https://t.co/MWaoGVY0qV
987375667355443200,Fri Apr 20 17:01:18 +0000 2018,RT @bethgelab: We are happy to announce the #NIPS2018 #AdversarialVisionChallenge! It's designed to inspire progress towards more robust vi‚Ä¶
987333762982670300,Fri Apr 20 14:14:47 +0000 2018,RT @hindupuravinash: Exactly an year after The GAN Zoo was compiled.. research on GANs is still growing at an explosive pace! Here's a grea‚Ä¶
987120942114418700,Fri Apr 20 00:09:07 +0000 2018,RT @dwf: And to those saying that changing the name of @NipsConference it won't solve our community's gender &amp; diversity problems: of cours‚Ä¶
987078489781055500,Thu Apr 19 21:20:25 +0000 2018,RT @elie: How to successfully harness AI to combat fraud and abuse  https://t.co/ejr5VzNXBS slides &amp; video recording #AI #RSAC2018 @googler‚Ä¶
987047277523955700,Thu Apr 19 19:16:24 +0000 2018,I‚Äôm speaking at @RSAConference at 3PM today about security and privacy of machine learning: https://t.co/0R7wY6ZIYD
986671591709753300,Wed Apr 18 18:23:33 +0000 2018,@sh_reya I too was undecided as a junior and did the coterm
986462055828938800,Wed Apr 18 04:30:56 +0000 2018,RT @alexey2004: We released code of the backend which was used for evaluation of NIPS17 adversarial competition: https://t.co/CaGr4QcGjO
985703997418815500,Mon Apr 16 02:18:41 +0000 2018,RT @liu_mingyu: MUNIT: Multimodal unsupervised image-to-image translation. Learn to translate one input dog image to a distribution of cat‚Ä¶
985332954413989900,Sun Apr 15 01:44:17 +0000 2018,@debraji4 @catherineols How often do you see news labeled as real vs fake though?
985191774112047100,Sat Apr 14 16:23:17 +0000 2018,@rajiinio @catherineols You can think of adversarial training as being like ‚Äúdeliberate practice.‚Äù It works well fo‚Ä¶ https://t.co/4SXcFGd8nk
985145880276680700,Sat Apr 14 13:20:55 +0000 2018,RT @JeffDean: I'm very much looking forward to being one of the speakers at the 2018 Indaba in South Africa in September.  Applications clo‚Ä¶
984853648457875500,Fri Apr 13 17:59:42 +0000 2018,@biggiobattista Stepping aside from vision for the moment, consider Go boards. There are Go board configurations wh‚Ä¶ https://t.co/dyMOL5gh5n
984852761958207500,Fri Apr 13 17:56:10 +0000 2018,@gokstudio @PMinervini The phrase "adversarial examples" comes from https://t.co/OU25r0oKED . Everything there is c‚Ä¶ https://t.co/FAycgYs6zh
984843045513314300,Fri Apr 13 17:17:34 +0000 2018,@Suuraj ...make the mistakes computationally difficult to find, make the mistakes relatively harmless (if person A‚Ä¶ https://t.co/NGRSyvSfZp
984842731334746100,Fri Apr 13 17:16:19 +0000 2018,@Suuraj Many potential routes to defend: make the model stochastic so it doesn't repeat the same test set mistakes,‚Ä¶ https://t.co/XZV8ggTJAU
984842321807069200,Fri Apr 13 17:14:41 +0000 2018,@gokstudio @PMinervini Yes, I intend for "adversarial examples" to include out-of-distribution samples chosen by an adversary.
984841605667471400,Fri Apr 13 17:11:50 +0000 2018,@biggiobattista How do you tell what's an "abstract image" and a "real object" though? People are divided about wha‚Ä¶ https://t.co/THbdszvKdb
984840531464241200,Fri Apr 13 17:07:34 +0000 2018,@biggiobattista Yes and I said there's a reason to do "more". But malware still isn't quite an example of what I wa‚Ä¶ https://t.co/ncvjyQmHDh
984620971133825000,Fri Apr 13 02:35:07 +0000 2018,@dileeplearning There can be philosophical difficulties with labeling images taken by cameras too. But philosophica‚Ä¶ https://t.co/rEcYREek0u
984602865346920400,Fri Apr 13 01:23:10 +0000 2018,@dlowd Yes, but that‚Äôs a different point. I‚Äôm saying it could be interesting to study failures of ML/human percepti‚Ä¶ https://t.co/967NNt60O0
984588996381569000,Fri Apr 13 00:28:04 +0000 2018,@tyrell_turing Yep! And by that definition, you could never make an "adversarial example" for a human. We had to de‚Ä¶ https://t.co/DooW7Wohzs
984588536765493200,Fri Apr 13 00:26:14 +0000 2018,This is one reason to do more work on adversarial examples in domains other than images. For images most points in‚Ä¶ https://t.co/c5DjTPHqNQ
984568651901644800,Thu Apr 12 23:07:13 +0000 2018,@PMinervini One thing we're aiming for with "intentionally designed" is to say that the attacker is trying to cause‚Ä¶ https://t.co/Muye0bgwBO
984518760764592100,Thu Apr 12 19:48:58 +0000 2018,The main downside of this definition: it's not a formal definition
984518760018034700,Thu Apr 12 19:48:58 +0000 2018,It isn't specific to classification; RL agents, generative models, autoencoders etc. all make different kinds of "m‚Ä¶ https://t.co/pmxH7KGOEW
984518759305035800,Thu Apr 12 19:48:58 +0000 2018,It doesn't invoke a human as a source of ground truth
984518758478692400,Thu Apr 12 19:48:58 +0000 2018,It doesn't reference the idea of imperceptibility at all
984518757774082000,Thu Apr 12 19:48:57 +0000 2018,It doesn't imply that the samples are out-of-distribution; "design" can just mean harvesting test set mistakes
984518757153292300,Thu Apr 12 19:48:57 +0000 2018,It isn't specific to making small changes
984518756415057900,Thu Apr 12 19:48:57 +0000 2018,It isn't specific to computer vision at all; you could use it NLP, malware, etc.
984518755546906600,Thu Apr 12 19:48:57 +0000 2018,The definition of "adversarial examples" I prefer these days is "Adversarial examples are inputs to machine learnin‚Ä¶ https://t.co/UW3Hu1Z7m0
984166670666162200,Wed Apr 11 20:29:53 +0000 2018,RT @juliagalef: We're hiring! @open_phil is a small team deciding how to give away billions of $; working here is a very high-leverage way‚Ä¶
983854491026931700,Tue Apr 10 23:49:24 +0000 2018,Extreme image compression with GANs: https://t.co/wwlllT5Fkp (h/t @D_Berthelot_ML )
983853064489611300,Tue Apr 10 23:43:44 +0000 2018,@infosecanon sure, what would you like to know?
983771612792029200,Tue Apr 10 18:20:04 +0000 2018,@vkhosla Is there a link to the full version now?
983411992865079300,Mon Apr 09 18:31:04 +0000 2018,@aijournalyt I was a masters student at Stanford, applying to PhD programs
983411942587908100,Mon Apr 09 18:30:52 +0000 2018,@alekhka grad school
983400463008546800,Mon Apr 09 17:45:15 +0000 2018,@rmarcilhoo I'm based in the Mountain View, California office. I don't know much about Canadian internet law
983395051274252300,Mon Apr 09 17:23:45 +0000 2018,Now that the FCC is no longer providing net neutrality, the state of California can do so. If you support the state‚Ä¶ https://t.co/gL2x97BgdA
982450033298628600,Sat Apr 07 02:48:35 +0000 2018,@tylerwhatsgood_ @YoQuinteroO Yes
982423434029285400,Sat Apr 07 01:02:53 +0000 2018,@jairo_luciano @YoQuinteroO I‚Äôm a maximally biased source but my coauthors and I tried hard to make the DL book sel‚Ä¶ https://t.co/EZBGFZYh5o
982405020632019000,Fri Apr 06 23:49:43 +0000 2018,@YoQuinteroO Back in 2008 I made a resolution to read 10 pages of Chris Bishop's book per day. Payed off well
982010650317566000,Thu Apr 05 21:42:38 +0000 2018,RT @prostheticknowl: @hardmaru @quasimondo @samim TempoGAN: volumetric GAN for Super Resolution Fluid Flow https://t.co/7IAKjR3cQW
981992581222420500,Thu Apr 05 20:30:50 +0000 2018,RT @gstsdn: This AMA is happening now! Feel free to ask questions about this paper or about how it relates to GAN training. I‚Äôll be answeri‚Ä¶
981965078315515900,Thu Apr 05 18:41:33 +0000 2018,RT @gdb: Reinforcement learning today lets you solve a particular environment, without learning skills that transfer to new environments. W‚Ä¶
981631364465242100,Wed Apr 04 20:35:29 +0000 2018,RT @NicolasPapernot: The code for the privacy analysis of PATE(-G) is now available on GitHub, this includes the aggregation mechanisms int‚Ä¶
981584439967760400,Wed Apr 04 17:29:02 +0000 2018,@zacharylipton @intel https://t.co/UGxnT9aiH1
981316342845493200,Tue Apr 03 23:43:42 +0000 2018,@chrisbenson @PracticalAIFM @dwhitena Thanks for inviting me! I'm sorry, but I'm trying to focus on writing code, r‚Ä¶ https://t.co/izvfi7K2py
981303446102921200,Tue Apr 03 22:52:27 +0000 2018,RT @fermatslibrary: This Thursday we are doing an AMA with Augustus Odena (@gstsdn) from Google Brain about local geometry of GAN generator‚Ä¶
981191682824663000,Tue Apr 03 15:28:21 +0000 2018,RT @alexey2004: Just released on arxiv a book chapter about "Adversarial attacks and defenses competition" which was part of NIPS17 competi‚Ä¶
981035132604706800,Tue Apr 03 05:06:17 +0000 2018,@zacharylipton Jon Shlens likes the panda pic and uses it as a sort of reference image for a lot of work, so it was‚Ä¶ https://t.co/5DFftA0ZqY
980973461257388000,Tue Apr 03 01:01:13 +0000 2018,RT @gstsdn: On Thursday I will do an AMA about this paper at https://t.co/mthvWpCsbp https://t.co/sV1UuHPjtl
980598707782533100,Mon Apr 02 00:12:05 +0000 2018,RT @karol_kurach: MemGEN paper released - generative modeling finally solved with @sylvain_gelly.  GANs are cool @goodfellow_ian but #DeepM‚Ä¶
980589669694844900,Sun Apr 01 23:36:10 +0000 2018,https://t.co/y86hIQ6arn
980556808879140900,Sun Apr 01 21:25:35 +0000 2018,RT @DeepMindAI: By learning to write programs that generate images our artificial agents can reason about how digits, characters and portra‚Ä¶
980519521306927100,Sun Apr 01 18:57:25 +0000 2018,@alterego I don‚Äôt think the present connotation was intended, just that it exists
980481631298371600,Sun Apr 01 16:26:52 +0000 2018,@SnShines Just used Bing for the screenshot. Trying to keep this about my own personal opinion and not involve my employer
980470009301356500,Sun Apr 01 15:40:41 +0000 2018,RT @NatureNews: PhD and master‚Äôs students worldwide report rates of depression and anxiety that are six times higher than those in the gene‚Ä¶
980453953652498400,Sun Apr 01 14:36:53 +0000 2018,Someone e-mailed me to say "The link between nipples and NIPS happened in your mind and was purely vindictive." Sea‚Ä¶ https://t.co/aJIWYpaIGY
980429908164804600,Sun Apr 01 13:01:20 +0000 2018,@cesncn Usually to normalize the input, you just normalize the whole dataset as a preprocessing step before the lea‚Ä¶ https://t.co/pyYMTbd6RK
980266187031330800,Sun Apr 01 02:10:46 +0000 2018,@cesncn Do you mean for ‚Äúbatch normalization‚Äù? If so, then yes, each minibatch is normalized with its own mean. The‚Ä¶ https://t.co/DWTcC8yLf2
980109824753942500,Sat Mar 31 15:49:26 +0000 2018,@BioNLProc @docmilanfar I think it's an empirical question as to how citation counts are actually distributed in di‚Ä¶ https://t.co/r3cGT6VFAi
979960485905817600,Sat Mar 31 05:56:01 +0000 2018,@docmilanfar Super interesting! I wonder if anyone has done the analysis for a wider / more diverse pool of researc‚Ä¶ https://t.co/Ln3flOY2DI
979944514268758000,Sat Mar 31 04:52:33 +0000 2018,RT @JeffDean: @KLdivergence Thank you for speaking out against behavior that has no place in our field (or any field!) and I'm hopeful that‚Ä¶
979944501711024100,Sat Mar 31 04:52:30 +0000 2018,RT @KLdivergence: Seeing my essay cited as a reason that prominent people in statistics and ML are taking a stand for a more inclusive conf‚Ä¶
979943131654242300,Sat Mar 31 04:47:03 +0000 2018,@OhmPye Is there anyone who objects to the names ICML, ICLR, UAI, or AISTATS?
979815527949385700,Fri Mar 30 20:20:00 +0000 2018,@docmilanfar (Also: I definitely feel quite vulnerable. I'm saying other people perceive me as invulnerable)
979814545924354000,Fri Mar 30 20:16:06 +0000 2018,@zacharylipton Systems for Processing Information Neurally (SPIN) would be a more accurate way of describing the wr‚Ä¶ https://t.co/FZCd81sc1M
979789090424942600,Fri Mar 30 18:34:57 +0000 2018,@docmilanfar I'm not saying it to brag. I'm saying it to point out how real the stress of the environment is. Other‚Ä¶ https://t.co/NESn7tqTP9
979788354400108500,Fri Mar 30 18:32:01 +0000 2018,@SussilloDavid Part of my reason for wanting the name change is also this: https://t.co/bHFCHk4TJP I think the term‚Ä¶ https://t.co/F4pzDpDPcQ
979788306673057800,Fri Mar 30 18:31:50 +0000 2018,@pfau @SussilloDavid Part of my reason for wanting the name change is also this: https://t.co/bHFCHk4TJP I think th‚Ä¶ https://t.co/Vrz03loIED
979756227654594600,Fri Mar 30 16:24:22 +0000 2018,NIPS has been, on at least one occasion, a very stressful environment for me, and when I tried to get help via the‚Ä¶ https://t.co/3TvRq0gBES
979755312176545800,Fri Mar 30 16:20:44 +0000 2018,I personally would also very much like to see NIPS 1) create and enforce a stronger code of conduct, and 2) change‚Ä¶ https://t.co/rtFqO0VFtd
979129084616753200,Wed Mar 28 22:52:19 +0000 2018,@ebozarik Thank you for inviting me! I'm sorry, but I won't be able to make it. With my current work / family situa‚Ä¶ https://t.co/c1SsHShE6A
979101376104902700,Wed Mar 28 21:02:13 +0000 2018,@elneurozorro @pietrovischia sometimes in ML running the experiment isn't intellectually complex but usually the pe‚Ä¶ https://t.co/dqaMAwLdqj
979035325035987000,Wed Mar 28 16:39:45 +0000 2018,@zacharylipton I never thought I‚Äôd live long enough to unironically prefer vintage computers yet here I am dreading‚Ä¶ https://t.co/J6NVqFlgNe
978970364351995900,Wed Mar 28 12:21:37 +0000 2018,In the first paper about adversarial examples, we focused on imperceptible perturbations. Since 2014, we've worked‚Ä¶ https://t.co/ob8sA4VRbs
978761740405039100,Tue Mar 27 22:32:38 +0000 2018,Answering AMA questions now https://t.co/U8NvC824hX
978652023523393500,Tue Mar 27 15:16:39 +0000 2018,@Carvalho96v2 @dwf If they do they haven't mentioned it. But keep in mind that we have written proof that we were w‚Ä¶ https://t.co/Pv0Gjk5d7q
978651617145765900,Tue Mar 27 15:15:02 +0000 2018,RT @OriolVinyalsML: RL + GANs: Program synthesis with an agent that uses a paint program to fool a discriminator. Paper+Blog: https://t.co/‚Ä¶
978646489512665100,Tue Mar 27 14:54:40 +0000 2018,@roydanroy @dwf It‚Äôs clearly a case of cluelessness but I know of at least 4 students of this PI making similar req‚Ä¶ https://t.co/deHycBt4pv
978645954055127000,Tue Mar 27 14:52:32 +0000 2018,@roydanroy @dwf It‚Äôs not an intern, it‚Äôs a Brain Resident. Brain Residents are not students. The resident has no as‚Ä¶ https://t.co/gziioxKNcw
978631706981818400,Tue Mar 27 13:55:55 +0000 2018,Hadrien Jean has made a series of notes on linear algebra, following the deep learning textbook: https://t.co/U3Ni2fsvpJ
978617284750028800,Tue Mar 27 12:58:37 +0000 2018,@pietrovischia Yeah. I also started off my career in neuroscience, where undergrad interns who run the experiments‚Ä¶ https://t.co/yllcWOTach
978616943086219300,Tue Mar 27 12:57:15 +0000 2018,@visarga They wanted us to cite a paper they wrote describing a different idea.
978616879534125000,Tue Mar 27 12:57:00 +0000 2018,@de3ug They wanted us to cite a paper they wrote describing a different idea.
978615184573964300,Tue Mar 27 12:50:16 +0000 2018,@togelius I'm not complaining about people asking to be cited when someone reinvents their idea. I'm complaining ab‚Ä¶ https://t.co/UOdFrm1Hct
978614648671952900,Tue Mar 27 12:48:08 +0000 2018,@togelius Recently I find that unjustified citation requests come from the most ahistorical people. One person want‚Ä¶ https://t.co/WpaoAH1zrO
978613944414715900,Tue Mar 27 12:45:20 +0000 2018,@dwf @roydanroy Checked with @dwf privately. Not the same student, but same PI. And this Brain resident actually go‚Ä¶ https://t.co/hUfkpcdWBv
978613514632798200,Tue Mar 27 12:43:38 +0000 2018,@roydanroy This Brain Resident actually got two similar requests from two students of the same PI (asking for citat‚Ä¶ https://t.co/FGggpaL4W1
978474675452878800,Tue Mar 27 03:31:56 +0000 2018,I'm frustrated with how much conflict / unjustified demand for credit there is in deep learning today. Someone wrot‚Ä¶ https://t.co/EN4U0Snf8J
978342155985993700,Mon Mar 26 18:45:21 +0000 2018,That's about it for today's brain-dump. Feel free to reply with your own advice for GAN paper reviewers.
978342155377770500,Mon Mar 26 18:45:21 +0000 2018,Mode collapse can also be very subtle repetition of textures or backgrounds in images that otherwise might look diverse to the human eye.
978342154677379100,Mon Mar 26 18:45:21 +0000 2018,For example, mode collapse is often to weird garbage points that don't resemble data. These points tend to move around during training.
978342153909715000,Mon Mar 26 18:45:20 +0000 2018,If you review a paper about mode collapse and the authors think mode collapse means memorizing a subset of the trai‚Ä¶ https://t.co/s1Mxmi1Zan
978342153100259300,Mon Mar 26 18:45:20 +0000 2018,Even I would be a frustratingly ignorant reviewer of a lot of GAN sub-topics.
978342152383086600,Mon Mar 26 18:45:20 +0000 2018,If you're an area chair, I highly suggest micro-targeting reviewer-paper matches. I don't think there is such a thi‚Ä¶ https://t.co/CjZyAeunxU
978342151623917600,Mon Mar 26 18:45:20 +0000 2018,Another thing to keep in mind is that it's possible to write a bad paper about a good method. Sometimes we see a pa‚Ä¶ https://t.co/8hgtaZzMok
978342150906691600,Mon Mar 26 18:45:20 +0000 2018,When explaining how hyperparameters were optimized, it's important to be clear about if they were chosen to optimiz‚Ä¶ https://t.co/g9HXuDJqLQ
978342150055198700,Mon Mar 26 18:45:19 +0000 2018,Even papers without evidence of cherry-picking often show a single learning curve of the new method and a single le‚Ä¶ https://t.co/v8tNedevvF
978342149132492800,Mon Mar 26 18:45:19 +0000 2018,A lot of papers that look like they show an improvement are just cherry-picking good runs of the new method and bad runs of the old method.
978342148402593800,Mon Mar 26 18:45:19 +0000 2018,Many DL algorithms, but especially GANs and RL, get very different results each time you run them. Papers should sh‚Ä¶ https://t.co/Ah94qj8EsV
978342147819683800,Mon Mar 26 18:45:19 +0000 2018,2nd thread on evaluating GAN papers (1st thread hit max thread length)
978340127754747900,Mon Mar 26 18:37:17 +0000 2018,RT @colinraffel: New short blog post where I try to write down the criteria I use when deciding whether a paper I'm reviewing should get ac‚Ä¶
978339499284447200,Mon Mar 26 18:34:47 +0000 2018,Achievement unlocked: max twitter thread length. I will continue in another thread
978339498575593500,Mon Mar 26 18:34:47 +0000 2018,It is extremely important to explain where all hyperparameters came from. Often new methods just seem like improvem‚Ä¶ https://t.co/KaG1CTqxum
978339497657053200,Mon Mar 26 18:34:47 +0000 2018,Sometimes if a paper studies a new task or a rarely evaluated aspect of a previously studied task, it is necessary‚Ä¶ https://t.co/JexQzCkPqa
978339496621035500,Mon Mar 26 18:34:47 +0000 2018,Of course other fields have trouble with sandbagging the baseline too: https://t.co/1UAuXYQT3H But I feel like it's‚Ä¶ https://t.co/HfdXhMzMHS
978339495811604500,Mon Mar 26 18:34:47 +0000 2018,Reviewers should check whether other papers have implemented models that perform the same task and check their scor‚Ä¶ https://t.co/WPQQXKe5Hq
978339495031357400,Mon Mar 26 18:34:46 +0000 2018,Usually, at least one of the baselines should be a result published in another paper, where the authors of that oth‚Ä¶ https://t.co/zZ4rzNkcTs
978339494020579300,Mon Mar 26 18:34:46 +0000 2018,Reviewers should be very suspicious of anyone who has implemented their own baseline. There are a lot of subtle way‚Ä¶ https://t.co/gwr5eKtcPJ
978339493387186200,Mon Mar 26 18:34:46 +0000 2018,Because of this, I don't generally regard CelebA, CIFAR-10 samples, etc. as anything more than a sanity check that the method isn't broken.
978339492149915600,Mon Mar 26 18:34:46 +0000 2018,I also don't really know how to rank images with one kind of minor defect against other images with a qualitatively‚Ä¶ https://t.co/Mwh0zK4m6a
978339491466248200,Mon Mar 26 18:34:46 +0000 2018,Many papers show samples from datasets like CIFAR-10 or CelebA and ask the reviewer to be impressed by them. For th‚Ä¶ https://t.co/UjEZZUSAvq
978339490816143400,Mon Mar 26 18:34:45 +0000 2018,(It's still possible that the improvement comes from factors other than the proposed method, like a new, bigger architecture, etc.)
978339489767505900,Mon Mar 26 18:34:45 +0000 2018,For example, generating ImageNet samples with a single GANs was very hard, with many papers showing basically faile‚Ä¶ https://t.co/FeY2oVFZnm
978339488697995300,Mon Mar 26 18:34:45 +0000 2018,The main way I know to use samples to make a case that there is an improvement is to generate samples from a domain‚Ä¶ https://t.co/wwfno2f01a
978339487959756800,Mon Mar 26 18:34:45 +0000 2018,A lot of papers encourage the reader to form their opinion of the method mostly by looking at the samples. This is usually a bad sign.
978339487255183400,Mon Mar 26 18:34:45 +0000 2018,Some papers that focus on special cases might be able to *include* other metrics (e.g. GANs with a Real NVP generat‚Ä¶ https://t.co/dmyPvSERPx
978339486470848500,Mon Mar 26 18:34:44 +0000 2018,As far as metrics go, Fr√®chet Inception Distance (or the intra-class version of it) is probably the best metric ava‚Ä¶ https://t.co/q9W9XQGzmD
978339485741072400,Mon Mar 26 18:34:44 +0000 2018,If a proposed method isn't really new, the paper might still be worthwhile, but reviewers should make sure the pape‚Ä¶ https://t.co/i7eQMAbHVv
978339484965118000,Mon Mar 26 18:34:44 +0000 2018,One good resource for keeping up with many GAN variants is the GAN zoo: https://t.co/ILjuNWzDcM
978339484126212100,Mon Mar 26 18:34:44 +0000 2018,One difficulty with GAN papers is assessing novelty. There are so many proposed GAN improvements that it's hard to‚Ä¶ https://t.co/WMCFhL6YJS
978339483257983000,Mon Mar 26 18:34:44 +0000 2018,Another good paper to read for background is "A note on the evaluation of generative models" (‚Ä¶ https://t.co/cJLfL7FpJg
978339481697730600,Mon Mar 26 18:34:43 +0000 2018,My #1 recommendation is that reviewers of GAN papers should read "Are GANs Created Equal?" (‚Ä¶ https://t.co/MFVj6sKABg
978339481035014100,Mon Mar 26 18:34:43 +0000 2018,This thread is about new methods that are meant to generically make GANs train more reliably or produce better samples, etc.
978339480242290700,Mon Mar 26 18:34:43 +0000 2018,There are also a lot of papers about GANs as part of a larger system, like GANs for semi-supervised learning, diffe‚Ä¶ https://t.co/c1ZRGo6MTn
978339479290224600,Mon Mar 26 18:34:43 +0000 2018,There are a lot of papers about theoretical or empirical studies of how GANs work, papers about how to do new stran‚Ä¶ https://t.co/EvNv8iQTYq
978339478560415700,Mon Mar 26 18:34:43 +0000 2018,Thread on how to review papers about generic improvements to GANs
978328288329269200,Mon Mar 26 17:50:15 +0000 2018,11/11) If I'm your area chair, you'll almost certainly get one reviewer who is an absolute expert on the topic of y‚Ä¶ https://t.co/l5g58FDGzc
978328287494602800,Mon Mar 26 17:50:14 +0000 2018,10/11) Automatic reviewer assignment systems often have to ignore a lot of bids to make sure every paper gets revie‚Ä¶ https://t.co/PP1wWMbW1J
978328286538358800,Mon Mar 26 17:50:14 +0000 2018,9/11) Another thing to keep in mind is that bids don't necessarily have as much of an effect as you might expect. A‚Ä¶ https://t.co/SwyX3OU9aJ
978328285711970300,Mon Mar 26 17:50:14 +0000 2018,8/11) There are also reviewers who bid following negative, selfish strategies. For example, a reviewer who has a pe‚Ä¶ https://t.co/8wT4vMvFRQ
978328284395012100,Mon Mar 26 17:50:14 +0000 2018,7/11) Other goals reviewers may have include: learn about exciting work earlier than the general public does (less‚Ä¶ https://t.co/rrXwdANAva
978328283635900400,Mon Mar 26 17:50:13 +0000 2018,6/11) Senior reviewers who are very busy may even bid *only* on papers that are clearly low quality, to minimize their reviewing workload
978328282734116900,Mon Mar 26 17:50:13 +0000 2018,5/11) I tend to have two goals: 1) Keep the quality of the literature high 2) Reduce the amount of work I need to d‚Ä¶ https://t.co/8Ghw4B0EUJ
978328281777823700,Mon Mar 26 17:50:13 +0000 2018,4/11) Reviewers can bid with many different goals in mind. You should think clearly about what your own goals are,‚Ä¶ https://t.co/jjAEVDQLcy
978328280884379600,Mon Mar 26 17:50:13 +0000 2018,3/11) Since I'm a senior reviewer, I thought people might be interested to know that I don't bid to review clearly good papers
978328280146182100,Mon Mar 26 17:50:13 +0000 2018,2/11) Lately I've seen a lot of people saying things like "clearly good papers get all the senior reviewers" or "re‚Ä¶ https://t.co/K7dMGuaZOd
978328279437344800,Mon Mar 26 17:50:12 +0000 2018,1/11) Thread on bidding to review conference papers
977318822649634800,Fri Mar 23 22:58:59 +0000 2018,@KnudJahnke Using technology to save lives and improve quality of life? I think it‚Äôs one of the best and most meani‚Ä¶ https://t.co/WIyeR0SgDl
977293449480163300,Fri Mar 23 21:18:10 +0000 2018,@KnudJahnke Think of it as just another hypothesis generation tool. Any proposal will still be rigorously tested be‚Ä¶ https://t.co/gAglOqaFpO
977292570341462000,Fri Mar 23 21:14:40 +0000 2018,@MelMitchell1 In principle, yes. @InSilicoMeds and presumably others are already working on it
977288227550720000,Fri Mar 23 20:57:25 +0000 2018,GANs for designing DNA: https://t.co/CQewsUzX5x
976954444427378700,Thu Mar 22 22:51:05 +0000 2018,RT @catherineols: I'm co-organizing an ICML workshop to host debates on the future of AI: https://t.co/ep0YX5guaP  Notably, the focus is *n‚Ä¶
976953645601144800,Thu Mar 22 22:47:54 +0000 2018,@hardmaru @schmidhubered McCulloch and Pitts (1943) https://t.co/NONDtY9sLU
976952926718455800,Thu Mar 22 22:45:03 +0000 2018,@hardmaru @schmidhubered I'm not sure if this is hand-drawn, but here is a diagram of the Neocognitron (1980) that‚Ä¶ https://t.co/1jSVL63i0S
976505730164379600,Wed Mar 21 17:08:03 +0000 2018,.@harinidkannan , @alexey2004 and I will do an AMA on Adversarial Logit Pairing, the state of the art defense again‚Ä¶ https://t.co/2fCZyfZINO
976131309243326500,Tue Mar 20 16:20:14 +0000 2018,Check out Adversarial Logit Pairing, the new state of the art defense against adversarial examples on ImageNet, by‚Ä¶ https://t.co/L2s5272ZEb
975870146496495600,Mon Mar 19 23:02:28 +0000 2018,RT @yonatanzunger: Think about this problem like SRE's, like safety engineers. Scope your failure modes out to things involving bad actors‚Ä¶
974422787912736800,Thu Mar 15 23:11:11 +0000 2018,RT @twimlai: Today we're joined by @goodfellow_ian of @GoogleBrain @googleresearch and Sandy Huang, PhD Student at @UCBerkeley, to discuss‚Ä¶
974319095796580400,Thu Mar 15 16:19:09 +0000 2018,I'm doing an AMA with @fermatslibrary today: https://t.co/RWYk0q56rx
974051530859950100,Wed Mar 14 22:35:56 +0000 2018,@Smerity The title got my hopes up that this would be a news outlet covering regular news but with a good understan‚Ä¶ https://t.co/ayaIcYifWE
974011136461844500,Wed Mar 14 19:55:25 +0000 2018,@RomualdGade I'll follow up by DM
973377113477726200,Tue Mar 13 01:56:02 +0000 2018,@davidmanheim @ExpectAPatronum @OsondeOsoba I think it‚Äôs the opposite problem. People often talk about ‚Äúinterpretab‚Ä¶ https://t.co/m15OHPrqLX
973331367462236200,Mon Mar 12 22:54:16 +0000 2018,RT @social_brains: Best illusion I've seen, maybe ever.  The blue and black lines are NOT moving.  Insanely good. https://t.co/gHGx5u3vTO
973271637909938200,Mon Mar 12 18:56:55 +0000 2018,@ibibby https://t.co/JNSK5MLLS3
973268016640045000,Mon Mar 12 18:42:32 +0000 2018,RT @fermatslibrary: We are doing an AMA (Ask Me Anything) about the GANs (Generative Adversarial Nets) paper with @goodfellow_ian on 3/15 (‚Ä¶
971588487689351200,Thu Mar 08 03:28:41 +0000 2018,@seth_stafford Augustus Odena has used that metric to detect when the images from a generative model are too simila‚Ä¶ https://t.co/45sDBWGG5c
971588276371972100,Thu Mar 08 03:27:50 +0000 2018,@seth_stafford That lets you measure similarity between two specific images, for example a raw image and lossily co‚Ä¶ https://t.co/dW4vEEs60T
971436545575043100,Wed Mar 07 17:24:55 +0000 2018,Debate over the cat-dog during Blake Richards' talk at #cosyne (sent by @thisismyhat to all cat-dog co-authors) las‚Ä¶ https://t.co/a9Th6vS6Fs
971435790789091300,Wed Mar 07 17:21:55 +0000 2018,@L_badikho @poolio You could write to the program chairs and see
971130004724531200,Tue Mar 06 21:06:50 +0000 2018,RT @black_in_ai: "We‚Äôre providing 6-10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time‚Ä¶
971022783533629400,Tue Mar 06 14:00:46 +0000 2018,RT @JeffDean: Totally agree with @etzioni that this a huge disaster in the making, and it is due to our current government's absurd immigra‚Ä¶
970057322650206200,Sat Mar 03 22:04:23 +0000 2018,@rhyolight Bayesian priors don‚Äôt need to be *informative*. A Gaussian distribution doesn‚Äôt know how to crawl. In my‚Ä¶ https://t.co/aYarjKuJlK
970055879960571900,Sat Mar 03 21:58:39 +0000 2018,@pacmansyyu I hope so
970007438396018700,Sat Mar 03 18:46:09 +0000 2018,@jackclarkSF Ants have about 250,000 neurons, which is about the same as just the ‚Äúretina‚Äù of a modern ImageNet cla‚Ä¶ https://t.co/7xoIbyNpau
969779405936455700,Sat Mar 03 03:40:02 +0000 2018,@jigarkdoshi I hope video + audio, imagination for RL and planning, automated design
969776035649675300,Sat Mar 03 03:26:39 +0000 2018,4 years of GAN progress (source: https://t.co/hlxW3NnTJP ) https://t.co/kmK5zikayV
969353358891888600,Thu Mar 01 23:27:05 +0000 2018,@nazaroff24 I also learned a lot from this book but it‚Äôs not as specific to the ideas within linear algebra that ar‚Ä¶ https://t.co/AtoHTQBlXI
969306960263749600,Thu Mar 01 20:22:42 +0000 2018,@nazaroff24 I learned a lot of linear algebra from my friend Zico Kolter‚Äôs lecture notes when I took Andrew Ng‚Äôs ma‚Ä¶ https://t.co/JJmDQmbjrg
969306376802418700,Thu Mar 01 20:20:23 +0000 2018,@nazaroff24 What would you like to learn more about? Linear algebra in general or a specific topic?
969255912908058600,Thu Mar 01 16:59:52 +0000 2018,@AlejandroMllo Very welcome!
969255395150540800,Thu Mar 01 16:57:48 +0000 2018,Yoshua, Aaron, and I have released the LaTeX template for the Deep Learning book: https://t.co/ldgr4N9Ni6 Useful if‚Ä¶ https://t.co/EIIYR2zmRH
969219989357105200,Thu Mar 01 14:37:07 +0000 2018,Adversarial examples for humans in IEEE Spectrum: https://t.co/4bUItJbQEk
969219921510101000,Thu Mar 01 14:36:51 +0000 2018,Some press coverage of adversarial examples for humans: https://t.co/dZCR5nhQkH
968316108183711700,Tue Feb 27 02:45:25 +0000 2018,RT @gstsdn: Preprint on local geometry of GAN generators w/ Jacob Buckman, @catherineols, @nottombrown, @ch402, @colinraffel, @goodfellow_i‚Ä¶
968250128774475800,Mon Feb 26 22:23:14 +0000 2018,@timnitGebru OK, there's a list of 10 papers off the top of my head that I think should catch you up fairly well. I‚Ä¶ https://t.co/oyyOuBDf9k
968249713924255700,Mon Feb 26 22:21:35 +0000 2018,@timnitGebru 10. You should be a little bit aware of the "theory of GAN convergence" space, one of my favorites is https://t.co/JpCKaHy9im
968249489139023900,Mon Feb 26 22:20:42 +0000 2018,@timnitGebru 9. You should be a little bit aware of the "GANs with encoders" space, one of my favorites is https://t.co/2uWTwu6kes
968249282670116900,Mon Feb 26 22:19:52 +0000 2018,@timnitGebru 8. Making all ML algorithms differentially private by training them on fake private data generated by‚Ä¶ https://t.co/WdnTz9TVfS
968249056932724700,Mon Feb 26 22:18:59 +0000 2018,@timnitGebru 7. StackGAN++: https://t.co/ccOlTNW43F High quality text-to-image synthesis with GANs
968248855065083900,Mon Feb 26 22:18:10 +0000 2018,@timnitGebru 6. WGAN-GP https://t.co/zJ6ZDSdz7w : probably the most popular GAN variant today and seems to be prett‚Ä¶ https://t.co/KuCSViAz04
968247248709607400,Mon Feb 26 22:11:47 +0000 2018,@timnitGebru 5. Are GANs created equal? https://t.co/4dIIOjPBC3 A big empirical study showing the importance of goo‚Ä¶ https://t.co/SLPXnrpL8v
968246916860452900,Mon Feb 26 22:10:28 +0000 2018,@timnitGebru 4. pix2pixHD (GANs for 2-megapixel video) https://t.co/98VGmrYniL
968246567244197900,Mon Feb 26 22:09:05 +0000 2018,@timnitGebru 3. Projection discriminator: https://t.co/qG1xwu1PuX (from the same lab as #2, both techniques work we‚Ä¶ https://t.co/tOjpxnnvhA
968246240642179100,Mon Feb 26 22:07:47 +0000 2018,@timnitGebru 2. Spectral normalization: https://t.co/tt2os9H1Py (got GANs working on lots of classes, which has been hard)
968246086077898800,Mon Feb 26 22:07:10 +0000 2018,@timnitGebru 1. Progressive GANs: https://t.co/UEFhewds2M (probably the highest quality images so far)
968245962081579000,Mon Feb 26 22:06:41 +0000 2018,@timnitGebru I'll reply a bunch in no particular order
968241484485939200,Mon Feb 26 21:48:53 +0000 2018,And the paper on real-world adversarial masks: https://t.co/jysLnRifUn https://t.co/hPXtTKDhdI
968199161832067100,Mon Feb 26 19:00:43 +0000 2018,@danoramas Thanks! I'm not sure if the photographer had that in mind ahead of time. The Building 43 lobby is actual‚Ä¶ https://t.co/wvRhk7q272
968198687590531100,Mon Feb 26 18:58:50 +0000 2018,@MaverickPramit @ChristophMolnar @ylecun @ChrSzegedy Yeah, adversarial examples could be at least one bridge
968198401320894500,Mon Feb 26 18:57:41 +0000 2018,@srchvrs @nsaphra @zacharylipton Empirical sciences are not necessarily easier to review than theoretical sciences.‚Ä¶ https://t.co/1Cy2kb9rEz
968198104926187500,Mon Feb 26 18:56:31 +0000 2018,@srchvrs @nsaphra @zacharylipton As someone who has been in the field since before it was hot, the average quality‚Ä¶ https://t.co/RKQM9a4lG3
968002536614461400,Mon Feb 26 05:59:24 +0000 2018,@pfau @GreeneScientist The idea about differential privacy isn‚Äôt specific to GANs. It could work with other generat‚Ä¶ https://t.co/U1k10QfgHW
967973589268906000,Mon Feb 26 04:04:22 +0000 2018,@pfau @GreeneScientist It‚Äôs a way to make all machine learning algorithms differentially private without having to‚Ä¶ https://t.co/wkPGL7nUb3
967943175154249700,Mon Feb 26 02:03:31 +0000 2018,@DamonCrockett @ChristophMolnar @zacharylipton Ironically, the interpretability literature is not very interpretabl‚Ä¶ https://t.co/Gh0xvnrWPY
967941733529997300,Mon Feb 26 01:57:47 +0000 2018,@ChristophMolnar @ylecun When @ChrSzegedy discovered adversarial examples, he was basically working on interpretabi‚Ä¶ https://t.co/ks2fVyxS2D
967940220023787500,Mon Feb 26 01:51:46 +0000 2018,@ChristophMolnar I don‚Äôt think this is a hypothetical (‚Äúmight‚Äù). I think this happens with most interpretability papers today
967938401059061800,Mon Feb 26 01:44:32 +0000 2018,@ChristophMolnar To say one model is ‚Äúmore interpretable‚Äù than another you‚Äôd need a definition of interpretability.‚Ä¶ https://t.co/qxEWeWLQrt
967937820961652700,Mon Feb 26 01:42:14 +0000 2018,@ChristophMolnar @ylecun In particular interpretability people tend to have findings like ‚ÄúI asked my tool why this‚Ä¶ https://t.co/I9l33zEfZo
967937143229243400,Mon Feb 26 01:39:33 +0000 2018,@ChristophMolnar @ylecun People who wear the ‚ÄúML security‚Äù hat and people who wear the ‚ÄúML interpretability‚Äù hat bo‚Ä¶ https://t.co/txwCyjV0l4
967936525559251000,Mon Feb 26 01:37:05 +0000 2018,@ChristophMolnar @ylecun I‚Äôm not actually opposed to studying interpretability in general. I am worried that the in‚Ä¶ https://t.co/4dAQdg0H0m
967575840228692000,Sun Feb 25 01:43:51 +0000 2018,@yablak @martin_wicke Maybe it‚Äôs possible to make trustable digital evidence using a camera that cryptographically‚Ä¶ https://t.co/iitk8cVsBp
967574466279620600,Sun Feb 25 01:38:24 +0000 2018,@yablak @martin_wicke Unfortunately the game theoretic analysis in the original GAN paper says the arms race ends w‚Ä¶ https://t.co/O3iMCU1nOk
967493313426174000,Sat Feb 24 20:15:55 +0000 2018,@DesolusDev @catherineols Yes, and viewing distance. Try sliding back away from your monitor, it‚Äôs interesting
967247074793111600,Sat Feb 24 03:57:27 +0000 2018,@nikolayid @catherineols The URL has a link to a gif version
967235388476612600,Sat Feb 24 03:11:01 +0000 2018,@jwphillips91 @dileeplearning @nikolayid Read the paper, we have several controls to address those specific objections
967220012527202300,Sat Feb 24 02:09:55 +0000 2018,@iandanforth @catherineols I‚Äôd assume that compression could change it a lot but I don‚Äôt know much about it
967216845416669200,Sat Feb 24 01:57:20 +0000 2018,@Jovonni Most of my ideas turn out not to be useful after less than a day of investigating them
967201169939382300,Sat Feb 24 00:55:03 +0000 2018,By looking at this image, you can see how sensitive your own eyes are to contrast at different frequencies (taller‚Ä¶ https://t.co/reKR9mS5gi
967200391673692200,Sat Feb 24 00:51:57 +0000 2018,@dribnet @RobMurrish While everyone else was scrambling to finish running experiments for ICML, my co-authors and I‚Ä¶ https://t.co/xTi6hF6xqJ
967139020701548500,Fri Feb 23 20:48:05 +0000 2018,@rhyolight @WallerLegal Sure, definitely
967098654547849200,Fri Feb 23 18:07:41 +0000 2018,@WallerLegal @rhyolight Yeah, I definitely agree with that. For judgment and science to be useful, there has to be‚Ä¶ https://t.co/PK5d0eB0ft
967088363533566000,Fri Feb 23 17:26:48 +0000 2018,@rakshesha @JeffDean @DynamicWebPaige @jaschasd I tried out an RNN model (MP-DBM with recurrent mean field inferenc‚Ä¶ https://t.co/tXIeTmum5j
967064636875931600,Fri Feb 23 15:52:31 +0000 2018,@rhyolight The machines are irrelevant. We could have this discussion in 500 BC without any reference to AI / ML /‚Ä¶ https://t.co/lBYctf7rsY
967063406820802600,Fri Feb 23 15:47:38 +0000 2018,@shrng_yan None of the machine learning models we used in this experiment update their answer given more time. Our‚Ä¶ https://t.co/JLDkDZHjbB
967062824710062100,Fri Feb 23 15:45:19 +0000 2018,@fletch_ai @rhyolight @RichardDawkins Yeah, we definitely acknowledge it‚Äôs tricky. That‚Äôs why we don‚Äôt attempt to d‚Ä¶ https://t.co/HxLHghGLv8
966919352699166700,Fri Feb 23 06:15:12 +0000 2018,@rhyolight Yes I disagree with that. People make mistakes all the time. External reality doesn‚Äôt automatically chan‚Ä¶ https://t.co/sgFoK0gOsL
966916324659089400,Fri Feb 23 06:03:10 +0000 2018,@dileeplearning @poolio @nikolayid We observe that adversarial examples change the aggregate statistics of many peo‚Ä¶ https://t.co/3uxS6Wgmve
966911616796188700,Fri Feb 23 05:44:28 +0000 2018,@tetraduzione Fig 5
966911383731298300,Fri Feb 23 05:43:32 +0000 2018,@poolio @dileeplearning @nikolayid Yeah I agree that bistable percepts don‚Äôt count as a size-0 perturbation causing a change
966911019384651800,Fri Feb 23 05:42:06 +0000 2018,@docmilanfar I didn‚Äôt know about that paper but @catherineols pointed us to the Einstein-Monroe version of that ill‚Ä¶ https://t.co/FLNckmybap
966910150861664300,Fri Feb 23 05:38:38 +0000 2018,@tetraduzione Most of the pictures fool only time-limited humans
966909835630428200,Fri Feb 23 05:37:23 +0000 2018,@rhyolight It‚Äôs worth mentioning that on some tasks, machines agree with votes by multiple humans more often than many individual humans do
966909633620205600,Fri Feb 23 05:36:35 +0000 2018,@rhyolight Me too... I‚Äôm saying ‚Äúhumans can make mistakes and aren‚Äôt by definition correct‚Äù not ‚Äúthere exists a mac‚Ä¶ https://t.co/N0v5oJAxAn
966905468399452200,Fri Feb 23 05:20:02 +0000 2018,@rhyolight I disagree. It‚Äôs hard to define a better ground truth, but there‚Äôs no reason to believe humans are alway‚Ä¶ https://t.co/OB8T3uAQ90
966904947219419100,Fri Feb 23 05:17:58 +0000 2018,@dileeplearning @nikolayid As we say in the text, there are philosophical barriers to defining a ground truth. But‚Ä¶ https://t.co/QpU9HaYC0r
966904468603220000,Fri Feb 23 05:16:04 +0000 2018,@yaringal The cat-vs-dog is one particularly strong example where we‚Äôre not sure if we fooled the no-limit human or‚Ä¶ https://t.co/vIYkPkHlge
966904147562848300,Fri Feb 23 05:14:47 +0000 2018,@yaringal The points created by adversarial example algorithms can sometimes be similar to what you would get by in‚Ä¶ https://t.co/m71f1cBJuu
966902939347374100,Fri Feb 23 05:09:59 +0000 2018,@vinayprabhu We were wondering specifically whether small p-norm perturbations of normal images could fool humans.‚Ä¶ https://t.co/qGBUJq4o9Q
966902288357802000,Fri Feb 23 05:07:24 +0000 2018,@SocraticDatum @catherineols pointed out that the cat image is kind of like a naturally occurring version of this o‚Ä¶ https://t.co/1fN1YrFnyA
966901965656490000,Fri Feb 23 05:06:07 +0000 2018,@SocraticDatum Based on discussion with @catherineols , I think this particular cat happens to look like a dog at l‚Ä¶ https://t.co/ovw6qGG2Cm
966901507957301200,Fri Feb 23 05:04:18 +0000 2018,@SocraticDatum I don‚Äôt actually see a cat face in there. I‚Äôm not saying you‚Äôre wrong, just that I personally don‚Äôt see it
966900651836887000,Fri Feb 23 05:00:54 +0000 2018,@dileeplearning @nikolayid I don‚Äôt think humans should be considered ground truth, but it‚Äôs hard to say what the ob‚Ä¶ https://t.co/fUN9P7Odav
966900112210378800,Fri Feb 23 04:58:45 +0000 2018,@dileeplearning @nikolayid For most of our examples, we show that the adversarial perturbation makes time-limited h‚Ä¶ https://t.co/AnTGZc9b1Z
966884054258696200,Fri Feb 23 03:54:57 +0000 2018,@ztjio I have been so nervous we were gonna get scooped
966883856254029800,Fri Feb 23 03:54:09 +0000 2018,@Kaaz1992K Transfer from classifiers trained on human-labeled images is kind of like model-based opt applied to cro‚Ä¶ https://t.co/56wo5mAX9C
966883471674064900,Fri Feb 23 03:52:38 +0000 2018,@Kaaz1992K In principle you could use any kind of gradient-free optimizer... model-based opt, evolution / random se‚Ä¶ https://t.co/NueIciZrWG
966882042217619500,Fri Feb 23 03:46:57 +0000 2018,@Kaaz1992K I think it‚Äôs worth trying. In this paper our idea was to use time-limited psychophysics experiments and‚Ä¶ https://t.co/w425u78GDU
966881237318058000,Fri Feb 23 03:43:45 +0000 2018,@Kaaz1992K I‚Äôd be interested in a link if you can remember it
966880143493886000,Fri Feb 23 03:39:24 +0000 2018,@nikolayid It might ‚Äúactually‚Äù be a dog... but is it? Or are you fooled into thinking it is? We don‚Äôt actually know for sure for that image
966878640909664300,Fri Feb 23 03:33:26 +0000 2018,@dribnet @RobMurrish Thank you! That is very interesting
966862290774507500,Fri Feb 23 02:28:28 +0000 2018,@RobMurrish Not yet. Our technique is based on fooling machines first so it doesn‚Äôt seem applicable in that way
966861655123542000,Fri Feb 23 02:25:56 +0000 2018,@Kaaz1992K We don‚Äôt know how to make an adversarial example like that yet. In this paper, the adversarial examples‚Ä¶ https://t.co/3XNQeK2ko5
966853052140470300,Fri Feb 23 01:51:45 +0000 2018,Adversarial examples that fool both human and computer vision https://t.co/jpeYjPuw6D https://t.co/i4ttmFNrHX
966732440482926600,Thu Feb 22 17:52:29 +0000 2018,MIT Technology Review listed GANs as 1 of 10 breakthrough technologies this year: https://t.co/bokfANfTz9
966414656297320400,Wed Feb 21 20:49:43 +0000 2018,@Spriteware Yes, I definitely think so
966398790734262300,Wed Feb 21 19:46:41 +0000 2018,@MelMitchell1 @techreview In Tech Review's defense, they're working off a talk at a NIPS workshop on Machine Creati‚Ä¶ https://t.co/fJxmKh4dKl
966391158296395800,Wed Feb 21 19:16:21 +0000 2018,@poolio The residents I mentor definitely learn a lot of cynicism! But I guess they learn it from my stories and not first-hand experience
966390730812940300,Wed Feb 21 19:14:39 +0000 2018,https://t.co/7Imrt1zfst
965967957594550300,Tue Feb 20 15:14:42 +0000 2018,@natarpr Welcome!
964980334801514500,Sat Feb 17 21:50:14 +0000 2018,A great Scientific American article on creativity and problem solving in machine learning by Chris Baraniuk: https://t.co/l4lwSREP5P
964215747869163500,Thu Feb 15 19:12:03 +0000 2018,@gabrielpeyre @GuillaumeG_ Is it feasible to solve the equation for the implicit method in the case of GANs though?
964215363213733900,Thu Feb 15 19:10:31 +0000 2018,@GuillaumeG_ @gabrielpeyre Is that result applicable to iterating on GAN parameters though? I think it's applicable‚Ä¶ https://t.co/vKhBbWFU0v
964183624332451800,Thu Feb 15 17:04:24 +0000 2018,@nikhilbd Partly I'm talking about "AI" type settings. I feel like the places where shallow models are still used i‚Ä¶ https://t.co/uHDSfGXOPi
964181155951112200,Thu Feb 15 16:54:35 +0000 2018,One of my main concerns about machine learning interpretability tools is that they will make people think they unde‚Ä¶ https://t.co/x3OOXNyBH0
964180632011026400,Thu Feb 15 16:52:30 +0000 2018,@SebastienBubeck Likewise vehicles other than "cars" are still in regular commercial use. I feel like "SVM for AI"‚Ä¶ https://t.co/PTpIZ72SSf
964180109958660100,Thu Feb 15 16:50:26 +0000 2018,@KordingLab I'd tell you anything I'd tell you if I were a prof
964179656105578500,Thu Feb 15 16:48:38 +0000 2018,@KordingLab @stochastician fwiw I would not tell most academics (except a very short trusted whitelist) about pre-p‚Ä¶ https://t.co/8ECSQchJS3
964179257789304800,Thu Feb 15 16:47:03 +0000 2018,@KordingLab I still consider myself part of the same enterprise. Actually you get a lot more of my time spent on th‚Ä¶ https://t.co/2RIMTFv101
964178603888975900,Thu Feb 15 16:44:27 +0000 2018,@stochastician @KordingLab I went to industry in part because I wanted to stay in the trenches
964168396072828900,Thu Feb 15 16:03:53 +0000 2018,The term ‚Äúdeep learning‚Äù reminds me of ‚Äúhorseless carriage.‚Äù It made sense when introduced, but now that it is the‚Ä¶ https://t.co/NxEHyqC2x9
964152564051722200,Thu Feb 15 15:00:59 +0000 2018,@dennybritz @jackclarkSF There‚Äôs plenty of work on creating data for supervised learning. One example: https://t.co/ljNrcU4Vh7
963998096358129700,Thu Feb 15 04:47:11 +0000 2018,@lukede0 @RogerGrosse @jeremyphoward When I chose UdeM over Stanford / Berkeley, a UdeM student tried to talk me out of it
963835696325697500,Wed Feb 14 18:01:51 +0000 2018,@volkuleshov @poolio That doesn‚Äôt mean someone else can just claim the idea as their own without attribution
963835417639338000,Wed Feb 14 18:00:45 +0000 2018,@poolio This is an even bigger problem in adversarial example land. Seems hard for most people to hang onto credit‚Ä¶ https://t.co/sM76CzFEGw
963834472717107200,Wed Feb 14 17:57:00 +0000 2018,@poolio Bid to review it for ICML
963498133031346200,Tue Feb 13 19:40:30 +0000 2018,@mali512 you mean like an idea for a research project?
963199726072950800,Mon Feb 12 23:54:44 +0000 2018,@mundt_martin @venkatesanragav Not really, maxout is pretty old at this point, and the next step in the evolution a‚Ä¶ https://t.co/SJTl9fzv59
963147096697200600,Mon Feb 12 20:25:36 +0000 2018,@venkatesanragav It's a bit of a hand-wavy argument since the output isn't a class, but yes I think that intuition makes sense
962516793821556700,Sun Feb 11 02:41:01 +0000 2018,RT @yaroslavvb: Posted some time/cost evals of training image classifiers to https://t.co/ekJpAGb1TR  . Somewhat counter-intuitively, the m‚Ä¶
961491127604949000,Thu Feb 08 06:45:23 +0000 2018,@furlanel It‚Äôs also possible to use a weak baseline for algorithmic novelty by writing a misleading ‚Äúrelated work‚Äù section
961464454796886000,Thu Feb 08 04:59:23 +0000 2018,RT @googleresearch: Congrats to Googlers Mart√≠n Abadi and Diane Greene, who have been elected to the National Academy of Engineering (NAE)‚Ä¶
961440471678574600,Thu Feb 08 03:24:05 +0000 2018,RT @JeffDean: Congrats to my Google colleagues Martin Abadi ("For contrib. to the formal theory of computer security") and Diane Greene ("F‚Ä¶
961328192924479500,Wed Feb 07 19:57:56 +0000 2018,A nice plot of baselines conveniently worsening each year when it's time to write a new paper.‚Ä¶ https://t.co/Dm2KMwayV0
961316081234198500,Wed Feb 07 19:09:48 +0000 2018,@Smerity Is it this one? https://t.co/4BLTSzF3Ul (I would be excited to learn there is more than one of these)
961314782509805600,Wed Feb 07 19:04:39 +0000 2018,@dmgarciatorres "Learning from Simulated and Unsupervised Images through Adversarial Training"
961313703084703700,Wed Feb 07 19:00:21 +0000 2018,I did a small scale version of this for one GAN metric. Paper with best baseline was rejected from ICLR 2018, paper‚Ä¶ https://t.co/NQPXYnKChw
961313451137155100,Wed Feb 07 18:59:21 +0000 2018,Meta-research idea: find all ICLR submissions that report baseline numbers for the same task. Determine whether hig‚Ä¶ https://t.co/lGDDBC7OVk
961312672577765400,Wed Feb 07 18:56:16 +0000 2018,Performance of new method &amp; performance of baseline was correlated across 10 ICLR papers. Positive interpretation:‚Ä¶ https://t.co/xWfQrmeM8A
960675832069943300,Tue Feb 06 00:45:41 +0000 2018,RT @deborahhanus: I've had several people ask me how the can start learning #MachineLearning, #DeepLearning, &amp; #ReinforcementLearning. I've‚Ä¶
960390201997586400,Mon Feb 05 05:50:42 +0000 2018,@Rahul_Bhalley You can have deep learning without backprop
960326247279505400,Mon Feb 05 01:36:34 +0000 2018,@deinactivation For example, I saw an article today saying deep learning is based on visual perception but no other‚Ä¶ https://t.co/64xfqMcwgs
960325723687854100,Mon Feb 05 01:34:29 +0000 2018,@deinactivation Most of the people who say we need to work on understanding the brain don‚Äôt seem to be advocating t‚Ä¶ https://t.co/5oGb9ak5NF
960302774884839400,Mon Feb 05 00:03:17 +0000 2018,@neurowitz This is why I went into AI instead. I spent the first two years of undergrad studying psych, cog sci, ne‚Ä¶ https://t.co/8zTecqWDv0
960288288681570300,Sun Feb 04 23:05:43 +0000 2018,@dileeplearning The 2006 revolution had some new ideas that ended up not panning out. Contrastive divergence was me‚Ä¶ https://t.co/uo6x0yjC86
960280338499911700,Sun Feb 04 22:34:08 +0000 2018,Deep learning isn't intended to model brain function with high fidelity (that's computational neuroscience) but it'‚Ä¶ https://t.co/0sH9cpOPTR
960279947163050000,Sun Feb 04 22:32:35 +0000 2018,I've seen several people recently say that instead of deep learning, AI researchers should reverse engineer the bra‚Ä¶ https://t.co/ppbAxwUlUX
960263523849855000,Sun Feb 04 21:27:19 +0000 2018,@HrSaghir @gokstudio @rsalakhu GANs would do SGD on JSD if the discriminator were fully optimal at all times, but i‚Ä¶ https://t.co/CQTPXMt6B1
960260734092365800,Sun Feb 04 21:16:14 +0000 2018,@mikamckinnon I‚Äôm not saying scientists should *control* what the reporter says, but it‚Äôs crazy that no editor chec‚Ä¶ https://t.co/osKNqOV5Op
960260470622990300,Sun Feb 04 21:15:11 +0000 2018,@mikamckinnon I‚Äôve had articles written about my work that implied they had interviewed me when they had not. Full‚Ä¶ https://t.co/X53rHBCpfr
960260149867720700,Sun Feb 04 21:13:55 +0000 2018,@mikamckinnon I‚Äôve literally seen an interview where the expert said ‚Äúthese are nice results, but it‚Äôs not a new in‚Ä¶ https://t.co/08dX2IjSIK
959489070786256900,Fri Feb 02 18:09:55 +0000 2018,@andrew_ilyas @roydanroy We welcome any black box attack method. We organized a NIPS 2017 competition on adversaria‚Ä¶ https://t.co/skxwOsAqvX
959478938249478100,Fri Feb 02 17:29:39 +0000 2018,@aleks_madry @NicolasPapernot @ChrSzegedy We reported training on l_infinity based PGD with no noise in our ICLR 20‚Ä¶ https://t.co/czkYbiUJo4
959475335929651200,Fri Feb 02 17:15:20 +0000 2018,@roydanroy They broke 7 papers, not 8. They tried and failed to break an 8th. One of the 3 they ignored is by us, a‚Ä¶ https://t.co/2fmOoEftRw
959386245217464300,Fri Feb 02 11:21:20 +0000 2018,@badfellow_ian I actually did get an e-mail from someone wanting to generate bitcoins with GANs
959374695400226800,Fri Feb 02 10:35:26 +0000 2018,Code for SN-GAN and the projection discriminator are now available: https://t.co/l4h8ZPSA11
959372887793659900,Fri Feb 02 10:28:15 +0000 2018,@dlowd @kdnuggets https://t.co/2mhzqwilwU https://t.co/vk3On7cBFD https://t.co/bKV0WAuCri
959320649612238800,Fri Feb 02 07:00:40 +0000 2018,@mjntendency @anishathalye This is seriously misleading. There are at least 3 other ICLR defense papers that haven't been broken.
959320425141424100,Fri Feb 02 06:59:47 +0000 2018,@reddit_ml This is seriously misleading. There were at least 11 defense papers at ICLR. At least 3 more that haven'‚Ä¶ https://t.co/IdUbynT9k3
959320269784432600,Fri Feb 02 06:59:10 +0000 2018,@logan_engstrom @aleks_madry This is not true. There were 2 defenses that are provable so they didn't attempt to br‚Ä¶ https://t.co/Xk1K65jtPi
959320023536844800,Fri Feb 02 06:58:11 +0000 2018,@kdnuggets This is seriously misleading. There were at least 11 defense papers at ICLR 2018. 2 have provable defens‚Ä¶ https://t.co/QrTTmIzNM5
959319828761686000,Fri Feb 02 06:57:25 +0000 2018,@poolio There were actually at least 11 defense papers, not 8. 2 have provable defenses, and 1 they didn't study. T‚Ä¶ https://t.co/ggkNpYb7ab
959319561727176700,Fri Feb 02 06:56:21 +0000 2018,@anishathalye @aleks_madry There were actually at least 11 defense papers submitted to ICLR. Your paper describes r‚Ä¶ https://t.co/60hAd4GzD4
959294864050438100,Fri Feb 02 05:18:13 +0000 2018,@ankesh_anand @Reza_Zadeh @anishathalye https://t.co/bKV0WAuCri appears not to have been broken
959294748610650100,Fri Feb 02 05:17:45 +0000 2018,@Reza_Zadeh Missed https://t.co/bKV0WAuCri
959294361354694700,Fri Feb 02 05:16:13 +0000 2018,@poolio They say they tested all defenses sent to ICLR, but they seem to have overlooked Ensemble Adversarial Train‚Ä¶ https://t.co/DhzpBUhbUR
958917534597566500,Thu Feb 01 04:18:50 +0000 2018,@tdot4tech https://t.co/2CkX4RlhGL is a good place to start
958752333021683700,Wed Jan 31 17:22:23 +0000 2018,RT @rbhar90: Another cool deep learning for physics paper. https://t.co/3x74FZsiiC
958099413062230000,Mon Jan 29 22:07:55 +0000 2018,Our paper on adversarial spheres has been accepted to the ICLR workshops. We show that even nearly perfect classifi‚Ä¶ https://t.co/Z6GwXJ1zaE
958095862042828800,Mon Jan 29 21:53:48 +0000 2018,MaskGAN, our paper on generating text with GANs, was accepted to ICLR: https://t.co/ivkXM6NkHx
958095620698288100,Mon Jan 29 21:52:51 +0000 2018,Our paper on using thermometer codes to resist adversarial examples has been accepted to ICLR. This model was highl‚Ä¶ https://t.co/jVALV5iGOQ
958094528136663000,Mon Jan 29 21:48:30 +0000 2018,Our paper on Ensemble Adversarial Training has been accepted to ICLR. This approach increases robustness of models‚Ä¶ https://t.co/PP9HQ2L4fd
958093794355720200,Mon Jan 29 21:45:35 +0000 2018,Our ICLR submission "Many paths to equilibrium" has been accepted. This submission corrects a few common misconcept‚Ä¶ https://t.co/hOrP73lgF9
957841899758342100,Mon Jan 29 05:04:39 +0000 2018,@pksahu_sahu Seems worth exploring, but no one has been able to make it work yet as far as I know
957749993812639700,Sun Jan 28 22:59:27 +0000 2018,@liefspace Yes. As far as I could tell, my privacy settings were configured so only followers I accepted could see‚Ä¶ https://t.co/xiF2Ytd3DW
957703767545163800,Sun Jan 28 19:55:46 +0000 2018,@scottlegrand @Strava I want to keep track of my GPS data. I just don‚Äôt want it shared with the whole world.
957699121023893500,Sun Jan 28 19:37:18 +0000 2018,@scottlegrand @Strava If a professional computer scientist can't correctly configure an app's privacy settings afte‚Ä¶ https://t.co/jOFXVe2F8J
957696391383457800,Sun Jan 28 19:26:27 +0000 2018,@liefspace For privacy settings to serve users correctly, they need to be clear. I personally was very confused and‚Ä¶ https://t.co/BjbZU5mB8z
957689782368219100,Sun Jan 28 19:00:11 +0000 2018,Users of @Strava have complained about the app's limited / confusing privacy settings since as far back as 2014. I‚Ä¶ https://t.co/eETzkuf56H
957345689050136600,Sat Jan 27 20:12:53 +0000 2018,RT @TensorFlow: TensorFlow 1.5.0 has been released, including previews of Eager execution (https://t.co/QpCXfuBvSD) and TensorFlow Lite (ht‚Ä¶
957055841236009000,Sat Jan 27 01:01:08 +0000 2018,@sh_reya @Stanford someone needs to use screen
957003594271617000,Fri Jan 26 21:33:31 +0000 2018,@Ningsung Thanks, followed up by e-mail
956718622256152600,Fri Jan 26 02:41:09 +0000 2018,@tremblerz @DickeySingh https://t.co/TGyeoqnfsq
956639677020172300,Thu Jan 25 21:27:27 +0000 2018,RT @doomie: I'll be giving a talk on video prediction at #REWORKDL this afternoon: https://t.co/YDVuhfJZhX
956614089261826000,Thu Jan 25 19:45:46 +0000 2018,@nikitaljohnson Thank you for inviting me!
956564545371172900,Thu Jan 25 16:28:54 +0000 2018,@bgalbraith @yoavgo @evanmiltenburg @haldaume3 @antske @tommaso_caselli @coling2018 Maybe the conference should inc‚Ä¶ https://t.co/dzYTiAbiA0
956254290904928300,Wed Jan 24 19:56:03 +0000 2018,RT @reworkkatie: Tomorrow, @goodfellow_ian will be signing his book "DEEP LEARNING" after his talk at the Deep Learning Summit. Make sure t‚Ä¶
956254199171375100,Wed Jan 24 19:55:42 +0000 2018,@bikmaeff No it's a GAN
956228822117986300,Wed Jan 24 18:14:51 +0000 2018,A correction: this video makes use of both SN-GAN and the technique from another paper, the projection discriminato‚Ä¶ https://t.co/0YtA2oB628
956228355661033500,Wed Jan 24 18:13:00 +0000 2018,@nlpmattg @yoavgo @haldaume3 @zehavoc @gchrupala @ArneKoehn @evanmiltenburg @antske @tommaso_caselli Maybe we shoul‚Ä¶ https://t.co/RAZ3iavxH5
955879957200232400,Tue Jan 23 19:08:35 +0000 2018,@geoffreyirving @jmgilmer @wattenberg I do think there are big advantages to going discrete: https://t.co/yh1obLMvIN
955879658649616400,Tue Jan 23 19:07:24 +0000 2018,@geoffreyirving @jmgilmer or @wattenberg are probably better prepared to answer a question about Theorem 5.1
955869793948549100,Tue Jan 23 18:28:12 +0000 2018,@lindsey What do you want to do?
955847487620657200,Tue Jan 23 16:59:34 +0000 2018,Adversarial patch in @sciam : https://t.co/IywSekxtNq
955839214469365800,Tue Jan 23 16:26:42 +0000 2018,@jeremyphoward @kevindewalt Less common knowledge: (my own observation, but probably known by someone else) you can‚Ä¶ https://t.co/W8EwjdkilR
955838920306057200,Tue Jan 23 16:25:31 +0000 2018,@jeremyphoward @kevindewalt I don‚Äôt know of a paper but it‚Äôs common knowledge that an embedding lookup (like tf.gat‚Ä¶ https://t.co/9JypT9RgQ3
955838625131913200,Tue Jan 23 16:24:21 +0000 2018,@jeremyphoward @kevindewalt Oh, I don‚Äôt mean Aurko came up with the general idea of thermometer coding. I meant it‚Ä¶ https://t.co/0kwwcB5RNk
955838203445071900,Tue Jan 23 16:22:40 +0000 2018,@haldaume3 My NIPS experience may also be a result of the way I bid
955836971938533400,Tue Jan 23 16:17:47 +0000 2018,@haldaume3 Another thought: as ML grows rapidly, a large share of the reviewers are beginners who may feel more lik‚Ä¶ https://t.co/4JTVX2AMCk
955836527820488700,Tue Jan 23 16:16:01 +0000 2018,@haldaume3 My theory is that reviewers are just busy, feel afraid of declining a reviewer invitation from an influe‚Ä¶ https://t.co/v5Q6GxaJsZ
955836167005470700,Tue Jan 23 16:14:35 +0000 2018,@haldaume3 I don‚Äôt have official stats but when I‚Äôve been a NIPS AC before I felt like most review scores were righ‚Ä¶ https://t.co/R5oG0Tj3Ah
955835731070541800,Tue Jan 23 16:12:51 +0000 2018,@kevindewalt @jeremyphoward Also worth mentioning that one-hot and thermometer are both embeddings, just hard-coded‚Ä¶ https://t.co/hbHyIrGmC2
955835495187071000,Tue Jan 23 16:11:55 +0000 2018,@kevindewalt @jeremyphoward An embedding lookup is equivalent to multiplying a one-hot code by a matrix. Multiplyin‚Ä¶ https://t.co/lP5W3ZMTk4
955834820206084100,Tue Jan 23 16:09:14 +0000 2018,@kevindewalt @jeremyphoward You don‚Äôt need to explicitly represent all the dims of one-hot or thermometer
955560963377254400,Mon Jan 22 22:01:01 +0000 2018,@Jovonni @united They are offering to pay us... $250 of credit to use for another United flight.
955560745835446300,Mon Jan 22 22:00:09 +0000 2018,@Jovonni @united They didn‚Äôt permit us to check in
955517072024354800,Mon Jan 22 19:06:37 +0000 2018,My family and I certainly did not benefit from any of these supposed policy changes. I was separated from my wife a‚Ä¶ https://t.co/gr6HaoRnCg
955516747116720100,Mon Jan 22 19:05:19 +0000 2018,After the video of David Dao being violently dragged off a @united flight went viral, @united announced a new set o‚Ä¶ https://t.co/lsGf8NDFNc
955515905055760400,Mon Jan 22 19:01:59 +0000 2018,In case anyone is wondering, this did not end well. I think @united has invented a new way to avoid paying people t‚Ä¶ https://t.co/EXy40QlTgm
954953036991905800,Sun Jan 21 05:45:20 +0000 2018,@CrystationalBio https://t.co/ADbHarptYi
954952810260348900,Sun Jan 21 05:44:26 +0000 2018,@CrystationalBio https://t.co/dvFZFx3rKp
954939907478249500,Sun Jan 21 04:53:10 +0000 2018,@CrystationalBio Yes, 3D voxels, particle physics data
954845259208433700,Sat Jan 20 22:37:04 +0000 2018,@htt921 @PreferredNet ?
954845183429898200,Sat Jan 20 22:36:46 +0000 2018,@htt921 My guess is they linearly interpolated between one-hot codes for each class, but I don‚Äôt know the details for sure
954788329475551200,Sat Jan 20 18:50:51 +0000 2018,@iantimmis Most of my post-high school math is relatively self taught. I figure out math topics that seem related t‚Ä¶ https://t.co/6tn5ZQmvDW
954787851970871300,Sat Jan 20 18:48:57 +0000 2018,@iantimmis I don‚Äôt actually know nonlinear dynamics but I wish I did. Usually machine learning researchers have dif‚Ä¶ https://t.co/ltmZ0sizjc
954787409031446500,Sat Jan 20 18:47:12 +0000 2018,@knazeri Yes
954554930555011100,Sat Jan 20 03:23:24 +0000 2018,Video of morphing between ImageNet categories with SN-GAN: https://t.co/U9ZIDIX6y9
954225376527401000,Fri Jan 19 05:33:53 +0000 2018,RT @lindsey: "Toward Scalable Verification for Safety-Critical Deep Networks" will appear at the inaugural SysML conference (sysml.cc) next‚Ä¶
953852168909418500,Thu Jan 18 04:50:53 +0000 2018,@KLdivergence @JamesJohndrow Now I‚Äôm curious what set of clothing items signal cryptocurrency startup collectively but not individually
953679482308640800,Wed Jan 17 17:24:41 +0000 2018,@zacharylipton @zeynep My top hit is a CNBC story about the price dropping below $10k, a sell-off in progress, etc.
953677201756450800,Wed Jan 17 17:15:38 +0000 2018,@friendly_aixi @peterxichen Thanks. Is there a density modeling (not classification accuracy) result based on training on the train set?
953511426886271000,Wed Jan 17 06:16:54 +0000 2018,@fchollet I also won an ML contest in 2011 with conv nets on GPU (NIPS transfer learning contest) but I‚Äôm not claim‚Ä¶ https://t.co/qG7Jf6gZXA
953509956040450000,Wed Jan 17 06:11:03 +0000 2018,@fchollet Were ICDAR / IJCNN actually hotly contested?
953500117851500500,Wed Jan 17 05:31:57 +0000 2018,@fchollet Convnets on GPU predate CUDA: https://t.co/xYjMCjdlzm
953426754294591500,Wed Jan 17 00:40:26 +0000 2018,RT @ycombinator: XIX.ai (W17) is organizing a conference about AI. You can get tickets here https://t.co/BkE5Nz6oVn
953332004786905100,Tue Jan 16 18:23:56 +0000 2018,@unsorsodicorda Unsupervised pretraining and deep belief nets were the start in 2006 of a much larger movement. Yos‚Ä¶ https://t.co/TAorsQYooD
953288903246544900,Tue Jan 16 15:32:40 +0000 2018,RT @RaiaHadsell: Announcing the inaugural Transylvanian Machine Learning Summer School! https://t.co/GZIhi9K5Ri  Please pass on to eastern‚Ä¶
953079891993378800,Tue Jan 16 01:42:08 +0000 2018,My friend @yaroslavvb did a lot of work on this https://t.co/f5JQ8FGFnU
953079483526930400,Tue Jan 16 01:40:30 +0000 2018,@KaiLashArul @ChombaBupe I wouldn't attribute the recent popularity of evolution to Uber. I'd say it's mostly due t‚Ä¶ https://t.co/FClnTLYum9
953048800532320300,Mon Jan 15 23:38:35 +0000 2018,@checker5555 Yoshua‚Äôs 2009 book mentions layerwise unsupervised learning but not backprop or supervised learning in‚Ä¶ https://t.co/MjbY1cp9GJ
953048400672448500,Mon Jan 15 23:37:00 +0000 2018,@checker5555 I think in 2009, someone asked to define deep learning might have said it means to use layerwise pretr‚Ä¶ https://t.co/b9zXju6iQZ
953047993963311100,Mon Jan 15 23:35:23 +0000 2018,@checker5555 My own opinion is that deep learning is just about learning multiple steps in a computational graph. A‚Ä¶ https://t.co/gZ8qLKsQ4A
953046868027523100,Mon Jan 15 23:30:54 +0000 2018,@checker5555 I don‚Äôt know that it‚Äôs a mistake per se, but definitely says something about the evolution of language
953046409892151300,Mon Jan 15 23:29:05 +0000 2018,@checker5555 Supervised learning and gradient-based optimization both ended up working better than people thought,‚Ä¶ https://t.co/A6J9HM3iWG
953046094845435900,Mon Jan 15 23:27:50 +0000 2018,@ChombaBupe In situations where you can‚Äôt use backprop, there are other methods you can fall back to. In situations‚Ä¶ https://t.co/MrBi4UH4Vz
953041934779494400,Mon Jan 15 23:11:18 +0000 2018,It‚Äôs strange to see people defining deep learning as supervised learning via backprop, considering that the 2006 de‚Ä¶ https://t.co/JNYiNgfQjL
953016774684897300,Mon Jan 15 21:31:19 +0000 2018,@peterxichen Accidentally. Got really excited about the results back in ~2012, then figured out why they were so good
953016366994374700,Mon Jan 15 21:29:42 +0000 2018,@peterxichen If you shuffle MNIST randomly and pick an abitrary 10k samples to be the test set with no regard for w‚Ä¶ https://t.co/Np0yTQfUMJ
953015088549478400,Mon Jan 15 21:24:37 +0000 2018,@peterxichen That would be true if the test set was IID but on MNIST examples within the same train / test partitio‚Ä¶ https://t.co/jHs43HuVC7
953006300987715600,Mon Jan 15 20:49:42 +0000 2018,@peterxichen Is it training on the test set though? I found the part about concatenating the train, valid and test set to be ambiguous
952623091309424600,Sun Jan 14 19:26:58 +0000 2018,@diegoalejogm The organizers asked me to speak about GANs, but if there's any particular GAN topic you'd like me to emphasize let me know
952286112742961200,Sat Jan 13 21:07:56 +0000 2018,I will speak at this event https://t.co/SgjOEgeP3A
951994325486862300,Sat Jan 13 01:48:29 +0000 2018,@RobMurrish If there is a connection it's not obvious to me. In the compression case the situation is "it is not po‚Ä¶ https://t.co/yH8Y5e1Pk8
951892513723367400,Fri Jan 12 19:03:55 +0000 2018,@unsorsodicorda @ToniCreswell https://t.co/z80DunKEsf
951891868081569800,Fri Jan 12 19:01:21 +0000 2018,@unsorsodicorda @ToniCreswell Technically yes but I haven't ended up writing much of anything for it: https://t.co/8GCLR0iJHt
951891570298507300,Fri Jan 12 19:00:10 +0000 2018,What the @GoogleBrain team accomplished in 2017: https://t.co/9w0zFz4ypt
951855134425808900,Fri Jan 12 16:35:23 +0000 2018,@unsorsodicorda @ToniCreswell I got to meet @ToniCreswell at NIPS 2017
951855006595956700,Fri Jan 12 16:34:52 +0000 2018,@unsorsodicorda @ToniCreswell I've seen it, but haven't had time to read it personally---there's so much ML-related‚Ä¶ https://t.co/7xOTMJc1dV
951684905963933700,Fri Jan 12 05:18:57 +0000 2018,Same goes for adversarial ML https://t.co/A8GoVkSjkG
951253976602656800,Thu Jan 11 00:46:36 +0000 2018,RT @hillarymsanders: Really awesome work done by old college friend Nicholas Carlini, showing that speech-to-text systems can be disturbing‚Ä¶
951210078421401600,Wed Jan 10 21:52:09 +0000 2018,@jmgilmer Welcome to twitter!
951206142729896000,Wed Jan 10 21:36:31 +0000 2018,@NicoChauvin74 We've tried to do that, and so far we've always been able to fool the "garbage" class detector
951178244757233700,Wed Jan 10 19:45:40 +0000 2018,To gain some idea of the far future of ML security, we studied a simple toy problem called "adversarial spheres," s‚Ä¶ https://t.co/lRcKxZpxcp
951165720703860700,Wed Jan 10 18:55:54 +0000 2018,@ICLR18 : https://t.co/9VgcL4qXvj redirects to https://t.co/uTA6MyqQ34
951105823828095000,Wed Jan 10 14:57:53 +0000 2018,@rahuledachali That‚Äôs not the point actually. I think it made a lot of sense to reject me at the time
950926453691985900,Wed Jan 10 03:05:08 +0000 2018,@WonderMicky Disappointed but not discouraged. I‚Äôve always thought ‚ÄúWhat‚Äôs the best thing for me to do next?‚Äù not ‚Äú‚Ä¶ https://t.co/50YwrcUjqy
950895660051525600,Wed Jan 10 01:02:46 +0000 2018,RT @lawlkat: To all those folks trying to automate online harassment detection and mitigation measures-- how carefully are you thinking abo‚Ä¶
950852659178758100,Tue Jan 09 22:11:54 +0000 2018,@kurtsy You should update your posterior to reflect that you're less likely than you knew before to be accepted to‚Ä¶ https://t.co/Gg9hLz035u
950840198560071700,Tue Jan 09 21:22:23 +0000 2018,@krishnaopine For machine learning: Chris Bishop's book, Daphne Koller and Nir Friedman's book, Andrew Ng's lecture notes
950840017655554000,Tue Jan 09 21:21:40 +0000 2018,@krishnaopine What subject specifically? I don't actually know a lot about the things people usually call "statisti‚Ä¶ https://t.co/rlGEbcZ5G1
950839130098884600,Tue Jan 09 21:18:09 +0000 2018,@kurtsy It's worth thinking about survivorship bias. Some of the decisions I made in my career were risky moves tha‚Ä¶ https://t.co/kS46wOcS2H
950838390118903800,Tue Jan 09 21:15:12 +0000 2018,@dwf No, I didn't know you'd applied to MIT or CMU
950838172954501100,Tue Jan 09 21:14:20 +0000 2018,@mrtz Wow, pretty harsh that they said you were not qualified. Stanford often says that there are many more qualifi‚Ä¶ https://t.co/LVeWLOUbhy
950773136701603800,Tue Jan 09 16:55:54 +0000 2018,I never heard back from MIT. I got rejected from CMU. I was accepted to U of T but not to work with the PI I wanted‚Ä¶ https://t.co/T3T3RjzZQF
950772250252210200,Tue Jan 09 16:52:23 +0000 2018,Adversarial patch covered by the BBC: https://t.co/LIbZxNQssi
950528198625787900,Tue Jan 09 00:42:37 +0000 2018,@sh_reya Are you tweeting about staying off Twitter?
950368740406775800,Mon Jan 08 14:08:59 +0000 2018,@ngouchetpaul That‚Äôs starting to change. Check out MaskGAN
950297294267498500,Mon Jan 08 09:25:05 +0000 2018,@DinaPomeranz @KathrynRough Any suggestions?
950200275565867000,Mon Jan 08 02:59:34 +0000 2018,@AaronSantMiller I see, I think I misunderstood your earlier tweet. Thanks
950173095670661100,Mon Jan 08 01:11:34 +0000 2018,@AaronSantMiller I‚Äôm not ‚Äúallure[ed] by a quick win‚Äù; I‚Äôm explaining why I have to follow a multi-year research dir‚Ä¶ https://t.co/A9OKrWcuir
950172788827947000,Mon Jan 08 01:10:20 +0000 2018,@AaronSantMiller I was speaking specifically about GAN research in that context. If GANs overfit, there are plenty‚Ä¶ https://t.co/wkJDgofDXB
950119812134355000,Sun Jan 07 21:39:50 +0000 2018,@ikanez How much DL is there in KL?
950119401474334700,Sun Jan 07 21:38:12 +0000 2018,@Miles_Brundage @zacharylipton And lumber
950081065904828400,Sun Jan 07 19:05:52 +0000 2018,@keingeniesser Also the audience has positive reactions. No audience member grabbing a mic to interrupt with ‚ÄúYour‚Ä¶ https://t.co/JLuXQRdIpt
950073709057814500,Sun Jan 07 18:36:38 +0000 2018,@gialdegheri It says ‚ÄúDeep Learning‚Äù in the intro text of the video
950054551465246700,Sun Jan 07 17:20:30 +0000 2018,@Albertorizzoli @united I think we‚Äôre in a different category because our flight wasn‚Äôt delayed or cancelled
949950821025833000,Sun Jan 07 10:28:19 +0000 2018,@thinking_code It looks more like an Apple product launch than an academic conference
949949762135969800,Sun Jan 07 10:24:07 +0000 2018,The new Justin Timberlake video is at a deep learning conference. This is just surreal to me. https://t.co/rTAHkzEYLV
949948997799563300,Sun Jan 07 10:21:04 +0000 2018,@mikaelrousson Yes, for example https://t.co/R5XxqB27mX
949812670454145000,Sun Jan 07 01:19:21 +0000 2018,An article about adversarial patch: https://t.co/sLXwqaZAyr
949568041242722300,Sat Jan 06 09:07:17 +0000 2018,@united Sent
949567766729842700,Sat Jan 06 09:06:12 +0000 2018,@QUOTELOBSTER @united I‚Äôm in Milano Malpensa attempting to fly home to San Francisco. No weather problems, etc. just a bureaucracy glitch
949566739624407000,Sat Jan 06 09:02:07 +0000 2018,Swiss Air says @united canceled my ticket (without notifying me in any way). The flight is still going and there is‚Ä¶ https://t.co/9MnzkhC9hZ
949565436030541800,Sat Jan 06 08:56:56 +0000 2018,I‚Äôve been trying to check in to my @united flight operated by Swiss Air for an hour and 15 minutes. Not allowed to‚Ä¶ https://t.co/x4BR1u6AT7
949528382911471600,Sat Jan 06 06:29:42 +0000 2018,RT @JeffDean: Less than four days left to apply for Google's AI Residency program (formerly the Google Brain Residency program). Applicatio‚Ä¶
949349543115620400,Fri Jan 05 18:39:03 +0000 2018,RT @RosemaryHKelly: Help us find the young innovators shaping our future. Nominate a stellar technologist for our @techreview 35 Innovators‚Ä¶
949337531274973200,Fri Jan 05 17:51:19 +0000 2018,@roydanroy You could use progressive structure with any GAN but @NvidiaAI uses WGAN in the paper
949337357836222500,Fri Jan 05 17:50:38 +0000 2018,@roydanroy You can apply spectral normalization to any GAN but iirc they use NS-GAN as the starting point in the paper
949337172582297600,Fri Jan 05 17:49:54 +0000 2018,@roydanroy Vanilla GANs just work for some tasks and don‚Äôt for others. For the ones where they work, different task‚Ä¶ https://t.co/Ma1b3JqTgu
949336496041091100,Fri Jan 05 17:47:13 +0000 2018,@skdh I usually use ‚Äúnon-&lt;field name&gt;‚Äù as adjective. Since I‚Äôm in machine learning, I‚Äôd say I‚Äôm speaking to a ‚Äúnon-ML audience‚Äù for example
949336035904942100,Fri Jan 05 17:45:23 +0000 2018,@skdh Muggles
949027014618632200,Thu Jan 04 21:17:27 +0000 2018,@gokstudio @lucastheis @avdnoord Frechet Inception Distance is probably a lot better than Inception Score. I say th‚Ä¶ https://t.co/5hNNliFizJ
948886851213021200,Thu Jan 04 12:00:29 +0000 2018,RT @ToniCreswell: Denoising Adversarial Autoencoders: Classifying Skin Lesions Using Limited Labelled Training Data https://t.co/xMBzVcOFt2‚Ä¶
948872946654875600,Thu Jan 04 11:05:14 +0000 2018,@chris_brockett @arxiv_org or don't :)
948872119584247800,Thu Jan 04 11:01:57 +0000 2018,@DoctaCloak @arxiv_org I'm in Italy
948866400097112000,Thu Jan 04 10:39:13 +0000 2018,@spartanhaden @arxiv_org Oh is there an account that anyone at ArXiv checks?
948866110958587900,Thu Jan 04 10:38:04 +0000 2018,@konet @nytimes I don't know ahead of time. I don't think I would have predicted I'd have the idea for GANs 30 minu‚Ä¶ https://t.co/lTISf7I8gl
948865676009238500,Thu Jan 04 10:36:20 +0000 2018,Suggestion for @arxiv_org : make this feature more prominent
948865529112121300,Thu Jan 04 10:35:45 +0000 2018,ML paper writing pro-tip: you can download the raw source of any arxiv paper. Click on the "Other formats" link, th‚Ä¶ https://t.co/coUR4Pptbx
948615165762850800,Wed Jan 03 18:00:54 +0000 2018,@teenybiscuit @hopefulcyborg @Esquiring How did you make the album? Did you choose the pictures yourself, or have a‚Ä¶ https://t.co/FnorVICHwu
948612690401988600,Wed Jan 03 17:51:04 +0000 2018,@hopefulcyborg @Esquiring I think this is originally by @teenybiscuit
948545155082186800,Wed Jan 03 13:22:42 +0000 2018,@visarga @nytimes I don't think that @NvidiaAI ran it on ImageNet for their ICLR submission, but in theory it is ap‚Ä¶ https://t.co/h68aSsYURi
948481664354799600,Wed Jan 03 09:10:25 +0000 2018,An article about GANs in the @nytimes : https://t.co/eyGH7Yvhru
948308697457061900,Tue Jan 02 21:43:06 +0000 2018,RT @NicolasPapernot: Alex Kurakin and I will both be speaking at Age of AI in San Francisco Jan 31 - Feb 1 about adversarial examples and p‚Ä¶
948079069995982800,Tue Jan 02 06:30:39 +0000 2018,@Jovonni LISA lab had been thinking about hosting a speech synthesis contest but we weren't sure how to numerically‚Ä¶ https://t.co/7wRmINP6bq
947908237898207200,Mon Jan 01 19:11:49 +0000 2018,@krishnaopine Not absolutely everyone in DL uses GPU. A lot of RL is still mostly on CPU for example. Of course a l‚Ä¶ https://t.co/JdtFpfvF6y
947907797915709400,Mon Jan 01 19:10:04 +0000 2018,@krishnaopine I imagine you could get at least one GPU somehow. I built the first CUDA machine at Stanford with my‚Ä¶ https://t.co/E0nwIftqL8
947907321459609600,Mon Jan 01 19:08:11 +0000 2018,@tremblerz @jppgks We do plan to add some eventually
947626871621062700,Mon Jan 01 00:33:46 +0000 2018,@jppgks  https://t.co/yeBtLj65GR
947508652684046300,Sun Dec 31 16:44:01 +0000 2017,@climagic https://t.co/6fJCZqW53Y
947230395183042600,Sat Dec 30 22:18:19 +0000 2017,RT @arxiv_org: Adversarial Patch. https://t.co/pzmftDG7ze https://t.co/Gw07pz9mbC
946661244580266000,Fri Dec 29 08:36:43 +0000 2017,@EeroTeppo @michael_nielsen @juliagalef This article is doing something different from cherry-picking though. The a‚Ä¶ https://t.co/qAf90A8zUq
946655428968173600,Fri Dec 29 08:13:36 +0000 2017,@TheSiame Yes, it‚Äôs possible. AI Residency is an opportunity for people from several backgrounds to start a career‚Ä¶ https://t.co/U21q5H1Np1
945767483411238900,Tue Dec 26 21:25:14 +0000 2017,RT @TalkPython: How is machine learning changing particle physics? Join @WonderMicky, @Michael_A_Kagan, and @HEPfeickert to learn how machi‚Ä¶
945381463339434000,Mon Dec 25 19:51:19 +0000 2017,@hamed_mo7amed @ThisIsJoshVarty Free to read online at https://t.co/2CkX4R3GPd
945343170832986100,Mon Dec 25 17:19:10 +0000 2017,@johnolafenwa Very welcome! #merrychristmas
943906663601397800,Thu Dec 21 18:11:00 +0000 2017,@maximus538 @fastml_extra the Google AI Residency program is a great way to start a career in machine learning research without a PhD
943713849621880800,Thu Dec 21 05:24:49 +0000 2017,@doomie @bousmalis "We need GANs... lots of GANs." https://t.co/YcLNc6rnCr
943615960279277600,Wed Dec 20 22:55:51 +0000 2017,@EmmanuelAmeisen One of the nice things about the real world is you can look at a real object more than once. If yo‚Ä¶ https://t.co/ebxKlhCAtM
943613143107887100,Wed Dec 20 22:44:39 +0000 2017,I started my Google career as an intern designing new kinds of conv nets for Google Maps and had a great time there https://t.co/k5iHLdZG1Z
943491968742473700,Wed Dec 20 14:43:09 +0000 2017,RT @twimlai: NEW SHOW ALERT!! @Samcharrington is joined by @TimnitGebru, postdoc at @MSFTResearch,  and one of the organizers of @black_in_‚Ä¶
943262131876593700,Tue Dec 19 23:29:51 +0000 2017,DreamScapes 3, the latest Inceptionist artwork from Daniel Ambrosi: https://t.co/ZkQuydsQkB
943136216525946900,Tue Dec 19 15:09:31 +0000 2017,Learn about how to use Street View imagery for demographic research from @timnitGebruon on @twimlai
943135946895106000,Tue Dec 19 15:08:27 +0000 2017,@Jovonni @alain_dagher Yeah, these are the first samples I made https://t.co/wZFQxyyaUO
942924939304173600,Tue Dec 19 01:09:58 +0000 2017,@alain_dagher We included the pub, Les Trois Brasseurs, in the acknowledgments of the paper:‚Ä¶ https://t.co/uC3yXk3ISS
942861213402144800,Mon Dec 18 20:56:45 +0000 2017,RT @NicolasPapernot: The submission deadline for the deep learning security workshop at @IEEESSP 2018 has been extended to Jan 5. Looking f‚Ä¶
942527442920472600,Sun Dec 17 22:50:28 +0000 2017,RT @dribnet: @fjafjan @goodfellow_ian thanks - prints for sale here; currently one fan print left. https://t.co/qrlbr8JbuK
942504552174985200,Sun Dec 17 21:19:30 +0000 2017,Many thanks to @dribnet for giving me this print at #NIPS2017 Now proudly on the wall at home https://t.co/m8knyuPZIE
942496512071802900,Sun Dec 17 20:47:33 +0000 2017,@Miles_Brundage Take Vitamin D supplements
942078642770686000,Sat Dec 16 17:07:06 +0000 2017,RT @sindero: A few folks asked, and so here‚Äôs a transcript of the talk I gave at the @black_in_ai workshop dinner at #NIPS2017. Thanks agai‚Ä¶
941785841088659500,Fri Dec 15 21:43:36 +0000 2017,RT @WiMLworkshop: For over a decade, WiML has showcased the outstanding technical skills of female researchers. Today, we highlight that al‚Ä¶
941682166882189300,Fri Dec 15 14:51:38 +0000 2017,RT @DaniCMBelg: Here's a copy of the slides from my presentation @black_in_ai workshop during #NIPS2017 "Machine Learning for Personalised‚Ä¶
941496386217902100,Fri Dec 15 02:33:25 +0000 2017,RT @colinraffel: New paper with Chung-Cheng Chiu: Monotonic Chunkwise Attention (MoChA), an online/linear-time attention mechanism which co‚Ä¶
941492801732145200,Fri Dec 15 02:19:10 +0000 2017,@mat_kelcey tf.stop_gradient
941387768139092000,Thu Dec 14 19:21:48 +0000 2017,@NourozRahman If you do a Google search for "GANs for anomaly detection" you get hits, but I haven't personally bee‚Ä¶ https://t.co/hyTIIagwvW
941333102168703000,Thu Dec 14 15:44:35 +0000 2017,RT @JeffDean: Read the accounts of what Kristian Lum described, and if you see such behavior in your own workplace or conferences, speak up‚Ä¶
941172774042615800,Thu Dec 14 05:07:30 +0000 2017,@hardmaru @NicolasPapernot used the same procedure as a defense against adversarial examples a few years ago. ‚ÄúDefensive distillation‚Äù
941140882102743000,Thu Dec 14 03:00:46 +0000 2017,@taz_didier We wanted to choose an image made by deep learning, but we knew generative models in 2015 would look ou‚Ä¶ https://t.co/vZOrFy3PjE
941140298868056000,Thu Dec 14 02:58:27 +0000 2017,@negar_rz Yeah very common. Three people canceled meetings with me on Monday due to NIPS flu. I chose not to fly to‚Ä¶ https://t.co/lrUycwtJ5d
941125831715307500,Thu Dec 14 02:00:58 +0000 2017,RT @NicolasPapernot: Looking forward to be speaking at this event on security and privacy in ML organised at Bar-Ilan University in Tel Avi‚Ä¶
941030967262658600,Wed Dec 13 19:44:00 +0000 2017,@doomie Train a World of Bits agent to use Twitter for you
941017849212035100,Wed Dec 13 18:51:53 +0000 2017,RT @Miles_Brundage: Reminder that @FHIOxford is still looking for interns in AI safety + RL (https://t.co/c632LPSI30) and policy/governance‚Ä¶
940971446557278200,Wed Dec 13 15:47:29 +0000 2017,RT @SussilloDavid: Folks, the Google AI Residency Program is accepting applications (due Jan 8).  So often I hear, "But I'm not a machine l‚Ä¶
940971253720006700,Wed Dec 13 15:46:43 +0000 2017,@ducha_aiki @dustinvtran @fhuszar @unsorsodicorda @rasbt @fchollet @jeremyphoward @hardmaru If you don‚Äôt have a GPU‚Ä¶ https://t.co/LrX63rol8t
940791943814004700,Wed Dec 13 03:54:13 +0000 2017,@sh_reya CS is fashionable now: https://t.co/RVItPIXrP9
940738913466904600,Wed Dec 13 00:23:29 +0000 2017,@lawlkat :D
940736596441047000,Wed Dec 13 00:14:17 +0000 2017,.@lawlkat is doing important work to make online communities more safe and fair: https://t.co/NF6sESuE0K
940691350680252400,Tue Dec 12 21:14:29 +0000 2017,RT @googleresearch: In order to make Generative Adversarial Networks (GANs) easier to experiment with, we‚Äôve open sourced TFGAN, a lightwei‚Ä¶
940417281389035500,Tue Dec 12 03:05:26 +0000 2017,RT @techreview: ‚ÄúThrough decades of public and private investment, the U.S. currently leads in basic AI research. Ill-advised policies can‚Ä¶
940409532924047400,Tue Dec 12 02:34:39 +0000 2017,I use this CMU font in all my slides so that pasted TeX matches the slide font. Same for figures in‚Ä¶ https://t.co/kWrWHq1D7M
940249274914238500,Mon Dec 11 15:57:50 +0000 2017,RT @JeffDean: Current U.S. policies that make it hard or impossible for some of the most talented people in the world to enter this country‚Ä¶
939900824842408000,Sun Dec 10 16:53:13 +0000 2017,@earino At #SOCML AI Ethics was the most popular session
939651415038820400,Sun Dec 10 00:22:09 +0000 2017,#NIPS2017 At 4:45 PM I will speak about overcoming limited data with GANs in Grand Ballroom B‚Ä¶ https://t.co/qlksDdFS5W
939651105666957300,Sun Dec 10 00:20:56 +0000 2017,Sorry, two schedules got out of sync. It will be 4:45 https://t.co/VDJTEbU0I4
939637711010349000,Sat Dec 09 23:27:42 +0000 2017,@LucaLonini I don‚Äôt know
939621615293182000,Sat Dec 09 22:23:45 +0000 2017,@benhamner That would make my life a lot easier
939613475323633700,Sat Dec 09 21:51:24 +0000 2017,@geomblog It is an overview of a general topic combining several papers, with parenthetical citations throughout the slides
939581039701196800,Sat Dec 09 19:42:31 +0000 2017,Don't try this at home https://t.co/A2HMWIElGK
939580841721655300,Sat Dec 09 19:41:43 +0000 2017,A poetic outcome: @L_badikho found out about @black_in_ai because of people questioning the need for @black_in_ai o‚Ä¶ https://t.co/ChIVHMAMZ9
939555161877364700,Sat Dec 09 17:59:41 +0000 2017,I had a great time at @black_in_ai . Really felt like a historic turning point https://t.co/3HrDaRKgpX
939552559345279000,Sat Dec 09 17:49:20 +0000 2017,RT @jackclarkSF: Probably the scariest thing about #NIPS2017 is the undeniably massive effects that will come from scaling up existing AI c‚Ä¶
939552386409906200,Sat Dec 09 17:48:39 +0000 2017,I had a great time visiting the CAIS++ student group at USC during NIPS. Many thanks for inviting me! https://t.co/4yc7oFmzPD
939526956709584900,Sat Dec 09 16:07:36 +0000 2017,#NIPS2017 I will speak about bridging the theory and practice of GANs in Hall A at 9:15
939400233083011100,Sat Dec 09 07:44:03 +0000 2017,RT @maithra_raghu: Deep Learning: Bridging Theory and Practice happening tomorrow at #NIPS2017! Final Schedule: https://t.co/QazhApfMfE @ls‚Ä¶
939389992467537900,Sat Dec 09 07:03:21 +0000 2017,@liu_mingyu Audio-Video. As in, get our laptops to work with conference projectors
939389514073620500,Sat Dec 09 07:01:27 +0000 2017,#nips2017 Which will we solve first?
939375979373277200,Sat Dec 09 06:07:40 +0000 2017,@JeffDean @poptimality @jekbradbury Welcome to Twitter!
939372804142612500,Sat Dec 09 05:55:03 +0000 2017,I remember being in ~4th grade when Toy Story came out and objecting to it being called the first fully computer ge‚Ä¶ https://t.co/32IbcC954k
939313616129376300,Sat Dec 09 01:59:52 +0000 2017,RT @_ehinosa: In concluding, @DaniCMBelg advises that when doing ML for health, 1)Think deeply about the problem. 2)Context matters.   3)Do‚Ä¶
939313398050779100,Sat Dec 09 01:59:00 +0000 2017,@divyanshkhanna1 I usually think about the connection a bit differently (generator is doing RL with a non-stationar‚Ä¶ https://t.co/DYP58LBwTK
939283449965191200,Sat Dec 09 00:00:00 +0000 2017,Blog post by @omojumiller about #SOCML17: https://t.co/RkJ6Kp4AE8
939272583756759000,Fri Dec 08 23:16:49 +0000 2017,Check out our poster on Ensemble Adversarial Training at the #nips2017 Machine Deception workshop, 4-5pm
939272260086411300,Fri Dec 08 23:15:32 +0000 2017,RT @DaniCMBelg: So amazing to see the work @black_in_ai are doing to solve problems on the African continent. @GeorgeWMusumba speaking on h‚Ä¶
939272223445073900,Fri Dec 08 23:15:23 +0000 2017,RT @NicolasPapernot: . @zicokolter presenting the best paper award in the defense series on provable defenses against adversarial examples‚Ä¶
939243749380563000,Fri Dec 08 21:22:14 +0000 2017,@pksahu_sahu We will have a chapter in the NIPS book but it‚Äôs not out yet. The code is posted in the contest forum
939227500680429600,Fri Dec 08 20:17:40 +0000 2017,#nips2017 I will speak at the machine learning and security workshop at 1:30 PM in the Shoreline Room of Hyatt Rege‚Ä¶ https://t.co/3m8OGYmv8Y
939202124516229100,Fri Dec 08 18:36:50 +0000 2017,#nips2017 At 11am in Hyatt Regency Seaview I‚Äôm doing a talk on GANs for Creativity and Design https://t.co/Iezqubztux
939194604116525000,Fri Dec 08 18:06:57 +0000 2017,#NIPS2017 Cihang Xie presenting the runner-up defense: randomization at test time https://t.co/FMAmTIxkDB
939192351070732300,Fri Dec 08 17:58:00 +0000 2017,#nips17 Fangzhou Liao presenting the winning defense: denoising adversarial images before classification https://t.co/GiOz1rgKTx
939191951684857900,Fri Dec 08 17:56:25 +0000 2017,#NIPS2017 adversarial example competition: winning attack adds momentum to FGSM, the resulting attacks transfer bet‚Ä¶ https://t.co/CiocaduFio
939183395468275700,Fri Dec 08 17:22:25 +0000 2017,RT @Kaaz1992K: Make your trained model more robust to adversarial attacks with no fine-tuning using basic game theoric principles. Stop by‚Ä¶
939183213112463400,Fri Dec 08 17:21:41 +0000 2017,#NIPS2017 Dawn Song sets the stage for the adversarial example competition by explaining why adversarial examples a‚Ä¶ https://t.co/bgF0ir0bvL
939170973189775400,Fri Dec 08 16:33:03 +0000 2017,Adversarial example competition in &lt;30 minutes https://t.co/49voaiy7Sa
939012167763771400,Fri Dec 08 06:02:01 +0000 2017,#NIPS2017 Come see the winners of the adversarial example competition, Friday morning 9-10:30 AM in 103a+b https://t.co/3pV813QdrP
938977624616927200,Fri Dec 08 03:44:45 +0000 2017,RT @benhamner: It‚Äôs embarrassing and infuriating that some #NIPS2017 authors couldn‚Äôt get visas to present their work. USA should be leadin‚Ä¶
938889206583009300,Thu Dec 07 21:53:25 +0000 2017,#WIML #WiML2017 Generative modeling mentoring starts in &lt; 30 minutes https://t.co/TxobbHRPA9
938830405905477600,Thu Dec 07 17:59:46 +0000 2017,RT @fightfortheftr: MIT Tech Review: Killing #NetNeutrality will harm innovation in the US https://t.co/dWeafP0CF8
938601997611229200,Thu Dec 07 02:52:09 +0000 2017,#WiML2017 #wiml #NIPS #NIPS2017 I'll moderate the discussion at the WIML mentorship table on generative models, Tab‚Ä¶ https://t.co/9jLJInqBHy
938583196660150300,Thu Dec 07 01:37:26 +0000 2017,@negar_rz @vkrakovna It was during the 3:50-4:20 coffee break
938579736757809200,Thu Dec 07 01:23:41 +0000 2017,RT @BW: A look into the life of Geoffrey Hinton, the world's preeminent expert in AI. He is being recognized a this year‚Äôs #Bloomberg50 htt‚Ä¶
938573995472928800,Thu Dec 07 01:00:53 +0000 2017,@vkrakovna No RL in the book :( so no cherry in the cake
938554659051941900,Wed Dec 06 23:44:02 +0000 2017,#NIPS #NIPS2017 Cake! https://t.co/mPKLXr4E91
938551443547603000,Wed Dec 06 23:31:16 +0000 2017,#NIPS #NIPS2017 cake in 20 minutes https://t.co/7b0pVaRNoj
938434122917097500,Wed Dec 06 15:45:04 +0000 2017,#NIPS #NIPS2017 @mitpress is bringing a cake to celebrate 1 year of the Deep Learning textbook. Come meet us at the‚Ä¶ https://t.co/ewG5uVgC5l
938228423981330400,Wed Dec 06 02:07:42 +0000 2017,RT @starsandrobots: RT if a connection you've made at a technical conference has ever significantly impacted your career.
938228203688140800,Wed Dec 06 02:06:49 +0000 2017,@CelestialPearl Yes, it is machine-made. A computer program has studied thousands of pictures of cats in order to l‚Ä¶ https://t.co/BjFmhA0jkW
938206812284715000,Wed Dec 06 00:41:49 +0000 2017,@algasoss @QUOTELOBSTER It's actually Lasagne not Keras
938077032738459600,Tue Dec 05 16:06:07 +0000 2017,Video modeling with GANs, no need to assume the background is stationary: https://t.co/nR7UYJCBwJ
937935358892769300,Tue Dec 05 06:43:10 +0000 2017,@BorealisAI Where can I get one?
937932241966997500,Tue Dec 05 06:30:47 +0000 2017,@spider0306 It‚Äôs in our paper ‚ÄúExplaining and Harnessing Adversarial Examples‚Äù.
937837489783320600,Tue Dec 05 00:14:16 +0000 2017,RT @WonderMicky: My poster at #WiML2017! If you didn‚Äôt manage to attend our poster session today, get in touch to ask me about my work on #‚Ä¶
937777270197854200,Mon Dec 04 20:14:58 +0000 2017,@fchollet It could mean that the people who disagree with you think that they might suffer some kind of retribution‚Ä¶ https://t.co/05g32qKLGQ
937776916899102700,Mon Dec 04 20:13:34 +0000 2017,RT @WiMLworkshop: #WiML2017 full room. Thanks to @ta_broderick for her amazing talk at @WiMLworkshop #NIPS2017 https://t.co/64AobezHbZ
937725887998435300,Mon Dec 04 16:50:48 +0000 2017,@ergodicwalk @mrtz  https://t.co/JmFVel0R7Y
937714580213477400,Mon Dec 04 16:05:52 +0000 2017,RT @AlexandruAmalia: What I learned at #SOCML? 1.Capsule networks 2.@goodfellow_ian throws one diverse conference üôè
937714480682754000,Mon Dec 04 16:05:28 +0000 2017,RT @NicolasPapernot: Had a great time discussing privacy in ML, how to define what an adversarial example is, and learned a bunch about eth‚Ä¶
937540916234948600,Mon Dec 04 04:35:47 +0000 2017,@doomie Oh maybe it was 2012
937537580001665000,Mon Dec 04 04:22:32 +0000 2017,@doomie Remembering NIPS 2013 is this a good idea?
937520167625429000,Mon Dec 04 03:13:20 +0000 2017,RT @sh_reya: Come check out our poster at #NIPS2017 Machine Learning for the Developing World workshop! https://t.co/qqjIOP1zoK
937517525335621600,Mon Dec 04 03:02:50 +0000 2017,@deborahhanus @zacharylipton Thank you for participating!
937516760105861100,Mon Dec 04 02:59:48 +0000 2017,@QUOTELOBSTER @gwern  https://t.co/g9sGpvVpuD
937459142045851600,Sun Dec 03 23:10:51 +0000 2017,@tarinziyaee Yes but see ‚ÄúA Note on the Evaluation of Generative Models‚Äù by @lucastheis et al for an explanation of‚Ä¶ https://t.co/LkuwGAfQL5
937408813086392300,Sun Dec 03 19:50:51 +0000 2017,@QUOTELOBSTER I don't know what language was in the training set, though it does look a bit like maybe one that has‚Ä¶ https://t.co/jqb7BrV6Lo
937408068119183400,Sun Dec 03 19:47:54 +0000 2017,@octonion Albert Camacho had a poster like that at #SOCML a few days ago
937406530743287800,Sun Dec 03 19:41:47 +0000 2017,One of my favorite samples from the Progressive GANs paper is this one from the "cat" category. Apparently some of‚Ä¶ https://t.co/fRSS0F7Jsg
937167241052696600,Sun Dec 03 03:50:56 +0000 2017,RT @heysarahsweeney: PLEASE call 1-202-418-1000 to reach the voicemail of the Chairman of the FCC. Say your name, city, and state and that‚Ä¶
937166239436218400,Sun Dec 03 03:46:57 +0000 2017,@Smerity @hardmaru One of the biggest problem with traditional review is that papers are evaluated by 3ish randomly‚Ä¶ https://t.co/Bxy7LbraXJ
937165839240904700,Sun Dec 03 03:45:22 +0000 2017,@Smerity @hardmaru You should resist the urge to sway discussion in favor of your friends‚Äô papers but if you suppor‚Ä¶ https://t.co/fpM3eZ0ol9
937165614744879100,Sun Dec 03 03:44:28 +0000 2017,@Smerity @hardmaru You‚Äôre not supposed to resist that urge. A large part of the point of open review is that anyone‚Ä¶ https://t.co/EG2hdmGOeB
937158227728384000,Sun Dec 03 03:15:07 +0000 2017,RT @irenetrampoline: Loving the loosely organized format of #SOCML organized by @goodfellow_ian. Great sessions and great crowd. See below‚Ä¶
937119221548326900,Sun Dec 03 00:40:07 +0000 2017,@Smerity Geoff Hinton has done this, for example in the dropout paper. In that case I think the plot plays a useful‚Ä¶ https://t.co/nddazZbcYl
937117420396822500,Sun Dec 03 00:32:58 +0000 2017,RT @zacharylipton: Tks @goodfellow_ian for meta-organizing awesome #socml! Takeaways: 1. Big picture issues better for unconf (vs technical‚Ä¶
937114290930118700,Sun Dec 03 00:20:32 +0000 2017,RT @mmitchell_ai: Amazing time at #socml. We dug into generatin human-like adversarial examples (The Dress), evaluating machine bias, AI Et‚Ä¶
937056956186992600,Sat Dec 02 20:32:42 +0000 2017,@hannawallach Sunday night
937051273206960100,Sat Dec 02 20:10:07 +0000 2017,@vukosi Thank you for participating!
937051216755900400,Sat Dec 02 20:09:54 +0000 2017,RT @vukosi: Very thankful for the time spent at #SOCML. We continue the journey to share our work, our stories and our networks. Enjoyed th‚Ä¶
936783935886975000,Sat Dec 02 02:27:49 +0000 2017,RT @karpathy: Wow, GANs are on a roll. Quite amazing results from pix2pixHD: https://t.co/sJUNWiWd9i Also the most tangible glimpse so far‚Ä¶
936621027471196200,Fri Dec 01 15:40:29 +0000 2017,@ethancaballero @soumithchintala @realDonaldTrump Donald Trump tries to keep discussion on twitter and make it infl‚Ä¶ https://t.co/rsL98LdMzi
936616806348832800,Fri Dec 01 15:23:42 +0000 2017,@jeremyphoward @soumithchintala OK, Soumith agreed. We‚Äôll discuss at NIPS, not tweet about it until then, but share conclusions after
936616249303351300,Fri Dec 01 15:21:29 +0000 2017,@jeremyphoward @soumithchintala I‚Äôm fine with sharing things openly once we reach a good conclusion but twitter is‚Ä¶ https://t.co/w4Kue1gshr
936616027252711400,Fri Dec 01 15:20:37 +0000 2017,@jeremyphoward @soumithchintala I‚Äôve proposed that we all meet at NIPS and discuss it rather than tweet.
936463823032033300,Fri Dec 01 05:15:48 +0000 2017,2 megapixel GANs: https://t.co/98VGmrYniL
936459469923352600,Fri Dec 01 04:58:30 +0000 2017,@martin_trapp Yes
936459383067705300,Fri Dec 01 04:58:10 +0000 2017,@AkshayGoelMD @drsxr For generative models the train / test split is messy because you develop the model by looking‚Ä¶ https://t.co/UKrkJesASo
936080005154484200,Thu Nov 30 03:50:39 +0000 2017,@zacharylipton There‚Äôs plenty of the reverse, deep learning about anime: https://t.co/TynvL0DlUa
936070170404995100,Thu Nov 30 03:11:34 +0000 2017,@haldaume3 @guyvdb @roydanroy Lol
936067787063099400,Thu Nov 30 03:02:06 +0000 2017,@drsxr @hardmaru The situation is actually worse than p-hacking. More of measuring and hacking the single best resu‚Ä¶ https://t.co/HLxStloU7w
935994508444971000,Wed Nov 29 22:10:55 +0000 2017,@roydanroy @guyvdb Yeah, it should be a sanity check, not the main selling point of the paper
935994208166412300,Wed Nov 29 22:09:43 +0000 2017,@soumithchintala I haven't read the final public version of the paper, but I discussed this work with the authors b‚Ä¶ https://t.co/r1YjjRQ4Rw
935978916279238700,Wed Nov 29 21:08:57 +0000 2017,@_amirbar It's worse for GANs and RL because the metrics aren't as crystal clear as for classifiers. Accuracy is co‚Ä¶ https://t.co/UysAVx5jIm
935978568902959100,Wed Nov 29 21:07:35 +0000 2017,@jmhessel I don't think a winter is imminent because there is still a lot of great work going on (in the case of GA‚Ä¶ https://t.co/NIqpBbq0Yx
935934544892407800,Wed Nov 29 18:12:38 +0000 2017,@antor @hardmaru @SussilloDavid @collinsljas @jaschasd I don't know of one. But I don't think the point is "everyon‚Ä¶ https://t.co/f7QPpvIjFD
935934253530886100,Wed Nov 29 18:11:29 +0000 2017,@jsylvest Well it's glamorous to me but I'm weird
935919958977941500,Wed Nov 29 17:14:41 +0000 2017,@ljbuturovic I actually think peer review sometimes *increases* this problem because reviewers reject papers for be‚Ä¶ https://t.co/GZ68LpryLR
935919345825300500,Wed Nov 29 17:12:15 +0000 2017,@unsorsodicorda @ljbuturovic Yes, @catherineols , who helped demonstrate the reproducibility problem in psychology,‚Ä¶ https://t.co/kVReAkgl2s
935915670801281000,Wed Nov 29 16:57:39 +0000 2017,@GiorgioPatrini FWIW, many of the papers citing the original GAN paper *are* improvements or extend GANs to solve n‚Ä¶ https://t.co/Jmvmm9fb9m
935914727733043200,Wed Nov 29 16:53:54 +0000 2017,@hardmaru @SussilloDavid @collinsljas @jaschasd It also reminds me of https://t.co/couzHkDL8Z  For both GANs and RL‚Ä¶ https://t.co/SF8eBpZb49
935914049325350900,Wed Nov 29 16:51:12 +0000 2017,@guyvdb @roydanroy I *would* vote for a ban on using pictures of tasks that are already very solved to argue that a‚Ä¶ https://t.co/HAATrioibH
935911917901639700,Wed Nov 29 16:42:44 +0000 2017,@guyvdb @roydanroy I also vote no because the quantitative metrics of sample quality are not that great yet
935911734807748600,Wed Nov 29 16:42:00 +0000 2017,@guyvdb @roydanroy I vote no. I actually think one of the best ways to argue that a new generative model is an impr‚Ä¶ https://t.co/XaZxMKR5u8
935903131447181300,Wed Nov 29 16:07:49 +0000 2017,@hardmaru @hichaelmart Ironically, a lot of these papers didn‚Äôt claim SOTAs. They claimed increased robustness to h‚Ä¶ https://t.co/lwvEPtLLVT
935901888062431200,Wed Nov 29 16:02:52 +0000 2017,@roydanroy This is more about doing empirical work correctly. Actually I would say a big problem this year has been‚Ä¶ https://t.co/nBbRKVGYkz
935886522607272000,Wed Nov 29 15:01:49 +0000 2017,ML researchers, reviewers, and press coverage of ML need to get a lot more serious about statistically robustness o‚Ä¶ https://t.co/SEJQlscAdm
935886101427798000,Wed Nov 29 15:00:09 +0000 2017,Some totally new GAN structures like StackGAN, Progressive GAN, CycleGAN, etc., are real advances, but this exhaust‚Ä¶ https://t.co/Y0FzzBJwlT
935742970493620200,Wed Nov 29 05:31:24 +0000 2017,@brthornbury Include the - . Twitter parsed it wrong
935376396267937800,Tue Nov 28 05:14:45 +0000 2017,StarGAN: learning one model that translates between *multiple* domains without supervision (previous works were abo‚Ä¶ https://t.co/hjwwxZHvhA
935367975720202200,Tue Nov 28 04:41:18 +0000 2017,@jfgagne @timnitGebru @sgouws @shakir_za
935367072049008600,Tue Nov 28 04:37:42 +0000 2017,@ppujari @WiMLworkshop I'm not a WIML organizer but I think not due to the format (people wandering around to many‚Ä¶ https://t.co/K7qsaucYUY
935321620603748400,Tue Nov 28 01:37:06 +0000 2017,I'll moderate the discussion at the mentorship table on Generative Models at @WiMLworkshop Thu Dec 7 2:20-3:20 PM. https://t.co/9GSsQkD4lf
935274858044203000,Mon Nov 27 22:31:17 +0000 2017,RT @colinraffel: A video of my talk "Doing Strange Things with Attention" which I gave at AI @WithTheBest in October is now online: https:/‚Ä¶
935261476041850900,Mon Nov 27 21:38:06 +0000 2017,@deborahhanus @astroVAV @AaronCourville It took us years of writing, 1-2 pages or sometimes sentences at a time :)
934949714398793700,Mon Nov 27 00:59:17 +0000 2017,@poolio There‚Äôs a difference between ‚Äúin this work we investigate whether X and Y work together and it turns out th‚Ä¶ https://t.co/cPCJz7PyJc
934805277064310800,Sun Nov 26 15:25:20 +0000 2017,@DaniCMBelg @WiMLworkshop @jennwvaughan An important new lower bound: 280 &lt; K(WIML excitement)
934804659113312300,Sun Nov 26 15:22:53 +0000 2017,RT @DaniCMBelg: 280 characters are insufficient to express how excited we are that @WiMLworkshop !starts in 1 week!!!!! We have an amazing‚Ä¶
934596106553454600,Sun Nov 26 01:34:10 +0000 2017,RT @junyanz89: For those who missed the horse2zebra live demo at ICCV tutorial on GANs, here is the video: https://t.co/JVV8uI0wP9  @philli‚Ä¶
934555332344299500,Sat Nov 25 22:52:09 +0000 2017,@sh_reya Maybe better software could make the laptop-&gt;cloud connection more seamless. User doesn‚Äôt invoke tmux but‚Ä¶ https://t.co/eWz6Zdg3ff
934471044542357500,Sat Nov 25 17:17:13 +0000 2017,Re-Work has prepared a whitepaper on whether you should use AI in your business. My contribution is: the availabili‚Ä¶ https://t.co/7CkyHRecFj
934176398004052000,Fri Nov 24 21:46:24 +0000 2017,@praneetx Seems worth trying
933791425321345000,Thu Nov 23 20:16:39 +0000 2017,@_omarshams_ Passwords have no function other than to be unique and hard to guess. Neural net weights have a primar‚Ä¶ https://t.co/r7WQpVKQxI
933791034495995900,Thu Nov 23 20:15:06 +0000 2017,@_omarshams_ No, there are other strategies that work with no access to the model.  https://t.co/OU25r0oKED   https://t.co/TegyIvmVFf
933789929661874200,Thu Nov 23 20:10:42 +0000 2017,@unsorsodicorda @rasbt @jeremyphoward @fhuszar I‚Äôve seen it but haven‚Äôt read it in detail yet. Do they actually com‚Ä¶ https://t.co/aNjhfIRmhK
933788013900963800,Thu Nov 23 20:03:06 +0000 2017,@_omarshams_ It is in principle possible to make a perfect classifier that can‚Äôt be fooled.l, but very unlikely to‚Ä¶ https://t.co/vXpAVI34PV
933787756999753700,Thu Nov 23 20:02:04 +0000 2017,@_omarshams_ ‚ÄúSpace of images people care about‚Äù is a lot bigger when you need to provide security (because you car‚Ä¶ https://t.co/mr1iZweZ54
933752455304699900,Thu Nov 23 17:41:48 +0000 2017,@ajlavin @unsorsodicorda @fhuszar @rasbt @jeremyphoward You can try it out by modifying the CleverHans tutorial
933740675828293600,Thu Nov 23 16:54:59 +0000 2017,@rasbt @fhuszar @unsorsodicorda @jeremyphoward You don‚Äôt need adversarial examples to fool traditional computer vision
933739113072562200,Thu Nov 23 16:48:47 +0000 2017,@fhuszar @unsorsodicorda @rasbt @jeremyphoward It works even if the defender isn‚Äôt a neural network
933738434996289500,Thu Nov 23 16:46:05 +0000 2017,@unsorsodicorda @fhuszar @rasbt @jeremyphoward Or you can directly use gradient-free optimization on the target mod‚Ä¶ https://t.co/ktTXm3VrVe
933738179638603800,Thu Nov 23 16:45:04 +0000 2017,@unsorsodicorda @fhuszar @rasbt @jeremyphoward The attacker can train their own neural net to mimic the black box d‚Ä¶ https://t.co/9X2ECwbqdG
933732471153107000,Thu Nov 23 16:22:23 +0000 2017,@rasbt @unsorsodicorda @jeremyphoward @fhuszar See ‚ÄúEnsemble Adversarial Training‚Äù, the code for which was used by‚Ä¶ https://t.co/1xMVIrN6re
933730815502049300,Thu Nov 23 16:15:48 +0000 2017,@unsorsodicorda @rasbt @jeremyphoward @fhuszar See the experiments on blurring in ‚ÄúAdversarial Examples in the Phys‚Ä¶ https://t.co/EkFsDSiZ6g
933530941854593000,Thu Nov 23 03:01:35 +0000 2017,@andresvourakis Twitter parsed the link wrong. You have to include the -
933176678121054200,Wed Nov 22 03:33:52 +0000 2017,RT @abhshkdz: Adversarial training + REINFORCE for Visual Dialog https://t.co/uHrol2z45r Nice results! State-of-the-art on VisDial https://‚Ä¶
933052759179276300,Tue Nov 21 19:21:27 +0000 2017,@JTremoureux @joelgrus @benhamner https://t.co/OCllCxe23p https://t.co/WZjDPGMuqE
932808988873199600,Tue Nov 21 03:12:48 +0000 2017,@hiconcep Add a - to the URL. Twitter parsed it wrong
932803646122737700,Tue Nov 21 02:51:34 +0000 2017,@Wihanbooyse Check out the AC-GAN paper. For too many classes, the model collapses disastrously. We are not really‚Ä¶ https://t.co/rxbnOHqr3G
932777404686245900,Tue Nov 21 01:07:18 +0000 2017,RT @D_Berthelot_ML: My new record "Latent Space" is out!!! https://t.co/ecwxHcKkf1 ‚Ä¶ @mat_kelcey @recursix https://t.co/aHFrUFAwG8
932733629641322500,Mon Nov 20 22:13:21 +0000 2017,Does twitter offer a user interface element that makes it possible to tweet the following URL?‚Ä¶ https://t.co/ipDnICWRlO
932732571019911200,Mon Nov 20 22:09:08 +0000 2017,@sedielem Yes. Fr√©chet Inception Distance is probably better. I imagine you could use this paper to game even FID t‚Ä¶ https://t.co/esxmb6ZuM2
932730613131391000,Mon Nov 20 22:01:22 +0000 2017,@sigfpe @noop_noob Well, obviously. They're Presian. &lt;/s&gt;
932728419640492000,Mon Nov 20 21:52:39 +0000 2017,While GANs have been great at generating realistic images from a single category (one GAN for faces, another GAN fo‚Ä¶ https://t.co/x6N2IQ9Vqa
932015506013372400,Sat Nov 18 22:39:47 +0000 2017,@azeem @iandanforth OK, that makes sense. Will be interesting to see if the app stays fast after its user base has had some time to grow
932007957834874900,Sat Nov 18 22:09:47 +0000 2017,@azeem @iandanforth I see. I didn't understand that the ad was for a newly launched service. If the high NHS wait t‚Ä¶ https://t.co/1az9f4XW4O
932007579743535100,Sat Nov 18 22:08:17 +0000 2017,@cournape @iandanforth I don't have personal experience with the NHS; I've just read the press articles about it like the one I linked.
932007286121234400,Sat Nov 18 22:07:07 +0000 2017,@biggiobattista @ICCV2017 Thanks!
931776356668411900,Sat Nov 18 06:49:29 +0000 2017,@iandanforth The average wait time to see an NHS GP is actually about two weeks, certainly not minutes. https://t.co/nOwjttZrf8
931751317629894700,Sat Nov 18 05:09:59 +0000 2017,RT @PHDcomics: Spread the word - Links at the bottom here: https://t.co/JIrELJ0M6i https://t.co/xqfqA9JMB2
931736932245160000,Sat Nov 18 04:12:50 +0000 2017,RT @AndrewYNg: It's not right for PhD programs to be accessible only to rich families. The current US proposal to tax tuition forgiveness i‚Ä¶
931651834065821700,Fri Nov 17 22:34:41 +0000 2017,@sashank06 @dennybritz @iamtrask @sirajraval @ylecun The proposal to tax grad student waivers is clearly terrible.‚Ä¶ https://t.co/93uiQnvng3
931560452978384900,Fri Nov 17 16:31:34 +0000 2017,@dwf Post a comment with @fermatslibrary ‚Äòs Librarian
931559454079729700,Fri Nov 17 16:27:36 +0000 2017,@theNikhilDev See ‚ÄúA note on the evaluation of generative models‚Äù by @lucastheis et al. It‚Äôs possible to generate r‚Ä¶ https://t.co/hLqAASi8O8
931275926968582100,Thu Nov 16 21:40:57 +0000 2017,Check out @fermatslibrary 's Librarian, a Chrome extension that automatically shows comments for ArXiv papers:‚Ä¶ https://t.co/u53kcT4LoO
931172327106084900,Thu Nov 16 14:49:17 +0000 2017,@javageek63 It‚Äôs worth trying out
931172057043279900,Thu Nov 16 14:48:13 +0000 2017,@Jovonni For both GANs and VAEs, their abilities today are probably very limited compared to their abilities a few years from now
931166498978070500,Thu Nov 16 14:26:08 +0000 2017,GANs for personalized "predictive fashion": https://t.co/m1BFiXJfi4
931016560277196800,Thu Nov 16 04:30:20 +0000 2017,RT @emsque: If my graduate tuition waiver had been taxed I would not have been able to afford to get my degree. I would not have the job I‚Ä¶
931011283507232800,Thu Nov 16 04:09:21 +0000 2017,RT @_AntreasAntonio: Check out our latest Data Augmentation GAN paper. https://t.co/BDLlX1WmZ3 https://t.co/thsQLSVJC1
930975069492224000,Thu Nov 16 01:45:27 +0000 2017,@IntuitMachine Keep in mind we do this only at the input layer. We still rely on continuous values and backprop thr‚Ä¶ https://t.co/q4kLM79L17
930974419630952400,Thu Nov 16 01:42:52 +0000 2017,@furlanel It's possible that black-box ensemble adversarial training would even be *better* (our black box results‚Ä¶ https://t.co/UP9xqEU1p7
930973835246968800,Thu Nov 16 01:40:33 +0000 2017,@poolio Yes, one big caveat is definitely that our white box results might be overly optimistic if we're just not v‚Ä¶ https://t.co/rXZlqHHQeW
930973004678381600,Thu Nov 16 01:37:15 +0000 2017,@roydanroy Are you anticipating that they'll think it's biologically plausible (some part of the nervous system use‚Ä¶ https://t.co/rzhmVjQXxG
930946493887914000,Wed Nov 15 23:51:54 +0000 2017,@furlanel Oh, I see what you mean. Yes, to make the adversarial example you do need some way to optimize over the d‚Ä¶ https://t.co/8fXGHNhlj8
930945359269937200,Wed Nov 15 23:47:24 +0000 2017,@twelshed I think not because all the spikes in a spike train still affect the same set of synapses. The key of thi‚Ä¶ https://t.co/rv9abNriqR
930943400978686000,Wed Nov 15 23:39:37 +0000 2017,@biggiobattista We haven't experimented much with different norms because it's hard to guarantee that class changes‚Ä¶ https://t.co/PqmkuNLMv3
930942560184426500,Wed Nov 15 23:36:17 +0000 2017,@biggiobattista For Fig 8, keep in mind that it's not quite an apples to apples comparison (discrete optimizer vs c‚Ä¶ https://t.co/oVsOnQlQEl
930937746029293600,Wed Nov 15 23:17:09 +0000 2017,@kcimc Thermometer worked the best for us: more robustness to adversarial examples, trains faster (when training on adversarial examples)
930937224798994400,Wed Nov 15 23:15:05 +0000 2017,@furlanel Actually there's no need to backprop through the encoding, because it's at the input of the model, before‚Ä¶ https://t.co/TiPhZIEqop
930931086938423300,Wed Nov 15 22:50:41 +0000 2017,@Miles_Brundage I like the title a lot too! It was @colinraffel 's idea
930928286582022100,Wed Nov 15 22:39:33 +0000 2017,Thermometer encoding has closed most of the accuracy gap for strong, iterative white-box adversarial examples on SV‚Ä¶ https://t.co/CdeUBCuon6
930783943120470000,Wed Nov 15 13:05:59 +0000 2017,RT @Smerity: @jeremyphoward @seb_ruder @yoavgo I feel adversarial training methods might be less used than they could be for "dataset augme‚Ä¶
930186453463609300,Mon Nov 13 21:31:47 +0000 2017,RT @dyobs: #ai #security - ensemble #adversarial training &amp; gradient masking  @GeekPwn @ComputerHistory @kaggle competition https://t.co/Yw‚Ä¶
929857203363758100,Sun Nov 12 23:43:27 +0000 2017,@LoveStats While this panel could stand to be more diverse, it does include Emily Denton
929416334869278700,Sat Nov 11 18:31:36 +0000 2017,@elionaimc @_ambodi There is hardware support for float64 but it‚Äôs typically significantly slower
929397067826393100,Sat Nov 11 17:15:02 +0000 2017,@javageek63 https://t.co/0Y9aam0MnF
929396260804501500,Sat Nov 11 17:11:50 +0000 2017,@spiantino @_ambodi I think float32 is still the most popular but custom half precision works well. The fewer bits‚Ä¶ https://t.co/nedLG7svUp
929393827059662800,Sat Nov 11 17:02:10 +0000 2017,10 minutes of ganime: https://t.co/R2bllerEAk
929392464816848900,Sat Nov 11 16:56:45 +0000 2017,@_mb46_ @_ambodi Just watch https://t.co/7XNSKxFkQ1
929381439119884300,Sat Nov 11 16:12:56 +0000 2017,@_ambodi Another downside to float64 is 2X memory consumption
929165600772915200,Sat Nov 11 01:55:16 +0000 2017,RT @shakir_za: The .@googleresearch PhD fellowship awards have been extended to include Africa. Please encourage good applicants to apply!‚Ä¶
928766169799995400,Thu Nov 09 23:28:05 +0000 2017,@fulhack @kdnuggets I feel like this chart is trying to make it hard. All you need is p(x_{n+1} | x_1, ..., x_n) =‚Ä¶ https://t.co/pYYpnAzaVe
928765070569386000,Thu Nov 09 23:23:43 +0000 2017,RT @andrewgwils: Our paper, the Bayesian GAN, is appearing as a spotlight at #nips2017!  https://t.co/4CPnHIrrlk +code! https://t.co/9tvbDe‚Ä¶
928743407991664600,Thu Nov 09 21:57:38 +0000 2017,@HiteshUVaidya @sirajraval Maybe, but it‚Äôs been difficult to generate discrete data so far
928609702866546700,Thu Nov 09 13:06:20 +0000 2017,RT @GeekPwn: Last year, Alexey Kurakin &amp; @goodfellow_ian came to #GeekPwn with "Adversarial Examples in the Physical World". https://t.co/v‚Ä¶
928421075117117400,Thu Nov 09 00:36:48 +0000 2017,@Mithun_Aggarwal @TensorFlow @Sydney_Uni @Eng_IT_Sydney @SydneyUni_Media @googleresearch One of the first programs‚Ä¶ https://t.co/RyWjxKL6Uj
928362061285003300,Wed Nov 08 20:42:18 +0000 2017,RT @googleresearch: See the GraspGAN in action  https://t.co/U4DhPUjU6E
928362021120290800,Wed Nov 08 20:42:08 +0000 2017,RT @googleresearch: Have you ever wondered what goes on inside #NeuralNetworks? Learn how @distillpub explores feature visualization at htt‚Ä¶
928324918193860600,Wed Nov 08 18:14:42 +0000 2017,RT @mtyka: Will be presenting on ML Generative Art (DeepDream, GAN Portraits, Archive Dreaming) at the AI Art and Aesthetics Symposium in O‚Ä¶
928255026459562000,Wed Nov 08 13:36:59 +0000 2017,RT @fightfortheftr: What  if  the  Internet  was  so  slow  and  throttled  that  everything  loaded  one  word  at  a  time  and  it  took‚Ä¶
928034020289581000,Tue Nov 07 22:58:47 +0000 2017,RT @techreview: Innovator Under 35 @goodfellow_ian invented a way for neural networks to get better by working together: https://t.co/bq86k‚Ä¶
927965001129824300,Tue Nov 07 18:24:31 +0000 2017,RT @genekogan: running face recognition over that one-hour video of GAN-generated celebrity faces released by @NvidiaAI last week (https://‚Ä¶
927964656769142800,Tue Nov 07 18:23:09 +0000 2017,@AndrewYNg Thanks!
927708059597721600,Tue Nov 07 01:23:32 +0000 2017,RT @sarahookr: Our work shows the explanations of a model prediction can be mislead by simple input transformations to show a cat.  https:/‚Ä¶
927374820563615700,Mon Nov 06 03:19:21 +0000 2017,Part of why I like @WithTheBest is that it doesn‚Äôt require travel-related carbon emissions to participate https://t.co/WIcipCoGXA
927350823998427100,Mon Nov 06 01:44:00 +0000 2017,@Ritwik_G I might come by next year while I‚Äôm in the general area for @NicolasPapernot ‚Äòs thesis defense
927094083939684400,Sun Nov 05 08:43:48 +0000 2017,@dribnet @hardmaru The problem is too many methods that fall apart on real data work fine on MNIST
926769449679470600,Sat Nov 04 11:13:50 +0000 2017,@hardmaru Why MNIST? There‚Äôs no interesting variation in performance on it anymore. A subset of SVHN can be just as fast but more realistic
926769211145252900,Sat Nov 04 11:12:53 +0000 2017,@hardmaru Notebooks are usually just an extra layer or two of config hell
926531652733620200,Fri Nov 03 19:28:54 +0000 2017,@jannesklaas Hard G, rhymes with ‚Äúcan‚Äù. But I‚Äôm fine with variations
925796649057833000,Wed Nov 01 18:48:16 +0000 2017,@lewisshepherd @NicolasPapernot https://t.co/Rzwb9baTrc
925796504144633900,Wed Nov 01 18:47:41 +0000 2017,@lewisshepherd @NicolasPapernot https://t.co/qSYz1aYQZ8 (Used by all the top entries in the NIPS contest)
925796320744476700,Wed Nov 01 18:46:57 +0000 2017,@lewisshepherd @NicolasPapernot https://t.co/x4UCNFn64I
925796192449171500,Wed Nov 01 18:46:27 +0000 2017,@lewisshepherd @NicolasPapernot Can‚Äôt guarantee we will write a new blog post but there have been some good advances this year
925445656856195100,Tue Oct 31 19:33:33 +0000 2017,TensorFlow launches Easy Mode... I mean, Eager Mode https://t.co/lwZrDO8uLU
925107590123737100,Mon Oct 30 21:10:11 +0000 2017,ICLR submissions are welcome at the NIPS Machine Deception workshop. Submissions close Wednesday. https://t.co/VyngWgGP9t
925103416375902200,Mon Oct 30 20:53:36 +0000 2017,An hour of GAN interpolation: https://t.co/Nxf7VW9pH9
924921005570711600,Mon Oct 30 08:48:46 +0000 2017,@AlisonBLowndes @AndrewYNg Definitely! I tweeted the progressive GANs video over the weekend
924715091995525100,Sun Oct 29 19:10:32 +0000 2017,RT @NicolasPapernot: NIPS ML and Security workshop deadline Fri Nov 3. We welcome your relevant Oakland and ICLR submissions! CFP here: htt‚Ä¶
924293252018294800,Sat Oct 28 15:14:18 +0000 2017,@divyanshkhanna1 @therumsticks The dataset is only celebrities, so not a very large / diverse training set
924232704887050200,Sat Oct 28 11:13:42 +0000 2017,@RobertoParPal Wow!
924172383266754600,Sat Oct 28 07:14:01 +0000 2017,@Kaaz1992K @AnimaAnandkumar @zacharylipton which results specifically?
924172237783097300,Sat Oct 28 07:13:26 +0000 2017,Impressive high-res GAN results! https://t.co/iwRC1UjkwN (Maybe jump to 2:00 or 4:30)
923955541818396700,Fri Oct 27 16:52:22 +0000 2017,@rgov @johnregehr Random perturbation is common too. A lot of the time people do it and don‚Äôt bother to mention it‚Ä¶ https://t.co/LkPUZ30mok
923602716466614300,Thu Oct 26 17:30:21 +0000 2017,@yoavgo  https://t.co/wglXTHsic0
923576574112251900,Thu Oct 26 15:46:29 +0000 2017,RT @WonderMicky: All #HEPML/#MLHEP ppl: go see @goodfellow_ian's talk on #GANs @CERN tmrw! Live webcast on page for CERNies abroad https://‚Ä¶
923514709663473700,Thu Oct 26 11:40:39 +0000 2017,@yusssk 2/2) that, we highly encourage candidates with non-traditional backgrounds and experiences from all over th‚Ä¶ https://t.co/G0JWiMb1HI
923514646388269000,Thu Oct 26 11:40:24 +0000 2017,@yusssk 1/2) "Ideal candidate either has a degree (BS, MS or PhD) or equivalent experience in STEM field such as CS‚Ä¶ https://t.co/Yyp0WLiACz
923472903252922400,Thu Oct 26 08:54:32 +0000 2017,Applications for the 2018 Google AI Residency Program are open.  If you want to learn to do deep learning research‚Ä¶ https://t.co/fBWckTvtsP
923292031954296800,Wed Oct 25 20:55:49 +0000 2017,@biggiobattista @ICCV2017 Christian's work was on arxiv as of 2013, not 2014. https://t.co/OU25r0oKED He showed it‚Ä¶ https://t.co/9uC4VQFwgz
923142737679077400,Wed Oct 25 11:02:34 +0000 2017,RT @balajiln: Check out our new paper with @elaClaudia, @shakir_za and @goodfellow_ian https://t.co/SMtTYb6Xr3
922903941146402800,Tue Oct 24 19:13:40 +0000 2017,@tranlaman Sorry, I‚Äôve already left the conference
922891514602278900,Tue Oct 24 18:24:18 +0000 2017,@itamblyn Thanks, will let you know. I love Ottawa but I don‚Äôt get much time to travel
922891366392266800,Tue Oct 24 18:23:42 +0000 2017,RT @junyanz89: Horse2Zebra live demo at ICCV 2017 tutorial on GANs. Horse mask is the most animal-friendly way. @phillip_isola @goodfellow_‚Ä¶
922885454428504000,Tue Oct 24 18:00:13 +0000 2017,RT @hardmaru: StackGAN-v2 looks impressive. https://t.co/rRITIZMWVn
922864286447398900,Tue Oct 24 16:36:06 +0000 2017,@itamblyn Yes, also check out https://t.co/6Dp3UA8IWT
922734623200858100,Tue Oct 24 08:00:52 +0000 2017,@unsorsodicorda There are GANs in the first edition
922503715369750500,Mon Oct 23 16:43:19 +0000 2017,Would you want to buy a Deep Learning textbook in person at NIPS 2017? If so, reply---trying to decide whether to do a signing
922365891941208000,Mon Oct 23 07:35:40 +0000 2017,@arturokkboss33 I‚Äôm not selling books at ICCV actually
921679013302718500,Sat Oct 21 10:06:15 +0000 2017,@ShadiAlbarqouni Yes, at least for my own talk
921628772968824800,Sat Oct 21 06:46:37 +0000 2017,@ernestyalumni I use TensorFlow for all my GAN research now. Haven‚Äôt updated to CUDA 9 yet though
921482722626990100,Fri Oct 20 21:06:16 +0000 2017,@triketora I'm imagining the alien message from Arrival decoding to "please add me to your LinkedIn network"
921481846290026500,Fri Oct 20 21:02:47 +0000 2017,@schaumberg_a @NipsConference At SOCML, we do our best to recruit participants from many underrepresented groups
921477439238402000,Fri Oct 20 20:45:16 +0000 2017,@PeterLoPR Yes, I‚Äôve seen it
921453930365767700,Fri Oct 20 19:11:51 +0000 2017,@timnitGebru I don‚Äôt know, sorry
921453720243769300,Fri Oct 20 19:11:01 +0000 2017,RT @lucastheis: I will speak about the evaluation of generative models at the tutorial on GANs. https://t.co/ceyzYB0Ur4
921414909212135400,Fri Oct 20 16:36:48 +0000 2017,If you‚Äôre at #iccv2017 on Sunday, check out our tutorial on GANs: https://t.co/o0BPVe4Pjn
921404253658386400,Fri Oct 20 15:54:27 +0000 2017,RT @techreview: One in every six deaths around the world is linked to toxic air, water, soil, or workplaces. https://t.co/D0rNZEp6F7
921385905079775200,Fri Oct 20 14:41:32 +0000 2017,@rohegde7 It will be added here later: https://t.co/g2rpXxI7Je
921364664121901000,Fri Oct 20 13:17:08 +0000 2017,@lanceTurnBull1 @jeremyphoward @PyGurl There‚Äôs the commonlounge forum linked on the book website
921173880781267000,Fri Oct 20 00:39:02 +0000 2017,Full room ready to hear about machine learning security at BayLearn today https://t.co/4yIY4Pr3rQ
921136642898911200,Thu Oct 19 22:11:04 +0000 2017,Come see several great speakers at Age of AI: https://t.co/ENsMCqhXiY
921135379687673900,Thu Oct 19 22:06:03 +0000 2017,@DimosGu @ozansener Wow, I wasn't aware Black in AI Participants got a million dollars. Those are generous travel grants!
921077622028714000,Thu Oct 19 18:16:32 +0000 2017,RT @jeremyphoward: Amazing resource thanks to @PyGurl: video walkthru of every single chapter of the famous @goodfellow_ian Deep Learning b‚Ä¶
921039603854819300,Thu Oct 19 15:45:28 +0000 2017,RT @WithTheBest: Didn't get a chance to attend our conference last weekend? Check out @goodfellow_ian's full talk for #AIWTB https://t.co/e‚Ä¶
920865932880126000,Thu Oct 19 04:15:21 +0000 2017,@xamat PCA (Presentation Components Analysis)
920751114651238400,Wed Oct 18 20:39:07 +0000 2017,XIX.ai has written an overview of adversarial examples: https://t.co/z65eozCmYJ
920450975470465000,Wed Oct 18 00:46:28 +0000 2017,@collawolley @typeload (It is @timnitGebru who deserves the credit, not me)
920356825739882500,Tue Oct 17 18:32:21 +0000 2017,@typeload @nicolouchka @Korede_TA How many black people do you think even attended NIPS last year?
920168354026889200,Tue Oct 17 06:03:26 +0000 2017,@Korede_TA That‚Äôs one word for it...
919331146839683100,Sat Oct 14 22:36:40 +0000 2017,@Abaybektursun This is press coverage of vue.ai and I think they haven‚Äôt written an academic paper
919307380092837900,Sat Oct 14 21:02:13 +0000 2017,@AiAiHealthcare At the moment they are aiming to replace marketing photoshoots
919305256990736400,Sat Oct 14 20:53:47 +0000 2017,As of dev round 3 in our competition, all top 10 defense teams used this technique https://t.co/eDBq3cfOIU
919245753469452300,Sat Oct 14 16:57:21 +0000 2017,@pfau @dribnet Yes, the main problem with GANs has always been underfitting (hard to find the equilibrium), not overfitting
919245583625289700,Sat Oct 14 16:56:40 +0000 2017,@rednecked_crake @pfau @dribnet Minibatch GANs (Salimans et al 2016) address that but it‚Äôs not enough apparently
919034400049737700,Sat Oct 14 02:57:30 +0000 2017,@DVA_AND_VDN You still need a 3D mesh of the clothes to render them though. There's variation in the 3D shape of th‚Ä¶ https://t.co/b9PyjuzKJJ
919031464670330900,Sat Oct 14 02:45:50 +0000 2017,@pfau @dribnet If you do have evidence of memorization you should publish it
919031371120513000,Sat Oct 14 02:45:28 +0000 2017,@pfau @dribnet The best published work on the subject says they have low output diversity, but don‚Äôt memorize train‚Ä¶ https://t.co/HcDwZ3HB3Q
919031060033183700,Sat Oct 14 02:44:14 +0000 2017,@pfau @dribnet I definitely am the first to say GANs need a lot of improvement, but I have never seen them memorize training examples
919030833553403900,Sat Oct 14 02:43:20 +0000 2017,@pfau @dribnet Keep in mind this is *conditional* generation so it can‚Äôt just repeat training images
919026911866585100,Sat Oct 14 02:27:45 +0000 2017,@DVA_AND_VDN I don‚Äôt think this method requires a 3D mesh of the clothing. Also the article says it generates the shape of the person
918984221183508500,Fri Oct 13 23:38:06 +0000 2017,@WuNeal @davegershgorn @GoAbiAryan Oh, yeah, you're right. I made a mistake based on 1 of the 2 she listed was inco‚Ä¶ https://t.co/bovmN4yubI
918983767795961900,Fri Oct 13 23:36:18 +0000 2017,@typeload @nicolouchka I'm just wondering why no one has asked this question about WIML / WIDL and gender
918983701068857300,Fri Oct 13 23:36:02 +0000 2017,@typeload @nicolouchka Other people asked the same question in my earlier replies and you can see some discussion there
918904743568666600,Fri Oct 13 18:22:17 +0000 2017,@chrisdonahuey 2/2 It sounds like it's meant to produce images for marketing, so all the fits will be good, but for‚Ä¶ https://t.co/09bfN2jysV
918904506657554400,Fri Oct 13 18:21:21 +0000 2017,@chrisdonahuey 1/2 The article doesn't give us enough information to know, but it sounds like it's not meant to pre‚Ä¶ https://t.co/HW6lNVXPoz
918902808820170800,Fri Oct 13 18:14:36 +0000 2017,@davegershgorn @GoAbiAryan So a human discriminator gets 12.5% accuracy, even with the hint that exactly 2 are real
918901967090364400,Fri Oct 13 18:11:15 +0000 2017,@GoAbiAryan I actually don't know
918901572616142800,Fri Oct 13 18:09:41 +0000 2017,@typeload I'm curious why this event is getting so much pushback. No one has ever questioned me when I promoted Women in Machine Learning.
918900712901197800,Fri Oct 13 18:06:16 +0000 2017,GANs for generating images of how clothes will fit. Only two of these images are photos. https://t.co/FYCBoveqh9 https://t.co/D001dT3Kng
918343715294294000,Thu Oct 12 05:12:58 +0000 2017,@xamat This is practically a Weird Al song line (‚ÄúI‚Äôm a million times as humble as thou art‚Äù)
918343121657667600,Thu Oct 12 05:10:36 +0000 2017,@WonderMicky Sounds like defensive programming, which is definitely not a strategy employed by idiots
918336258245460000,Thu Oct 12 04:43:20 +0000 2017,@KavehHassani If it weren‚Äôt useful, the members wouldn‚Äôt want to participate
918297367576682500,Thu Oct 12 02:08:48 +0000 2017,The first Black in AI event will take place at NIPS 2017: https://t.co/fDYNW61I3h
917569729316888600,Tue Oct 10 01:57:25 +0000 2017,RT @NicolasPapernot: Looking forward to be speaking at Cybersecurity @WithTheBest this weekend! Check out the program here: https://t.co/hS‚Ä¶
917544514708836400,Tue Oct 10 00:17:14 +0000 2017,@BayesForDays @gchrupala @nips Symposia and workshops usually have much lighter reviewing than journals / conferences
917441817007628300,Mon Oct 09 17:29:09 +0000 2017,The @nips symposium on interpretable ML has a call for papers: https://t.co/MWB5kArp0x
917170551562444800,Sun Oct 08 23:31:14 +0000 2017,RT @techreview: Stay on the cutting edge by attending the emerging tech conference of the year: #EmTechMIT. Register today! - https://t.co/‚Ä¶
916702015408922600,Sat Oct 07 16:29:26 +0000 2017,RT @lishali88: Really excited to participate in the first @3Blue1Brown video on deep learning! https://t.co/gttUyqOfcA
916360744253382700,Fri Oct 06 17:53:21 +0000 2017,Face swapping videos with CycleGAN: https://t.co/3VFKfYnVhP
916046715983061000,Thu Oct 05 21:05:31 +0000 2017,@ellisorellis Best to wait and include the new work
916009444604993500,Thu Oct 05 18:37:24 +0000 2017,RT @timhwang: New job! Excited to be joining the Ethics and Governance of AI Fund as its Director. Announced earlier this year: https://t.c‚Ä¶
915790666252222500,Thu Oct 05 04:08:04 +0000 2017,RT @liu_mingyu: Snowy to summery image translation. Results from our NIPS 17 paper (https://t.co/Zu8pm1KXCQ) Full video available in https:‚Ä¶
914988035791495200,Mon Oct 02 22:58:42 +0000 2017,@ybarzov Wait, they say the actual color of the Apple logo is gray, and then the example they show is black. And reality is it differs
914987378283909100,Mon Oct 02 22:56:05 +0000 2017,Google Brain Residency has been upgraded to Google AI Residency. Now possible to work with more AI teams at Google. https://t.co/zr5I0Y3o2p
914542009112682500,Sun Oct 01 17:26:20 +0000 2017,@dgueraco @elonmusk @karpathy @fchollet @OriolVinyalsML
914263865399042000,Sat Sep 30 23:01:06 +0000 2017,@cvondrick Also, scientists can't make use of scientific articles if the signal to noise ratio drops too low
913580726875914200,Fri Sep 29 01:46:33 +0000 2017,@colinraffel Theano: an acorn that split apart and gave us a tree
913562132263739400,Fri Sep 29 00:32:40 +0000 2017,@sagelywizard Google Sunnyvale, roughly business hours, exact schedule to be determined by participants
913432623153766400,Thu Sep 28 15:58:02 +0000 2017,@srbutner I see all kinds of ML industry / ML research parallels in fiction now
912711024540659700,Tue Sep 26 16:10:40 +0000 2017,@RobertoParPal As we said in the competition forum, we'll update it as soon as the results are in. This round takes‚Ä¶ https://t.co/FrPiyCptcg
912540757839532000,Tue Sep 26 04:54:05 +0000 2017,RT @NicolasPapernot: The PGD attack from @aleks_madry et al.  is now implemented in CleverHans thanks to @FartashFg https://t.co/2tTINzonHv‚Ä¶
912540508748165100,Tue Sep 26 04:53:06 +0000 2017,@danieldewey Done: https://t.co/qyD02yrJrg
912471979978055700,Tue Sep 26 00:20:47 +0000 2017,The Bayesian Deep Learning workshop at NIPS has opened a call for papers: https://t.co/jb9hdAoTRj
912445387197358100,Mon Sep 25 22:35:07 +0000 2017,@rmarcilhoo @pbloemesquire @hardmaru I haven't read the paper but I don't have any strong opinions about how to tel‚Ä¶ https://t.co/ndrg4w2dta
912443794125131800,Mon Sep 25 22:28:47 +0000 2017,RT @hardmaru: Exciting work by @bousmalis @mat_kelcey et al. Check out the video of GraspGAN in action: https://t.co/guUUalbJUE
912408377074044900,Mon Sep 25 20:08:03 +0000 2017,@averdones Yes, but more focused on reviews. Ideally where reviews are citable entities themselves
912129891134509000,Mon Sep 25 01:41:27 +0000 2017,@roydanroy @NewLeibniz 2/2 Culturally, people react negatively to independent critical review articles. An official‚Ä¶ https://t.co/LR4WIE5CmI
912129551718867000,Mon Sep 25 01:40:06 +0000 2017,@roydanroy @NewLeibniz 1/2 You have to go looking for the responses though. Takes discipline and expertise. I want‚Ä¶ https://t.co/gPfTrbnowo
912106499983515600,Mon Sep 25 00:08:30 +0000 2017,@NewLeibniz and it's not "pre" if you never submit to a reviewed venue
912106413920604200,Mon Sep 25 00:08:09 +0000 2017,@NewLeibniz I would like to see a site + browser plugin that can provide comments on any URL. So reviewers could an‚Ä¶ https://t.co/xOjPyDHatO
912096961209225200,Sun Sep 24 23:30:36 +0000 2017,The arxiv of the future must have comments and open peer review: https://t.co/YaxhSsRZk7
912026593652035600,Sun Sep 24 18:50:59 +0000 2017,@alwyn_mathew Yes. StackGAN is a great recent example
911335072422178800,Fri Sep 22 21:03:07 +0000 2017,@abrad1212 I wrote a loader script for it as part of pylearn2. I don't have time to do further ongoing support
911271703430414300,Fri Sep 22 16:51:19 +0000 2017,@nerdworldorder Since workshops are not considered "archival proceedings" the review process is usually lighter than for conference papers
911267300208132100,Fri Sep 22 16:33:49 +0000 2017,https://t.co/PTJ8LwKnKD
911262003502604300,Fri Sep 22 16:12:46 +0000 2017,The NIPS Workshop on Machine Deception has an open call for papers: https://t.co/mH1uwt3RIx
910698172892143600,Thu Sep 21 02:52:19 +0000 2017,@abrad1212 OK, glad you like it. Just wondering if it was featured in a blog post in the last few days or something.
910695182672085000,Thu Sep 21 02:40:26 +0000 2017,@abrad1212 Note that there is one file with a "Usage" column saying whether each example was used for training, pub‚Ä¶ https://t.co/6zoEb6cfqQ
910695023661817900,Thu Sep 21 02:39:48 +0000 2017,@abrad1212 Just curious, why are so many people suddenly interested in FER2013 again the last few days?
910694864827826200,Thu Sep 21 02:39:10 +0000 2017,@abrad1212 https://t.co/cPLTgt0U03
910693668847099900,Thu Sep 21 02:34:25 +0000 2017,@feifei_cui https://t.co/Ne1TLCYjwD
910631322866946000,Wed Sep 20 22:26:40 +0000 2017,@Octavio_Arriaga @kcimc This dataset was made by Pierre Luc Carrier and Aaron Courville. I don't know much about where the images came from.
910190006433542100,Tue Sep 19 17:13:02 +0000 2017,https://t.co/h3p2ZSz4vp
909909183402618900,Mon Sep 18 22:37:09 +0000 2017,The call for papers for the NIPS workshop on Bridging Theory and Practice in deep learning is now open! https://t.co/ds8gZ5SPnv
909103281053380600,Sat Sep 16 17:14:47 +0000 2017,@abhi9u I taught some lessons on GANs but other people covered CNN and RNN
908840776284594200,Fri Sep 15 23:51:41 +0000 2017,@nelsonfliu @JonClarkSeattle Yes, I did. Also many presentation slides
907680610176483300,Tue Sep 12 19:01:36 +0000 2017,@zacharylipton I'm regularizing a self-organizing conference :)
907674330083065900,Tue Sep 12 18:36:38 +0000 2017,The second Self-Organizing Conference on Machine Learning will take place in November. Apply here: https://t.co/FTG3QQjQfw
907033469691232300,Mon Sep 11 00:10:05 +0000 2017,@ellisorellis @ragvri Google Brain Residency is a great way to do this
907028806724137000,Sun Sep 10 23:51:33 +0000 2017,@karpathy "Wow, that's funny"?
907014744531497000,Sun Sep 10 22:55:41 +0000 2017,@KaiLashArul Thank you for doing careful evaluations!
907014274039664600,Sun Sep 10 22:53:49 +0000 2017,@NourozRahman Making a plot is an easy way to see a violation
907008535543926800,Sun Sep 10 22:31:00 +0000 2017,@NourozRahman In this case they're asking for you to disprove convexity, so you want to find a counter example to those properties
906539813213368300,Sat Sep 09 15:28:28 +0000 2017,@ragvri I know undergrads who have interned at Google Brain, NVIDIA and OpenAI. It's very competitive but possible
905896902801055700,Thu Sep 07 20:53:47 +0000 2017,@indicoData Thank you for DC-GANs!
905896755811815400,Thu Sep 07 20:53:11 +0000 2017,Thanks to @nvidia and @USC for hosting me in their distinguished lecture series! My slides are available here: https://t.co/HN5egT45a4
905593966350835700,Thu Sep 07 00:50:01 +0000 2017,RT @negar_rz: Read about our @WiCVworkshop (Women in Computer Vision) workshop 2017 here: https://t.co/wke0K01qZp
905440920639758300,Wed Sep 06 14:41:52 +0000 2017,@catherineols We're thrilled that you're joining!
904744211248906200,Mon Sep 04 16:33:23 +0000 2017,@elonmusk WWAI
904476638842306600,Sun Sep 03 22:50:09 +0000 2017,@AlbertoRoman Sure, e-mail to figure out time
904140043744190500,Sun Sep 03 00:32:39 +0000 2017,@mbrendan1 Format has been ok for us as organizers
903992233761824800,Sat Sep 02 14:45:18 +0000 2017,Martin Abadi has written a short overview of recent work on our + our coauthors' recent work on private ML: https://t.co/lQ7peHQNHi
903779956311896000,Sat Sep 02 00:41:47 +0000 2017,@m_alzantot Send an email
903289805278027800,Thu Aug 31 16:14:06 +0000 2017,@kaustubhn @CrystationalBio @AndrewYNg Some of the mathematical ideas used in cryptography might be useful for veri‚Ä¶ https://t.co/oWU3KZTajT
903240644553875500,Thu Aug 31 12:58:45 +0000 2017,@CrystationalBio @AndrewYNg Here's a reading list Alex Kurakin and I made for the NIPS competition: https://t.co/cQfLwVhfPS
903095525607579600,Thu Aug 31 03:22:06 +0000 2017,@yanxia_wh it's hiding in the p_g(x)
902976066259529700,Wed Aug 30 19:27:25 +0000 2017,@robertskmiles @ArtirKel I was hoping to turn it into a real scientific term but it didn't catch on
902975957073485800,Wed Aug 30 19:26:59 +0000 2017,@robertskmiles @ArtirKel For GANs, it's when you put too much probability mass in the same place
902975682333950000,Wed Aug 30 19:25:53 +0000 2017,@robertskmiles @ArtirKel In Look Around You, the Helvetica Scenario happens when you put too much industrial calcium in the same place
902973874333130800,Wed Aug 30 19:18:42 +0000 2017,@ArtirKel @robertskmiles Yes, it is a Look Around You reference :)
902931621946441700,Wed Aug 30 16:30:48 +0000 2017,@pooja_LuvIndia @atiorh Yes, https://t.co/IJC9UwrWRa
902687471170838500,Wed Aug 30 00:20:38 +0000 2017,The second dev round of the NIPS 2017 adversarial example competition closes soon: https://t.co/97DZqAHOQP
902622569794117600,Tue Aug 29 20:02:45 +0000 2017,@atiorh Yes, coming to USC next week, Sep 5
902531175201226800,Tue Aug 29 13:59:35 +0000 2017,@rmarcilhoo I think if you pick any one decent model family (LSTM, GRU) and spend a lot of time optimizing your choice, it will usually win
902371281705680900,Tue Aug 29 03:24:13 +0000 2017,RT @techreview: Don‚Äôt miss the emerging #techconference of the year. Register for #emtechmit TODAY! - https://t.co/5o10nPPVYR https://t.co/‚Ä¶
902368663394672600,Tue Aug 29 03:13:49 +0000 2017,@zacharylipton In this case the heuristic is: if the model thinks it found something, it asks for a label. Else assume label is negative
902362189310320600,Tue Aug 29 02:48:05 +0000 2017,@zacharylipton Weak detector goes through huge number of presumed negatives, asks for labels for medium number of e‚Ä¶ https://t.co/wD5mRgX8hU
902358170219176000,Tue Aug 29 02:32:07 +0000 2017,@zacharylipton There is definitely a lot of bootstrapping involved in making the dataset for e.g. https://t.co/9tbvjZMh25
902357737375273000,Tue Aug 29 02:30:24 +0000 2017,@zacharylipton Most of the time someone releases a dataset for a detection task, they bootstrapped it using weaker‚Ä¶ https://t.co/5cyecXqhlv
902356896232882200,Tue Aug 29 02:27:03 +0000 2017,@zacharylipton Ad hoc active learning schemes similar to hard negative mining are ubiquitous behind the scenes but‚Ä¶ https://t.co/bQ3jDo344Y
902353054120288300,Tue Aug 29 02:11:47 +0000 2017,RT @elonmusk: https://t.co/IypZm9FdQk
902216267548901400,Mon Aug 28 17:08:15 +0000 2017,@coolrv9619 I don't know of any major open source GAN frameworks, just implementations of specific papers so far
901953006618394600,Sun Aug 27 23:42:08 +0000 2017,RT @dwf: Advice to young ML researchers: make an effort to read something, once a week, written more than 10 years ago, without "deep" in t‚Ä¶
901952966600474600,Sun Aug 27 23:41:59 +0000 2017,@julius_adebayo @dwf One way is to look at older work cited in newer work. e.g., here's the bib for the deep learni‚Ä¶ https://t.co/wDHNd4ixeY
901952825697067000,Sun Aug 27 23:41:25 +0000 2017,@JoshMiller656 @dwf https://t.co/u0WuLOBLFW
901103300732268500,Fri Aug 25 15:25:43 +0000 2017,Amazon using GANs for fashion: https://t.co/vsvmyv9JxD
900933909487079400,Fri Aug 25 04:12:37 +0000 2017,@jwangARK @Joe_Pater @ylecun @yoavgo IIRC, there was some theoretical work in the 1940s about the expressive power‚Ä¶ https://t.co/niCtrZFIt7
900909417394077700,Fri Aug 25 02:35:17 +0000 2017,@Joe_Pater @ylecun @yoavgo As we say in the book, work that could be called deep learning goes back at least as lon‚Ä¶ https://t.co/NrYimgt33G
900589694559305700,Thu Aug 24 05:24:49 +0000 2017,RT @colinraffel: Belated blog post about what I did during the Brain residency and what I'm doing now: https://t.co/qllqqMzi38
900468368699871200,Wed Aug 23 21:22:43 +0000 2017,Dreamscapes by Dan Ambrosi (used in the deep learning book cover) on exhibit at Google-NYC: https://t.co/yZdjtCg4mi
900406833243758600,Wed Aug 23 17:18:12 +0000 2017,CleverHans 2.0.0 is out: https://t.co/bfRyJ0GDXB Many thanks to all our contributors!
900202751518539800,Wed Aug 23 03:47:15 +0000 2017,@surya_s Thanks!
899741935971127300,Mon Aug 21 21:16:08 +0000 2017,Have an idea for blocking adversarial examples or making them stronger? Join our NIPS 2017 competition on Kaggle: https://t.co/iHyuM2iRIg
899029615582167000,Sat Aug 19 22:05:38 +0000 2017,@communicating No, I think PyTorch launched around Jan 2017 and we finished our manuscript in early 2016
898637698189086700,Fri Aug 18 20:08:17 +0000 2017,@wielandbr @NicolasPapernot @aleks_madry Sure, follow up by e-mail?
898355178205622300,Fri Aug 18 01:25:39 +0000 2017,@_Desmoden @nasa_fdl Thanks!
898355001831039000,Fri Aug 18 01:24:57 +0000 2017,@theotherEros @Redo @nasa_fdl @AlisonBLowndes @JLGalache @jonathanknowles Very interesting! Impressive work especia‚Ä¶ https://t.co/oZ0pBSU3Z5
898051790788112400,Thu Aug 17 05:20:06 +0000 2017,@kbeguir @gdb @VladMnih Thank you!
898051581689471000,Thu Aug 17 05:19:16 +0000 2017,@amlookingbill Thank you!
897927054238171100,Wed Aug 16 21:04:27 +0000 2017,@EmilMikhailov Thank you!
897868954584010800,Wed Aug 16 17:13:35 +0000 2017,@triketora @techreview @gdb @__apf__ Congratulations to you too!
897342140505665500,Tue Aug 15 06:20:12 +0000 2017,RT @NicolasPapernot: Working on @aleks_madry et al.'s adv ex challenge? CleverHans now includes a wrapper for it (thanks @goodfellow_ian) h‚Ä¶
897304342281113600,Tue Aug 15 03:50:00 +0000 2017,@prabhantsingh Leaderboard is up today
897242414741454800,Mon Aug 14 23:43:56 +0000 2017,The results of the first dev round for the Kaggle contest on adversarial examples are out: https://t.co/AjAidDPqzt
896243491637837800,Sat Aug 12 05:34:34 +0000 2017,RT @OpenAI: Our Dota 2 AI is undefeated against the world's best solo players: https://t.co/cUvTbGW7ya
895991412415578100,Fri Aug 11 12:52:54 +0000 2017,@prabhantsingh Still running the submissions from Deb round 1
895849119452774400,Fri Aug 11 03:27:28 +0000 2017,@cmannyz See Sec 6
895805863830495200,Fri Aug 11 00:35:35 +0000 2017,RT @NicolasPapernot: At ICML? Check out my talk about adversarial ML with CleverHans in room C4.10 at 11am: https://t.co/Oj44w04mCY
895664509368401900,Thu Aug 10 15:13:54 +0000 2017,@NourozRahman Yes. Probably via Stephen Boyd's book or course. We used ideas from that book to prove the Nash equilibrium of GANs
895445100880306200,Thu Aug 10 00:42:03 +0000 2017,RT @pabbeel: @AndrewYNg interviewed me for new DL course! Also: Hinton, Bengio, @goodfellow_ian @karpathy @YuanqingLin @rsalakhu https://t.‚Ä¶
895344770465251300,Wed Aug 09 18:03:22 +0000 2017,RT @AndrewYNg: Big thanks Hinton, Bengio @pabbeel @goodfellow_ian @karpathy @YuanqingLin @rsalakhu in course's Heroes of DL videos! https:/‚Ä¶
895104076182036500,Wed Aug 09 02:06:56 +0000 2017,@tkasasagi Glad you like it! Curious to hear how you use AI to preserve historical material
892746016662868000,Wed Aug 02 13:56:51 +0000 2017,RT @NicolasPapernot: I'll be speaking about CleverHans at the ICML workshop on reproducibility! Lmk if you want me to cover some topics htt‚Ä¶
892495282323079200,Tue Aug 01 21:20:31 +0000 2017,Evading malware detectors with RL: https://t.co/02vmDd0sWi
892495237435670500,Tue Aug 01 21:20:21 +0000 2017,RT @shakir_za: All papers for the #icml2017 Implicit Generative Models workshop online. All the latest in GANs, ABC, liklihd-free. https://‚Ä¶
891675034745307100,Sun Jul 30 15:01:09 +0000 2017,@Pgtgrly Deep Dream. It's from Dan Ambrosi's DreamScapes art exhibit https://t.co/9jX18OWX1Y
891493697342144500,Sun Jul 30 03:00:35 +0000 2017,Adversarial examples that make stop signs misclassified 100% of the time, from multiple viewpoints: https://t.co/gRSG7XXonr
890565023474499600,Thu Jul 27 13:30:22 +0000 2017,@pengyunli1 Yes, you can do that / you don't need permission
890396838620045300,Thu Jul 27 02:22:03 +0000 2017,@jackclarkSF @zacharylipton @smolix (If prev tweet is ambiguous: it's a humorous comment that there isn't much to the core of deep learning)
890358267414585300,Wed Jul 26 23:48:47 +0000 2017,@jackclarkSF @zacharylipton @smolix https://t.co/cMy4riu5ad
889932440071950300,Tue Jul 25 19:36:42 +0000 2017,Adversarial examples for text comprehension systems: https://t.co/AvEXiJ836S
889932043961876500,Tue Jul 25 19:35:08 +0000 2017,@cosminnegruseri Yes, great work by @SussilloDavid !
889931838407426000,Tue Jul 25 19:34:19 +0000 2017,The tech report on the multi-viewpoint adversarial kitten is out: https://t.co/lgEiULKbzk
889535572716339200,Mon Jul 24 17:19:41 +0000 2017,@xamat @adamdangelo @ferrouswheel I think that work on "AI security" is required as a prerequisite for there to be "AI safety"
889223900675977200,Sun Jul 23 20:41:13 +0000 2017,@Miles_Brundage @jackclarkSF there are several popular audience AI books in the works right now
889213564153602000,Sun Jul 23 20:00:09 +0000 2017,@jimmfleming @jackclarkSF https://t.co/M7U0pqT4sl is somewhat like this---closer to Arxiv than to AI journalism
889212665511514100,Sun Jul 23 19:56:34 +0000 2017,@jackclarkSF That Bloomberg guy who wrote the best AI journalism articles isn't doing it anymore
889173499419480000,Sun Jul 23 17:20:56 +0000 2017,GANs for dataset augmentation received a best paper award at #CVPR17 ! https://t.co/lTj5UezV39
888913994907500500,Sun Jul 23 00:09:46 +0000 2017,@adosaariel I actually don't know
888794338427191300,Sat Jul 22 16:14:17 +0000 2017,The Chinese edition of our deep learning textbook has launched at CCA 2017 https://t.co/FHdWIWWa5Q
888564914599608300,Sat Jul 22 01:02:39 +0000 2017,@hugo_larochelle @m_aggrey @ylecun  https://t.co/0jm9IcYtXE
888500989946339300,Fri Jul 21 20:48:38 +0000 2017,@m_aggrey (I'm not actually at CVPR, but researchers similar to me are)
888243794457514000,Fri Jul 21 03:46:38 +0000 2017,@kau_mad @sid_srk I'm not sure. Is there a particular language you'd want?
888177313325514800,Thu Jul 20 23:22:27 +0000 2017,@iandanforth Human is probably best for now unfortunately. Ask someone who knows that topic well for recommendations.
888131412443799600,Thu Jul 20 20:20:04 +0000 2017,RT @liu_mingyu: Our unsupervised image translation code is now available in https://t.co/fO6PSNx8sm Thank @goodfellow_ian for letting us us‚Ä¶
888131329363017700,Thu Jul 20 20:19:44 +0000 2017,RT @liu_mingyu: Check out our MoCoGAN work on motion and content decomposed random video generation via GAN. https://t.co/SNBwuFaPPN https:‚Ä¶
888090822129795100,Thu Jul 20 17:38:46 +0000 2017,@AI_RSS Which attacks have you tried running it on?
888090712943636500,Thu Jul 20 17:38:20 +0000 2017,@AI_RSS Are you using a color version of MNIST?
888033773123534800,Thu Jul 20 13:52:05 +0000 2017,MIT Technology Review article on the adversarial example competition: https://t.co/ke1z6KihrT Join today if it sounds fun!
887900907530108900,Thu Jul 20 05:04:07 +0000 2017,The Chinese translation is now ready to go! https://t.co/Zio87fiWOr
887854602019668000,Thu Jul 20 02:00:07 +0000 2017,RT @abursuc: Nice writeup by Chelsea Finn on recent meta-learning and few-shot learning techniques https://t.co/K89CVG9Bod
887772944801292300,Wed Jul 19 20:35:38 +0000 2017,Adversarially controlling an image segmentation algorithm to make it draw a minion: https://t.co/Onn2mbmrud (h/t‚Ä¶ https://t.co/3WQMpScqQD
887743987456409600,Wed Jul 19 18:40:34 +0000 2017,@NourozRahman I like that Shilov clearly defines ideas in concrete detail. When other authors try to simplify and a‚Ä¶ https://t.co/WT0gbrFsx1
887718569282158600,Wed Jul 19 16:59:34 +0000 2017,Apple has launched an online machine learning journal, similar to Distill. First article is on GANs! https://t.co/HILKT1ZY7W
887542377182900200,Wed Jul 19 05:19:27 +0000 2017,RT @FartashFg: VSE++: Improved Visual-Semantic Embeddings, with D. Fleet, J. Kiros, S. Fidler https://t.co/oiqjKQRmGH @PyTorch code https:/‚Ä¶
887541841737941000,Wed Jul 19 05:17:19 +0000 2017,@botminds @jackiefloyd @pmddomingos Which is why all animals are really good at reading MNIST digits
887496346713768000,Wed Jul 19 02:16:32 +0000 2017,@justintstanley @pmddomingos After you have training data
887396096883908600,Tue Jul 18 19:38:11 +0000 2017,@pmddomingos s«ùƒ± á◊ün…îƒ±…ü…üƒ±p …π…ê◊üƒ±…Øƒ±s s…ê…• …Ø«ù ás és ◊ü…ênsƒ± å u ço …πno é  á…î«ùdx«ù ƒ±
887379746308333600,Tue Jul 18 18:33:12 +0000 2017,@willwolf_ @chrisalbon Linear algebra, probability, minimization of multidimensional functions. Focused on just the‚Ä¶ https://t.co/yfmUhKBzkR
887377698879750100,Tue Jul 18 18:25:04 +0000 2017,@chrisalbon Glad you like it! Thank you!
887095484648636400,Mon Jul 17 23:43:39 +0000 2017,The paper they are refuting used 2D objects too https://t.co/jRLaxIoOzR
887038788391665700,Mon Jul 17 19:58:22 +0000 2017,@PresidentMuneeb Ended at 12PM California time
887038605717262300,Mon Jul 17 19:57:38 +0000 2017,@ozansener The blog post includes a video where they print out the adversarial example and physically move the came‚Ä¶ https://t.co/yD7FFC5yx4
887025450957938700,Mon Jul 17 19:05:22 +0000 2017,Rumors of viewpoint changes defeating adversarial examples have been greatly exaggerated https://t.co/LBCiOSmWTI
886994729639878700,Mon Jul 17 17:03:17 +0000 2017,Alexey Kurakin and I starting our Quora session now: https://t.co/GxynUZvcJ4
885714201766907900,Fri Jul 14 04:14:56 +0000 2017,@jigarkdoshi Their table 1 shows their detector succeeding on only 7% of examples
885708086085681200,Fri Jul 14 03:50:38 +0000 2017,Alexey Kurakin and I will answer questions about the adversarial ML contest in this Quora session Monday: https://t.co/vPEwleakmF
885672188304425000,Fri Jul 14 01:27:59 +0000 2017,@blancemorris Their own table 1 shows their object detector failing on 93% of FGSM adversarial examples, so the adv‚Ä¶ https://t.co/MwmPm2MyVS
885209018477666300,Wed Jul 12 18:47:31 +0000 2017,https://t.co/wLD7X06j5M
885182026017521700,Wed Jul 12 17:00:15 +0000 2017,RT @sundarpichai: Important day - #NetNeutrality protections support a vibrant internet and create opportunities for everyone¬† https://t.co‚Ä¶
885176164746010600,Wed Jul 12 16:36:58 +0000 2017,RT @SenMarkey: I'm live with @RonWyden @SenFranken @SenBlumenthal @FrankPallone @RepAnnaEshoo @USRepMikeDoyle &amp; more. #netneutrali‚Ä¶ https:/‚Ä¶
885176028577931300,Wed Jul 12 16:36:25 +0000 2017,https://t.co/XUybHulwUy
884764374795042800,Tue Jul 11 13:20:39 +0000 2017,RT @googleresearch: This month we "graduate" our first class of the Google Brain Residency Program! Learn all about their research at https‚Ä¶
884762805596848100,Tue Jul 11 13:14:25 +0000 2017,RT @techreview: Google's PAIR project is led by researchers who specialize in making complex information more comprehensible. https://t.co/‚Ä¶
884507648401449000,Mon Jul 10 20:20:31 +0000 2017,There are now Cloud Compute credits available for the adversarial example competition: https://t.co/M4V1H7Je5N
884496946596986900,Mon Jul 10 19:37:59 +0000 2017,@pranavathiyani This is one of the reasons I wanted to study AI: to build the tools for others to use to solve hard‚Ä¶ https://t.co/nyXqxlkaOp
884469112868544500,Mon Jul 10 17:47:23 +0000 2017,@WilsonHuang11 For text, it doesn't work as well as an RNN trained with maximum likelihood yet. GANs work best when‚Ä¶ https://t.co/kB8EgFY6aR
884468798928977900,Mon Jul 10 17:46:08 +0000 2017,Announcing PAIR, People and AI Research: https://t.co/JQPVNcKNlq
883460683358064600,Fri Jul 07 23:00:15 +0000 2017,RT @colinraffel: New blog post summarizing our ICML paper about online/linear time attention with monotonic alignments: https://t.co/03WjQ7‚Ä¶
883351387572064300,Fri Jul 07 15:45:57 +0000 2017,@liyzhen2 @yaringal @lawrennd @anotherjohng @dmarthal @TlkngMchns @maalvarezl @icmlconf Or in Sandy Huang's paper,‚Ä¶ https://t.co/BT7r45wRlt
883350961489453000,Fri Jul 07 15:44:15 +0000 2017,@liyzhen2 @yaringal @lawrennd @anotherjohng @dmarthal @TlkngMchns @maalvarezl @icmlconf Not really. There are many‚Ä¶ https://t.co/hiec2AGi8U
883349953346641900,Fri Jul 07 15:40:15 +0000 2017,@_ambodi I'm actually not used to using that few dimensions
883140713751265300,Fri Jul 07 01:48:48 +0000 2017,Generating cat photos with GANs: https://t.co/ogO6yAawjB https://t.co/rYTRChvAVB
883034074893307900,Thu Jul 06 18:45:04 +0000 2017,@lawrennd @anotherjohng @dmarthal @TlkngMchns Monte Carlo dropout at test time is one of the few defenses that stoo‚Ä¶ https://t.co/uPB2DY3n5Q
883033841757073400,Thu Jul 06 18:44:08 +0000 2017,@lawrennd @anotherjohng @dmarthal @TlkngMchns Yes, Monte Carlo dropout at test time is a proposed defense: https://t.co/SOfBrtDm0f
883033273969950700,Thu Jul 06 18:41:53 +0000 2017,Differentially private GANs generate fake clinical trial data to train any ML algorithm without sacrificing privacy: https://t.co/J6z0wH9qqE
882989697244348400,Thu Jul 06 15:48:43 +0000 2017,@dmarthal @lawrennd What's the question?
882848484730183700,Thu Jul 06 06:27:35 +0000 2017,@matthew_wicker The adversarial examples must respect an L_infinity constraint
882629128448491500,Wed Jul 05 15:55:57 +0000 2017,NIPS 2017 adversarial examples challenge: https://t.co/g0Nt8BxefX Test your defenses against others' adversarial examples and vice versa!
882608979288838100,Wed Jul 05 14:35:53 +0000 2017,@Suuraj @__ishaan You want to show consistent, low-cost success using some standardized hyperparameter search procedure
882606702863962100,Wed Jul 05 14:26:50 +0000 2017,@__ishaan Would you take a drug that was approved based on a clinical trial using a single patient?
882335223014236200,Tue Jul 04 20:28:04 +0000 2017,@__ishaan That problem is much worse when you use only a single point rather than a space
882324277541744600,Tue Jul 04 19:44:35 +0000 2017,@halhod @olivercameron Section 4 of https://t.co/BESD3223uR. Written in terms of GANs but the math is abstract enou‚Ä¶ https://t.co/JB8dyHSbJs
882319575475396600,Tue Jul 04 19:25:54 +0000 2017,@halhod @olivercameron There will probably be a lot of leapfrogging before we get to that eventual outcome, but yes‚Ä¶ https://t.co/3kkxUCvReu
881354497364082700,Sun Jul 02 03:31:01 +0000 2017,RT @LibyaLiberty: When you hear "all-girls robotics team from Afghanistan", you'd assume the Taliban would be what stops their success, not‚Ä¶
881354483459997700,Sun Jul 02 03:30:58 +0000 2017,RT @LibyaLiberty: "To interview for their visas, the girls risked a 500 mile trek cross-country to the American embassy in Kabul."  Twice.‚Ä¶
881155821593284600,Sat Jul 01 14:21:33 +0000 2017,https://t.co/OQayKGS7EI
881146445423796200,Sat Jul 01 13:44:18 +0000 2017,@semiDL @IntuitMachine @RogerGrosse That's the backprop algorithm. The point of FA is that it doesn't need to compute transposes
880989592928763900,Sat Jul 01 03:21:01 +0000 2017,@IntuitMachine @RogerGrosse https://t.co/tnaXUeUQn3
880920177814130700,Fri Jun 30 22:45:11 +0000 2017,@jonnesaleva @dustinvtran @RogerGrosse e.g. for example from 2006-2012 many papers say deep nets work well but say‚Ä¶ https://t.co/kgxW0AdYi0
880919858786967600,Fri Jun 30 22:43:55 +0000 2017,@jonnesaleva @dustinvtran @RogerGrosse In machine learning literature, we're usually correct that a method works an‚Ä¶ https://t.co/XRLIrXTg2k
880851391408885800,Fri Jun 30 18:11:51 +0000 2017,RT @NicolasPapernot: Madry et al. challenge the community to come up with adversarial examples evading their defended model. Great idea!  h‚Ä¶
880805441885818900,Fri Jun 30 15:09:16 +0000 2017,@RogerGrosse For example, it was interesting to learn that feedback alignment worked before we had any explanation for it
880805244422070300,Fri Jun 30 15:08:29 +0000 2017,@RogerGrosse Showing that a technique works paves the way for a subsequent scientist to figure out why.
880805050682978300,Fri Jun 30 15:07:43 +0000 2017,@RogerGrosse I think it's sufficient to demonstrate empirically (with proper controls, statistical analysis) that the technique works
880305230570598400,Thu Jun 29 06:01:36 +0000 2017,@ferrouswheel @elaClaudia (The dots are a new innovation for this paper AFAIK)
880305104955392000,Thu Jun 29 06:01:06 +0000 2017,@ferrouswheel @elaClaudia The text says the dots are the 10 best scores. I think horizontal spread is just for legibility.
880304276626485200,Thu Jun 29 05:57:49 +0000 2017,@seth_stafford I'm impressed. The GAN Zoo already has alpha-GAN
880303985508339700,Thu Jun 29 05:56:40 +0000 2017,@semiDL Hey on MNIST we compete over single test set errors
880303555013300200,Thu Jun 29 05:54:57 +0000 2017,@semiDL It's more of a recent problem that people claim robustness to hyperparams based on a single choice of hyperparams
880303341665828900,Thu Jun 29 05:54:06 +0000 2017,@semiDL No, we've done these plots for years: https://t.co/hWVZnxurWq
880302966279880700,Thu Jun 29 05:52:37 +0000 2017,@NeelShah_Indian Yes
880278801757884400,Thu Jun 29 04:16:35 +0000 2017,These box and whisker plots from https://t.co/sZIKlmhMG2 by @elaClaudia et al are the right way to measure robustne‚Ä¶ https://t.co/seOcuqxshG
880263924620214300,Thu Jun 29 03:17:28 +0000 2017,@TedInRealLife @zeynep link?
880263833301901300,Thu Jun 29 03:17:07 +0000 2017,"We use the Greek Œ± prefix for Œ±-GAN, as AEGAN and most other Latin prefixes seem to have been taken" https://t.co/sZIKlmhMG2 :D
880260212770218000,Thu Jun 29 03:02:43 +0000 2017,@TedInRealLife @zeynep no problem, there's more than one recent paper that is frequently called "classic"
880258928075874300,Thu Jun 29 02:57:37 +0000 2017,@TedInRealLife @zeynep It's one of my own papers that people call "classic" and while I appreciate the compliment i‚Ä¶ https://t.co/deUmCQIu3O
880238159803539500,Thu Jun 29 01:35:05 +0000 2017,A rare exception to Betteridge's law: https://t.co/n4qyUvGXDh (also, can't believe this article doesn't mention arxiv)
880181767260569600,Wed Jun 28 21:51:00 +0000 2017,@zeynep Yes, it's also amazing to see how well some work from the 1950s and 1980s has held up
880179878267674600,Wed Jun 28 21:43:30 +0000 2017,@halhod Thanks! Didn't know your twitter handle
880175658177105900,Wed Jun 28 21:26:44 +0000 2017,@zeynep A lot of people refer to deep learning papers from 2014 as "classic"
880175333382791200,Wed Jun 28 21:25:27 +0000 2017,@ak1010 I haven't. This piece is more about predicting the future.
880170459429572600,Wed Jun 28 21:06:04 +0000 2017,By @halhod
880143288044531700,Wed Jun 28 19:18:06 +0000 2017,GANs in the Economist: https://t.co/7iyyrVNLFx
879519949236166700,Tue Jun 27 02:01:11 +0000 2017,@suryadantuluri1 Montreal
879344612925554700,Mon Jun 26 14:24:27 +0000 2017,On my way to the MILA summer school!
879344277402173400,Mon Jun 26 14:23:07 +0000 2017,@iandanforth How do you think I got this job? (j/k)
879344200076021800,Mon Jun 26 14:22:49 +0000 2017,RT @iandanforth: I wonder how long until @goodfellow_ian starts crafting adversarial LinkedIn profiles https://t.co/cRNWHnbvO9
878599561593233400,Sat Jun 24 13:03:53 +0000 2017,RT @NandoDF: The man who helped turn the World rather! Can't believe they haven't given him a Turing Award still. https://t.co/x0TTIecJMI
878255650442051600,Fri Jun 23 14:17:18 +0000 2017,@daniel_bilar @peterdodds @svalver I didn't understand what's going on in the last panel
878069100106235900,Fri Jun 23 01:56:01 +0000 2017,RT @SussilloDavid: 1. Some folks have been asking what is the point of our new LFADS model.  What is it for?  Allow me to explain. ‚òùÔ∏èü§ì http‚Ä¶
877909098674532400,Thu Jun 22 15:20:14 +0000 2017,@bapalto Works for me
877905176937480200,Thu Jun 22 15:04:39 +0000 2017,GeekPwn 2017 offers a 5 million RMB prize to white hat AI hackers: https://t.co/vhA70WflR3
877654046630322200,Wed Jun 21 22:26:45 +0000 2017,RT @SussilloDavid: Folks! ü§ìüëâOur preprint on LFADS applied to neurophys data.  Single trial dynamics!  Data stitching!  Inferred inputs! htt‚Ä¶
877200876066062300,Tue Jun 20 16:26:01 +0000 2017,I'll present at the @reworkAI deep learning summit in SF in January. https://t.co/5gkY4ApWlP
876852940157222900,Mon Jun 19 17:23:26 +0000 2017,Video of my talk on GANs at NVIDIA's GTC 2017: https://t.co/VWxPOe27Rv
876085100584214500,Sat Jun 17 14:32:19 +0000 2017,@dguerreropx @roydanroy They still fool the model. See for example fig 1.2 of https://t.co/MMHiW2EM7L
875818572601212900,Fri Jun 16 20:53:14 +0000 2017,@roydanroy #NotAllEnsembles
875571249811935200,Fri Jun 16 04:30:27 +0000 2017,RT @Miles_Brundage: These are unusually entertaining GAN text samples for some reason (braces for GAN-text tomatoes) https://t.co/UvbDLyZdc‚Ä¶
875566918148669400,Fri Jun 16 04:13:15 +0000 2017,@rbhar90 Learning the n-bit parity function is surprisingly difficult. https://t.co/IkfPMgibND
875566073264750600,Fri Jun 16 04:09:53 +0000 2017,Another paper showing that several proposed defenses against adversarial examples don't hold up to scrutiny: https://t.co/fvvfVF5EN8
875202949865066500,Thu Jun 15 04:06:58 +0000 2017,New blog post with @NicolasPapernot on why verification methods for machine learning are so difficult: https://t.co/JgCDYLCgBl
874498483910131700,Tue Jun 13 05:27:40 +0000 2017,https://t.co/TMieyzfKYx
874479534686453800,Tue Jun 13 04:12:22 +0000 2017,@fchollet https://t.co/m4CuLfaRPq
874474514515546100,Tue Jun 13 03:52:25 +0000 2017,RT @shivon: Icebreaker at ML dinner we're hosting tonight: "Is machine learning more of an art or a sport?"
874473628800176100,Tue Jun 13 03:48:54 +0000 2017,Adversarial examples for the human visual system https://t.co/HT2milRnzv
874363513203859500,Mon Jun 12 20:31:21 +0000 2017,@HiteshUVaidya Check out one of my lectures on why adversarial examples happen. Here's one: https://t.co/o7TmTDM6AO
873952573404741600,Sun Jun 11 17:18:25 +0000 2017,@AdwinKnook Which format of the book and which iPad?
873205854459240400,Fri Jun 09 15:51:13 +0000 2017,@atg_abhishek @xprize @ITU Forgot I have to follow you first. Should work now.
873194637355212800,Fri Jun 09 15:06:39 +0000 2017,@atg_abhishek @xprize @ITU Yes, of course you can DM me
873167312639082500,Fri Jun 09 13:18:04 +0000 2017,@atg_abhishek There was a miscommunication about my time and topic so I wasn't able to present, but I'm happy to videochat with participants
872917537830322200,Thu Jun 08 20:45:33 +0000 2017,@daniel_bilar @moyix @axiomsofchoice @RetractionWatch @IACRePrint I don't know of such a list, but I know of some examples of it happening.
872535500074082300,Wed Jun 07 19:27:28 +0000 2017,RT @NvidiaAI: Learn from @goodfellow_ian on how he created Generative Adversarial Networks, an #AI breakthrough for researchers: https://t.‚Ä¶
872511905948065800,Wed Jun 07 17:53:43 +0000 2017,RT @OriolVinyalsML: It's never clear how to measure overfitting in GANs, but generating up to 4kx4k res faces is pretty drastic! https://t.‚Ä¶
872212869202325500,Tue Jun 06 22:05:27 +0000 2017,CleverHans has a new home in the TensorFlow organization: https://t.co/Co7dIU7EDH
870813726751957000,Sat Jun 03 01:25:46 +0000 2017,Adversarial examples for the human visual system https://t.co/pYWsaiB1Bm
870674258917081100,Fri Jun 02 16:11:34 +0000 2017,RT @balajiln: We (@shakir_za, @goodfellow_ian, @dustinvtran &amp; others) are organizing a workshop on implicit models at ICML 2017: https://t.‚Ä¶
870500705504706600,Fri Jun 02 04:41:55 +0000 2017,RT @tim_cook: Decision to withdraw from the #ParisAgreeement was wrong for our planet. Apple is committed to fight climate change and we wi‚Ä¶
870416512732901400,Thu Jun 01 23:07:22 +0000 2017,RT @WiMLworkshop: WiML's Directory of Women in ML has reached a milestone - 1000 listings! https://t.co/xvBhL86j3H #machinelearning #WiML20‚Ä¶
870391090196627500,Thu Jun 01 21:26:21 +0000 2017,RT @MikeDelMoro: Countries committed to the Paris Climate Accord shaded in blue, via @mashable https://t.co/1RGVGjUUyu
870391060190515200,Thu Jun 01 21:26:14 +0000 2017,RT @IndivisibleTeam: #PollutingPruitt claims he listened to us ‚Äì but the majority of Americans wanted to stay in the #ParisAgreement https:‚Ä¶
870390729310314500,Thu Jun 01 21:24:55 +0000 2017,@filippie509 For 15 latent classes, it's still pretty consistent, though not perfect like for 5 or 10 https://t.co/ZccudbHk5a
870390341236441100,Thu Jun 01 21:23:23 +0000 2017,@filippie509 Here he gave it 5 latent classes, and it assigned 2 of each of the 10 real classes to each of the late‚Ä¶ https://t.co/PgyTYF14Fb
870390176412979200,Thu Jun 01 21:22:43 +0000 2017,@filippie509 Jeff isn't on twitter, but he tells me it works for different amounts of latent classes
870389652649197600,Thu Jun 01 21:20:38 +0000 2017,RT @elonmusk: Am departing presidential councils. Climate change is real. Leaving Paris is not good for America or the world.
870389599478046700,Thu Jun 01 21:20:26 +0000 2017,RT @sundarpichai: Disappointed with today‚Äôs decision. Google will keep working hard for a cleaner, more prosperous future for all.
870343226623836200,Thu Jun 01 18:16:10 +0000 2017,Jeff Donahue's thesis: https://t.co/HC2DhmcRVC In Fig 6.1, a standard GAN learns to separate the 10 MNIST classes with no supervision
870291166641627100,Thu Jun 01 14:49:18 +0000 2017,RT @jackclarkSF: An ancient map of Babylon, transmuted via CycleGAN into a modern Google Map &amp; Satellite View https://t.co/TIH82rLmxc
869313758467719200,Mon May 29 22:05:25 +0000 2017,@KaiLashArul @soumithchintala I don't see much work on robustness to seeds and hyperparams. People claim robustness‚Ä¶ https://t.co/KSxOKFQVlV
869313481027092500,Mon May 29 22:04:19 +0000 2017,@carlesgelada @soumithchintala I do test many adversarial example defense ideas on MNIST first. But I test GAN ideas on ImageNet first now
869313168853553200,Mon May 29 22:03:05 +0000 2017,@visarga @soumithchintala The only significant MNIST accuracy improvement I'm aware of is Tim Salimans' semi-superv‚Ä¶ https://t.co/onPwlJ6Nz1
869302872755667000,Mon May 29 21:22:10 +0000 2017,@ian_soboroff What is 20NG?
869302564394721300,Mon May 29 21:20:56 +0000 2017,@douglas_eck I think using *only* MNIST should almost always mean rejection. Including MNIST is OK though.
869302133526364200,Mon May 29 21:19:14 +0000 2017,@ylecun @soumithchintala It was the most common dataset used in NIPS 2016 papers, not just homework
869301908892078100,Mon May 29 21:18:20 +0000 2017,@soumithchintala Oh no!
869196931901210600,Mon May 29 14:21:12 +0000 2017,Google Trends for interest in "MNIST" since 2004. https://t.co/y2PghbfpRG
868857873945608200,Sun May 28 15:53:54 +0000 2017,@zacharylipton I think your opinion of Schmidhuber would change quite a lot if you became one of his targets.
868557167896309800,Sat May 27 19:59:00 +0000 2017,@ppourbeik I won't go to ICML this year. Hard to travel for family reasons
868557061616844800,Sat May 27 19:58:35 +0000 2017,@visarga @nvidia Yes
868256575714021400,Sat May 27 00:04:33 +0000 2017,Nicholas Carlini and David Wagner have broken *10* recently proposed defenses against adversarial examples: https://t.co/riu36Gy8fG
868170991482003500,Fri May 26 18:24:28 +0000 2017,@OktayGardener Put a cool project on github and write a medium post about it
867905637178515500,Fri May 26 00:50:03 +0000 2017,@patrickshafto I see, makes sense!
867905284982718500,Fri May 26 00:48:39 +0000 2017,@loantricot @dwf @mtyka And @dwf is a GAN co-author :) He is saying NIPS papers should have results on other datase‚Ä¶ https://t.co/68rFDYbz6X
867809214416076800,Thu May 25 18:26:54 +0000 2017,@patrickshafto Why can't you?
867795431656378400,Thu May 25 17:32:08 +0000 2017,Call for papers on human interpretable ML: https://t.co/vqCbcJayGT
866312270464262100,Sun May 21 15:18:35 +0000 2017,@bbaugh0 @roydanroy Makes double blind reviewing possible again
866312119297335300,Sun May 21 15:17:59 +0000 2017,@bbaugh0 @roydanroy Currently everyone in ML puts their work on arxiv so conference reviewers have often seen the w‚Ä¶ https://t.co/9VnVk5I3My
866311936614453200,Sun May 21 15:17:15 +0000 2017,@bbaugh0 @roydanroy A conference that does double blind reviewing could request that any arxiv submission of the same material be anonymous
866115282594439200,Sun May 21 02:15:49 +0000 2017,RT @roydanroy: It's time for arXiv to allow anonymous submission (anonymous to arXiv too), but allow the owner to claim ownership at future‚Ä¶
865637408989106200,Fri May 19 18:36:55 +0000 2017,NIPS submission ID for NIPS 2017 is already greater than the total number of submissions to NIPS 2016 https://t.co/k3uVUi662l
865026555336048600,Thu May 18 02:09:36 +0000 2017,RT @tensorflow: Introducing the TensorFlow Research Cloud: 1,000 Cloud TPUs to support open machine learning research. https://t.co/Jk5a3f9‚Ä¶
864949198826815500,Wed May 17 21:02:13 +0000 2017,@gLeHeinrich @nvidia Great minds think alike!
864872175626408000,Wed May 17 15:56:09 +0000 2017,. @nvidia blog post on my #GTC2017 presentation about GANs: https://t.co/mQh9b31Ahn
864690472240914400,Wed May 17 03:54:08 +0000 2017,@karpathy @AlecRad Wait why are you still in the same room as the GPU?
864326028625199100,Tue May 16 03:45:58 +0000 2017,@TimothyMDevlin @jeffclune I haven't but I don't know a lot about construction sites. Are they computerized enough for ML to help?
862837041486102500,Fri May 12 01:09:16 +0000 2017,@tensorDroid I personally won't be
862829766025519100,Fri May 12 00:40:21 +0000 2017,RT @deeplearning4j: Real-Time User-Guided Image Colorization with Learned Deep Priors https://t.co/bLmScAn01K
862493239407857700,Thu May 11 02:23:07 +0000 2017,RT @badnetworker: Best machine translation bug of the week: https://t.co/5atVMelTNn
862321965666754600,Wed May 10 15:02:32 +0000 2017,@damianborth @Apple @DFKI ( USB-C MacBook + HDMI adapter-&gt; MacBook wouldn't recognize AV system)
862028834865991700,Tue May 09 19:37:44 +0000 2017,RT @KyleCranmer: Generative Models (GANs) for particle physics detector data. Nice work @WonderMicky @BPNachman @lukede0. @goodfellow_ian h‚Ä¶
861566649941475300,Mon May 08 13:01:11 +0000 2017,@OktayGardener 31. Was 24 when I finished my MS
860319270479069200,Fri May 05 02:24:32 +0000 2017,RT @petewarden: We've just released a set of benchmarks for @TensorFlow: https://t.co/eRwR0BVkGE - see https://t.co/PWm8xIKL0M for performa‚Ä¶
859881422311497700,Wed May 03 21:24:41 +0000 2017,https://t.co/uBPdvcepZv
857978820300636200,Fri Apr 28 15:24:25 +0000 2017,ISPs should *not* control what we read/watch/say online. That‚Äôs #NetNeutrality &amp; now it‚Äôs under attack. Defend it! https://t.co/Ye4GyyTjZo
857746550704848900,Fri Apr 28 00:01:28 +0000 2017,@jordanmonson Yes, is it out now?
857573711767064600,Thu Apr 27 12:34:40 +0000 2017,CycleGAN applied to bears-&gt;pandas! https://t.co/J8s6dW4Om3 https://t.co/CLulsDMXEk
857573471261470700,Thu Apr 27 12:33:43 +0000 2017,GANs for translation: https://t.co/CDreYgG1pk
857480229475844100,Thu Apr 27 06:23:12 +0000 2017,I just donated to @fightfortheftr to protect net neutrality. Don't let Comcast decide what you can see online. https://t.co/94rdrZ90IH
857247008498647000,Wed Apr 26 14:56:28 +0000 2017,#iclr2017 Come see poster W18 on adversarial examples in the physical world. Complete with live phone demo
857240010986213400,Wed Apr 26 14:28:40 +0000 2017,#iclr2017 Check out C25 for our poster on semi-supervised learning with virtual adversarial training https://t.co/VHnADkw9jk
857198563914379300,Wed Apr 26 11:43:58 +0000 2017,RT @NicolasPapernot: Come see our poster on adversarial examples in reinforcement learning! It will be up at W8 between 4.30pm and 6.30pm.‚Ä¶
857144805515817000,Wed Apr 26 08:10:21 +0000 2017,@realhamed :) will reply by email
856816179939246100,Tue Apr 25 10:24:30 +0000 2017,#iclr2017 At 2-4PM, check out poster C13 on PATE-G ( https://t.co/PRGnQHw9j4 ), our generic framework for ML with d‚Ä¶ https://t.co/1SFRioa2Vd
856592856986771500,Mon Apr 24 19:37:06 +0000 2017,Lots of exciting work from Google at #iclr2017 ! Be sure to check out our booth (I'm there most coffee breaks) https://t.co/j2gEnmnl8k
856504451204612100,Mon Apr 24 13:45:48 +0000 2017,#iclr2017 at 4:30 PM, come check out poster C16, "Adversarial Machine Learning at Scale" https://t.co/eVsjcgVeng https://t.co/zuLhximsMI
856456296328974300,Mon Apr 24 10:34:27 +0000 2017,@aravindxk Oh it was today. I have run out of shirts now but my co-authors might still have some
856423705919995900,Mon Apr 24 08:24:57 +0000 2017,@aravindxk I'm at the Google booth for the coffee break
856404574520979500,Mon Apr 24 07:08:56 +0000 2017,#iclr2017 My PATE-G ( https://t.co/PRGnQHw9j4 ) co-authors and I are giving away a limited number of T-shirts while‚Ä¶ https://t.co/tMmJ2mm2qC
856113588397723600,Sun Apr 23 11:52:39 +0000 2017,@venkatesanragav I mostly rely on trusted colleagues to summarize other papers for me (and I do the same for them)
856113387498950700,Sun Apr 23 11:51:52 +0000 2017,@venkatesanragav I skim a lot, but probably fully read only around 2 per week, chosen very carefully
856099154380116000,Sun Apr 23 10:55:18 +0000 2017,@venkatesanragav Current ML conferences probably have more than enough. They need to focus the happy hour conversat‚Ä¶ https://t.co/l6g1zwQnav
856087899913175000,Sun Apr 23 10:10:35 +0000 2017,@venkatesanragav Built on earlier non-bar ideas but yes, the pieces clicked together at the bar
856073817919180800,Sun Apr 23 09:14:37 +0000 2017,@venkatesanragav Mine too. I don't know anything about most of these
855149958457991200,Thu Apr 20 20:03:32 +0000 2017,RT @shakir_za: Announcing the Deep Learning Indaba; to stimulate participation of fellow Africans in Machine Learning. Help spread the word‚Ä¶
855091388836438000,Thu Apr 20 16:10:48 +0000 2017,The GAN zoo, a list of named GAN variants: https://t.co/Snb10XRfnf
854626222504112100,Wed Apr 19 09:22:24 +0000 2017,Differentially private ML needs to balance low error rate with low privacy cost. PATE-G (Papernot et al 2017) achie‚Ä¶ https://t.co/ODGzJLp59y
854625189707087900,Wed Apr 19 09:18:18 +0000 2017,Nice comparison of differentially private ML benchmarks put together by @npapernot to track state of the art: https://t.co/pvnWvAlYv1
854609936667598800,Wed Apr 19 08:17:41 +0000 2017,Excited to be speaking at AI @WithTheBest online conference April 29! #AIWTB https://t.co/swMIVszgSA
854323718851633200,Tue Apr 18 13:20:21 +0000 2017,@romefort Thanks for the invitation, but I'm too busy building the new research group on adversarial techniques in‚Ä¶ https://t.co/scgIU75xZF
853659581582528500,Sun Apr 16 17:21:19 +0000 2017,@ThomasSchander They could be
853385527067791400,Sat Apr 15 23:12:19 +0000 2017,@RUSH1L That's MRI not EEG. GANs could be useful for this, haven't heard of anything published let though. Let the race begin!
853032035685867500,Fri Apr 14 23:47:40 +0000 2017,@edersantana It's OK to publish MNIST experiments but there should be experiments on at least 1 other dataset
852765100360454100,Fri Apr 14 06:06:58 +0000 2017,@NoPtrException Biologists grow cells. Psychologists track children's development. Computer scientists should be ab‚Ä¶ https://t.co/mhjuzm2DuA
852764717332406300,Fri Apr 14 06:05:26 +0000 2017,@NoPtrException MNIST experiments used to take days. And somehow we wrote NIPS papers before the 1080 existed
852764491674550300,Fri Apr 14 06:04:33 +0000 2017,@NoPtrException If you're publishing in a top scientific venue, it's completely reasonable for your experiment to take days
852716972806623200,Fri Apr 14 02:55:43 +0000 2017,RT @Miles_Brundage: :-O https://t.co/vrLMxwoct1 https://t.co/YDtby5jJgG
852716527937667100,Fri Apr 14 02:53:57 +0000 2017,@WonderMicky Maybe check out https://t.co/bczqgEnv6J and use our specialized batch norm
852685603988701200,Fri Apr 14 00:51:04 +0000 2017,@WonderMicky What kind of batch norm?
852672752557346800,Fri Apr 14 00:00:00 +0000 2017,@WonderMicky Are you using batch norm? Batch norm should fix several init problems
852627037801955300,Thu Apr 13 20:58:21 +0000 2017,@alexattia Guess w/o evidence: NIPS 2016 required one author of each publication to serve as reviewer, so maybe nov‚Ä¶ https://t.co/e2uEbkGlTo
852626367124430800,Thu Apr 13 20:55:41 +0000 2017,@jordanmonson Ask press@google.com
852591106655043600,Thu Apr 13 18:35:34 +0000 2017,Instead of moving on to harder datasets than MNIST, the ML community is studying it more than ever. Even proportion‚Ä¶ https://t.co/slF8xjike1
852514754929111000,Thu Apr 13 13:32:11 +0000 2017,@AdrianoCarmezim I think Cade means most classifiers in production today are fully supervised
852221025693466600,Wed Apr 12 18:05:00 +0000 2017,Article in The Verge about adversarial ML: https://t.co/fQSvG27ze6
852182677272764400,Wed Apr 12 15:32:37 +0000 2017,@nerdworldorder Hard to quantify which matters more. Keep in mind some of our arguments are based on carefully constructed datasets
852177777587503100,Wed Apr 12 15:13:09 +0000 2017,@amirieb The best defense so far is adding them at training time. You want to regenerate constantly, not augment the training set once
852024460597018600,Wed Apr 12 05:03:55 +0000 2017,@aerinykim Wish I had, but no
851998091846623200,Wed Apr 12 03:19:09 +0000 2017,Estimating the dimensionality of the subspace of adversarial examples: https://t.co/HIvbRdwTAe
851996875674730500,Wed Apr 12 03:14:19 +0000 2017,@Vatlidak @Miles_Brundage He tweets the papers faster than the authors do!
851995207822221300,Wed Apr 12 03:07:41 +0000 2017,@ram_ssk It's actually easier that way. Ballmer peak
851942063469805600,Tue Apr 11 23:36:30 +0000 2017,@androidscience My guess is yes. ZCA whitening is similar and it doesn't help
851835034583449600,Tue Apr 11 16:31:13 +0000 2017,Wired article with the GAN origin story: https://t.co/RbKvRRH39S
851815464804077600,Tue Apr 11 15:13:27 +0000 2017,RT @Tbeltramelli: A great article from @Wired about the power of GANs and how @goodfellow_ian got the initial idea https://t.co/xBVF88G959‚Ä¶
851598999941292000,Tue Apr 11 00:53:18 +0000 2017,@sickeningjar If you have a training set of unicorn photos
851302355823861800,Mon Apr 10 05:14:32 +0000 2017,RT @AliMakhzani: Adversarial autoencoders for predicting human cell organization: https://t.co/WGSdQlR9D6
851300915684425700,Mon Apr 10 05:08:49 +0000 2017,@click_arun @dribnet Looks OK to me
851260865760247800,Mon Apr 10 02:29:40 +0000 2017,@Lim_JeiKei Yeah the paper shows both mappings
851258255703593000,Mon Apr 10 02:19:18 +0000 2017,@kastnerkyle @edersantana @dribnet #rocketai
851245885967159300,Mon Apr 10 01:30:09 +0000 2017,@click_arun @dribnet That's probably just a standard overfitting / underfitting mistake
851245814265421800,Mon Apr 10 01:29:52 +0000 2017,@click_arun @dribnet No, even if the model doesn't know which aspect of the data we want transformed, it should see‚Ä¶ https://t.co/YJL2bGB4P4
851209955868790800,Sun Apr 09 23:07:22 +0000 2017,@dribnet This is also because it's totally unsupervised so it doesn't even know the horse is the only part we want it to care about
851148595386433500,Sun Apr 09 19:03:33 +0000 2017,@pdvalentini is there a training set of unicorn photos?
851139169535406100,Sun Apr 09 18:26:06 +0000 2017,@thejackgoode Actually... https://t.co/bpnBYCPO1f
851124988903997400,Sun Apr 09 17:29:45 +0000 2017,CycleGAN turning a horse video into a zebra video ( https://t.co/YYCsVt4rIP ) https://t.co/KlZlKG5k6W
851124820473282600,Sun Apr 09 17:29:04 +0000 2017,@recurseparadox @NPR April 14
851085434322997200,Sun Apr 09 14:52:34 +0000 2017,This Planet Money episode on getting people to pay taxes might be helpful for getting people to write ICML reviews: https://t.co/Ln3R0yFMAe
850516178351013900,Sat Apr 08 01:10:33 +0000 2017,RT @TerryUm_ML: I developed a GANN (Generative adversarial name-making networks), for you, @hardmaru @karpathy. The source code is availabl‚Ä¶
850421553107947500,Fri Apr 07 18:54:32 +0000 2017,@chrisdonahuey @hardmaru There are also two LS-GANs (least squares and loss-sensitive)
850421381414236200,Fri Apr 07 18:53:52 +0000 2017,@chrisdonahuey @hardmaru For the ICCV workshop we accidentally posted a link to Stacked GAN when we meant StackGAN
850401908342665200,Fri Apr 07 17:36:29 +0000 2017,https://t.co/LwfwhUpQf4
850051230080450600,Thu Apr 06 18:23:01 +0000 2017,https://t.co/sf66zBBeF2
849838308410523600,Thu Apr 06 04:16:56 +0000 2017,@pjreddie @nerdherdempire @soumithchintala @karpathy TensorFlow queues. All the code for it is in the repo I linked
849836586254475300,Thu Apr 06 04:10:06 +0000 2017,@nerdherdempire @pjreddie @soumithchintala @karpathy Just 4
849834438871482400,Thu Apr 06 04:01:34 +0000 2017,@pjreddie @soumithchintala @karpathy https://t.co/bczqgEnv6J should train roughly overnight
849795967754747900,Thu Apr 06 01:28:41 +0000 2017,@edersantana @hardmaru @chrisdonahuey those are disconnected in the input space too. i mean a generator transform t‚Ä¶ https://t.co/nSHNyxur0F
849787989228044300,Thu Apr 06 00:56:59 +0000 2017,@hardmaru @chrisdonahuey No, topologically disconnected output regions
849783992823930900,Thu Apr 06 00:41:06 +0000 2017,@chrisdonahuey @hardmaru I worked on and abandoned an idea I called DiscoGANs in late 2014. Had nothing to do with‚Ä¶ https://t.co/FKNAntLrKZ
849448212335407100,Wed Apr 05 02:26:50 +0000 2017,https://t.co/n60F80uoll
848742838334390300,Mon Apr 03 03:43:56 +0000 2017,RT @sundarpichai: Proud to support AI research in Canada w/ new Google Brain Toronto team and our contribution to the #VectorInstitute http‚Ä¶
847973157126287400,Sat Apr 01 00:45:29 +0000 2017,@moien_mostafavi Python (+TensorFlow )
847937728121495600,Fri Mar 31 22:24:42 +0000 2017,RT @googlecanada: Why üá®üá¶ is having an AI moment: Google VP Geoffrey Hinton helps welcome #VectorInstitute &amp; Google Brain Team to TO https:/‚Ä¶
847933067205386200,Fri Mar 31 22:06:11 +0000 2017,@vbjelak Not sure about streaming / recording yet, will post info when we know what's possible
847933010750062600,Fri Mar 31 22:05:58 +0000 2017,@vbjelak To attend, you should register for the tutorials portion of ICCV 2017: https://t.co/cU94ZJsgfz
847836929886376000,Fri Mar 31 15:44:10 +0000 2017,@erfannoury Fixed, thanks
847835976252571600,Fri Mar 31 15:40:23 +0000 2017,Mihaela Rosca and I are co-organizing a full day GAN tutorial at ICCV 2017, featuring over 10 speakers and demos: https://t.co/LiY85JOlSu
847806003865309200,Fri Mar 31 13:41:17 +0000 2017,CycleGAN learns to turn horses into zebras *without supervision*: https://t.co/JVTWIyDYAj https://t.co/FRpCtYCwM9
847640259705749500,Fri Mar 31 02:42:40 +0000 2017,RT @atiorh: @ctnzr GTC 2017 GAN session will include newest research post-NIPS2016 workshopüëåüèø https://t.co/PIuc57EYDk
847624165863563300,Fri Mar 31 01:38:43 +0000 2017,https://t.co/Z9jMV4AOvW
847437278750408700,Thu Mar 30 13:16:06 +0000 2017,RT @hugo_larochelle: The application deadline is April 21 https://t.co/onxTknEraQ
847320144611221500,Thu Mar 30 05:30:39 +0000 2017,@atiorh Yes, probably StackGANs, DiscoGANs, AVB, and Sanjeev Arora et al's work on equilibria. And whatever comes out in April :)
847110201463365600,Wed Mar 29 15:36:25 +0000 2017,https://t.co/ZASOA1DkOM
847079910371876900,Wed Mar 29 13:36:03 +0000 2017,@biggiobattista Yes, I cite your work now that I know about it. I think you mean ICLR not NIPS
846879975567376400,Wed Mar 29 00:21:35 +0000 2017,@asthesparksfly you can get the image from the "other formats" download on arxiv
846879845292290000,Wed Mar 29 00:21:04 +0000 2017,@asthesparksfly yes, as long as it's properly attributed
846879556501844000,Wed Mar 29 00:19:55 +0000 2017,@Meaningness see my tweet from earlier today. I already described this in 2014...
846879183254933500,Wed Mar 29 00:18:26 +0000 2017,@snagglechud can email me. Lastname.firstname@gmail.com
846774440222376000,Tue Mar 28 17:22:13 +0000 2017,A weight vector for a specific class is a universal perturbation against all other classes
846774313634037800,Tue Mar 28 17:21:43 +0000 2017,@goodfellow_ian It's easiest to see in @karpathy 's blog post : https://t.co/hRL4ae4YYV
846774128061300700,Tue Mar 28 17:20:59 +0000 2017,@goodfellow_ian "Because it is the direction that matters most, adversarial perturbations generalize across different clean examples."
846774086424379400,Tue Mar 28 17:20:49 +0000 2017,We already knew about "universal adversarial perturbations" in 2014. https://t.co/j4Q3KWCxtd
846388198913695700,Mon Mar 27 15:47:26 +0000 2017,RT @NicolasPapernot: Looking forward to my talk on security and privacy in ML at @Cambridge_Uni on March 31st (11:00)! cc @arberesford http‚Ä¶
845651865530335200,Sat Mar 25 15:01:30 +0000 2017,@ariachernik @DukeU sure, e-mail me at lastname.firstname@gmail.com
845289356931715100,Fri Mar 24 15:01:02 +0000 2017,@yishern no, see chap 9 of the book
844974772811251700,Thu Mar 23 18:10:59 +0000 2017,Applications to @WiCVworkshop are open now. Submit an abstract here: https://t.co/FLhrUa49e0
843914191152984000,Mon Mar 20 19:56:36 +0000 2017,@ferrouswheel @michael_nielsen it's now a journal rather than only a website. Also the prizes are new
843882046522970100,Mon Mar 20 17:48:53 +0000 2017,The paper on adversarial examples for RL by Sandy Huang and my other co-authros has been accepted to ICLR Workshops: https://t.co/skT2wrhAMt
843874174863003600,Mon Mar 20 17:17:36 +0000 2017,Want to learn about machine learning? Follow @distillpub
843873818871382000,Mon Mar 20 17:16:11 +0000 2017,RT @ch402: Why I'm moving on from https://t.co/ZX12RZ708a to editing @distillpub. https://t.co/zpLhn0Jtzt https://t.co/m8QOi3y4Ji
843873802656206800,Mon Mar 20 17:16:07 +0000 2017,RT @ycombinator: Distill: An Interactive, Visual Journal for Machine Learning Research - @michael_nielsen https://t.co/N2vrctVIB6 https://t‚Ä¶
843873786483040300,Mon Mar 20 17:16:03 +0000 2017,RT @michael_nielsen: Distill is a modern medium for presenting research https://t.co/ETql2X6gg0
843873770104279000,Mon Mar 20 17:15:59 +0000 2017,RT @michael_nielsen: Announcing Distill https://t.co/HpT1lNy295, a new interactive, visual journal for machine learning research. Details h‚Ä¶
843873750068031500,Mon Mar 20 17:15:55 +0000 2017,RT @distillpub: Distill is a interactive, visual journal for machine learning research. https://t.co/BZegy07cmL https://t.co/P4qCe8wgHB
843873673421324300,Mon Mar 20 17:15:36 +0000 2017,RT @michael_nielsen: That medium will enable new ways of thinking that enable new discoveries https://t.co/ZRJTeXD700
843873634363953200,Mon Mar 20 17:15:27 +0000 2017,RT @distillpub: Machine Learning Research Should Be Clear, Dynamic and Vivid. Distill Is Here to Help. https://t.co/BZegy07cmL https://t.co‚Ä¶
843873480965673000,Mon Mar 20 17:14:50 +0000 2017,RT @googleresearch: Announcing Distill (@distillpub), a science journal and ecosystem supporting the understanding of #MachineLearning - ht‚Ä¶
843471065103835100,Sun Mar 19 14:35:47 +0000 2017,@rasmusoxenvad no https://t.co/5bwCiaoCve
843208071836975100,Sat Mar 18 21:10:45 +0000 2017,RT @NandoDF: Learned Optimizers that Scale and Generalize - learning to learn take 2  https://t.co/xi5CTR6484
842953246469636100,Sat Mar 18 04:18:09 +0000 2017,@gitanjaligulve @udacity @iamtrask @sirajraval https://t.co/oRa4E31ac5
842762006759268400,Fri Mar 17 15:38:14 +0000 2017,RT @udacity: Clear your evening, we're talking #deeplearning w/ @goodfellow_ian @iamtrask @sirajraval tonight at 6pm PT https://t.co/OmFEFl‚Ä¶
842532014431457300,Fri Mar 17 00:24:20 +0000 2017,RT @udacity: Join us Friday for "On the State of #deeplearning" w/ @goodfellow_ian @iamtrask @sirajraval ‚Äî Live at 6pm PT! https://t.co/OmF‚Ä¶
842492504658206700,Thu Mar 16 21:47:20 +0000 2017,I‚Äôm speaking at #GTC17 about #GANs. Use code FFSGTC17 to save 20% off registration. https://t.co/1ZuN328EmB
842416082237374500,Thu Mar 16 16:43:39 +0000 2017,@FCC @AjitPaiFCC why cut #lifeline? Rural America needs more internet access not less
842399841380528100,Thu Mar 16 15:39:07 +0000 2017,RT @danieldewey: Schelling's lecture on the nuke taboo. Among the most important socio-political phenomena? https://t.co/RNKBvEqkiG h/t @mi‚Ä¶
841742299004510200,Tue Mar 14 20:06:17 +0000 2017,Keshav Dhandhania has set up a Commonlounge community for discussing the Deep Learning textbook: https://t.co/b9Qy27yxhd
841462023217020900,Tue Mar 14 01:32:34 +0000 2017,RT @ericschmidt: John Goodenough, inventor of the lithium battery, has developed the first all-solid-state battery cells. Promising! https:‚Ä¶
841308527532499000,Mon Mar 13 15:22:38 +0000 2017,RT @katecrawford: We're building the @AINowInitiative to study the social impacts of artificial intelligence. It starts here: https://t.co/‚Ä¶
840977645491781600,Sun Mar 12 17:27:49 +0000 2017,RT @NicolasPapernot: My talk at @enigmaconf on adversarial examples is now up! Thanks to @goodfellow_ian and @UlfarEr for helping out https‚Ä¶
840743482792726500,Sun Mar 12 01:57:21 +0000 2017,@jskDr studying lots of other generative models + thinking about how to avoid their disadvantages
840709748458643500,Sat Mar 11 23:43:18 +0000 2017,@jasonpurdy @schmilblick42 it means 50,000 developers are interested in TensorFlow
840611366301921300,Sat Mar 11 17:12:22 +0000 2017,TensorFlow has reached 50,000 stars: https://t.co/zjPbdH2O9g (h/t Zak Stone)
840606654257233900,Sat Mar 11 16:53:38 +0000 2017,RT @yaroslav_ganin: Alright folks, here is a #deepwarp web demo: https://t.co/WgBApTNPtC  (a bit unpolished). Also, eye-rolling @goodfellow‚Ä¶
840606070305259500,Sat Mar 11 16:51:19 +0000 2017,Congratulations @yaroslav_ganin https://t.co/tioWfHbMI4
840287237518508000,Fri Mar 10 19:44:23 +0000 2017,@JCornebise I do not believe so. He promotes citation of his own work, not accurate citation of multiple community members' work
840204707566035000,Fri Mar 10 14:16:27 +0000 2017,@egrefen @JCornebise @PeterDjecob I already have a lot of trouble with attribution for this paper and don't want to make it worse
840203929048686600,Fri Mar 10 14:13:21 +0000 2017,@egrefen @JCornebise @PeterDjecob people have told me they ignored an article because they thought an arxiv change indicated a serious flaw
840203357256077300,Fri Mar 10 14:11:05 +0000 2017,@egrefen @JCornebise @PeterDjecob there are other things that can go wrong with arxiv changes too
840203251727261700,Fri Mar 10 14:10:40 +0000 2017,@egrefen @JCornebise @PeterDjecob and it's easier to see the typo is wrong than to see the citation date is wrong
840203111801139200,Fri Mar 10 14:10:06 +0000 2017,@egrefen @JCornebise @PeterDjecob most people are not that diligent. It matters because original work ends up described as derivative
840085624619057200,Fri Mar 10 06:23:15 +0000 2017,RT @mrtz: Compressed sensing using generative neural models. My favorite application of GANs yet: https://t.co/yDfbEIzgCq
840084111331008500,Fri Mar 10 06:17:14 +0000 2017,@JCornebise @PeterDjecob people would cite it as "Goodfellow et al 2017". This has happened every time I've made such an edit
839910141000507400,Thu Mar 09 18:45:57 +0000 2017,@NandoDF thanks!
839904141862293500,Thu Mar 09 18:22:06 +0000 2017,@yen_chen_lin sure, link?
839606990548586500,Wed Mar 08 22:41:20 +0000 2017,RT @AlisonBLowndes: This ones for you @goodfellow_ian with lots of love &amp; hugs from @SamAlbanie &amp; the entire UK #deeplearning community htt‚Ä¶
839292454234796000,Wed Mar 08 01:51:29 +0000 2017,Videos are now available for the NIPS 2016 workshop on reliable machine learning in the wild: https://t.co/XCuFzvDJfK
839283045676937200,Wed Mar 08 01:14:05 +0000 2017,@alirezasmr @datarade @mlweekly you need to ask press@google.com
838196465226829800,Sun Mar 05 01:16:24 +0000 2017,RT @OriolVinyalsML: ML &amp; health: awesome news! (89% ML vs 73% human) Something my parents can appreciate more than detecting cats! https://‚Ä¶
838132343554486300,Sat Mar 04 21:01:37 +0000 2017,RT @Iprogrammerinfo: AI Security At Online Conference: An Interview With Ian Goodfellow @goodfellow_ian https://t.co/w101xP1ICu via @Iprogr‚Ä¶
837375244146880500,Thu Mar 02 18:53:10 +0000 2017,RT @NicolasPapernot: The video of a talk on adversarial examples that @goodfellow_ian and I jointly gave at @AutoSens_  is now up https://t‚Ä¶
836656978076147700,Tue Feb 28 19:19:02 +0000 2017,RT @weballergy: 'Boundary-Seeking Generative Adversarial Networks': Nice new results by Yoshua Bengio's group. https://t.co/3yDnEqZkLG #dee‚Ä¶
836590108241346600,Tue Feb 28 14:53:19 +0000 2017,RT @saakohl: `Adversarial Networks for the Detection of Aggressive Prostate Cancer' - https://t.co/aOc9AuHzEn @soumithchintala @goodfellow_‚Ä¶
836281754902118400,Mon Feb 27 18:28:02 +0000 2017,@piccolbo I'm saying it adds additional errors that are harder to detect. Single character typo errors are generally not harmful
836097848496173000,Mon Feb 27 06:17:15 +0000 2017,@piccolbo people cite the paper as coming from the wrong year, think it was not the first paper on the subject, etc
836097649908441100,Mon Feb 27 06:16:28 +0000 2017,@piccolbo every time I've fixed an arxiv typo, I've had problems that were much bigger than the typo result from it
836097494131974100,Mon Feb 27 06:15:51 +0000 2017,@piccolbo while they may verbally encourage it, the way the site works causes trouble in practice
835983342738681900,Sun Feb 26 22:42:15 +0000 2017,@piccolbo can't fix the typo or arxiv will change time stamp to 2017
835894061101809700,Sun Feb 26 16:47:28 +0000 2017,@piccolbo I would call it a regularization term added to the logits
835893956525203500,Sun Feb 26 16:47:04 +0000 2017,@piccolbo OK. i just meant a "term" is something that is added. Since it's inside the softplus, it's not a "term" of the cost.
835758597594210300,Sun Feb 26 07:49:11 +0000 2017,@piccolbo note that it's not a regularization term, it's an adjustment of the prediction in the existing likelihood term
835681738189754400,Sun Feb 26 02:43:47 +0000 2017,@piccolbo oh, yes that's a typo. The loss right below is correct though
835508108524826600,Sat Feb 25 15:13:50 +0000 2017,@piccolbo do you mean the equation on page 4? The target is y; it is there
835170445645103100,Fri Feb 24 16:52:05 +0000 2017,RT @zinmalu: DROP EVERYTHING you're doing (yes, also them ICML papers - totally worth it) and check out this #edges2cats applet https://t.c‚Ä¶
834923237075144700,Fri Feb 24 00:29:46 +0000 2017,RT @NicolasPapernot: I will be speaking about adversarial examples and #cleverhans tonight in Menlo Park. Check for livestream link here: h‚Ä¶
834917963006238700,Fri Feb 24 00:08:49 +0000 2017,@ram_ssk @NicolasPapernot thank you!
834917654666207200,Fri Feb 24 00:07:35 +0000 2017,RT @deborahhanus: Are you a woman in #computervision? Submit an abstract to @WiCVworkshop at @CVPR by 4/21: https://t.co/1iMS134tkw #WiCV20‚Ä¶
834876992117805000,Thu Feb 23 21:26:00 +0000 2017,@goodfellow_ian Congratulations to first author @NicolasPapernot !
834876602282479600,Thu Feb 23 21:24:27 +0000 2017,The Brain-OpenAI collaboration on differential privacy won an ICLR best paper award! https://t.co/PRGnQHexUu
834411272787603500,Wed Feb 22 14:35:24 +0000 2017,RT @oleivarrudi: just a normal housecat  #edges2cats #pixsrv https://t.co/adp6Cs5oPj
834411124938387500,Wed Feb 22 14:34:49 +0000 2017,RT @BlurTheFur: WHO'S THAT POKEMON It's Oh dear GOD #edges2cats https://t.co/ZlXtunWyum
834411079161765900,Wed Feb 22 14:34:38 +0000 2017,RT @ivymyt: Okay total creepy uncanny valley time but #breadcat #edges2cats https://t.co/i3ALRn9yFD
834411051382878200,Wed Feb 22 14:34:31 +0000 2017,RT @EimhinMcNamara: I did some #animation using the #edges2cats applet https://t.co/U1N7jYwB9W https://t.co/FtMnDMnvV0
834410113301672000,Wed Feb 22 14:30:48 +0000 2017,TensorFlow port of Isola et al's image-to-image translation GANs: https://t.co/YBR04ONqJ9
834247206509101000,Wed Feb 22 03:43:28 +0000 2017,@leakyrelu oh read the tutorial: https://t.co/v1rAvk2bKt
834075375680553000,Tue Feb 21 16:20:40 +0000 2017,Apply here for this year's MILA summer school. I'll teach a lecture on generative models: https://t.co/jiRGIzHukP
833914896949641200,Tue Feb 21 05:42:59 +0000 2017,@gadipatil_akki arguing with friends in a bar (Les Trois Brasseurs in downtown Montreal)
833839278731907100,Tue Feb 21 00:42:30 +0000 2017,RT @NicolasPapernot: New #cleverhans feature: you can now visualize adversarial examples. See tutorial here: https://t.co/IT0PT0I0Gk
833692392779808800,Mon Feb 20 14:58:50 +0000 2017,The high quality videos of the NIPS 2016 workshop on adversarial training are now available: https://t.co/DfgGvDs7gL
833093875669532700,Sat Feb 18 23:20:32 +0000 2017,@NicolasPapernot @mcarroll_ specifically Jon Shlens, 2nd author of that paper
832764665172201500,Sat Feb 18 01:32:22 +0000 2017,RT @vinayprabhu: Word-cloud of @iclr2017 workshop submission titles. Very GANsy ! (@goodfellow_ian). Also, 58% of the submissions were last‚Ä¶
832725030148509700,Fri Feb 17 22:54:53 +0000 2017,@ReubenFeinman @NicolasPapernot so far it has always been possible to fool them into thinking they are not extrapolating
832609279626661900,Fri Feb 17 15:14:56 +0000 2017,@ArnauTibau you can think of it as overfitting to the data-generating distribution rather than overfitting to a specific set of examples
832608999568732200,Fri Feb 17 15:13:49 +0000 2017,@ArnauTibau somewhat but not entirely. It's possible to have superhuman accuracy on the test set and ~0 accuracy on adversarial examples
832376081873248300,Thu Feb 16 23:48:17 +0000 2017,@douglas_eck @YouTube why not a magenta t-shirt?
832338842044792800,Thu Feb 16 21:20:18 +0000 2017,@cdvarano @OpenAI previous attempts to do that haven't worked. See https://t.co/UMJWLckInG for example
832300019365589000,Thu Feb 16 18:46:02 +0000 2017,@daniel_bilar there's already some follow-up work: https://t.co/kY7CKU4kTW
832299821289578500,Thu Feb 16 18:45:15 +0000 2017,@daniel_bilar it's a promising direction
832293579863314400,Thu Feb 16 18:20:27 +0000 2017,@Cortu01 @OpenAI Yes, they are from a different distribution designed by the adversary
832292924868132900,Thu Feb 16 18:17:51 +0000 2017,RT @NicolasPapernot: New #cleverhans blog post with @goodfellow_ian: "Is attacking machine learning easier than defending it?" https://t.co‚Ä¶
832290298906673200,Thu Feb 16 18:07:25 +0000 2017,OpenAI blog post on adversarial examples: https://t.co/dnKtcgppuh
831888856970588200,Wed Feb 15 15:32:13 +0000 2017,Drug Discovery Magazine article about GANs / adversarial autoencoders for identifying cancer drug candidates: https://t.co/E2I1Wm06l5
831694667750203400,Wed Feb 15 02:40:35 +0000 2017,RT @dribnet: @KyleCranmer @goodfellow_ian roses are red violets are blue GAN flower samples with identical latents but conditioned on text:‚Ä¶
831634968782655500,Tue Feb 14 22:43:22 +0000 2017,@KyleCranmer they do look quite GAN-like!
831634896414138400,Tue Feb 14 22:43:04 +0000 2017,RT @KyleCranmer: Roses are red, violets are blue, These images are from a GAN, or did I fool you?  ‚ô•Ô∏è@goodfellow_ian https://t.co/l9dAwpHrd3
830607809284710400,Sun Feb 12 02:41:48 +0000 2017,Improved SMT solver approach for showing there are no adversarial examples within specific regions: https://t.co/yMmXJOhPYF
830516352754425900,Sat Feb 11 20:38:23 +0000 2017,@cjordansquire it's easier to build a house with a million bricks than with three bricks, even if more bricks is superficially complicated
830515956451405800,Sat Feb 11 20:36:48 +0000 2017,@cjordansquire yeah the key is to design the model to be "easy to optimize" not to be simple
830456949112086500,Sat Feb 11 16:42:20 +0000 2017,@cjordansquire it's usually deep learning people that want to make the model more complicated and then make the optimizer more powerful
830456546039525400,Sat Feb 11 16:40:44 +0000 2017,@cjordansquire Boyd's convex optimization class is mostly about how to redesign problems to make them convex, not about optimization algs
830456274454077400,Sat Feb 11 16:39:39 +0000 2017,@cjordansquire On the contrary, I would say that's the main lesson I learned from Stephen Boyd's convex optimization class
830213110602489900,Sat Feb 11 00:33:24 +0000 2017,@aasensior just behind on email
829553744467472400,Thu Feb 09 04:53:19 +0000 2017,RT @NicolasPapernot: Just added a tutorial on black-box attacks (from https://t.co/Fz3xKXKZbX) to cleverhans, you can find it here:  https:‚Ä¶
829377424429166600,Wed Feb 08 17:12:41 +0000 2017,Adversarial examples for RL: https://t.co/K1tOyaXmAy
829334519903694800,Wed Feb 08 14:22:12 +0000 2017,@SeanPedersen96 Amazon says Feb 12. I think you can pre-order
829192492469850100,Wed Feb 08 04:57:50 +0000 2017,@1910roz @Miles_Brundage you can read it for free at https://t.co/2CkX4R3GPd
829192188819042300,Wed Feb 08 04:56:38 +0000 2017,@1910roz @Miles_Brundage it's intended for people with a CS background who are beginners to ML and want to become experts
829074533785100300,Tue Feb 07 21:09:06 +0000 2017,#AAAI2017 : because the book sold out early, I actually won't come to AAAI in the end. DM me if you bought one counting on getting it signed
828756290235035600,Tue Feb 07 00:04:31 +0000 2017,@mitpress is selling the Deep Learning textbook at #AAAI2017 . I'll sign books at 3:30PM tomorrow (Feb 7)
828638907331776500,Mon Feb 06 16:18:05 +0000 2017,Brain+OpenAI collaboration on differential privacy accepted as an oral presentation at ICLR: https://t.co/NEjdywsAUX
828042405639180300,Sun Feb 05 00:47:48 +0000 2017,@_ambodi several chapters suggest a full book expanding on the chapter
827979774018494500,Sat Feb 04 20:38:55 +0000 2017,RT @gdm3000: Single-blind reviewing heavily biased towards top institutions: Results of the controlled experiment at WSDM 2017 https://t.co‚Ä¶
827944310293172200,Sat Feb 04 18:18:00 +0000 2017,RT @earnmyturns: Single-blind vs double-blind reviewing: fame pays https://t.co/fEYaTEvTls
827550496894226400,Fri Feb 03 16:13:08 +0000 2017,@aasensior suggest discussing by email
826842836981014500,Wed Feb 01 17:21:08 +0000 2017,@jackclarkSF yes, concrete distribution and Gumbel softmax came out more or less simultaneously. ALI and BiGAN. Many others
826840993374707700,Wed Feb 01 17:13:49 +0000 2017,@jackclarkSF not surprising, just yet another indication of how fast research is moving recently
826824323285409800,Wed Feb 01 16:07:34 +0000 2017,Nature magazine article on generative models for astronomy: https://t.co/rYgQTJW06F
826548135111467000,Tue Jan 31 21:50:06 +0000 2017,Interview with Richard Mallah and me for FLI podcast, where we explain some of the AI breakthroughs of 2016 https://t.co/hWy9BgIIcr
826546538205753300,Tue Jan 31 21:43:45 +0000 2017,@goodfellow_ian Crazy thing is, my tutorial posted Dec 31 says no one has done this yet. Done by Jan 17. (Not done in response to tutorial)
826546056074666000,Tue Jan 31 21:41:50 +0000 2017,Using GANs to sample from the posterior of a directed model: https://t.co/lai6w4Pfhc
826545267310596100,Tue Jan 31 21:38:42 +0000 2017,@kchonyc is there a way to vote separately for each of them?
826544735388995600,Tue Jan 31 21:36:36 +0000 2017,@Taniel do you know if this would apply to green card holders too?
826240437807505400,Tue Jan 31 01:27:25 +0000 2017,@radhk it would be good if they could release the code
826190129702187000,Mon Jan 30 22:07:31 +0000 2017,Seq2seq RL GANs for dialogue generation: https://t.co/jfNpWbjRN6
826109789302198300,Mon Jan 30 16:48:16 +0000 2017,RT @driainmurray: More fun pushing #googletranslate's neural net into weird states. (BTW try GT on real text if you haven't recently. It's‚Ä¶
826105560609067000,Mon Jan 30 16:31:28 +0000 2017,RT @WangCecillia: We have gotten disturbing reports that @CustomsBorder is refusing to comply with the court order
825729512432234500,Sun Jan 29 15:37:11 +0000 2017,@punksandwitch @NinaDontPlayMtG or Lyft
825543653376471000,Sun Jan 29 03:18:39 +0000 2017,RT @sama: Time to Take a Stand: https://t.co/xHs5fV6PYP
825543409603469300,Sun Jan 29 03:17:41 +0000 2017,RT @NazliNus: @goodfellow_ian https://t.co/naiSLBNrow
825524615690625000,Sun Jan 29 02:03:00 +0000 2017,@chrishareau @ch9 thanks
825510626940186600,Sun Jan 29 01:07:25 +0000 2017,At a protest against the anti-immigrant executive orders, at SFO right now https://t.co/sQVNWLpF8t
825013656039497700,Fri Jan 27 16:12:38 +0000 2017,RT @reworkkatie: If you missed out on getting the Deep Learning book, @goodfellow_ian left some discount codes at the registration desk! #r‚Ä¶
824840977474998300,Fri Jan 27 04:46:28 +0000 2017,@Vanguard_space free to read at https://t.co/2CkX4RlhGL or should be back in stock soon
824836655622221800,Fri Jan 27 04:29:18 +0000 2017,@mmitchell_ai ok, yes, I agree criminality isn't in genes
824833548968300500,Fri Jan 27 04:16:57 +0000 2017,@Vanguard_space i will be back at work tmr
824820841003094000,Fri Jan 27 03:26:27 +0000 2017,@mmitchell_ai https://t.co/j2gXr4ay51
824820319168761900,Fri Jan 27 03:24:23 +0000 2017,@thinkmariya the NIPS video is the most complete. The rework talk was shorter and less technical
824820154068447200,Fri Jan 27 03:23:43 +0000 2017,@mmitchell_ai southern Italy actually does have a higher crime rate than northern Italy though, that's not an example of bias
824819124064841700,Fri Jan 27 03:19:38 +0000 2017,@thinkmariya similar videos / slides at https://t.co/NXIK98ysvn
824818987888369700,Fri Jan 27 03:19:05 +0000 2017,@thinkmariya rework will post the video later
824686494702899200,Thu Jan 26 18:32:36 +0000 2017,@Vanguard_space if you're at #reworkdl I have some that @mitpress donated to give out here. Other than that I only have my own personal copy
824686195837841400,Thu Jan 26 18:31:25 +0000 2017,Video of my NIPS tutorial on GANs: https://t.co/tEmIWmuyDT
824666606617792500,Thu Jan 26 17:13:35 +0000 2017,RT @sarahkendzior: The Doomsday Clock Is Now 30 Seconds Closer To Midnight https://t.co/Q8UsvVANRn &lt;-- Worst since 1953. Two and a half min‚Ä¶
824660074190680000,Thu Jan 26 16:47:37 +0000 2017,RT @Gifted_AI: An incredible public resource. I particularly enjoyed @goodfellow_ian talk re: GANN https://t.co/61opySAefD https://t.co/wFT‚Ä¶
824327743332462600,Wed Jan 25 18:47:03 +0000 2017,GANs for simulating high-energy particle physics: https://t.co/6Dp3UzR7yj
824292293167304700,Wed Jan 25 16:26:11 +0000 2017,@wster I don't know, better to ask @mitpress
823582909869084700,Mon Jan 23 17:27:21 +0000 2017,@hardmaru It doesn't seem paywalled to me. The link works in my browser, even in incognito tab, and I don't have a C&amp;EN account
823578532911558700,Mon Jan 23 17:09:58 +0000 2017,Chemical and Engineering News covers the rise of deep learning for drug discovery: https://t.co/yq9yeU44Ul
823571459339534300,Mon Jan 23 16:41:51 +0000 2017,.@SussilloDavid making brain interfaces more robust: https://t.co/V3fIZd0cmJ
823237069904351200,Sun Jan 22 18:33:07 +0000 2017,Geoff Hinton on the societal implications of AI:  https://t.co/ObajzDfFP8
823031793750134800,Sun Jan 22 04:57:25 +0000 2017,In his final interview as president, Obama urges preparation for the loss of jobs to accelerating automation: https://t.co/GZVP6dCgCn
822606572006346800,Sat Jan 21 00:47:44 +0000 2017,RT @WithTheBest: Have you checked out the first #aiwtb confirmed speakers? You should! Some of the best are joining us! https://t.co/srrSRZ‚Ä¶
821865745365618700,Wed Jan 18 23:43:57 +0000 2017,RT @aminert: hey @goodfellow_ian check out this skill I built for Alexa to read ML papers from arXiv https://t.co/P4Pp5tadGg
821359164806996000,Tue Jan 17 14:10:59 +0000 2017,@halvarflake semisupervised learning. See https://t.co/ZAXsg5yfg4
820042580700250100,Fri Jan 13 22:59:21 +0000 2017,@iandanforth @daniel_bilar they're not all bunk but it can be hard to confirm that those trees actually get planted
819944706058506200,Fri Jan 13 16:30:26 +0000 2017,@carlosgr_nlp I'm suggesting that individuals go to fewer confs, not that confs shut down. This would make the confs smaller / more local
819940963959193600,Fri Jan 13 16:15:34 +0000 2017,@yoavgo @nsaphra keep in mind Penn State has access to me as well as vice versa
819940746333540400,Fri Jan 13 16:14:42 +0000 2017,@carlosgr_nlp you mean your funding for next year is contingent on going to many confs this year?
819940408629178400,Fri Jan 13 16:13:21 +0000 2017,@totopampin it's not an either-or choice. You can do both.
819925379842330600,Fri Jan 13 15:13:38 +0000 2017,@nsaphra also, I successfully remote collab with Pennsylvania State, Google Brain, using videochat, not mutual conf attendance
819924982604017700,Fri Jan 13 15:12:03 +0000 2017,@nsaphra I'm advocating reducing / prioritizing travel, not totally eliminating it
819924339772379100,Fri Jan 13 15:09:30 +0000 2017,@totopampin many people who have stopped eating animals fly enough to more than reverse that benefit
819923788594757600,Fri Jan 13 15:07:19 +0000 2017,@tschfflr @tallinzen @jasonbaldridge no, there are conferences where participants interact 1:1 with videochat. Like AI With the Best
819652427754311700,Thu Jan 12 21:09:01 +0000 2017," if you took 3 or more trips in the past year, you belong to an exceptional group"
819652341385150500,Thu Jan 12 21:08:41 +0000 2017,"It is essential to change transportation behavior as well."
819652288717299700,Thu Jan 12 21:08:28 +0000 2017,"It is impossible to meet global greenhouse gas targets for the transportation sector through efficiency gains alone. "
819651909489344500,Thu Jan 12 21:06:58 +0000 2017,from @daniel_bilar : why academics and industry researchers should greatly reduce flying: https://t.co/24rT13Nqqe
819629633637261300,Thu Jan 12 19:38:27 +0000 2017,@tdietterich if the format of the event is many participants interact with each other, it should be in person
819629557493874700,Thu Jan 12 19:38:09 +0000 2017,@tdietterich I think if the format of an event is "one person on a stage addresses many people in an audience" it should be online
819629469602152400,Thu Jan 12 19:37:48 +0000 2017,@tdietterich Yes, I agree
819627202287280100,Thu Jan 12 19:28:47 +0000 2017,@goodfellow_ian And in particular, we should do better videoconferencing and move more of our conference activities to online interaction
819627088302915600,Thu Jan 12 19:28:20 +0000 2017,Computer scientists should try to reduce travel for conferences in order to reduce carbon emissions: https://t.co/gO99FbsIj1
819615349075128300,Thu Jan 12 18:41:41 +0000 2017,Great blog post by @lindsey summarizing a paper on proving the absence of adversarial examples using SMT solvers: https://t.co/dZteIekodS
819357984954253300,Thu Jan 12 01:39:01 +0000 2017,RT @OpenAI: GTA V + Universe: https://t.co/2bpZ6QNv4R
819269664404422700,Wed Jan 11 19:48:03 +0000 2017,RT @laparisa: Here's why I'm going to #enigma2017 &amp; why I hope you come too: https://t.co/7anSLGNKXg  üë©üèæ‚Äçüíª‚ö°Ô∏èüíªüêõüì±üîèüë®‚Äçüíª
818892090847334400,Tue Jan 10 18:47:43 +0000 2017,RT @kdnuggets: #AI #DataScience #MachineLearning: Main Developments 2016, Key Trends 2017 @zacharylipton @jilldyche @goodfellow_ian https:/‚Ä¶
818534055524253700,Mon Jan 09 19:05:01 +0000 2017,GANs highlighted by @techreview : https://t.co/qH35NPkeji
818532544589115400,Mon Jan 09 18:59:00 +0000 2017,@mrjreid I have no objections to being mistaken for Geoffrey E. Hinton
818532297540386800,Mon Jan 09 18:58:01 +0000 2017,"I would have liked calculus better in undergrad if I had known what it had to do with misclassifying cat pictures." https://t.co/BGGoB7WH31
818505996309958700,Mon Jan 09 17:13:31 +0000 2017,@TigerScorpior Where did you get the link?
818144047436951600,Sun Jan 08 17:15:15 +0000 2017,@TigerScorpior I'll ask @NipsConference to fix the link
818123789535846400,Sun Jan 08 15:54:46 +0000 2017,@maxpihlstrom I don't know of plans for one
817818662383992800,Sat Jan 07 19:42:18 +0000 2017,@AlbertoRoman @NicolasPapernot You could make an ensemble out of the two of them (and optionally train a single student network to mimic it)
817817504907083800,Sat Jan 07 19:37:42 +0000 2017,@AlbertoRoman @NicolasPapernot No problem. I'm happy to try to fix whatever method was broken
817816698807984100,Sat Jan 07 19:34:29 +0000 2017,@AlbertoRoman @NicolasPapernot Are you doing the same thing?
817816631950725100,Sat Jan 07 19:34:14 +0000 2017,@AlbertoRoman @NicolasPapernot I'm using the RSS Feed Reader 5.6.6 Chrome extension, adding the feed via the "+" button within the extension
817814871253209100,Sat Jan 07 19:27:14 +0000 2017,@AlbertoRoman @NicolasPapernot RSS works for me. Which reader are you using and what goes wrong?
817737378735407100,Sat Jan 07 14:19:18 +0000 2017,@parindam they don't work well for categorical data yet
817175663014617100,Fri Jan 06 01:07:15 +0000 2017,@hardmaru @edersantana 4) The https://t.co/gfjwSfySdf 10MB limit preventing me from uploading a 50MB pdf of GAN samples
817171823028621300,Fri Jan 06 00:51:59 +0000 2017,@jackccrawford https://t.co/AsemW9PJRC says Dazzle was designed to fool Viola-Jones (2001), doesn't show tests that it succeeds
817163009780904000,Fri Jan 06 00:16:58 +0000 2017,@edersantana 3) fake arxiv papers
817149289176498200,Thu Jan 05 23:22:27 +0000 2017,Single image in, 3D model out, using VAEs+GANs. https://t.co/ovoCkePaer https://t.co/X3dw8f6aes
817145478047404000,Thu Jan 05 23:07:18 +0000 2017,@poolio The DAM here is a shallow model: tanh of power of relu of weighted linear function. Not very far from a shallow RBF template matcher
817145144352784400,Thu Jan 05 23:05:58 +0000 2017,@poolio Seems very similar to the same result for shallow RBFs in https://t.co/j4Q3KWCxtd
817082629593776100,Thu Jan 05 18:57:34 +0000 2017,RT @ivan_bezdomny: I just published ‚ÄúGANs will change the world‚Äù https://t.co/rpG62bQvOl
816813971428646900,Thu Jan 05 01:10:01 +0000 2017,@jackccrawford @guardian I haven't seen any mention of this clothing being tested against any specific CV system
816813859394621400,Thu Jan 05 01:09:34 +0000 2017,@jackccrawford @guardian the criminality detection algorithm mentioned in the article doesn't actually work
816813675818328000,Thu Jan 05 01:08:50 +0000 2017,@jackccrawford @guardian without access to government systems, you can't know if you're succeeding in fooling them for sure
816813555529879600,Thu Jan 05 01:08:21 +0000 2017,@jackccrawford @guardian generating a lot of false positives is definitely possible
816721465512820700,Wed Jan 04 19:02:25 +0000 2017,My friend @aerinykim has made a resume feedback bot. Try it out here: https://t.co/pnReUrOeDv
816644227018866700,Wed Jan 04 13:55:30 +0000 2017,@bimba_tim MIT Press has already sold the rights to publish in China
816384499499925500,Tue Jan 03 20:43:27 +0000 2017,RT @mattmayo13: And... out of stock again :) https://t.co/1sbDeGl9au
816355816559153200,Tue Jan 03 18:49:28 +0000 2017,@bweston92 It looks like it's in "Further Maths" in the GCSE program: https://t.co/WM5Q6GuJO3
816355733000196100,Tue Jan 03 18:49:08 +0000 2017,@bweston92 I don't know much about the UK education system, but it would still be called calculus there.
816354053781409800,Tue Jan 03 18:42:28 +0000 2017,@bweston92 good luck!
816353839771025400,Tue Jan 03 18:41:37 +0000 2017,@bweston92 also this: https://t.co/rdBT9oZXFn
816353703854678000,Tue Jan 03 18:41:04 +0000 2017,@bweston92 I also like "Elementary Calculus: An Infinitesimal Approach" by H. Jerome Keisler
816353521293348900,Tue Jan 03 18:40:21 +0000 2017,@bweston92 for my learning style, "Elementary Real and Complex Analysis" by Georgi Shilov was pretty good
816353450132803600,Tue Jan 03 18:40:04 +0000 2017,@bweston92 Different people have different learning styles. I like when everything is explained very precisely with lots of concrete detail
816352954374467600,Tue Jan 03 18:38:06 +0000 2017,@bweston92 I self-taught a lot of math after I got interested in ML in 2006 by reading cheap Dover books
816352797566214100,Tue Jan 03 18:37:28 +0000 2017,@bweston92 I learned calculus in high school, but if you're out of school already, maybe khan academy or coursera have a good class
816352611351695400,Tue Jan 03 18:36:44 +0000 2017,@bweston92 chap 2-4 of the book teach a lot of the math, but they assume you know calculus
816315317257261000,Tue Jan 03 16:08:32 +0000 2017,@Lidinwise stackGAN does seem good
816304574440931300,Tue Jan 03 15:25:51 +0000 2017,@Lidinwise for image generation I don't have a clear favorite yet. For semi-sup classification, feature matching GAN
816304324301049900,Tue Jan 03 15:24:51 +0000 2017,@mimoralea NIPS recorded it, but there will be a delay before they post it
816098717153378300,Tue Jan 03 01:47:51 +0000 2017,A tech report summarizing my NIPS tutorial on GANs https://t.co/v1rAvkjMC1
816008565399830500,Mon Jan 02 19:49:37 +0000 2017,@soumithchintala any recommendation for the leak coefficient of the leaky relus?
815610867953741800,Sun Jan 01 17:29:18 +0000 2017,@gkowarzyk happy new year to you too!
814602257912057900,Thu Dec 29 22:41:27 +0000 2016,@davegershgorn it's a research area. Evader still has the advantage for now
814600523030462500,Thu Dec 29 22:34:33 +0000 2016,@davegershgorn the right way to evade face recognition is to do it with adversarial examples: https://t.co/jysLnRifUn
814149869287841800,Wed Dec 28 16:43:49 +0000 2016,@soumithchintala @markus_with_k @TimSalimans I endorse this advice :)
814149580153491500,Wed Dec 28 16:42:40 +0000 2016,@markus_with_k @soumithchintala @TimSalimans my intuition is that you always want the discriminator to be optimal, shouldn't ever weaken it
813952794877014000,Wed Dec 28 03:40:43 +0000 2016,@haldaume3 @azeem @pmangg BTW, related project: https://t.co/OxIR25Lg47 (not appropriate for NLP though, relies on continuous inputs)
813952332639502300,Wed Dec 28 03:38:53 +0000 2016,RT @haldaume3: @goodfellow_ian @azeem @pmangg put it to the test! https://t.co/soZPX7ToUk
813874623628525600,Tue Dec 27 22:30:05 +0000 2016,@ankesh_anand @mmitchell_ai @haldaume3 does pretrained seqGAN offer an advantage over pure maximum likelihood?
813865191687360500,Tue Dec 27 21:52:37 +0000 2016,@ankesh_anand @mmitchell_ai @haldaume3 I haven't read it in detail, but doesn't it rely heavily on maximum likelihood pretraining?
813857691210649600,Tue Dec 27 21:22:48 +0000 2016,@mmitchell_ai @haldaume3 @azeem @pmangg I hope so! Lots of people were talking about ideas for it at NIPS
813857037469630500,Tue Dec 27 21:20:13 +0000 2016,@haldaume3 @azeem @pmangg in this context "adversarial training" doesn't refer to GANs, it refers to https://t.co/j4Q3KWCxtd
813856721395294200,Tue Dec 27 21:18:57 +0000 2016,@haldaume3 @azeem @pmangg deep models benefit from adversarial training but shallow ones don't benefit much because they lack the capacity
813856587991240700,Tue Dec 27 21:18:25 +0000 2016,@haldaume3 @azeem @pmangg naively trained deep models and shallow models are about equally vulnerable to adv examples
813856336056156200,Tue Dec 27 21:17:25 +0000 2016,@haldaume3 @azeem @pmangg yes, I don't mean GAN adv examples. I mean examples optimized to fool a classifier
813856055780220900,Tue Dec 27 21:16:19 +0000 2016,@mmitchell_ai @haldaume3 @azeem @pmangg GANs don't really work for discrete outputs yet, so they're not good for language
813849056761901000,Tue Dec 27 20:48:30 +0000 2016,@haldaume3 @azeem @pmangg first Google hit is an article I wrote saying the idea in this slide is a misconception. https://t.co/MyqxhN0Dso
813848845436080100,Tue Dec 27 20:47:39 +0000 2016,@haldaume3 @azeem @pmangg pretty sure they mean what I do. Do a Google search for "adversarial example"
813847783715192800,Tue Dec 27 20:43:26 +0000 2016,@haldaume3 @azeem @pmangg it's already tested, since the first adversarial examples paper
813844936369913900,Tue Dec 27 20:32:07 +0000 2016,@azeem @pmangg shallow models are more vulnerable to adv examples than deep ones. Deep ones can be partially defended with adv training
813770654130409500,Tue Dec 27 15:36:57 +0000 2016,RT @alexjc: DARN: Deep Adversarial ResNet for Intrinsic Image Decomposition https://t.co/G7wCv82xki https://t.co/gtKLVmAGNP NN splits albed‚Ä¶
813770267285536800,Tue Dec 27 15:35:25 +0000 2016,@haldaume3 @kchonyc @beck_daniel I teach LA first
813768914903543800,Tue Dec 27 15:30:03 +0000 2016,@savanvisalpara7 @amazonbooks I don't know, it would be best to ask MIT Press
813552043889594400,Tue Dec 27 01:08:16 +0000 2016,Apple's first ML publication is about GANs: https://t.co/ljNrcU4Vh7
813466595213201400,Mon Dec 26 19:28:44 +0000 2016,The Deep Learning textbook is back in stock. It no longer costs $10,000. https://t.co/V0roen5d7T
812805155066290200,Sat Dec 24 23:40:24 +0000 2016,GANs for medicine! Inferring CT scans from much safer MRI scans: https://t.co/q8jPMqkuuH
812105983694471200,Fri Dec 23 01:22:09 +0000 2016,RT @wimlds: Please help add to the list by replying with additional handles! I started with #DeepLearning researchers from https://t.co/2H7‚Ä¶
812105976635527200,Fri Dec 23 01:22:07 +0000 2016,RT @wimlds: We created a list of women in #DeepLearning on Twitter: https://t.co/NARbTIQR5B cc @drfeifei @robot_MD @neurophoenix @WiMLworks‚Ä¶
812027785539485700,Thu Dec 22 20:11:25 +0000 2016,@allanzelener @kchonyc mostly just because it doesn't seem like a priority. It doesn't hurt to know but there are many other ideas to cover
812015811523022800,Thu Dec 22 19:23:50 +0000 2016,RT @Miles_Brundage: The whole AI thing seems to be working for NVIDIA. https://t.co/RFXY2VWjIb
811991440456679400,Thu Dec 22 17:47:00 +0000 2016,@kchonyc I say the perceptron existed but I don't describe its learning rule
811614751310499800,Wed Dec 21 16:50:10 +0000 2016,White House report on AI and the economy: https://t.co/woip2ELNpJ
811452698855809000,Wed Dec 21 06:06:14 +0000 2016,RT @BrianRoemmele: This is what AI looks like when it is learning to interact with websites Via OpenAI Universe https://t.co/e51lRiFuA0 htt‚Ä¶
811450676144279600,Wed Dec 21 05:58:11 +0000 2016,RT @shakir_za: Forbes Now: McKinsey's 2016 Analytics Study Defines The Future Of Machine Learning. https://t.co/JkKGH2lAup
811401655899955200,Wed Dec 21 02:43:24 +0000 2016,@14prakash i would support that, its up to MIT Press though
811358244358668300,Tue Dec 20 23:50:54 +0000 2016,Many thanks to Satya Prakash Mallick who is giving away 10 copies of the Deep Learning book! https://t.co/QVktoPnwT1
811067449646776300,Tue Dec 20 04:35:23 +0000 2016,@mrdrozdov check out unrolled GANs, or some of the recent work from FAIR on stabilizing GANs
811065955937697800,Tue Dec 20 04:29:27 +0000 2016,@mrdrozdov seems mostly fixed for carefully tuned hyperparameters. Adam seems to help. No strong theoretical fix yet
811049984988581900,Tue Dec 20 03:25:59 +0000 2016,@mrdrozdov yes, that doesn't correspond to an equilibrium, but it's a common way that SGD fails to equilibrate
810982411148234800,Mon Dec 19 22:57:28 +0000 2016,Why people who use backprop should understand what it's doing for you: https://t.co/2RhozmtFMc
810695922493653000,Mon Dec 19 03:59:04 +0000 2016,@sirajraval interviews @OpenAI engineer @catherineols https://t.co/ERIcJG55CP
810653924407406600,Mon Dec 19 01:12:11 +0000 2016,@AirJoshua I would like to see a Kindle edition. The decision is up to MIT Press. I'm not sure what their plan for Kindle is
810238931090493400,Sat Dec 17 21:43:09 +0000 2016,https://t.co/ghSVc0QTvB
810219417749450800,Sat Dec 17 20:25:36 +0000 2016,@latentjasper note that the gizmodo article also has a joke in its title ("notable human man")
810166266824536000,Sat Dec 17 16:54:24 +0000 2016,@nlpnyc @gusl sorry about that, will fix it
809935280635580400,Sat Dec 17 01:36:33 +0000 2016,@Philduan  there are a handful of reading groups throughout SF and bay area. I'll post on twitter / facebook next time I go to one
809926388547539000,Sat Dec 17 01:01:13 +0000 2016,@Philduan I'll probably sign books at a SF reading group meeting sometime
809901969620041700,Fri Dec 16 23:24:11 +0000 2016,@soumithchintala OK, thanks!
809898312493047800,Fri Dec 16 23:09:39 +0000 2016,@soumithchintala Trying out some of these now, thanks! Is PixelShuffle another name for subpixel CNN?
809896982147960800,Fri Dec 16 23:04:22 +0000 2016,@pkmital Complete with Schmidhuber saying "Should it perhaps be called 'inverse PM'?"
809895965574447100,Fri Dec 16 23:00:19 +0000 2016,@Smerity https://t.co/dQz2eLCrM0
809895672954679300,Fri Dec 16 22:59:10 +0000 2016,@Smerity https://t.co/JoFgs4zWTn
809846445075353600,Fri Dec 16 19:43:33 +0000 2016,RT @KyleCranmer: ‚ÄúConditional Generative Models for Particle Physics‚Äù to learn our expensive detector simulation. (CC @goodfellow_ian ) @NY‚Ä¶
809837564802658300,Fri Dec 16 19:08:16 +0000 2016,Amazon says the book will be back in stock Dec 22: https://t.co/2KwW8wljY0
809817267714175000,Fri Dec 16 17:47:36 +0000 2016,Stencil palimpsest fight in the Mission https://t.co/YPQLHtDnCn
809811320556036100,Fri Dec 16 17:23:59 +0000 2016,@GilgameshNusku it wasn't @soumithchintala that chose to frame it as a competition
809564304559247400,Fri Dec 16 01:02:25 +0000 2016,.@NicolasPapernot and I starting an informal blog about machine learning security and privacy: https://t.co/BloQy138iw
809513036339769300,Thu Dec 15 21:38:42 +0000 2016,RT @mmitchell_ai: @goodfellow_ian The ultimate sign of success:  xkcd just two years ago is blown out of the water. https://t.co/NXnAQRFau0
809419947218604000,Thu Dec 15 15:28:48 +0000 2016,Nice article on the NIPS Reliable ML in the Wild workshop. Hope some of you work on defenses and come to the worksh‚Ä¶ https://t.co/CDrLw9pm0j
809226036344819700,Thu Dec 15 02:38:16 +0000 2016,@0xD1 I think mostly due to LAPGAN and DCGAN making them popular. NIPS papers would appear on arxiv in June
809224221595353100,Thu Dec 15 02:31:03 +0000 2016,@goodfellow_ian https://t.co/HRdS5u8cH6 https://t.co/k1gdRiGTZg
809224138237747200,Thu Dec 15 02:30:43 +0000 2016,There are now so many GANs that we have both "StackGAN" and "Stacked Generative Adversarial Networks" (different papers!) in the same week
809220717833109500,Thu Dec 15 02:17:08 +0000 2016,@CraigglesO glad you like it!
808824897346539500,Wed Dec 14 00:04:17 +0000 2016,StackGAN: very good text-to-image results! https://t.co/74pza71hrG https://t.co/0FY6WFRMSq
808683506410717200,Tue Dec 13 14:42:27 +0000 2016,RT @kelseyrkennedy: This is an actual headline on Breitbart. Apparently peer-reviewed science is so threatening, you should arm yourself. h‚Ä¶
808682566513328100,Tue Dec 13 14:38:43 +0000 2016,RT @tomwestland: I would like to suggest that "Guys, it's time for some game theory" is another universal New Yorker cartoon caption. https‚Ä¶
808659696479371300,Tue Dec 13 13:07:50 +0000 2016,@Ser4r should be soon. I thought it was going to be last week
808481753660682200,Tue Dec 13 01:20:45 +0000 2016,Three Body Problem plot hole: aliens have speed of light probes, we are closest star. They didn't need humans to initiate contact
808467424248926200,Tue Dec 13 00:23:49 +0000 2016,RT @scottwongDC: In rare bipartisan statement, McCAIN, GRAHAM, SCHUMER &amp; REED say reports of Russian interference in election "should alarm‚Ä¶
808349996420476900,Mon Dec 12 16:37:12 +0000 2016,RT @janexwang: @jackclarkSF #wiml registrants grew more than #nips2016 registrants, 600 in total! Maybe increased interest in diversity?
808349979710459900,Mon Dec 12 16:37:08 +0000 2016,RT @janexwang: @jackclarkSF although total % female at main conference not much improved, 15% vs 13%
808349938744639500,Mon Dec 12 16:36:58 +0000 2016,RT @janexwang: @jackclarkSF 2015: 265 participants, 2016: 570 participants, so more than double https://t.co/16nGykpfCK
808160884992266200,Mon Dec 12 04:05:44 +0000 2016,RT @ArthurGretton: Code for the GAN workshop talk "learning features to compare distributions": https://t.co/mQbMzXGwxT and https://t.co/iy‚Ä¶
808148583027347500,Mon Dec 12 03:16:51 +0000 2016,RT @jackclarkSF: What were the most provocative and/or surprising things people heard at #nips2016 ? Putting together next issue of Import‚Ä¶
807879753965387800,Sun Dec 11 09:28:37 +0000 2016,RT @KyleCranmer: Gaud√≠ exposes his genius by using a physical computer to do finite element analysis for structural stability! #InverseMeth‚Ä¶
807878717527720000,Sun Dec 11 09:24:30 +0000 2016,@rivatez everything pertaining to #rocketai is amazing
807752678860357600,Sun Dec 11 01:03:40 +0000 2016,@_AntreasAntonio #rocketai started TROL. I just made it more like Online Bayesian Variational Inference Over Unobserved States
807736245245870100,Sat Dec 10 23:58:22 +0000 2016,@_AntreasAntonio the founders had a dinner to plan their first publication tonight
807732393851420700,Sat Dec 10 23:43:04 +0000 2016,@_AntreasAntonio it has by far the best Fully Automatic Kernel Expansion technology on the market
807731111468142600,Sat Dec 10 23:37:58 +0000 2016,@_AntreasAntonio When the probability is one, the information has to be zero. The lack of information is because success is guaranteed
807721903976841200,Sat Dec 10 23:01:23 +0000 2016,#rocketai definitely has the most popular Jacobian-Optimized Kernel Expansion of NIPS 2016
807688676998201300,Sat Dec 10 20:49:21 +0000 2016,RT @DCivin: A sign of a lot of generative models at #nips2016 #gan #vae https://t.co/hHQZninEwj
807582020511662100,Sat Dec 10 13:45:32 +0000 2016,#nips2016 I will participate in the Bayesian deep Learning panel discussion, 4pm, area 1
807565818921910300,Sat Dec 10 12:41:09 +0000 2016,@TriBasNach the unrolled GANs paper treats MNIST as a time series
807565641360244700,Sat Dec 10 12:40:27 +0000 2016,#nips2016 At 2 pm I will present some ideas for adversarial+Bayesian ML in the Bayesian DL workshop, area 1. Slides: https://t.co/BcFezp3SA7
807274027492446200,Fri Dec 09 17:21:41 +0000 2016,@ram_ssk Also, Aaron Courville said it might be a NIPS first to have a workshop and a tutorial on a NIPS paper from two years earlier
807273846424404000,Fri Dec 09 17:20:58 +0000 2016,@ram_ssk Yes, I was in two panels back to back. Not sure if it's a NIPS first.
807267957923573800,Fri Dec 09 16:57:34 +0000 2016,RT @ram_ssk: If youre at #nips2016 and working in #security, visit @NicolasPapernot poster! His papers r insightful and I always learn new‚Ä¶
807267861378891800,Fri Dec 09 16:57:11 +0000 2016,@ram_ssk I believe it was recorded but not streamed. Different organizers
807247450717220900,Fri Dec 09 15:36:04 +0000 2016,#nips2016 I'm participating in the reliable ML in the wild panel discussion, 5pm in room 113
807243156131561500,Fri Dec 09 15:19:00 +0000 2016,#nips2016 Andrew Dai now presenting spotlight / poster for virtual adversarial text classification, in the adv. training workshop, area 3
807218796478038000,Fri Dec 09 13:42:13 +0000 2016,#nips2016 panorama of the adversarial training workshop https://t.co/v5RsbCKK6Q
807212428048080900,Fri Dec 09 13:16:54 +0000 2016,#nips2016 I'm a member of the adversarial training panel, answering questions from the reddit AMA, at 3pm in area 3
807183353552191500,Fri Dec 09 11:21:22 +0000 2016,#nips2016 I present "Adversarial Training and Adversarial Examples", at the Reliable ML workshop, 1:45PM, room 113. https://t.co/AbkPK68LLO
807149425932070900,Fri Dec 09 09:06:33 +0000 2016,#nips2016 Check out Nicolas Papernot's spotlight talk on differentially private deep learning at 12:15pm room 131-132. Poster at 3:30pm
807138607043637200,Fri Dec 09 08:23:34 +0000 2016,#nips2016 This is about half the audience for the adversarial training workshop, 10 min before it starts https://t.co/zW4GspG9XL
806987973392814100,Thu Dec 08 22:25:00 +0000 2016,https://t.co/BCTv2aE4LE
806986139743768600,Thu Dec 08 22:17:43 +0000 2016,@_AntreasAntonio I'm not the real MVP, the workshop organizers are
806985962597195800,Thu Dec 08 22:17:01 +0000 2016,@beaulieujones my understanding is that NIPS recorded it but there will be a delay before posting it. I have posted the slides
806935545871994900,Thu Dec 08 18:56:40 +0000 2016,@christopher5106 @Smerity I managed him the way you recommend. Still huge reaction by audience and everyone who heard of it
806923816026837000,Thu Dec 08 18:10:04 +0000 2016,@christopher5106 @Smerity It is bullying and abuse of his respected position, and he needs to stop it, not do it after the tutorial.
806923671277162500,Thu Dec 08 18:09:29 +0000 2016,@christopher5106 @Smerity And he is not welcome to talk to me after the tutorial. He has harassed me for years about the same thing.
806923534089846800,Thu Dec 08 18:08:57 +0000 2016,@christopher5106 @Smerity That is more or less what I did, but he still stole several minutes of time before being quieted.
806922884341854200,Thu Dec 08 18:06:22 +0000 2016,@christopher5106 @Smerity It also took away several minutes of time from teaching about the subject that thousands of people came to learn
806922714292203500,Thu Dec 08 18:05:41 +0000 2016,@CricTweetzz My understanding is that NIPS records many of the talks but will have a significant delay before posting the video
806921427844595700,Thu Dec 08 18:00:34 +0000 2016,#nips2016 I will present an introduction to GANs at 9:30 AM at the adversarial training workshop, in Area 3. Slides: https://t.co/eM1xN72sOt
806919516722630700,Thu Dec 08 17:52:59 +0000 2016,#nips2016 Tomorrow's workshop on adversarial training will be livestreamed for those unable to attend in person: https://t.co/F5oWSepvkA
806916228308607000,Thu Dec 08 17:39:55 +0000 2016,@christopher5106 @Smerity Schmidhuber claims to have invented far more things than the LSTM, often falsely, and unfairly bullies many people
806916018576556000,Thu Dec 08 17:39:05 +0000 2016,@christopher5106 @Smerity Schmidhuber is a co-author of the LSTM paper, but I'm not sure if he or Sepp Hochreiter invented it
806915272921620500,Thu Dec 08 17:36:07 +0000 2016,@AlfredoCanziani Sure, follow up by DM / e-mail
806914905584455700,Thu Dec 08 17:34:39 +0000 2016,@christopher5106 @Smerity It was Schmidhuber bashing my work, not me or @smerity bashing Schmidhuber's work
806914227315183600,Thu Dec 08 17:31:58 +0000 2016,@christopher5106 @Smerity Our complaint is that Schmidhuber was not respectful to me by interrupting my tutorial
806537584000323600,Wed Dec 07 16:35:19 +0000 2016,Browser plugin for checking news story links against a database of unreliable sources: https://t.co/zbsS7ef5Vb
806530924779360300,Wed Dec 07 16:08:51 +0000 2016,RT @newsycombinator: The major advancements in Deep Learning in 2016 https://t.co/iM9J4qDQ8Z
806518156529430500,Wed Dec 07 15:18:07 +0000 2016,@jnhwkim I'm in the lobby of the Hilton Diagonal Mar for a while
806105839916449800,Tue Dec 06 11:59:43 +0000 2016,@jnhwkim k, followed
806103072158060500,Tue Dec 06 11:48:43 +0000 2016,@jnhwkim follow up by DM
806066464876859400,Tue Dec 06 09:23:15 +0000 2016,@ramana_95 the video isn't up yet, but the slides are here: https://t.co/gFh9q0SG15
806066248777924600,Tue Dec 06 09:22:24 +0000 2016,@cmarschner @Smerity Predictability Minimization
806065723160326100,Tue Dec 06 09:20:19 +0000 2016,@AmbrishTweets https://t.co/gFh9q0SG15 Not sure when NIPS will post the video
805830590079631400,Mon Dec 05 17:45:58 +0000 2016,#nips2016 also come see poster 166, "Improved Techniques for Training GANs" https://t.co/dDXIu7gqv4
805826207824670700,Mon Dec 05 17:28:34 +0000 2016,#nips2016 Come see poster #62 on generative models of video of robot motion https://t.co/jMK4f3GVfb
805816875129143300,Mon Dec 05 16:51:29 +0000 2016,@vyraun @alxndrkalinin Aaron told me it was recorded. I don't think the link is posted yet
805754117826248700,Mon Dec 05 12:42:06 +0000 2016,#nips2016 I will present a tutorial on GANs at 2:30 in area 1+2. Slides here: https://t.co/gFh9q0SG15
805725186544767000,Mon Dec 05 10:47:08 +0000 2016,RT @catherineols: Working on Universe with this team has been an *amazing* experience - come chat about it at our #WiML2016 booth in room 1‚Ä¶
805718397287862300,Mon Dec 05 10:20:10 +0000 2016,#wiml2016 / #nips2016 I'm at OpenAI's WIML booth for the next few hours
805679870592352300,Mon Dec 05 07:47:04 +0000 2016,@KevinAyuque Currently, it would only be able to if there were an iOS emulator that runs on linux
805666497045659600,Mon Dec 05 06:53:56 +0000 2016,Elon Musk-backed OpenAI reveals Universe ‚Äì a universal training ground for computers ‚Ä¢ The Register https://t.co/0A7MpL7bIu
805505207329243100,Sun Dec 04 20:13:01 +0000 2016,#nips2016 Yoshua, Aaron, and I will sign Deep Learning textbooks for sale at the MIT Press booth 4:30 PM Monday, hall P2, 4th level
805428561020678100,Sun Dec 04 15:08:27 +0000 2016,@jackclarkSF @graphific I haven't tried that dataset yet but I think it's a good idea
805188715983142900,Sat Dec 03 23:15:24 +0000 2016,RT @ryf_feed: We Built a Bot That Trolls Twitter‚Äôs Worst Anti-Semitic Trolls https://t.co/9sAFn4PPT8
804765411174543400,Fri Dec 02 19:13:20 +0000 2016,A video history of CAPTCHAs: https://t.co/UmDlmDZ1Xy (and the paper that got 99.8% on them: https://t.co/Xd2qAeFGwu )
804364583397769200,Thu Dec 01 16:40:35 +0000 2016,RT @phaner_m: Conf√©rence @papernot @CentraleLyon  Double dipl√¥m√© avec @penn_state  doctorat sur le "machine learning" avec @google https://‚Ä¶
804042791571423200,Wed Nov 30 19:21:54 +0000 2016,reddit AMA for the #nips2016 adversarial training workshop panel: https://t.co/9GNVXGRKm5 (Ask now through Dec 8, panel answers at NIPS)
803808267356938200,Wed Nov 30 03:49:59 +0000 2016,RT @TheEconomist: There is a growing divide between the GOP and America‚Äôs high-tech workers https://t.co/8oeGD2QHvi https://t.co/Yb1p4475Ck
803673419648598000,Tue Nov 29 18:54:09 +0000 2016,@DoYouQA @jessysaurusrex corollary: when building a login system, do not include security questions
803673258692227100,Tue Nov 29 18:53:31 +0000 2016,RT @DoYouQA: Non InfoSec Translation: When answering security questions to reset your password, use made up answers I cannot find on your F‚Ä¶
803636989127888900,Tue Nov 29 16:29:23 +0000 2016,@bchjam anch'io
803618839036465200,Tue Nov 29 15:17:16 +0000 2016,@benrwilde 2/2 If someone buys at the crazy price, the vendor hopes to find it at a smaller markup, buy and resell
803618688817430500,Tue Nov 29 15:16:40 +0000 2016,@benrwilde Another guess: 1/2 it's a bot that sells sold-out products the vendor doesn't have at an insane markup.
803618006282616800,Tue Nov 29 15:13:57 +0000 2016,@benrwilde I've heard Amazon gives merchants benefits for having a product in stock. A crazy price keeps the last copy in stock.
803617461832552400,Tue Nov 29 15:11:48 +0000 2016,An art project uses Berkeley's image-to-image translation GANs to reimagine Milan in the style of LA: https://t.co/NnvtV0gE7X
803432533421473800,Tue Nov 29 02:56:57 +0000 2016,@robert_winslow we do intend to add more exercises, but don't have a concrete timeline
803350786084323300,Mon Nov 28 21:32:07 +0000 2016,@moormaan @_c_r_p @AndrewYNg https://t.co/2CkX4R3GPd
803350703284437000,Mon Nov 28 21:31:47 +0000 2016,@moormaan @_c_r_p @AndrewYNg yes, should be accessible to advanced undergrads or software engineers without ML experience
803339665340125200,Mon Nov 28 20:47:56 +0000 2016,RT @NicolasPapernot: A brief presentation of cleverhans and machine learning security https://t.co/SyVl0tYJXY Clone cleverhans on GitHub at‚Ä¶
803332815349694500,Mon Nov 28 20:20:43 +0000 2016,RT @AndrewYNg: We should ask each other more often: ‚ÄúWhat are you reading?‚Äù Tweet your response! https://t.co/VLbSs9SfSo
803332776850141200,Mon Nov 28 20:20:33 +0000 2016,@AndrewYNg @WSJ Rise and Fall of the Third Reich
803064962218225700,Mon Nov 28 02:36:21 +0000 2016,@mbeissinger I will be there
802600013738053600,Sat Nov 26 19:48:49 +0000 2016,RT @gdb: I'm looking for beta testers for some new reinforcement learning software. Ping me if interested: gdb@openai.com.
802545649036062700,Sat Nov 26 16:12:47 +0000 2016,RT @NandoDF: If you care about big brother surveillance and the erosion of privacy and human dignity, please retweet this. Thanks https://t‚Ä¶
802288823375831000,Fri Nov 25 23:12:15 +0000 2016,@aminert I would ask for a replacement if it were me
801913680120070100,Thu Nov 24 22:21:34 +0000 2016,@vcheplygina @AnodyneCode I think it's Central Park in New York. We chose it from Dan Ambrosi's Dreamscapes work
801908154179035100,Thu Nov 24 21:59:37 +0000 2016,RT @paulkrugman: A number of liberal writers, me included, seem to have gotten this notice yesterday. https://t.co/OROGP1qbDF
801636735994081300,Thu Nov 24 04:01:06 +0000 2016,My copy just arrived! https://t.co/P6WYwvnwgi
801612014904754200,Thu Nov 24 02:22:52 +0000 2016,@mmitchell_ai I didn't get a notification about this tweet yesterday. Follow up by email, since char limit is constraining?
801611600696262700,Thu Nov 24 02:21:13 +0000 2016,@mmitchell_ai main distinction is that 7 years ago, only the last step was learned. Earlier steps were hand coded features
801606095240204300,Thu Nov 24 01:59:20 +0000 2016,@mmitchell_ai @jackclarkSF oh I was confused which tweet you replied to. I thought you were saying to add "neural network" to my definition
801603234028654600,Thu Nov 24 01:47:58 +0000 2016,@mmitchell_ai @jackclarkSF yes, learning a neural network with multiple layers is a good / equivalent definition
801599395107991600,Thu Nov 24 01:32:43 +0000 2016,@mmitchell_ai @haldaume3 @yoavgo @drfeifei Learning multiple steps of a computer program
801434930873929700,Wed Nov 23 14:39:12 +0000 2016,@mmitchell_ai I do suggest women to interview
801146612311466000,Tue Nov 22 19:33:31 +0000 2016,@peteskomoroch I'm not saying "what is truth?" and leave repeat offenders alone. I'm saying to use signals other than "truth classification"
801138351956893700,Tue Nov 22 19:00:42 +0000 2016,@peteskomoroch @jackclarkSF @scottlegrand @fchollet I didn't say you need truth classification to fight fake news. We have no disagreement.
801138245773848600,Tue Nov 22 19:00:16 +0000 2016,@peteskomoroch @jackclarkSF @scottlegrand @fchollet What the reporter asked me is if "truth classification" can be done yet and I said "no"
801137296414097400,Tue Nov 22 18:56:30 +0000 2016,@peteskomoroch @jackclarkSF @scottlegrand @fchollet I'm in favor of domain features. Further clarification here: https://t.co/Zd5upupax6
801128957349273600,Tue Nov 22 18:23:22 +0000 2016,@ooidesigns it would give you something that looks like a photo of a real face. it wouldn't identify the suspect any better than the sketch
801127940343746600,Tue Nov 22 18:19:19 +0000 2016,@fchollet web searches for "does hillary traffic children" suggest the answer is yes; search has solved relevance but not veracity
801126663119458300,Tue Nov 22 18:14:15 +0000 2016,@goodfellow_ian https://t.co/XjaHPIzjzx
801126441375014900,Tue Nov 22 18:13:22 +0000 2016,More GAN magic from Berkeley: give a GAN a sketch, it gives you a photo: https://t.co/KLm5ulNUxY
801126018345898000,Tue Nov 22 18:11:41 +0000 2016,@TarinZiyaee @davegershgorn snopes says it is really a Paul Ryan survey, but does not say how they know: https://t.co/r9WC1PEdLi
801125627445157900,Tue Nov 22 18:10:08 +0000 2016,@TarinZiyaee @davegershgorn I was not sure if it was legit, or an attempt to DDOS Paul Ryan or someone else's phone, or gather numbers
801125305045790700,Tue Nov 22 18:08:51 +0000 2016,@TarinZiyaee @davegershgorn A recent hard example: a Facebook copy-paste saying to call a phone number to participate in a Paul Ryan survey
801119490750545900,Tue Nov 22 17:45:45 +0000 2016,@scottlegrand @jackclarkSF or a solution based on AI to detect spammy posting behavior rather than discerning truth
801119227792920600,Tue Nov 22 17:44:42 +0000 2016,@TarinZiyaee @davegershgorn part of why I don't think modern AI could do it well is that average humans seem bad at it
801118852167802900,Tue Nov 22 17:43:13 +0000 2016,@VahidK it's one sentence from a larger interview. I meant that the AI doesn't need to conduct research and do fact checking to translate
801118557077545000,Tue Nov 22 17:42:02 +0000 2016,@scottlegrand @jackclarkSF a user driven solution is probably best because of the current limitations of AI
801114277494997000,Tue Nov 22 17:25:02 +0000 2016,@fchollet We mean to tell whether a story is true or false, not to evaluate a particular post that has a lot of metadata, user behavior, etc
801109112524181500,Tue Nov 22 17:04:30 +0000 2016,Modern AI is good enough to detect bots and spam, but not yet good enough to tell whether a news article is credible https://t.co/m9HvgMuQRK
801066794748244000,Tue Nov 22 14:16:21 +0000 2016,@rasmusoxenvad I think there is not enough attention to the issue of humans potentially using AI / ML in malicious ways
800852885470728200,Tue Nov 22 00:06:21 +0000 2016,@cosminstamate @nips thanks
800124405330260000,Sat Nov 19 23:51:38 +0000 2016,@daniel_bilar yes, I plan to write something for distill too
800121313545179100,Sat Nov 19 23:39:21 +0000 2016,NIPS attendees: what would you like to see in my two hour tutorial on GANs? what would make a tutorial most useful to you?
800060179609854000,Sat Nov 19 19:36:25 +0000 2016,"A Connection Between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models": https://t.co/4hFkAWeuoo
799820323067527200,Sat Nov 19 03:43:19 +0000 2016,RT @MarceloPLima: Best books to read as a new graduate seeking a job in 2000 and 2017: https://t.co/AHv6jvoUj6
799371863822475300,Thu Nov 17 22:01:18 +0000 2016,RT @RepMarkTakano: I'm calling on @realDonaldTrump to immediately denounce the comments made by a surrogate regarding Japanese-American Int‚Ä¶
799295647543214100,Thu Nov 17 16:58:27 +0000 2016,Me too!
799095801125290000,Thu Nov 17 03:44:20 +0000 2016,RT @NicolasPapernot: I'm speaking at @usenix #enigma2017 in Oakland, happening Jan 30‚ÄìFeb 1, 2017 https://t.co/O0dMV9hVKL
799023169059180500,Wed Nov 16 22:55:43 +0000 2016,@davegershgorn @fchollet unfortunately, there will almost definitely be more and smarter bots manipulating the next election
799022392408322000,Wed Nov 16 22:52:38 +0000 2016,@davegershgorn @fchollet (detecting a bot is much easier than detecting fake news)
799022280902705200,Wed Nov 16 22:52:11 +0000 2016,@davegershgorn @fchollet preventable by FB or twitter. Detecting bots and shutting them down
799022120986505200,Wed Nov 16 22:51:33 +0000 2016,RT @mattmfm: Trump has now tweeted 18 times since the election.  Of those tweets, one third have been attacks on the media for simply repor‚Ä¶
798699229409460200,Wed Nov 16 01:28:30 +0000 2016,@lindsey I believe the camera demo app is Inception v1. We used v3 and v4 for other experiments.
798681719595356200,Wed Nov 16 00:18:55 +0000 2016,RT @yaringal: Congrats to the authors of the 41 accepted abstracts to the NIPS 2016 Workshop on Bayesian Deep Learning!  https://t.co/pbm63‚Ä¶
798631866488062000,Tue Nov 15 21:00:49 +0000 2016,RT @RonWyden: Steve Bannon ran a website that trafficked in anti-Semitism &amp; misogyny. He is an unacceptable choice to advise a U.S. preside‚Ä¶
798631819914580000,Tue Nov 15 21:00:38 +0000 2016,RT @RepBarbaraLee: Trump‚Äôs choice of Steve Bannon means a white nationalist will serve as the President‚Äôs closest adviser in the White Hous‚Ä¶
798364282899435500,Tue Nov 15 03:17:32 +0000 2016,@zuzoovn I'd suggest adding links to relevant chapters on https://t.co/2CkX4RlhGL
798254946781012000,Mon Nov 14 20:03:04 +0000 2016,@deanpomerleau @MKronert @daniellevalore do you not understand that Trump is currently rumored to choose Carson for Sec of Education ?
798239726389989400,Mon Nov 14 19:02:36 +0000 2016,@deanpomerleau @daniellevalore @MKronert so what, you think we should just give up and quit criticizing anything?
798239490737246200,Mon Nov 14 19:01:39 +0000 2016,@deanpomerleau @MKronert @daniellevalore there's no innuendo. It's his explicitly stated desire.
798220835777441800,Mon Nov 14 17:47:32 +0000 2016,RT @GeorgeTakei: These are some Breitbart headlines. Their white nationalist CEO is now Trump's top White House strategist. Pay attention.‚Ä¶
798220331169087500,Mon Nov 14 17:45:31 +0000 2016,RT @daniellevalore: Let's talk more about how this is a normal transfer of power and we're being paranoid: https://t.co/5b7BKfgs8u
798201909676912600,Mon Nov 14 16:32:19 +0000 2016,RT @shakir_za: Thought-provoking connection between different areas of machine learning. From my colleagues .@pfau .@OriolVinyalsML https:/‚Ä¶
798195031806910500,Mon Nov 14 16:04:59 +0000 2016,A review paper on ML security and privacy by Nicolas Papernot et al: https://t.co/rfE9pF7pJl
798189277741887500,Mon Nov 14 15:42:08 +0000 2016,Ontario considering a basic income pilot program: https://t.co/kUfi5uPTSM
797980959698075600,Mon Nov 14 01:54:21 +0000 2016,@zuzoovn what about it? Just advertise that it exists?
797498271602118700,Sat Nov 12 17:56:19 +0000 2016,RT @ACLU: Today we published a full-page open letter in the New York Times to President-elect Trump https://t.co/FOpRqn9oNY
796920947705974800,Fri Nov 11 03:42:14 +0000 2016,Hugo Larochelle's TEDx talk: https://t.co/axI5FMk3Y9
796789866826645500,Thu Nov 10 19:01:22 +0000 2016,RT @lindsey: Seeing lots of my contacts show up on Signal, the secure SMS app. Join us! It's easy. https://t.co/KiR0XcbJnx  https://t.co/76‚Ä¶
796789077454385200,Thu Nov 10 18:58:14 +0000 2016,RT @xtimv: If you use MCMC, you should know and love Geweke's "getting it right" test. https://t.co/40R8Dqs5V0
796780324608847900,Thu Nov 10 18:23:27 +0000 2016,RT @dustinvtran: Variational Lossy Autoencoder by Xi Chen and others at OpenAI. interesting interpretation from information theory https://‚Ä¶
795826131899326500,Tue Nov 08 03:11:50 +0000 2016,@lindsey @awesomeintheory Also https://t.co/j4Q3KWCxtd has some results on transferability
795826003088011300,Tue Nov 08 03:11:19 +0000 2016,@lindsey @awesomeintheory Also https://t.co/tNQMohswXo
795825484697210900,Tue Nov 08 03:09:15 +0000 2016,@strife076 Thanks, will check in
795650374967312400,Mon Nov 07 15:33:26 +0000 2016,RNNs that can make an animated character dance to music and can sing karaoke from a script: https://t.co/d3mMy4NajR
795640948617162800,Mon Nov 07 14:55:59 +0000 2016,@abhi9u DNS problem. It's fixed now
795306478731030500,Sun Nov 06 16:46:55 +0000 2016,Otto and Budweiser: First Shipment by Self-Driving Truck https://t.co/LvogaRFl6R
795083393650159600,Sun Nov 06 02:00:27 +0000 2016,RT @egrefen: Top 10 words in @iclr2017 sub titles: learning neural network(s) deep model(s) representation(s) recurrent generative adversar‚Ä¶
794933560926826500,Sat Nov 05 16:05:04 +0000 2016,@johnplattml The weight vector for class i is a "universal adversarial perturbation" for an n-class linear classifier. Error rate ~ (n-1)/n
794933234995839000,Sat Nov 05 16:03:47 +0000 2016,@johnplattml We knew this in 2014. "... adversarial perturbations generalize across different clean examples." https://t.co/7BA6LxZwQH
794658032156184600,Fri Nov 04 21:50:13 +0000 2016,RT @goodfellow_ian: @dwf and I contributed a chapter about GANs and adversarial training to this textbook, available for preorder now: http‚Ä¶
794594420007940100,Fri Nov 04 17:37:27 +0000 2016,@dwf and I contributed a chapter about GANs and adversarial training to this textbook, available for preorder now: https://t.co/ZwhP8TzC8p
794249498453278700,Thu Nov 03 18:46:51 +0000 2016,GeekPwn is the only conference where I've had the opportunity to pose for photos with a quarterstaff https://t.co/hQt3IYpcng
794019203594321900,Thu Nov 03 03:31:44 +0000 2016,Interview with @ylecun . Description of GANs starting around 8:00. https://t.co/VDuJlJJsFF
793994922281947100,Thu Nov 03 01:55:15 +0000 2016,@fchollet I don't see the problem: If p(y= 1 | x = 0) = 1, p(y = 1 | x = 1) = .7, and p(x = 1) = 1/3, then p(y=1) = .9 and p(y=1|x=1) = .7
793992716266786800,Thu Nov 03 01:46:29 +0000 2016,@fchollet @HerbieLewis @538politics Entropy over y can increase if you observe a low probability x that has high entropy of p(y|x)
793470656176193500,Tue Nov 01 15:12:01 +0000 2016,Awesome speaker souvenirs from Bob Sturm's HORSE 2016 https://t.co/X6exA7TFeR
790965566731235300,Tue Oct 25 17:17:41 +0000 2016,If want to do ML for biofeedback or emotion recognition, check out my friend's new very accurate heart rate sensor: https://t.co/uyuLgywzHw
790648862071361500,Mon Oct 24 20:19:12 +0000 2016,@deanpomerleau One of my favorite creepy images from minibatch-GAN on ImageNet https://t.co/R4enPmh2M6
790647259134177300,Mon Oct 24 20:12:50 +0000 2016,@deanpomerleau OK, I agree those are not so good.
790642913130614800,Mon Oct 24 19:55:34 +0000 2016,@deanpomerleau Those images are showing how learning progresses early in training (1st epoch and 5th epoch). They are not finished results
790636729082351600,Mon Oct 24 19:31:00 +0000 2016,@deanpomerleau Neural Face (DCGANs) seems reasonably non-ghoulish: https://t.co/0yAvDRWB49
790635576164692000,Mon Oct 24 19:26:25 +0000 2016,@doomie I found out NIPS offers mentors and practice talks too.
790630023749259300,Mon Oct 24 19:04:21 +0000 2016,Quartz article on the teacher-student approach to differential privacy: https://t.co/JsWXaPdLlw
790610307081134100,Mon Oct 24 17:46:00 +0000 2016,Making scary faces for Halloween with GANs: https://t.co/AqQQqSbiVm https://t.co/4kYBl9Erhz
790599336199458800,Mon Oct 24 17:02:25 +0000 2016,RT @martin_wicke: We finally have a real official TensorFlow Twitter: @tensorflow
790599267178061800,Mon Oct 24 17:02:08 +0000 2016,@doomie Do you mean that NIPS would improve, or do you mean that some of the rhyme / chiasmus suggestions don't seem appropriate for NIPS?
790593971856650200,Mon Oct 24 16:41:06 +0000 2016,@hardmaru Agreed. Also, it's more than just pointers. Enigma provides / requires practice sessions with feedback from the program committee
790586146283659300,Mon Oct 24 16:10:00 +0000 2016,I'm excited that Enigma places so much emphasis on crafting a great presentation: https://t.co/UlFAXSqOoL
790400751856029700,Mon Oct 24 03:53:18 +0000 2016,@karoly_zsolnai thanks for covering GANs!
790330213963923500,Sun Oct 23 23:13:01 +0000 2016,Chang Liu at GeekPwn: an adversarial example for a 5 model ensemble is almost never classified correctly by a 6th m‚Ä¶ https://t.co/cK93vEQB3o
790323968687222800,Sun Oct 23 22:48:12 +0000 2016,GeekPwn has the best souvenirs for speakers https://t.co/JmMJ3R57ky
790045106128642000,Sun Oct 23 04:20:06 +0000 2016,Two Minute Papers - Image Editing with Generative Adversarial Networks https://t.co/RLvIVhT7s5
790022556640084000,Sun Oct 23 02:50:30 +0000 2016,@orion_yin @fchollet @NandoDF Feedback alignment
789174006104502300,Thu Oct 20 18:38:39 +0000 2016,How to interpret t-SNE visualizations: https://t.co/yha1Ut41FJ
788877911700877300,Wed Oct 19 23:02:05 +0000 2016,My co-authors and I have developed an effective and general deep learning algorithm that has privacy guarantees https://t.co/PRGnQHexUu
788828260129910800,Wed Oct 19 19:44:47 +0000 2016,Scott Reed et al show how to use GANs to generate images with control over the size, shape and position of objects‚Ä¶ https://t.co/s9kMc47QZn
788817886621999100,Wed Oct 19 19:03:34 +0000 2016,RT @ylecun: TensoFlow implementation of our Energy-Based GAN model.  Paper here: https://t.co/fYRMGA6BbV With Jake... https://t.co/5xWnOXDu‚Ä¶
788463468278001700,Tue Oct 18 19:35:14 +0000 2016,RT @fchollet: Introducing the Artificial Intelligence Open Network: a 100% open-source AI research community. https://t.co/i6G27YUgsF
788145398661603300,Mon Oct 17 22:31:20 +0000 2016,I like the "Author Contributions" section of Distill articles. Like credits in movies. Academic papers need this. https://t.co/lZeWmaoM8o
788127504288456700,Mon Oct 17 21:20:14 +0000 2016,@edersantana [year, month, date]
788127232812130300,Mon Oct 17 21:19:09 +0000 2016,More super-resolution with GANs: https://t.co/xpMqqMOaBf
788059821341683700,Mon Oct 17 16:51:17 +0000 2016,RT @deborahhanus: How to fix checkerboard artifacts in images made by #NeuralNets. Nice post @ch402! https://t.co/k5rLzbe3da #MachineLearni‚Ä¶
787821023521411100,Mon Oct 17 01:02:23 +0000 2016,RT @drfeifei: Agree w @POTUS there should be more "public discussions" about #AI &amp; issues like jobs, diversity in the changing era https://‚Ä¶
787798967333421000,Sun Oct 16 23:34:45 +0000 2016,RT @NandoDF: Important question: What is the best way for me or others to improve access to AI and CS for women, the poor, and all races? H‚Ä¶
787730670776836100,Sun Oct 16 19:03:21 +0000 2016,RT @vkrakovna: Some impressions from the OpenAI unconference last weekend and a summary of the AI safety discussion session.... https://t.c‚Ä¶
787657401621020700,Sun Oct 16 14:12:13 +0000 2016,RT @ToniCreswell: Landed in Amsterdam for #eccv2016 ... #visART presentation on Sunday : Adversarial ... https://t.co/KvKW4Xie3J
787006423142047700,Fri Oct 14 19:05:27 +0000 2016,@00pii @mashable Yes, and for a Director of Engineering role? Of course the bar should be high
786998882924232700,Fri Oct 14 18:35:30 +0000 2016,Max Welling on how AI will affect your future: https://t.co/wt2QRmQzKs
786724868452515800,Fri Oct 14 00:26:39 +0000 2016,RT @ashevat: Love this! #Bots #swag #AI @ChatbotConf https://t.co/UDCG7DzjNn
786592076204879900,Thu Oct 13 15:38:59 +0000 2016,Report from #socml16: https://t.co/ZQosB1YeaT
786332358580449300,Wed Oct 12 22:26:58 +0000 2016,https://t.co/4pS7td7WnZ
786244053906001900,Wed Oct 12 16:36:04 +0000 2016,Glad to see that the White House report on preparing for the future of AI explains adversarial examples: https://t.co/z6oMcHX3dl
786008538929692700,Wed Oct 12 01:00:13 +0000 2016,Nicolas Papernot will give talks on adversarial examples at Berkeley at 11.30am Oct 12 and at the Stanford security seminar at 4.15pm Oct 13
785906417886638100,Tue Oct 11 18:14:26 +0000 2016,Healthcare + AI event at NVIDIA tomorrow. Registration still open: https://t.co/x4iGJkG4ig
785565659996364800,Mon Oct 10 19:40:23 +0000 2016,@jackccrawford "Who won the Nobel Prize for physics in 1927?" -&gt; "I think the fans were the big winners, don't you?‚Ä¶ https://t.co/7ZkT2eExuA
785560345595097100,Mon Oct 10 19:19:16 +0000 2016,@jackccrawford Is this the best link to the bot itself? Where should we send feedback? https://t.co/1gGGgBZb8N
785526784611586000,Mon Oct 10 17:05:54 +0000 2016,https://t.co/NAEx9coTpG
785524873607032800,Mon Oct 10 16:58:18 +0000 2016,@moustaki @OpenAI Thank you for participating! It was great to see you
785173276368568300,Sun Oct 09 17:41:11 +0000 2016,Joshua Achiam will present Ch 12 of the Deep Learning book at the SF study group tomorrow (livestreamed) at 6:30PM: https://t.co/SnUwPLE7C8
785116418475864000,Sun Oct 09 13:55:15 +0000 2016,@negar_rz Thank you for participating! And thanks for helping out at the registration desk!
785016890133352400,Sun Oct 09 07:19:46 +0000 2016,RT @vkrakovna: Lively discussion in the AI safety session at the @OpenAI unconference #socml16 (thanks @_beenkim for the photo!) https://t.‚Ä¶
784959043995439100,Sun Oct 09 03:29:54 +0000 2016,@deborahhanus @OpenAI thanks for participating! We were all so excited to have you here!
784784231713022000,Sat Oct 08 15:55:16 +0000 2016,NIPS workshop on interpretable ML for complex systems: https://t.co/eS6x0U1uMg Submission deadline in two weeks
784395553308155900,Fri Oct 07 14:10:47 +0000 2016,@jigarkdoshi some other people have planned an unofficial after party. There's a link to it on the #socml16 wiki
784203206762963000,Fri Oct 07 01:26:28 +0000 2016,@hugo_larochelle yes, there will be one room that is live streamed
784193425377820700,Fri Oct 07 00:47:36 +0000 2016,@daniel_bilar Thanks!
784192746554728400,Fri Oct 07 00:44:55 +0000 2016,Excited and a little nervous to see how this experiment turns out. #socml16 tomorrow
783704313612730400,Wed Oct 05 16:24:03 +0000 2016,@weballergy @daviottenheimer @fchollet avoiding redundancy is just one factor to take into account. Ten years ago, it was negligible for DL.
783702079835562000,Wed Oct 05 16:15:10 +0000 2016,@daviottenheimer @weballergy @fchollet I don't think we'll achieve those things via n people all trying the most obvious potential solution
783700955753648100,Wed Oct 05 16:10:42 +0000 2016,@daviottenheimer @weballergy @fchollet if everyone makes their bets based on what they personally can do best, the world avoids redundancy
783700000471527400,Wed Oct 05 16:06:55 +0000 2016,@daviottenheimer @weballergy @fchollet the world benefits when smart people try to discover non-obvious advances. I think it works
783696375661731800,Wed Oct 05 15:52:30 +0000 2016,@weballergy @fchollet @daviottenheimer You use the Kelly criterion. Place your bets based on where you personally have an edge.
783668331169448000,Wed Oct 05 14:01:04 +0000 2016,@brandondamos thanks, Nicolas has fixed it. The update will take about 12 hours to go live on arxiv.
783667464802476000,Wed Oct 05 13:57:38 +0000 2016,@daviottenheimer @fchollet research has changed from optimization to game theory. You need to anticipate/avoid other researchers' ideas.
783666081646858200,Wed Oct 05 13:52:08 +0000 2016,RT @fchollet: The pace at which AI is moving these days is incredible. It's stressful to do research, because of the constant fear of getti‚Ä¶
782967505518104600,Mon Oct 03 15:36:14 +0000 2016,@yoh_okuno there are several https://t.co/KMIQzqIrWX groups for deep learning but I don't know of one for the book. You could start one
782761698427973600,Mon Oct 03 01:58:26 +0000 2016,@evan_cofer  if you read my answer to the quora question it's clear I don't think they are a failure in general
781865338522570800,Fri Sep 30 14:36:37 +0000 2016,@innerproduct @xamat Autoencoders are not a failure in general, but they failed to solve deep supervised learning.
781604480794132500,Thu Sep 29 21:20:04 +0000 2016,The Information was one of the first news sources to start asking me about deep learning. Should be an interesting‚Ä¶ https://t.co/35Kki3N189
781537959644323800,Thu Sep 29 16:55:44 +0000 2016,RT @prisharma25: Interview with @goodfellow_ian, Research Scientist at OpenAI ‚Äì TechSights ‚Äì Medium https://t.co/2vECSEfUjF #AI https://t.c‚Ä¶
781184486356586500,Wed Sep 28 17:31:09 +0000 2016,https://t.co/cTY8TGNDPz
780805674548596700,Tue Sep 27 16:25:54 +0000 2016,https://t.co/Bz2XvKcS4Q
780405000157614100,Mon Sep 26 13:53:45 +0000 2016,Chapter 11 of the Deep Learning textbook 6:30PM tonight in SF. Attend in person or sign up for the livestream: https://t.co/nejkREjiqQ
779809932094734300,Sat Sep 24 22:29:10 +0000 2016,@daviottenheimer @tdaxp @Aelkus @peterwsinger @thegrugq Just one slide announcing it in this presentation: https://t.co/2vUC7Ep7rD
779004091452325900,Thu Sep 22 17:07:03 +0000 2016,@daniel_bilar Yes, I believe that was Nicolas' first paper on adversarial examples. Nicolas and I work together a lot now.
779002890748911600,Thu Sep 22 17:02:16 +0000 2016,@daniel_bilar Yes, or you can write your own attack in tensorflow format and the defense algorithm will automatically train with your attack
778999562480586800,Thu Sep 22 16:49:03 +0000 2016,Try out our new cleverhans library for testing machine learning systems' vulnerability to adversarial examples: https://t.co/OxIR262RsH
778499244239888400,Wed Sep 21 07:40:58 +0000 2016,The code for iGAN (GAN-assisted art) is now available: https://t.co/bJCj1hElNy
776846543403950100,Fri Sep 16 18:13:43 +0000 2016,Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network: https://t.co/DvZTbDMUlx
776806243209875500,Fri Sep 16 15:33:35 +0000 2016,Check whether you have copy-pasted this into your own codebase. https://t.co/rArBklXKsT
776552751186620400,Thu Sep 15 22:46:18 +0000 2016,@multihyphenate @OpenAI travel grants for the self-organizing conference have been announced. (have i understood the question correctly?)
776545271211630600,Thu Sep 15 22:16:34 +0000 2016,On Monday I'll speak via Skype at HORSE 2016 about adversarial examples: https://t.co/hlqm0dhn4I
776122003174494200,Wed Sep 14 18:14:39 +0000 2016,@goodfellow_ian It's also in collaboration with Adobe
776114481692684300,Wed Sep 14 17:44:46 +0000 2016,Amazing computer assisted art demo from Berkeley. Draw a triangle, a GAN turns it into a photo-realistic mountain. https://t.co/fRG8eCUcNK
