id,created_at,text
1254020709891924000,Sat Apr 25 12:13:30 +0000 2020,RT @vansteenkiste_s: We have extended the submission deadline of our virtual  @icmlconf 2020 workshop on Object-Oriented Learning since pre…
1249650356889550800,Mon Apr 13 10:47:17 +0000 2020,o uczeniu nienadzorowanym, autoenkoderach i mojej pracy: https://t.co/5fQuJl39Im
1247974008760537000,Wed Apr 08 19:46:04 +0000 2020,FB has just changed its layout to be Twitter-like, and Twitter is down. Is Facebook trying to becoming the new Twit… https://t.co/8pfKdQevEB
1247810408586662000,Wed Apr 08 08:55:59 +0000 2020,RT @skaasj: So excited to announce ICML Workshop on Object-Oriented Learning: Perception, Representation, and Reasoning that I'm co-organiz…
1247494175291060200,Tue Apr 07 11:59:23 +0000 2020,I'm delighted to announce the call for papers for an ICML workshop on object-oriented learning I'm co-organizing wi… https://t.co/Ddau5mnDbm
1240299045022847000,Wed Mar 18 15:28:30 +0000 2020,@AjdDavison Thanks @AjdDavison, I'll rely your feedback to the devs
1240285665784467500,Wed Mar 18 14:35:20 +0000 2020,Live map with confirmed covid19 cases in the UK: https://t.co/9wYD2BtMJJ
1236655169397547000,Sun Mar 08 14:09:02 +0000 2020,Thanks, @yeewhye! and thank you and @IngmarPosner for being such great supervisors over the past three years. It wa… https://t.co/OiVr1Oe52G
1235942222664806400,Fri Mar 06 14:56:03 +0000 2020,Just passed my thesis defence with Andrew Zisserman and @wellingmax, photo by @yeewhye :) https://t.co/WToSni4IlG
1227199944471306200,Tue Feb 11 11:57:21 +0000 2020,@YugeTen Oh, it's my old office! We really missed Stefan when he went to MTV for his Brain internship and decided t… https://t.co/Cgor9ybUv9
1225792807568380000,Fri Feb 07 14:45:54 +0000 2020,RT @DeepSpiker: Building flows on non-Euclidean manifolds is quite tricky. So I'm happy to share our work, "Normalizing Flows on Tori and S…
1224695671770448000,Tue Feb 04 14:06:16 +0000 2020,RT @martinengelcke: #ICLR2020 camera-ready version of GENESIS is now online:  https://t.co/my5uk5HLU7 https://t.co/nV5WmVshOk  We would lik…
1222858995850981400,Thu Jan 30 12:27:58 +0000 2020,RT @RaiaHadsell: We are planning to hold #WiML events, big and small, for #ICLR2020 in Ethiopia, #ICML2020 in Austria, #CoRL2020 in Boston,…
1217419066606071800,Wed Jan 15 12:11:38 +0000 2020,Congrats to @tom_rainforth! I've learned a lot from this guy and would totally recommend working with him for all t… https://t.co/qHxLvE68su
1216355163549655000,Sun Jan 12 13:44:04 +0000 2020,RT @fhuszar: In prior work (Doe et al, 2019) has considered the problem of parrot walking, however, the proposed method had severe limitati…
1214854515553378300,Wed Jan 08 10:21:02 +0000 2020,@thomaskipf Congrats Thomas!
1214839526683754500,Wed Jan 08 09:21:28 +0000 2020,I'm excited to announce that I've just joined DeepMind in London as a Research Scientist in @DeepSpiker's team. I'm… https://t.co/iQxpSkhYWa
1214179589012017200,Mon Jan 06 13:39:07 +0000 2020,@qbeer666 I'd encourage you to apply to as good schools as possible, but also to apply to somewhat-weaker ones, and… https://t.co/B4KJExnYJC
1212073639618732000,Tue Dec 31 18:10:49 +0000 2019,@wgrathwohl That's a very good point. I got my start at an internship at a Samsung R&amp;D Lab in Poland during my undergrad.
1212066847580921900,Tue Dec 31 17:43:50 +0000 2019,@HanchungLee @nevesetal We should reeducate the recruiters, then.
1212000968453349400,Tue Dec 31 13:22:03 +0000 2019,@zacharylipton @nevesetal I agree with you @zacharylipton. There is also a large proportion of PhD students, even s… https://t.co/nOG6DPYMD1
1211979373580112000,Tue Dec 31 11:56:14 +0000 2019,@nevesetal That's what I mean -- If you can publish as a standalone researcher, why bother with a PhD? At this poin… https://t.co/5FUi1zuPvU
1211934015999099000,Tue Dec 31 08:56:00 +0000 2019,@tonyduan_ Technically it's true, but in practice, everyone in ML gets funded by the school.
1211746896609497000,Mon Dec 30 20:32:27 +0000 2019,@YugeTen Whether it is better or not depends on the goal. You could even spend several years doing research and lea… https://t.co/4mP1HytS3V
1211640990890692600,Mon Dec 30 13:31:38 +0000 2019,@markovxmachina Hard to say, and it probably depends on departments. ML here exists in Maths, Engineering Science,… https://t.co/RY7qFWLewQ
1211640435426365400,Mon Dec 30 13:29:25 +0000 2019,@mvaldenegro The majority of PhD students in the UK I know have a Masters, myself included. I feel that Masters in… https://t.co/1xdQJDHoxl
1211626562757509000,Mon Dec 30 12:34:18 +0000 2019,Now, I'm about to graduate after about three years at Oxford, and I can keep doing whatever research I like, and wh… https://t.co/ZQGGBZlOWo
1211626430662160400,Mon Dec 30 12:33:46 +0000 2019,Is it really this much worse to get a PhD at a slightly worse school, and to prove your worth with your research wo… https://t.co/GjQxy78v7J
1211626312684724200,Mon Dec 30 12:33:18 +0000 2019,Sure, these schools are prestigious, but, as US institutions, they often require 4-6 years to finish the PhD. You a… https://t.co/0STn5a3LpH
1211626211807547400,Mon Dec 30 12:32:54 +0000 2019,Getting a PhD is only the first stage of a scientific career, and its purpose is to learn how to do research. If yo… https://t.co/StAu3EeuMx
1211626126134718500,Mon Dec 30 12:32:34 +0000 2019,Apparently, you need 1-2 publications at top-tier ML conferences to get into a top school for a PhD:… https://t.co/3mtSuoNUU0
1210946766490738700,Sat Dec 28 15:33:02 +0000 2019,Is @ETH_en worth it over @TU_Muenchen for an undergrad in CS? Asking for my little bro :)
1208445364048662500,Sat Dec 21 17:53:21 +0000 2019,GENESIS just got accepted to #ICLR2020. Great job @martinengelcke and the team; see you all in Ethiopia! :) https://t.co/pQNhyNrx4l
1207292005241503700,Wed Dec 18 13:30:19 +0000 2019,@hyunjik11 @Cyanogenoid Good find, thanks @hyunjik11!
1206992177810825200,Tue Dec 17 17:38:54 +0000 2019,what's the difference between density estimation and generative modelling?
1206958725426294800,Tue Dec 17 15:25:59 +0000 2019,@skaasj @gdm3000 this is very nice :)
1206905923219923000,Tue Dec 17 11:56:09 +0000 2019,@RobertoParPal clustering and prediction are quite different...
1206905564246290400,Tue Dec 17 11:54:44 +0000 2019,by @Cyanogenoid and @jon_hare
1206905135621968000,Tue Dec 17 11:53:02 +0000 2019,@RobertoParPal I guess the authors are vision-oriented, but the same principle can be used to predict any set, e.g.… https://t.co/we8aaEkbZj
1206904680405721000,Tue Dec 17 11:51:13 +0000 2019,The idea is that you can predict a set from any  conditioning by: 1. Encoding the conditioning. 2. Encoding a rando… https://t.co/GMIW7H9IHi
1206904594489630700,Tue Dec 17 11:50:53 +0000 2019,@danijarh The idea is that you can predict a set from any  conditioning by: 1. Encoding the conditioning. 2. Encodi… https://t.co/SLZxh9YluD
1206903650020409300,Tue Dec 17 11:47:08 +0000 2019,@Marek_Bardonski I've no idea about fairness, causal inference, RL and meta-learning, nor am I very interested in t… https://t.co/biQfryuScr
1206638942994481200,Mon Dec 16 18:15:16 +0000 2019,A nice summary of #NeurIPS2019: https://t.co/yiUNh4xroq. Interestingly,  it's almost completely orthogonal to my experience...
1206611036243140600,Mon Dec 16 16:24:23 +0000 2019,@techreview coin-flip please
1206610253158240300,Mon Dec 16 16:21:16 +0000 2019,This paper had the biggest subjective "wow" factor for me at #NeurIPS2019: "Deep Set Prediction Networks" by Yan Zh… https://t.co/9brIEGNKQC
1205675489093767200,Sat Dec 14 02:26:51 +0000 2019,RT @FabianFuchsML: Come to our poster tomorrow (Saturday) on relational reasoning in multi-object tracking! ✌️  9:45 - 10:30, Sets &amp; Partit…
1205550524818280400,Fri Dec 13 18:10:17 +0000 2019,@erikdax good point, now it should work
1203070561599082500,Fri Dec 06 21:55:48 +0000 2019,Going to #NeurIPS2019 ? Come see us on Thursday in the East Exhibition Hall B+C at 5pm, where we're presenting Stac… https://t.co/IxK7neTY1l
1202974270168731600,Fri Dec 06 15:33:10 +0000 2019,Ever wondered how to do meta-learning directly in function space? Here's a treat from @jinxu06 with soma SOTA resul… https://t.co/LrTLvHIoII
1202973859567276000,Fri Dec 06 15:31:32 +0000 2019,The most comprehensive overview of normalizing flows to date! https://t.co/puSpx0z20m
1202631562136817700,Thu Dec 05 16:51:22 +0000 2019,Let me know if you want to meet up at #NeurIPS2019 via either pm or adamk at https://t.co/eMpzX90RRc
1201989155162644500,Tue Dec 03 22:18:41 +0000 2019,@counterattack9 @sabour_sara @yeewhye @geoffreyhinton I think it is fair to say, yes. Shapes can be made of high-di… https://t.co/fmX1a2G4dz
1201980821139275800,Tue Dec 03 21:45:34 +0000 2019,@counterattack9 @sabour_sara @yeewhye @geoffreyhinton this figure is not in the paper (yet)
1201980752822444000,Tue Dec 03 21:45:17 +0000 2019,@counterattack9 @sabour_sara @yeewhye @geoffreyhinton We have an experiment in the paper for constellations of 2d p… https://t.co/faDb3VFf4j
1201970350013264000,Tue Dec 03 21:03:57 +0000 2019,We've just updated our paper on Stacked Capsule Autoencoders -- an unsupervised model that achieves SOTA classifica… https://t.co/UAQzEgA66k
1200064796651073500,Thu Nov 28 14:51:58 +0000 2019,very cool paper :) https://t.co/7xbAAHBf7n
1199680295739543600,Wed Nov 27 13:24:06 +0000 2019,@FedPernici @y0b1byte @SchmidhuberAI thanks!
1199320720855179300,Tue Nov 26 13:35:16 +0000 2019,@random_walker I learned something here. I wonder how many people suffer from the "difficult name" problem?
1199268425488572400,Tue Nov 26 10:07:28 +0000 2019,Dear Twitterverse, what's the earliest reference to Siamese networks you know of?
1196777197358461000,Tue Nov 19 13:08:13 +0000 2019,That's cool. More competition in the accelerator market would benefit everyone. https://t.co/JmpMMCLXbg
1194984711824785400,Thu Nov 14 14:25:31 +0000 2019,@deepgradient @sabour_sara @yeewhye @geoffreyhinton nope
1194900431006244900,Thu Nov 14 08:50:37 +0000 2019,RT @rvcraiu: Found on the web https://t.co/G4R7XkcVjr
1194899799998423000,Thu Nov 14 08:48:07 +0000 2019,@deepgradient @sabour_sara @yeewhye @geoffreyhinton Because most of the code was written before the official release of tf2.0
1194765816023199700,Wed Nov 13 23:55:42 +0000 2019,We've just open-sourced the code for Stacked Capsule Autoencoders (NeurIPS '19): https://t.co/tP5FSq6dqC  joint wor… https://t.co/15bQwXdxVK
1194760190475849700,Wed Nov 13 23:33:21 +0000 2019,@jwvdm I thought that proofreading was obvious, but maybe not. Thanks, that's a good point, I'll suggest it.
1194747635862777900,Wed Nov 13 22:43:28 +0000 2019,@jwvdm I think it'd be great if people hired professional editors to improve their papers. In this particular case,… https://t.co/mHgXeNoPz4
1194742617403199500,Wed Nov 13 22:23:31 +0000 2019,lol in author response to one of my ICLR reviews: "We will carefully revise our manuscript and hire professional co… https://t.co/3xzrp2MH3p
1193104817985593300,Sat Nov 09 09:55:30 +0000 2019,I can't recommend this place enough! https://t.co/n0R0t3Fk5C
1190593961976615000,Sat Nov 02 11:38:15 +0000 2019,RT @StatMLIO: PhD applications are now open for the EPSRC CDT in Modern Statistics and Statistical Machine Learning at Imperial and Oxford…
1189557278283829200,Wed Oct 30 14:58:50 +0000 2019,@MaxiIgl @emidup Ha ha, we actually do have someone like that:  @SchmidhuberAI does it all the time! So hypocritical of him...
1189556899693367300,Wed Oct 30 14:57:20 +0000 2019,@lorenlugosch @emidup indeed
1189225502692782000,Tue Oct 29 17:00:29 +0000 2019,RT @martinengelcke: @arkosiorek @oiwi3000 @IngmarPosner @a2i_oxford @oxfordrobots @PyTorch The repository also includes a re-implementation…
1189225479242440700,Tue Oct 29 17:00:23 +0000 2019,RT @martinengelcke: Our new work on GENESIS introduces an object-centric, generative latent-variable model that performs both unsupervised…
1188788665453105200,Mon Oct 28 12:04:39 +0000 2019,@tmramalho What is it, then? Or how does it differ from P(x|c)?
1187748615302930400,Fri Oct 25 15:11:51 +0000 2019,@MatthiasSBauer I use these for running but I tend to tear them whenever I take them for proper hikes, same with Bare Access
1187356515499421700,Thu Oct 24 13:13:47 +0000 2019,@BayesianBrad ideally zero-drop and relatively light
1187329404537622500,Thu Oct 24 11:26:04 +0000 2019,can anyone recommend minimalist hiking shoes?
1180496991782150100,Sat Oct 05 14:56:30 +0000 2019,@deepgradient https://t.co/tBD8ag0dCF
1180045125138993200,Fri Oct 04 09:00:56 +0000 2019,@deepgradient embedding produced by a capsule network ; )
1180034979750920200,Fri Oct 04 08:20:37 +0000 2019,tsne of capsule embeddings on mnist ;)
1179756380774903800,Thu Oct 03 13:53:34 +0000 2019,https://t.co/VGPvR85EL4
1179369198260293600,Wed Oct 02 12:15:03 +0000 2019,@ShuyuLin_n The architect has an interesting taste...
1179058722926157800,Tue Oct 01 15:41:20 +0000 2019,RT @martinengelcke: @arkosiorek @oiwi3000 @IngmarPosner @a2i_oxford @oxfordrobots We updated the GENESIS paper on arXiv, featuring more ext…
1169904364753809400,Fri Sep 06 09:25:10 +0000 2019,The same thing happened for a paper I reviewed (not this one, different scores), some ACs are truly amazing! https://t.co/FpMic5vnEp
1166680970797428700,Wed Aug 28 11:56:33 +0000 2019,I get that the new name is NeurIPS, but I still think that we should refer to pre-2018 instances as NIPS. Why do pe… https://t.co/Xelx9LzB1W
1161936809049428000,Thu Aug 15 09:44:57 +0000 2019,We should all do tf.reduce_variance on our gradient estimators :D https://t.co/imEXnAQuan
1161929719220187100,Thu Aug 15 09:16:47 +0000 2019,Dear recruiters,  If you cannot disclose the name of the company you represent, please do not bother reaching out.  Yours sincerely,
1159725287782924300,Fri Aug 09 07:17:09 +0000 2019,Yay! SPIRAL is open-source :) https://t.co/JpjgfQGp9N
1158727162414977000,Tue Aug 06 13:10:58 +0000 2019,@andrewgwils @ArthurGretton What is the accuracy of a GP trained for a few minutes on Cifar100 (compared to WRN)?
1158696167720521700,Tue Aug 06 11:07:48 +0000 2019,Looks like an amazing tool :) https://t.co/OIofm4xCST
1157306949421150200,Fri Aug 02 15:07:33 +0000 2019,@AlieeHana @sabour_sara @yeewhye @geoffreyhinton Nope
1157020110932123600,Thu Aug 01 20:07:45 +0000 2019,I've been contacted by a recruiter directly through FB. I find it somewhat creepy, but maybe it's just me? What do… https://t.co/CeBKMQ4Tya
1156595533852676000,Wed Jul 31 16:00:38 +0000 2019,RT @hardmaru: NeurIPS deadline is coming https://t.co/0pbH6Fp3Sa
1156479881909362700,Wed Jul 31 08:21:04 +0000 2019,GENESIS is the first fully probabilistic model for unsupervised image segmentation with amortized inference, develo… https://t.co/06dN3hVXoR
1156479174808395800,Wed Jul 31 08:18:16 +0000 2019,We developed MOHART-an RNN with attention mechanisms for multi-object tracking, where several trackers communicate… https://t.co/AjptkipfYG
1154455070349627400,Thu Jul 25 18:15:12 +0000 2019,@gdbassett @sineadwilliamso This actually exists: https://t.co/PuK7cUWFu5
1154322960565657600,Thu Jul 25 09:30:14 +0000 2019,Come visit our poster at #UAI. Thanks @tuananhle7 for presenting! https://t.co/x8H7mbpNRA
1154280329231966200,Thu Jul 25 06:40:50 +0000 2019,Is it just me or is the left control panel really ugly? It seems too big and intrusive. #TwitterLayout… https://t.co/qGI1YCKzlt
1153645869960454100,Tue Jul 23 12:39:43 +0000 2019,@dileeplearning @geoffreyhinton @theAlexLavin Interesting indeed. I'll need to read up on this :)
1153645609011822600,Tue Jul 23 12:38:41 +0000 2019,I didn't know that @yeewhye writes blogs! Check this out: https://t.co/GeQVwnWC7T https://t.co/R7MUTDeiem
1153415872364593200,Mon Jul 22 21:25:48 +0000 2019,@Ella_Maru @sabour_sara @yeewhye @geoffreyhinton Good question. That's why inference is hard. In this version, we l… https://t.co/ekygvQTjAN
1153405325606867000,Mon Jul 22 20:43:53 +0000 2019,@ikdeepl @sabour_sara @yeewhye @geoffreyhinton Thanks @ikdeepl. I think that if you use the Zhang 2019 trick and ma… https://t.co/g9SSkLGKaz
1153380330138669000,Mon Jul 22 19:04:34 +0000 2019,It might take a few months due to IP issues. https://t.co/10uhuPcG6i
1153325419439038500,Mon Jul 22 15:26:22 +0000 2019,We recently developed a new, unsupervised version of capsule networks (with @sabour_sara, @yeewhye,  and… https://t.co/qrQlZ5a1bJ
1153290174102724600,Mon Jul 22 13:06:19 +0000 2019,Yet another intro to normalizing flows :) https://t.co/EuTkJrEQI1
1151510699971096600,Wed Jul 17 15:15:19 +0000 2019,made my day :D https://t.co/hxc5GC2ZPf
1151477256390369300,Wed Jul 17 13:02:25 +0000 2019,@frankdonaldwood @Mvandepanne That's impressive @frankdonaldwood, keep it up :)
1149051832418930700,Wed Jul 10 20:24:39 +0000 2019,@KareemYousrii that's a good idea... maybe :)
1149025734423392300,Wed Jul 10 18:40:57 +0000 2019,@Ektor75716525 It does work for me, so I would recommend getting a copy it. It's only worth it if you implement it… https://t.co/gHfljpydaX
1148965826265079800,Wed Jul 10 14:42:54 +0000 2019,I couldn't agree more. Ever since I started implementing Deep Work rules (https://t.co/lVqxNNfeNf) I work less, am… https://t.co/kUszCBOYIK
1146126081193381900,Tue Jul 02 18:38:46 +0000 2019,RT @joost_v_amersf: Do you often use MNIST on a GPU for prototyping?  Do you use @pytorch?  You can get 2-3x *training* speed up and save C…
1141602701689667600,Thu Jun 20 07:04:28 +0000 2019,@dielian8 @sabour_sara @yeewhye @geoffreyhinton I hope so, but I'm not at Brain anymore, so it might take a while.
1141268945590206500,Wed Jun 19 08:58:15 +0000 2019,@ashleygritzman @sabour_sara @yeewhye @geoffreyhinton That's the plan, yes, but it might take a few months.
1140960605551169500,Tue Jun 18 12:33:01 +0000 2019,@GuillermoPuebl6 Thanks for the geons reference, I'll read up on that :)
1140930200894672900,Tue Jun 18 10:32:12 +0000 2019,I'm proud to share our work on a new version of capsule networks, called Stacked Capsule Autoencoders, with… https://t.co/fybfP63NfB
1138146598704123900,Mon Jun 10 18:11:09 +0000 2019,I'm at ICML @icmlconf this week, let me know if you'd like to catch up!
1125800201892110300,Tue May 07 16:30:59 +0000 2019,If anyone is still looking for ML experiment framework: Forge now works with @PyTorch thanks to @martinengelcke  :) https://t.co/fcu8RtcEcn
1123591450174926800,Wed May 01 14:14:11 +0000 2019,a very interesting post about how neural nets are over-parametrized and what it means: https://t.co/BFqZPUa1Vt
1120673476505940000,Tue Apr 23 12:59:12 +0000 2019,Multi-branch neural nets for the win: apparently the more branches there are, the easier the optimization gets. Mor… https://t.co/NJZBTnhxta
1107630726705565700,Mon Mar 18 13:11:58 +0000 2019,It is a common belief that humans learn quickly due to very strong priors and prior experience. I always thought th… https://t.co/IlUJvqscDZ
1098600390138970100,Thu Feb 21 15:08:38 +0000 2019,Well done @xenia_22! https://t.co/KvA55EWmrw
1092853442022948900,Tue Feb 05 18:32:19 +0000 2019,TF-replicator is a delightful tool, I can't recommend it enough! https://t.co/KSedubK8gQ
1091735039409377300,Sat Feb 02 16:28:11 +0000 2019,The first industrial AI residency program in Poland has just been opened. Kudos to the @Tooploox team, I can only r… https://t.co/XvMVW4SdBv
1090322802094366700,Tue Jan 29 18:56:27 +0000 2019,RT @tom_rainforth: Can we extend disentanglement to a more general notion of structure in VAEs? Should we care more about the prior? Why do…
1088915617611165700,Fri Jan 25 21:44:48 +0000 2019,@iam_mahajan While I love the idea, training on 6 GPUs for a week to do well on MNIST is a definite no-go.
1088795942541770800,Fri Jan 25 13:49:16 +0000 2019,@iskorna awesome, thanks @iskorna!
1088739095029993500,Fri Jan 25 10:03:22 +0000 2019,It's a really great place to learn about and explore frontiers of machine learning! https://t.co/85XTrT3zvI
1088445180733055000,Thu Jan 24 14:35:28 +0000 2019,@alexggmatthews @ryan_p_adams @DeepSpiker @shakir_za thanks Alex!
1088416886407286800,Thu Jan 24 12:43:02 +0000 2019,Are there any other invertible neural nets than RealNVP, GLOW or iRevNet? I'm looking for old papers - the older the better. Thanks!
1086313799576100900,Fri Jan 18 17:26:07 +0000 2019,RT @hyunjik11: ‘Attentive Neural Processes’ is live! We learn stochastic processes using deep architectures, and once trained on images, th…
1081897357757894700,Sun Jan 06 12:56:45 +0000 2019,@twiecki Thanks!
1081851556046295000,Sun Jan 06 09:54:45 +0000 2019,Hey Twitter, do you know of any good introductory texts on copulas for modeling correlated binary events?
1072171982018527200,Mon Dec 10 16:51:35 +0000 2018,This is where I learned about machine learning: a really good course by @argmax_ai and @padsmagt: https://t.co/r4wBFrsGg5
1070069929548939300,Tue Dec 04 21:38:46 +0000 2018,Our work at one of NeurIPS workshops :) Congrats @FabianFuchsML! https://t.co/om8QzHFFEB
1068546312344223700,Fri Nov 30 16:44:28 +0000 2018,@oxcsml is on Twitter, so it actually exists! :) https://t.co/maReYrodoJ
1068311065010663400,Fri Nov 30 01:09:40 +0000 2018,RT @lqh20: Happy to share our latest work on neural probabilistic motor primitives - joint work with Josh Merel, @agalashov, @arahuja, Vu P…
1067856347088138200,Wed Nov 28 19:02:47 +0000 2018,How do you handle the complexity of machine learning experiments? Here's how I do it: https://t.co/wyUzfXA1jf
1066044585716080600,Fri Nov 23 19:03:30 +0000 2018,RT @BayesianBrad: Wahoo! https://t.co/3VMub3RDzD
1065293443902124000,Wed Nov 21 17:18:43 +0000 2018,Our NIPS video for Sequential Attend, Infer, Repeat (SQAIR): https://t.co/rRJcsIRtCr
1064898740971020300,Tue Nov 20 15:10:19 +0000 2018,I'm excited to attend PL in ML (https://t.co/ow150GDERY) and give a talk about Sequential Attend, Infer, Repeat (https://t.co/xNO8imFuIi)
1064622826001436700,Mon Nov 19 20:53:56 +0000 2018,@alirahimi0 This just sounds wrong.
1061317032199761900,Sat Nov 10 17:57:53 +0000 2018,RT @yeewhye: Can somebody help advice? I created a new twitter account for an organization, and on asked for the birthday, I entered the bi…
1054839385093488600,Tue Oct 23 20:58:02 +0000 2018,@Gang1man Do you have a link for this explicit-air? I'm curious.
1054675587481157600,Tue Oct 23 10:07:09 +0000 2018,I'm excited to finally release source code for SQAIR (which was accepted as a spotlight at NIPS this year):… https://t.co/ZrpnRvKn8T
1052677312028823600,Wed Oct 17 21:46:43 +0000 2018,RT @arkitus: If you're interested in interning at DeepMind, the deadline for applications is Oct 29th. You need to be in the last two years…
1047900016436826100,Thu Oct 04 17:23:27 +0000 2018,@DavidDuvenaud @wgrathwohl @rtqichen @jessebett @ilyasut 2. In VAE experiments you report only ELBO. The improvemen… https://t.co/OwlDAQzd9u
1047841709634330600,Thu Oct 04 13:31:46 +0000 2018,@DavidDuvenaud @wgrathwohl @rtqichen @jessebett @ilyasut 1 cont'd: this would be closer to FFJORD, which reuses par… https://t.co/KFI1TTs9fP
1047841467572650000,Thu Oct 04 13:30:48 +0000 2018,@DavidDuvenaud @wgrathwohl @rtqichen @jessebett @ilyasut Great work, congrats. I have two concerns about evaluation… https://t.co/kvUoBv0Pv5
1047428917525659600,Wed Oct 03 10:11:28 +0000 2018,Have you ever worked with sets of things? Learning good representations for sets *used to* be challenging, until no… https://t.co/biuPjcJuDl
1047423788290330600,Wed Oct 03 09:51:05 +0000 2018,RT @DeepSpiker: Taming VAEs: A theoretical analysis of their properties and behaviour in the high-capacity regime. We also argue for a diff…
1047423672963813400,Wed Oct 03 09:50:38 +0000 2018,RT @fabiointheuk: In https://t.co/oU7BGWoRW4 @DeepSpiker and I discuss a very effective method to train VAEs using constrained optimisation…
1043423393629040600,Sat Sep 22 08:54:57 +0000 2018,@adam_golinski I think so, but I have yet to confirm with rework.
1043404611846135800,Sat Sep 22 07:40:19 +0000 2018,Slides for my #reworkDL talk on visual attention: https://t.co/BSNtyxE44m
1042770219347988500,Thu Sep 20 13:39:28 +0000 2018,RT @yeewhye: It's great that ML has exploded in recent years both in terms of size and advances. But my feeling is that the growth has crea…
1042769736558362600,Thu Sep 20 13:37:33 +0000 2018,RT @Yssybyl: Impressive results on multiple object tracking using new SQAIR approach @arkosiorek #ReworkDL https://t.co/39w4tYw3fM
1042713092692557800,Thu Sep 20 09:52:28 +0000 2018,I'm about to give at talk at #reworkDL in London https://t.co/gbNpBKCzi2
1041441618082062300,Sun Sep 16 21:40:05 +0000 2018,RT @tom_rainforth: Along with my co-organizers Matt Kusner, Ben Bloem-Reddy, Brooks Paige, Rich Caruana, and @yeewhye, I'm excited to annou…
1041441441078235100,Sun Sep 16 21:39:23 +0000 2018,RT @cjmaddison: Excited to share this paper. We generalize the momentum method for optimization, and in the process find that you can great…
1041373342966710300,Sun Sep 16 17:08:47 +0000 2018,Hierarchical Attentive Recurrent Tracking: https://t.co/L1nOpjRv7o przez @YouTube
1038457610708688900,Sat Sep 08 16:02:42 +0000 2018,RT @yeewhye: We invite you to our workshop on Continual Learning at this year’s @NipsConference. Submission deadline for 4-page abstracts i…
1038457396916625400,Sat Sep 08 16:01:51 +0000 2018,Nicely put. https://t.co/4a50tLtnFQ
1029803764507705300,Wed Aug 15 18:55:24 +0000 2018,RT @kasparmartens: Neural Processes - what they are and how they behave as distributions over functions. This blog post is my attempt to an…
1029803504309870600,Wed Aug 15 18:54:22 +0000 2018,RT @arkitus: Two reasons why vision is hard: 1. 2D images are always only /projections/ of an underlying 3D reality. 2. Sometimes we're int…
1025683462198575100,Sat Aug 04 10:02:48 +0000 2018,Great work! https://t.co/tsC8o2B8g7
1008399091674636300,Sun Jun 17 17:20:53 +0000 2018,So true. https://t.co/LH8XgOHrua
1007696609570902000,Fri Jun 15 18:49:28 +0000 2018,@atroyn I'd go with mathcal.
1007556505623810000,Fri Jun 15 09:32:45 +0000 2018,Interpretability in neural nets is amazingly hard. Here's our stab at it: https://t.co/XJGVAhnKbD https://t.co/On8DoqdIlH
1007554990137925600,Fri Jun 15 09:26:43 +0000 2018,Amazing work from @DeepMindAI. Congrats @arkitus,@DeepSpiker and the team! https://t.co/Yj0dtFZnZt
1004299835716128800,Wed Jun 06 09:51:54 +0000 2018,My newest work with @hyunjik11,@IngmarPosner and @yeewhye: generative modelling, detecting, tracking and prediction… https://t.co/bbmyxwDRIV
1001489023205085200,Tue May 29 15:42:44 +0000 2018,RT @adam_golinski: Still fresh work by @tuananhle7 @arkosiorek @yeewhye @frankdonaldwood https://t.co/Jwh1DFA4DJ
981234230725349400,Tue Apr 03 18:17:25 +0000 2018,One of my favourite ways to learn something new is to describe it in my own terms, summarise, or try to explain it… https://t.co/cTFT76qbwT
975045341073563600,Sat Mar 17 16:24:59 +0000 2018,@DeepSpiker @hardmaru @MannyKayy Perhaps; what I wanted to point out are the trade-offs: people often use IWAE as a… https://t.co/YTZ5rphdOy
975044191238705200,Sat Mar 17 16:20:25 +0000 2018,Nice to see people posting my stuff :) https://t.co/nSmvFaWDNW
975044191238705200,Sat Mar 17 16:20:25 +0000 2018,Nice to see people posting my stuff :) https://t.co/nSmvFaWDNW
